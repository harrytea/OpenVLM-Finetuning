[2025-08-21 12:19:04,518] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-21 12:19:07,936] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-21 12:19:08,080] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-21 12:19:08,103] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-21 12:19:08,171] [INFO] [comm.py:652:init_distributed] cdb=None
[W821 12:19:08.158617282 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:08.158637194 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[2025-08-21 12:19:08,339] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-21 12:19:08,399] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-21 12:19:08,428] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-21 12:19:08,478] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[INFO|2025-08-21 12:19:08] llamafactory.hparams.parser:410 >> Process rank: 4, world size: 8, device: cuda:4, distributed training: True, compute dtype: torch.bfloat16
[2025-08-21 12:19:09,966] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-21 12:19:09,966] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W821 12:19:09.954824818 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:09.954845130 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[2025-08-21 12:19:09,990] [INFO] [comm.py:652:init_distributed] cdb=None
[W821 12:19:09.978386659 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:09.978410822 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[2025-08-21 12:19:10,027] [INFO] [comm.py:652:init_distributed] cdb=None
[W821 12:19:10.014340705 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:10.014355250 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[INFO|2025-08-21 12:19:11] llamafactory.hparams.parser:410 >> Process rank: 0, world size: 8, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,074 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,074 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,074 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,074 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,074 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,074 >> loading file chat_template.jinja
[INFO|2025-08-21 12:19:11] llamafactory.hparams.parser:410 >> Process rank: 1, world size: 8, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-08-21 12:19:11] llamafactory.hparams.parser:410 >> Process rank: 7, world size: 8, device: cuda:7, distributed training: True, compute dtype: torch.bfloat16
[2025-08-21 12:19:11,267] [INFO] [comm.py:652:init_distributed] cdb=None
[W821 12:19:11.253405467 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:11.253427316 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[2025-08-21 12:19:11,535] [INFO] [comm.py:652:init_distributed] cdb=None
[W821 12:19:11.525053644 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:11.525077603 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[INFO|processing_utils.py:822] 2025-08-21 12:19:11,611 >> loading configuration file /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf/processor_config.json
[2025-08-21 12:19:11,612] [INFO] [comm.py:652:init_distributed] cdb=None
[INFO|image_processing_base.py:378] 2025-08-21 12:19:11,612 >> loading configuration file /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-08-21 12:19:11,613 >> Image processor LlavaNextImageProcessorFast {
  "aspect_ratio_setting": "anyres",
  "crop_size": {
    "height": 336,
    "width": 336
  },
  "data_format": "channels_first",
  "default_to_square": false,
  "device": null,
  "do_center_crop": true,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": true,
  "do_rescale": true,
  "do_resize": true,
  "image_grid_pinpoints": [
    [
      336,
      672
    ],
    [
      672,
      336
    ],
    [
      672,
      672
    ],
    [
      1008,
      336
    ],
    [
      336,
      1008
    ]
  ],
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "LlavaNextImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "processor_class": "LlavaNextProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "shortest_edge": 336
  }
}

[W821 12:19:11.597173444 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:11.597190595 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,618 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,619 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,619 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,619 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,619 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2058] 2025-08-21 12:19:11,619 >> loading file chat_template.jinja
[2025-08-21 12:19:11,648] [INFO] [comm.py:652:init_distributed] cdb=None
[W821 12:19:11.633464618 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W821 12:19:11.633479684 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[INFO|2025-08-21 12:19:11] llamafactory.hparams.parser:410 >> Process rank: 5, world size: 8, device: cuda:5, distributed training: True, compute dtype: torch.bfloat16
[INFO|processing_utils.py:822] 2025-08-21 12:19:11,900 >> loading configuration file /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf/processor_config.json
[INFO|processing_utils.py:884] 2025-08-21 12:19:12,002 >> Processor LlavaNextProcessor:
- image_processor: LlavaNextImageProcessorFast {
  "aspect_ratio_setting": "anyres",
  "crop_size": {
    "height": 336,
    "width": 336
  },
  "data_format": "channels_first",
  "default_to_square": false,
  "device": null,
  "do_center_crop": true,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": true,
  "do_rescale": true,
  "do_resize": true,
  "image_grid_pinpoints": [
    [
      336,
      672
    ],
    [
      672,
      336
    ],
    [
      672,
      672
    ],
    [
      1008,
      336
    ],
    [
      336,
      1008
    ]
  ],
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "LlavaNextImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "processor_class": "LlavaNextProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "shortest_edge": 336
  }
}

- tokenizer: LlamaTokenizerFast(name_or_path='/opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf', vocab_size=32000, model_max_length=4096, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>', 'image_token': '<image>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	32000: AddedToken("<image>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)

{
  "image_token": "<image>",
  "num_additional_image_tokens": 1,
  "patch_size": 14,
  "processor_class": "LlavaNextProcessor",
  "vision_feature_select_strategy": "default"
}

[INFO|2025-08-21 12:19:12] llamafactory.data.loader:143 >> Loading dataset tgdoc.json...
[INFO|2025-08-21 12:19:12] llamafactory.hparams.parser:410 >> Process rank: 2, world size: 8, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-08-21 12:19:12] llamafactory.hparams.parser:410 >> Process rank: 6, world size: 8, device: cuda:6, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-08-21 12:19:12] llamafactory.hparams.parser:410 >> Process rank: 3, world size: 8, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
Converting format of dataset (num_proc=128): 100%|██████████| 185985/185985 [00:00<?, ? examples/s]Converting format of dataset (num_proc=128): 186159 examples [00:00, 183.65 examples/s]            [WARNING|2025-08-21 12:19:19] llamafactory.data.converter:148 >> Invalid message count in [{'content': '<image>Can you tell me about the individuals present in the image?', 'role': 'user'}, {'content': 'The image features two men standing together. One of them is wearing a black shirt, and the other is wearing a hat.\\n ', 'role': 'assistant'}, {'content': 'Describe the text found within the image, which I believe to be some sort of sign or title.', 'role': 'user'}].
[WARNING|2025-08-21 12:19:19] llamafactory.data.converter:148 >> Skipping this abnormal example.
[WARNING|2025-08-21 12:19:19] llamafactory.data.converter:148 >> Invalid message count in [{'content': 'What is the primary title on the book cover?<image>', 'role': 'user'}, {'content': 'The primary title on the book cover is "JOHN" and "LITIGATORS"[0.061, 0.06, 0.95, 0.224].', 'role': 'assistant'}, {'content': 'Is there any other title or subtitle on the cover? What are their positions?', 'role': 'user'}].
[WARNING|2025-08-21 12:19:19] llamafactory.data.converter:148 >> Skipping this abnormal example.
Converting format of dataset (num_proc=128): 198182 examples [00:01, 15893.55 examples/s]Converting format of dataset (num_proc=128): 205413 examples [00:01, 21582.65 examples/s]Converting format of dataset (num_proc=128): 211899 examples [00:01, 28629.63 examples/s]Converting format of dataset (num_proc=128): 219276 examples [00:01, 37110.35 examples/s]Converting format of dataset (num_proc=128): 232675 examples [00:01, 57605.79 examples/s]Converting format of dataset (num_proc=128): 261159 examples [00:01, 110472.26 examples/s]Converting format of dataset (num_proc=128): 307346 examples [00:01, 197916.63 examples/s]Converting format of dataset (num_proc=128): 349424 examples [00:01, 256144.27 examples/s]Converting format of dataset (num_proc=128): 371970 examples [00:02, 63774.60 examples/s] 
NCCL version 2.20.5+cuda11.0
Running tokenizer on dataset (num_proc=128): 100%|██████████| 185985/185985 [00:00<?, ? examples/s][WARNING|2025-08-21 12:19:53] llamafactory.data.processor.supervised:148 >> Dropped invalid example: []
Running tokenizer on dataset (num_proc=128): 186985 examples [00:29, 34.33 examples/s]             Running tokenizer on dataset (num_proc=128): 187985 examples [00:29, 81.21 examples/s]Running tokenizer on dataset (num_proc=128): 188985 examples [00:29, 146.45 examples/s]Running tokenizer on dataset (num_proc=128): 189985 examples [00:30, 227.28 examples/s]Running tokenizer on dataset (num_proc=128): 190985 examples [00:30, 347.99 examples/s]Running tokenizer on dataset (num_proc=128): 191985 examples [00:31, 492.13 examples/s]Running tokenizer on dataset (num_proc=128): 192985 examples [00:31, 692.84 examples/s]Running tokenizer on dataset (num_proc=128): 193985 examples [00:31, 876.26 examples/s]Running tokenizer on dataset (num_proc=128): 193985 examples [00:48, 876.26 examples/s]Running tokenizer on dataset (num_proc=128): 194438 examples [00:51, 121.90 examples/s][WARNING|2025-08-21 12:20:23] llamafactory.data.processor.supervised:148 >> Dropped invalid example: []
Running tokenizer on dataset (num_proc=128): 194891 examples [01:03, 83.96 examples/s] Running tokenizer on dataset (num_proc=128): 197610 examples [01:11, 156.49 examples/s]Running tokenizer on dataset (num_proc=128): 198610 examples [01:12, 205.68 examples/s]Running tokenizer on dataset (num_proc=128): 251610 examples [01:12, 4035.42 examples/s]Running tokenizer on dataset (num_proc=128): 268610 examples [01:14, 4872.27 examples/s]Running tokenizer on dataset (num_proc=128): 280610 examples [01:19, 3789.78 examples/s]Running tokenizer on dataset (num_proc=128): 289610 examples [01:20, 4183.22 examples/s]Running tokenizer on dataset (num_proc=128): 295610 examples [01:21, 4476.93 examples/s]Running tokenizer on dataset (num_proc=128): 300610 examples [01:22, 4525.67 examples/s]Running tokenizer on dataset (num_proc=128): 304610 examples [01:23, 4688.55 examples/s]Running tokenizer on dataset (num_proc=128): 307610 examples [01:23, 4870.01 examples/s]Running tokenizer on dataset (num_proc=128): 309610 examples [01:24, 5152.73 examples/s]Running tokenizer on dataset (num_proc=128): 311610 examples [01:24, 4960.18 examples/s]Running tokenizer on dataset (num_proc=128): 313610 examples [01:25, 3607.51 examples/s]Running tokenizer on dataset (num_proc=128): 314610 examples [01:27, 2430.95 examples/s]Running tokenizer on dataset (num_proc=128): 315610 examples [01:29, 1462.11 examples/s]Running tokenizer on dataset (num_proc=128): 316610 examples [01:30, 1460.11 examples/s]Running tokenizer on dataset (num_proc=128): 317063 examples [01:35, 602.13 examples/s] Running tokenizer on dataset (num_proc=128): 317516 examples [01:35, 627.19 examples/s]Running tokenizer on dataset (num_proc=128): 317969 examples [01:36, 664.66 examples/s]Running tokenizer on dataset (num_proc=128): 318969 examples [01:36, 921.11 examples/s]Running tokenizer on dataset (num_proc=128): 319422 examples [01:37, 854.27 examples/s]Running tokenizer on dataset (num_proc=128): 319875 examples [01:38, 709.25 examples/s]Running tokenizer on dataset (num_proc=128): 320328 examples [01:38, 793.95 examples/s]Running tokenizer on dataset (num_proc=128): 320781 examples [01:39, 677.25 examples/s]Running tokenizer on dataset (num_proc=128): 321234 examples [01:39, 799.30 examples/s]Running tokenizer on dataset (num_proc=128): 321687 examples [01:40, 949.99 examples/s]Running tokenizer on dataset (num_proc=128): 322140 examples [01:40, 947.14 examples/s]Running tokenizer on dataset (num_proc=128): 323046 examples [01:40, 1316.71 examples/s]Running tokenizer on dataset (num_proc=128): 323499 examples [01:41, 1374.68 examples/s]Running tokenizer on dataset (num_proc=128): 323952 examples [01:42, 892.81 examples/s] Running tokenizer on dataset (num_proc=128): 324405 examples [01:42, 1047.16 examples/s]Running tokenizer on dataset (num_proc=128): 324858 examples [01:42, 1282.86 examples/s]Running tokenizer on dataset (num_proc=128): 325311 examples [01:43, 1026.53 examples/s]Running tokenizer on dataset (num_proc=128): 325764 examples [01:43, 1319.98 examples/s]Running tokenizer on dataset (num_proc=128): 327123 examples [01:44, 1601.77 examples/s]Running tokenizer on dataset (num_proc=128): 328029 examples [01:44, 2143.44 examples/s]Running tokenizer on dataset (num_proc=128): 328935 examples [01:44, 2663.31 examples/s]Running tokenizer on dataset (num_proc=128): 330294 examples [01:44, 3945.11 examples/s]Running tokenizer on dataset (num_proc=128): 331200 examples [01:44, 4114.66 examples/s]Running tokenizer on dataset (num_proc=128): 333012 examples [01:44, 6095.70 examples/s]Running tokenizer on dataset (num_proc=128): 333918 examples [01:45, 4752.61 examples/s]Running tokenizer on dataset (num_proc=128): 334824 examples [01:45, 4953.26 examples/s]Running tokenizer on dataset (num_proc=128): 336183 examples [01:45, 6197.99 examples/s]Running tokenizer on dataset (num_proc=128): 337089 examples [01:45, 6648.02 examples/s]Running tokenizer on dataset (num_proc=128): 337995 examples [01:45, 7138.44 examples/s]Running tokenizer on dataset (num_proc=128): 338901 examples [01:45, 7141.40 examples/s]Running tokenizer on dataset (num_proc=128): 340713 examples [01:45, 9654.39 examples/s]Running tokenizer on dataset (num_proc=128): 342072 examples [01:46, 8474.00 examples/s]Running tokenizer on dataset (num_proc=128): 343431 examples [01:46, 8588.70 examples/s]Running tokenizer on dataset (num_proc=128): 345243 examples [01:46, 9721.01 examples/s]Running tokenizer on dataset (num_proc=128): 346602 examples [01:46, 9298.48 examples/s]Running tokenizer on dataset (num_proc=128): 347961 examples [01:46, 10064.68 examples/s]Running tokenizer on dataset (num_proc=128): 350679 examples [01:46, 13673.46 examples/s]Running tokenizer on dataset (num_proc=128): 352491 examples [01:47, 9939.30 examples/s] Running tokenizer on dataset (num_proc=128): 353850 examples [01:47, 9971.13 examples/s]Running tokenizer on dataset (num_proc=128): 355209 examples [01:47, 10303.04 examples/s]Running tokenizer on dataset (num_proc=128): 356568 examples [01:47, 6892.49 examples/s] Running tokenizer on dataset (num_proc=128): 357927 examples [01:47, 7754.93 examples/s]Running tokenizer on dataset (num_proc=128): 360192 examples [01:48, 9412.11 examples/s]Running tokenizer on dataset (num_proc=128): 361551 examples [01:48, 10176.34 examples/s]Running tokenizer on dataset (num_proc=128): 362910 examples [01:48, 10823.44 examples/s]Running tokenizer on dataset (num_proc=128): 364269 examples [01:48, 8658.89 examples/s] Running tokenizer on dataset (num_proc=128): 365628 examples [01:48, 9481.09 examples/s]Running tokenizer on dataset (num_proc=128): 366987 examples [01:48, 9525.25 examples/s]Running tokenizer on dataset (num_proc=128): 368346 examples [01:48, 8094.29 examples/s]Running tokenizer on dataset (num_proc=128): 369705 examples [01:49, 3585.28 examples/s]Running tokenizer on dataset (num_proc=128): 370611 examples [01:50, 2190.98 examples/s]Running tokenizer on dataset (num_proc=128): 371517 examples [01:51, 1839.99 examples/s]Running tokenizer on dataset (num_proc=128): 371970 examples [01:53, 1061.36 examples/s]Running tokenizer on dataset (num_proc=128): 371970 examples [01:53, 1635.44 examples/s]
training example:
input_ids:
[319, 13563, 1546, 263, 12758, 1404, 322, 385, 23116, 21082, 20255, 29889, 450, 20255, 4076, 8444, 29892, 13173, 29892, 322, 1248, 568, 6089, 304, 278, 1404, 29915, 29879, 5155, 29889, 3148, 1001, 29901, 1938, 366, 1073, 278, 3611, 310, 445, 7977, 29973, 18601, 596, 24481, 411, 278, 10350, 518, 29916, 1195, 29892, 343, 1195, 29892, 921, 3317, 29892, 343, 3317, 29962, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 319, 1799, 9047, 13566, 29901, 450, 7977, 338, 4257, 376, 1576, 3826, 23838, 310, 28052, 663, 310, 278, 3303, 3900, 310, 6813, 29908, 29961, 29900, 29889, 29900, 29906, 29892, 29871, 29900, 29889, 29900, 29945, 29892, 29871, 29900, 29889, 29947, 29947, 29892, 29871, 29900, 29889, 29896, 29945, 1822, 2, 3148, 1001, 29901, 11644, 8640, 278, 4148, 3527, 310, 445, 1426, 29973, 18601, 596, 5995, 411, 278, 10350, 518, 29916, 1195, 29892, 343, 1195, 29892, 921, 3317, 29892, 343, 3317, 29962, 319, 1799, 9047, 13566, 29901, 450, 1426, 338, 491, 376, 1349, 18902, 29011, 29908, 29961, 29900, 29889, 29900, 29906, 29892, 29871, 29900, 29889, 29906, 29946, 29955, 29892, 29871, 29900, 29889, 29946, 29906, 29892, 29871, 29900, 29889, 29906, 29929, 29955, 1822, 2]
inputs:
A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Do you know the title of this volume? Support your reasoning with the coordinates [xmin, ymin, xmax, ymax]<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image> ASSISTANT: The volume is named "The Declaration of Independence of the United States of America"[0.02, 0.05, 0.88, 0.15].</s> USER: Who holds the authorship of this text? Support your claim with the coordinates [xmin, ymin, xmax, ymax] ASSISTANT: The text is by "Thomas Jefferson"[0.02, 0.247, 0.42, 0.297].</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 450, 7977, 338, 4257, 376, 1576, 3826, 23838, 310, 28052, 663, 310, 278, 3303, 3900, 310, 6813, 29908, 29961, 29900, 29889, 29900, 29906, 29892, 29871, 29900, 29889, 29900, 29945, 29892, 29871, 29900, 29889, 29947, 29947, 29892, 29871, 29900, 29889, 29896, 29945, 1822, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 450, 1426, 338, 491, 376, 1349, 18902, 29011, 29908, 29961, 29900, 29889, 29900, 29906, 29892, 29871, 29900, 29889, 29906, 29946, 29955, 29892, 29871, 29900, 29889, 29946, 29906, 29892, 29871, 29900, 29889, 29906, 29929, 29955, 1822, 2]
labels:
The volume is named "The Declaration of Independence of the United States of America"[0.02, 0.05, 0.88, 0.15].</s> The text is by "Thomas Jefferson"[0.02, 0.247, 0.42, 0.297].</s>
[INFO|configuration_utils.py:691] 2025-08-21 12:21:21,510 >> loading configuration file /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf/config.json
[INFO|configuration_utils.py:765] 2025-08-21 12:21:21,518 >> Model config LlavaNextConfig {
  "architectures": [
    "LlavaNextForConditionalGeneration"
  ],
  "ignore_index": -100,
  "image_grid_pinpoints": [
    [
      336,
      672
    ],
    [
      672,
      336
    ],
    [
      672,
      672
    ],
    [
      1008,
      336
    ],
    [
      336,
      1008
    ]
  ],
  "image_seq_length": 576,
  "image_token_index": 32000,
  "model_type": "llava_next",
  "multimodal_projector_bias": true,
  "projector_hidden_act": "gelu",
  "text_config": {
    "_name_or_path": "lmsys/vicuna-7b-v1.5",
    "architectures": [
      "LlamaForCausalLM"
    ],
    "attention_bias": false,
    "attention_dropout": 0.0,
    "head_dim": 128,
    "hidden_act": "silu",
    "hidden_size": 4096,
    "initializer_range": 0.02,
    "intermediate_size": 11008,
    "max_position_embeddings": 4096,
    "mlp_bias": false,
    "model_type": "llama",
    "num_attention_heads": 32,
    "num_hidden_layers": 32,
    "num_key_value_heads": 32,
    "pad_token_id": 0,
    "pretraining_tp": 1,
    "rms_norm_eps": 1e-05,
    "rope_scaling": null,
    "rope_theta": 10000.0,
    "torch_dtype": "float16",
    "use_cache": true,
    "vocab_size": 32064
  },
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.51.1",
  "use_image_newline_parameter": true,
  "vision_config": {
    "attention_dropout": 0.0,
    "hidden_act": "quick_gelu",
    "hidden_size": 1024,
    "image_size": 336,
    "initializer_factor": 1.0,
    "initializer_range": 0.02,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-05,
    "model_type": "clip_vision_model",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": 14,
    "projection_dim": 768,
    "vocab_size": 32000
  },
  "vision_feature_layer": -2,
  "vision_feature_select_strategy": "default",
  "vocab_size": 32064
}

[INFO|2025-08-21 12:21:21] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
[INFO|modeling_utils.py:1121] 2025-08-21 12:21:21,538 >> loading weights file /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf/model.safetensors.index.json
[INFO|modeling_utils.py:2167] 2025-08-21 12:21:21,539 >> Instantiating LlavaNextForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1142] 2025-08-21 12:21:21,543 >> Generate config GenerationConfig {
  "use_cache": false
}

[INFO|modeling_utils.py:2167] 2025-08-21 12:21:21,699 >> Instantiating CLIPVisionModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2167] 2025-08-21 12:21:21,759 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1142] 2025-08-21 12:21:21,760 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0,
  "use_cache": false
}

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:12,  6.07s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.69s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.70s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.71s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.70s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:07<00:14,  7.10s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.71s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:09,  9.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:09,  9.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:09,  9.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:09,  9.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:09,  9.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:09,  9.29s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:09,  9.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:18<00:09,  9.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.66s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.79s/it]


Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.60s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.79s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.75s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.93s/it]
[INFO|modeling_utils.py:4930] 2025-08-21 12:21:45,632 >> All model checkpoint weights were used when initializing LlavaNextForConditionalGeneration.

[INFO|modeling_utils.py:4938] 2025-08-21 12:21:45,633 >> All the weights of LlavaNextForConditionalGeneration were initialized from the model checkpoint at /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlavaNextForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1095] 2025-08-21 12:21:45,642 >> loading configuration file /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf/generation_config.json
[INFO|configuration_utils.py:1142] 2025-08-21 12:21:45,642 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0
}

[INFO|2025-08-21 12:21:45] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-08-21 12:21:45] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-08-21 12:21:45] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.
[INFO|2025-08-21 12:21:45] llamafactory.model.adapter:143 >> Fine-tuning method: Full
[INFO|2025-08-21 12:21:45] llamafactory.model.model_utils.visual:143 >> Set vision model not trainable: ['vision_tower'].
[INFO|2025-08-21 12:21:45] llamafactory.model.model_utils.visual:143 >> Set multi model projector not trainable: multi_modal_projector.
[INFO|2025-08-21 12:21:46] llamafactory.model.loader:143 >> trainable params: 6,738,944,000 || all params: 7,063,431,168 || trainable%: 95.4061
[INFO|trainer.py:748] 2025-08-21 12:21:46,345 >> Using auto half precision backend
[WARNING|2025-08-21 12:21:46] llamafactory.train.callbacks:154 >> Previous trainer log in this folder will be deleted.
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 8. Using DeepSpeed's value.
[2025-08-21 12:21:46,717] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.2, git-hash=unknown, git-branch=unknown
[2025-08-21 12:21:46,717] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-21 12:21:55,566] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-08-21 12:21:55,569] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-08-21 12:21:55,569] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-08-21 12:21:55,601] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-08-21 12:21:55,601] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-08-21 12:21:55,601] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-08-21 12:21:55,601] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1000000000
[2025-08-21 12:21:55,601] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1000000000
[2025-08-21 12:21:55,601] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-08-21 12:21:55,601] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: True
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
[2025-08-21 12:22:20,084] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-08-21 12:22:20,085] [INFO] [utils.py:782:see_memory_usage] MA 16.3 GB         Max_MA 16.3 GB         CA 19.0 GB         Max_CA 19 GB 
[2025-08-21 12:22:20,085] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 0.0 GB, percent = 0.0%
[2025-08-21 12:22:20,346] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-08-21 12:22:20,347] [INFO] [utils.py:782:see_memory_usage] MA 16.3 GB         Max_MA 19.44 GB         CA 22.13 GB         Max_CA 22 GB 
[2025-08-21 12:22:20,347] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 0.0 GB, percent = 0.0%
[2025-08-21 12:22:20,347] [INFO] [stage_1_and_2.py:544:__init__] optimizer state initialized
[2025-08-21 12:22:20,533] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-08-21 12:22:20,533] [INFO] [utils.py:782:see_memory_usage] MA 16.3 GB         Max_MA 16.3 GB         CA 22.13 GB         Max_CA 22 GB 
[2025-08-21 12:22:20,533] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 0.0 GB, percent = 0.0%
[2025-08-21 12:22:20,535] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-08-21 12:22:20,535] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-08-21 12:22:20,535] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-08-21 12:22:20,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-08-21 12:22:20,537] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-08-21 12:22:20,537] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-08-21 12:22:20,537] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-08-21 12:22:20,537] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f22c64bb5b0>
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-08-21 12:22:20,538] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 8
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-08-21 12:22:20,539] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   train_batch_size ............. 64
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   world_size ................... 8
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  True
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1000000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1000000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=True zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-08-21 12:22:20,540] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[2025-08-21 12:22:20,541] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 64, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 8, 
    "gradient_clipping": 1.0, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "initial_scale_power": 16, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "bf16": {
        "enabled": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 1.000000e+09, 
        "overlap_comm": false, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 1.000000e+09, 
        "contiguous_gradients": true, 
        "round_robin_gradients": true
    }, 
    "steps_per_print": inf
}
[INFO|trainer.py:2414] 2025-08-21 12:22:20,542 >> ***** Running training *****
[INFO|trainer.py:2415] 2025-08-21 12:22:20,542 >>   Num examples = 185,983
[INFO|trainer.py:2416] 2025-08-21 12:22:20,542 >>   Num Epochs = 1
[INFO|trainer.py:2417] 2025-08-21 12:22:20,542 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2420] 2025-08-21 12:22:20,542 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:2421] 2025-08-21 12:22:20,542 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:2422] 2025-08-21 12:22:20,542 >>   Total optimization steps = 2,906
[INFO|trainer.py:2423] 2025-08-21 12:22:20,544 >>   Number of trainable parameters = 6,738,944,000
  0%|          | 0/2906 [00:00<?, ?it/s]/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
  0%|          | 1/2906 [00:15<12:11:23, 15.11s/it]                                                   {'loss': 1.1253, 'grad_norm': 3.771137237548828, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 1/2906 [00:15<12:11:23, 15.11s/it]  0%|          | 2/2906 [00:26<10:32:39, 13.07s/it]                                                   {'loss': 1.1178, 'grad_norm': 3.252462387084961, 'learning_rate': 5.0000000000000004e-08, 'epoch': 0.0}
  0%|          | 2/2906 [00:26<10:32:39, 13.07s/it]  0%|          | 3/2906 [00:38<10:10:56, 12.63s/it]                                                   {'loss': 1.0922, 'grad_norm': 3.4835944175720215, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.0}
  0%|          | 3/2906 [00:38<10:10:56, 12.63s/it]  0%|          | 4/2906 [00:50<10:00:09, 12.41s/it]                                                   {'loss': 1.067, 'grad_norm': 3.47806453704834, 'learning_rate': 1.5000000000000002e-07, 'epoch': 0.0}
  0%|          | 4/2906 [00:50<10:00:09, 12.41s/it]  0%|          | 5/2906 [01:02<9:49:44, 12.20s/it]                                                   {'loss': 1.1804, 'grad_norm': 4.7696533203125, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.0}
  0%|          | 5/2906 [01:02<9:49:44, 12.20s/it]  0%|          | 6/2906 [01:14<9:39:57, 12.00s/it]                                                  {'loss': 1.0798, 'grad_norm': 4.271550178527832, 'learning_rate': 2.5000000000000004e-07, 'epoch': 0.0}
  0%|          | 6/2906 [01:14<9:39:57, 12.00s/it]  0%|          | 7/2906 [01:26<9:35:46, 11.92s/it]                                                  {'loss': 1.2482, 'grad_norm': 4.625021934509277, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.0}
  0%|          | 7/2906 [01:26<9:35:46, 11.92s/it]  0%|          | 8/2906 [01:38<9:37:29, 11.96s/it]                                                  {'loss': 1.0757, 'grad_norm': 3.6121792793273926, 'learning_rate': 3.5000000000000004e-07, 'epoch': 0.0}
  0%|          | 8/2906 [01:38<9:37:29, 11.96s/it]  0%|          | 9/2906 [01:49<9:34:59, 11.91s/it]                                                  {'loss': 1.1474, 'grad_norm': 3.7146477699279785, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.0}
  0%|          | 9/2906 [01:49<9:34:59, 11.91s/it]  0%|          | 10/2906 [02:00<9:19:34, 11.59s/it]                                                   {'loss': 1.1496, 'grad_norm': 3.586296558380127, 'learning_rate': 4.5000000000000003e-07, 'epoch': 0.0}
  0%|          | 10/2906 [02:00<9:19:34, 11.59s/it]  0%|          | 11/2906 [02:12<9:24:44, 11.70s/it]                                                   {'loss': 1.0823, 'grad_norm': 3.9223220348358154, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 11/2906 [02:12<9:24:44, 11.70s/it]  0%|          | 12/2906 [02:24<9:29:31, 11.81s/it]                                                   {'loss': 1.185, 'grad_norm': 4.076253414154053, 'learning_rate': 5.5e-07, 'epoch': 0.0}
  0%|          | 12/2906 [02:24<9:29:31, 11.81s/it]  0%|          | 13/2906 [02:36<9:28:01, 11.78s/it]                                                   {'loss': 1.1447, 'grad_norm': 3.8488776683807373, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.0}
  0%|          | 13/2906 [02:36<9:28:01, 11.78s/it]  0%|          | 14/2906 [02:48<9:28:20, 11.79s/it]                                                   {'loss': 1.1623, 'grad_norm': 4.039175033569336, 'learning_rate': 6.5e-07, 'epoch': 0.0}
  0%|          | 14/2906 [02:48<9:28:20, 11.79s/it]  1%|          | 15/2906 [03:00<9:33:39, 11.91s/it]                                                   {'loss': 1.11, 'grad_norm': 3.4377388954162598, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.01}
  1%|          | 15/2906 [03:00<9:33:39, 11.91s/it]  1%|          | 16/2906 [03:12<9:30:15, 11.84s/it]                                                   {'loss': 1.1719, 'grad_norm': 3.7185473442077637, 'learning_rate': 7.5e-07, 'epoch': 0.01}
  1%|          | 16/2906 [03:12<9:30:15, 11.84s/it]  1%|          | 17/2906 [03:24<9:31:34, 11.87s/it]                                                   {'loss': 1.2233, 'grad_norm': 3.7938106060028076, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.01}
  1%|          | 17/2906 [03:24<9:31:34, 11.87s/it]  1%|          | 18/2906 [03:35<9:27:34, 11.79s/it]                                                   {'loss': 1.1683, 'grad_norm': 3.455873489379883, 'learning_rate': 8.500000000000001e-07, 'epoch': 0.01}
  1%|          | 18/2906 [03:35<9:27:34, 11.79s/it]  1%|          | 19/2906 [03:47<9:25:05, 11.74s/it]                                                   {'loss': 1.1285, 'grad_norm': 3.5503926277160645, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.01}
  1%|          | 19/2906 [03:47<9:25:05, 11.74s/it]  1%|          | 20/2906 [03:58<9:22:06, 11.69s/it]                                                   {'loss': 1.154, 'grad_norm': 3.6702020168304443, 'learning_rate': 9.500000000000001e-07, 'epoch': 0.01}
  1%|          | 20/2906 [03:58<9:22:06, 11.69s/it]  1%|          | 21/2906 [04:11<9:28:57, 11.83s/it]                                                   {'loss': 1.1362, 'grad_norm': 7.614651203155518, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}
  1%|          | 21/2906 [04:11<9:28:57, 11.83s/it]  1%|          | 22/2906 [04:22<9:21:18, 11.68s/it]                                                   {'loss': 1.0699, 'grad_norm': 3.2534053325653076, 'learning_rate': 1.0500000000000001e-06, 'epoch': 0.01}
  1%|          | 22/2906 [04:22<9:21:18, 11.68s/it]  1%|          | 23/2906 [04:35<9:34:11, 11.95s/it]                                                   {'loss': 1.0424, 'grad_norm': 2.8912224769592285, 'learning_rate': 1.1e-06, 'epoch': 0.01}
  1%|          | 23/2906 [04:35<9:34:11, 11.95s/it]  1%|          | 24/2906 [04:46<9:33:07, 11.93s/it]                                                   {'loss': 1.101, 'grad_norm': 3.6529533863067627, 'learning_rate': 1.1500000000000002e-06, 'epoch': 0.01}
  1%|          | 24/2906 [04:46<9:33:07, 11.93s/it]  1%|          | 25/2906 [04:58<9:33:42, 11.95s/it]                                                   {'loss': 1.0229, 'grad_norm': 3.4012327194213867, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.01}
  1%|          | 25/2906 [04:58<9:33:42, 11.95s/it]  1%|          | 26/2906 [05:10<9:33:29, 11.95s/it]                                                   {'loss': 1.0114, 'grad_norm': 2.977289915084839, 'learning_rate': 1.25e-06, 'epoch': 0.01}
  1%|          | 26/2906 [05:10<9:33:29, 11.95s/it]  1%|          | 27/2906 [05:22<9:35:54, 12.00s/it]                                                   {'loss': 1.0502, 'grad_norm': 2.9289982318878174, 'learning_rate': 1.3e-06, 'epoch': 0.01}
  1%|          | 27/2906 [05:23<9:35:54, 12.00s/it]  1%|          | 28/2906 [05:35<9:41:37, 12.13s/it]                                                   {'loss': 1.0123, 'grad_norm': 3.9406914710998535, 'learning_rate': 1.3500000000000002e-06, 'epoch': 0.01}
  1%|          | 28/2906 [05:35<9:41:37, 12.13s/it]  1%|          | 29/2906 [05:47<9:37:33, 12.04s/it]                                                   {'loss': 1.0395, 'grad_norm': 3.8825840950012207, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.01}
  1%|          | 29/2906 [05:47<9:37:33, 12.04s/it]  1%|          | 30/2906 [05:59<9:39:50, 12.10s/it]                                                   {'loss': 0.981, 'grad_norm': 3.664354085922241, 'learning_rate': 1.45e-06, 'epoch': 0.01}
  1%|          | 30/2906 [05:59<9:39:50, 12.10s/it]  1%|          | 31/2906 [06:11<9:35:18, 12.01s/it]                                                   {'loss': 0.952, 'grad_norm': 6.936008453369141, 'learning_rate': 1.5e-06, 'epoch': 0.01}
  1%|          | 31/2906 [06:11<9:35:18, 12.01s/it]  1%|          | 32/2906 [06:22<9:28:25, 11.87s/it]                                                   {'loss': 0.9832, 'grad_norm': 3.226644277572632, 'learning_rate': 1.5500000000000002e-06, 'epoch': 0.01}
  1%|          | 32/2906 [06:22<9:28:25, 11.87s/it]  1%|          | 33/2906 [06:34<9:29:26, 11.89s/it]                                                   {'loss': 0.9998, 'grad_norm': 3.347475290298462, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.01}
  1%|          | 33/2906 [06:34<9:29:26, 11.89s/it]  1%|          | 34/2906 [06:46<9:33:09, 11.97s/it]                                                   {'loss': 0.9608, 'grad_norm': 3.015629529953003, 'learning_rate': 1.6500000000000003e-06, 'epoch': 0.01}
  1%|          | 34/2906 [06:46<9:33:09, 11.97s/it]  1%|          | 35/2906 [06:58<9:27:46, 11.87s/it]                                                   {'loss': 0.9688, 'grad_norm': 3.3055286407470703, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.01}
  1%|          | 35/2906 [06:58<9:27:46, 11.87s/it]  1%|          | 36/2906 [07:10<9:27:16, 11.86s/it]                                                   {'loss': 0.9603, 'grad_norm': 4.273316860198975, 'learning_rate': 1.75e-06, 'epoch': 0.01}
  1%|          | 36/2906 [07:10<9:27:16, 11.86s/it]  1%|▏         | 37/2906 [07:22<9:37:04, 12.07s/it]                                                   {'loss': 0.9361, 'grad_norm': 3.609527587890625, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.01}
  1%|▏         | 37/2906 [07:22<9:37:04, 12.07s/it]  1%|▏         | 38/2906 [07:34<9:31:06, 11.95s/it]                                                   {'loss': 0.933, 'grad_norm': 2.601719379425049, 'learning_rate': 1.85e-06, 'epoch': 0.01}
  1%|▏         | 38/2906 [07:34<9:31:06, 11.95s/it]  1%|▏         | 39/2906 [07:46<9:29:07, 11.91s/it]                                                   {'loss': 1.0009, 'grad_norm': 4.398407459259033, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.01}
  1%|▏         | 39/2906 [07:46<9:29:07, 11.91s/it]  1%|▏         | 40/2906 [07:58<9:26:34, 11.86s/it]                                                   {'loss': 0.9434, 'grad_norm': 7.951906204223633, 'learning_rate': 1.9500000000000004e-06, 'epoch': 0.01}
  1%|▏         | 40/2906 [07:58<9:26:34, 11.86s/it]  1%|▏         | 41/2906 [08:09<9:22:20, 11.78s/it]                                                   {'loss': 0.9334, 'grad_norm': 4.253877639770508, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
  1%|▏         | 41/2906 [08:09<9:22:20, 11.78s/it]  1%|▏         | 42/2906 [08:21<9:14:59, 11.63s/it]                                                   {'loss': 0.9856, 'grad_norm': 3.5298802852630615, 'learning_rate': 2.05e-06, 'epoch': 0.01}
  1%|▏         | 42/2906 [08:21<9:14:59, 11.63s/it]  1%|▏         | 43/2906 [08:32<9:09:43, 11.52s/it]                                                   {'loss': 0.9277, 'grad_norm': 4.125153064727783, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.01}
  1%|▏         | 43/2906 [08:32<9:09:43, 11.52s/it]  2%|▏         | 44/2906 [08:44<9:12:11, 11.58s/it]                                                   {'loss': 0.9332, 'grad_norm': 2.3725855350494385, 'learning_rate': 2.15e-06, 'epoch': 0.02}
  2%|▏         | 44/2906 [08:44<9:12:11, 11.58s/it]  2%|▏         | 45/2906 [08:55<9:11:22, 11.56s/it]                                                   {'loss': 0.9784, 'grad_norm': 2.8528547286987305, 'learning_rate': 2.2e-06, 'epoch': 0.02}
  2%|▏         | 45/2906 [08:55<9:11:22, 11.56s/it]  2%|▏         | 46/2906 [09:07<9:14:55, 11.64s/it]                                                   {'loss': 0.9028, 'grad_norm': 2.814523220062256, 'learning_rate': 2.25e-06, 'epoch': 0.02}
  2%|▏         | 46/2906 [09:07<9:14:55, 11.64s/it]  2%|▏         | 47/2906 [09:18<9:06:15, 11.46s/it]                                                   {'loss': 0.8857, 'grad_norm': 3.46006441116333, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.02}
  2%|▏         | 47/2906 [09:18<9:06:15, 11.46s/it]  2%|▏         | 48/2906 [09:30<9:15:07, 11.65s/it]                                                   {'loss': 0.8474, 'grad_norm': 2.7459816932678223, 'learning_rate': 2.35e-06, 'epoch': 0.02}
  2%|▏         | 48/2906 [09:30<9:15:07, 11.65s/it]  2%|▏         | 49/2906 [09:42<9:19:44, 11.76s/it]                                                   {'loss': 0.9377, 'grad_norm': 3.023357629776001, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.02}
  2%|▏         | 49/2906 [09:42<9:19:44, 11.76s/it]  2%|▏         | 50/2906 [09:53<9:12:50, 11.61s/it]                                                   {'loss': 0.8775, 'grad_norm': 2.2636356353759766, 'learning_rate': 2.4500000000000003e-06, 'epoch': 0.02}
  2%|▏         | 50/2906 [09:53<9:12:50, 11.61s/it]  2%|▏         | 51/2906 [10:05<9:16:23, 11.69s/it]                                                   {'loss': 0.8572, 'grad_norm': 1.7165848016738892, 'learning_rate': 2.5e-06, 'epoch': 0.02}
  2%|▏         | 51/2906 [10:05<9:16:23, 11.69s/it]  2%|▏         | 52/2906 [10:16<9:08:25, 11.53s/it]                                                   {'loss': 0.905, 'grad_norm': 2.2875654697418213, 'learning_rate': 2.55e-06, 'epoch': 0.02}
  2%|▏         | 52/2906 [10:16<9:08:25, 11.53s/it]  2%|▏         | 53/2906 [10:28<9:12:42, 11.62s/it]                                                   {'loss': 0.9069, 'grad_norm': 4.439069747924805, 'learning_rate': 2.6e-06, 'epoch': 0.02}
  2%|▏         | 53/2906 [10:28<9:12:42, 11.62s/it]  2%|▏         | 54/2906 [10:41<9:25:40, 11.90s/it]                                                   {'loss': 0.8018, 'grad_norm': 1.8115644454956055, 'learning_rate': 2.6500000000000005e-06, 'epoch': 0.02}
  2%|▏         | 54/2906 [10:41<9:25:40, 11.90s/it]  2%|▏         | 55/2906 [10:53<9:37:31, 12.15s/it]                                                   {'loss': 0.8381, 'grad_norm': 2.214597225189209, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.02}
  2%|▏         | 55/2906 [10:53<9:37:31, 12.15s/it]  2%|▏         | 56/2906 [11:05<9:28:54, 11.98s/it]                                                   {'loss': 0.8907, 'grad_norm': 3.0956711769104004, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.02}
  2%|▏         | 56/2906 [11:05<9:28:54, 11.98s/it]  2%|▏         | 57/2906 [11:16<9:19:55, 11.79s/it]                                                   {'loss': 0.89, 'grad_norm': 1.9556777477264404, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.02}
  2%|▏         | 57/2906 [11:16<9:19:55, 11.79s/it]  2%|▏         | 58/2906 [11:28<9:23:10, 11.86s/it]                                                   {'loss': 0.8742, 'grad_norm': 1.5122520923614502, 'learning_rate': 2.85e-06, 'epoch': 0.02}
  2%|▏         | 58/2906 [11:28<9:23:10, 11.86s/it]  2%|▏         | 59/2906 [11:40<9:18:24, 11.77s/it]                                                   {'loss': 0.8855, 'grad_norm': 1.8705390691757202, 'learning_rate': 2.9e-06, 'epoch': 0.02}
  2%|▏         | 59/2906 [11:40<9:18:24, 11.77s/it]  2%|▏         | 60/2906 [11:52<9:24:46, 11.91s/it]                                                   {'loss': 0.8833, 'grad_norm': 1.6672520637512207, 'learning_rate': 2.95e-06, 'epoch': 0.02}
  2%|▏         | 60/2906 [11:52<9:24:46, 11.91s/it]  2%|▏         | 61/2906 [12:04<9:23:22, 11.88s/it]                                                   {'loss': 0.907, 'grad_norm': 1.5895121097564697, 'learning_rate': 3e-06, 'epoch': 0.02}
  2%|▏         | 61/2906 [12:04<9:23:22, 11.88s/it]  2%|▏         | 62/2906 [12:16<9:24:04, 11.90s/it]                                                   {'loss': 0.9482, 'grad_norm': 1.6450976133346558, 'learning_rate': 3.05e-06, 'epoch': 0.02}
  2%|▏         | 62/2906 [12:16<9:24:04, 11.90s/it]  2%|▏         | 63/2906 [12:28<9:22:43, 11.88s/it]                                                   {'loss': 0.8342, 'grad_norm': 1.6336541175842285, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.02}
  2%|▏         | 63/2906 [12:28<9:22:43, 11.88s/it]  2%|▏         | 64/2906 [12:40<9:24:33, 11.92s/it]                                                   {'loss': 0.8492, 'grad_norm': 1.5260716676712036, 'learning_rate': 3.1500000000000003e-06, 'epoch': 0.02}
  2%|▏         | 64/2906 [12:40<9:24:33, 11.92s/it]  2%|▏         | 65/2906 [12:52<9:29:01, 12.02s/it]                                                   {'loss': 0.8795, 'grad_norm': 1.8052138090133667, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.02}
  2%|▏         | 65/2906 [12:52<9:29:01, 12.02s/it]  2%|▏         | 66/2906 [13:05<9:42:35, 12.31s/it]                                                   {'loss': 0.8572, 'grad_norm': 1.4427210092544556, 'learning_rate': 3.2500000000000002e-06, 'epoch': 0.02}
  2%|▏         | 66/2906 [13:05<9:42:35, 12.31s/it]  2%|▏         | 67/2906 [13:17<9:32:58, 12.11s/it]                                                   {'loss': 0.8359, 'grad_norm': 1.4531081914901733, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.02}
  2%|▏         | 67/2906 [13:17<9:32:58, 12.11s/it]  2%|▏         | 68/2906 [13:28<9:27:08, 11.99s/it]                                                   {'loss': 0.8339, 'grad_norm': 2.0148093700408936, 'learning_rate': 3.3500000000000005e-06, 'epoch': 0.02}
  2%|▏         | 68/2906 [13:28<9:27:08, 11.99s/it]  2%|▏         | 69/2906 [13:41<9:34:26, 12.15s/it]                                                   {'loss': 0.8666, 'grad_norm': 1.9554473161697388, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.02}
  2%|▏         | 69/2906 [13:41<9:34:26, 12.15s/it]  2%|▏         | 70/2906 [13:53<9:30:00, 12.06s/it]                                                   {'loss': 0.8938, 'grad_norm': 2.0070083141326904, 'learning_rate': 3.45e-06, 'epoch': 0.02}
  2%|▏         | 70/2906 [13:53<9:30:00, 12.06s/it]  2%|▏         | 71/2906 [14:04<9:24:36, 11.95s/it]                                                   {'loss': 0.8464, 'grad_norm': 1.662540316581726, 'learning_rate': 3.5e-06, 'epoch': 0.02}
  2%|▏         | 71/2906 [14:04<9:24:36, 11.95s/it]  2%|▏         | 72/2906 [14:16<9:20:14, 11.86s/it]                                                   {'loss': 0.8385, 'grad_norm': 1.4645743370056152, 'learning_rate': 3.5500000000000003e-06, 'epoch': 0.02}
  2%|▏         | 72/2906 [14:16<9:20:14, 11.86s/it]  3%|▎         | 73/2906 [14:28<9:19:03, 11.84s/it]                                                   {'loss': 0.8585, 'grad_norm': 1.528821587562561, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.03}
  3%|▎         | 73/2906 [14:28<9:19:03, 11.84s/it]  3%|▎         | 74/2906 [14:39<9:13:13, 11.72s/it]                                                   {'loss': 0.8849, 'grad_norm': 1.4667357206344604, 'learning_rate': 3.65e-06, 'epoch': 0.03}
  3%|▎         | 74/2906 [14:39<9:13:13, 11.72s/it]  3%|▎         | 75/2906 [14:52<9:20:00, 11.87s/it]                                                   {'loss': 0.8327, 'grad_norm': 1.437941074371338, 'learning_rate': 3.7e-06, 'epoch': 0.03}
  3%|▎         | 75/2906 [14:52<9:20:00, 11.87s/it]  3%|▎         | 76/2906 [15:04<9:26:44, 12.02s/it]                                                   {'loss': 0.9048, 'grad_norm': 1.6977763175964355, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.03}
  3%|▎         | 76/2906 [15:04<9:26:44, 12.02s/it]  3%|▎         | 77/2906 [15:15<9:14:25, 11.76s/it]                                                   {'loss': 0.8805, 'grad_norm': 1.4518563747406006, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.03}
  3%|▎         | 77/2906 [15:15<9:14:25, 11.76s/it]  3%|▎         | 78/2906 [15:27<9:12:52, 11.73s/it]                                                   {'loss': 0.88, 'grad_norm': 1.9356061220169067, 'learning_rate': 3.85e-06, 'epoch': 0.03}
  3%|▎         | 78/2906 [15:27<9:12:52, 11.73s/it]  3%|▎         | 79/2906 [15:39<9:15:09, 11.78s/it]                                                   {'loss': 0.8108, 'grad_norm': 1.4369770288467407, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.03}
  3%|▎         | 79/2906 [15:39<9:15:09, 11.78s/it]  3%|▎         | 80/2906 [15:51<9:17:33, 11.84s/it]                                                   {'loss': 0.8228, 'grad_norm': 1.44960618019104, 'learning_rate': 3.95e-06, 'epoch': 0.03}
  3%|▎         | 80/2906 [15:51<9:17:33, 11.84s/it]  3%|▎         | 81/2906 [16:02<9:13:12, 11.75s/it]                                                   {'loss': 0.8048, 'grad_norm': 1.6514616012573242, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.03}
  3%|▎         | 81/2906 [16:02<9:13:12, 11.75s/it]  3%|▎         | 82/2906 [16:14<9:15:28, 11.80s/it]                                                   {'loss': 0.8699, 'grad_norm': 2.188124418258667, 'learning_rate': 4.05e-06, 'epoch': 0.03}
  3%|▎         | 82/2906 [16:14<9:15:28, 11.80s/it]  3%|▎         | 83/2906 [16:26<9:14:08, 11.78s/it]                                                   {'loss': 0.849, 'grad_norm': 5.172863960266113, 'learning_rate': 4.1e-06, 'epoch': 0.03}
  3%|▎         | 83/2906 [16:26<9:14:08, 11.78s/it]  3%|▎         | 84/2906 [16:38<9:22:36, 11.96s/it]                                                   {'loss': 0.7729, 'grad_norm': 1.5157747268676758, 'learning_rate': 4.15e-06, 'epoch': 0.03}
  3%|▎         | 84/2906 [16:38<9:22:36, 11.96s/it]  3%|▎         | 85/2906 [16:50<9:13:49, 11.78s/it]                                                   {'loss': 0.8429, 'grad_norm': 2.1666202545166016, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.03}
  3%|▎         | 85/2906 [16:50<9:13:49, 11.78s/it]  3%|▎         | 86/2906 [17:01<9:13:30, 11.78s/it]                                                   {'loss': 0.8167, 'grad_norm': 1.5605236291885376, 'learning_rate': 4.25e-06, 'epoch': 0.03}
  3%|▎         | 86/2906 [17:01<9:13:30, 11.78s/it]  3%|▎         | 87/2906 [17:13<9:13:12, 11.77s/it]                                                   {'loss': 0.8053, 'grad_norm': 1.5132782459259033, 'learning_rate': 4.3e-06, 'epoch': 0.03}
  3%|▎         | 87/2906 [17:13<9:13:12, 11.77s/it]  3%|▎         | 88/2906 [17:25<9:11:06, 11.73s/it]                                                   {'loss': 0.7957, 'grad_norm': 1.5524249076843262, 'learning_rate': 4.350000000000001e-06, 'epoch': 0.03}
  3%|▎         | 88/2906 [17:25<9:11:06, 11.73s/it]  3%|▎         | 89/2906 [17:37<9:11:34, 11.75s/it]                                                   {'loss': 0.8329, 'grad_norm': 1.5166085958480835, 'learning_rate': 4.4e-06, 'epoch': 0.03}
  3%|▎         | 89/2906 [17:37<9:11:34, 11.75s/it]  3%|▎         | 90/2906 [17:48<9:01:58, 11.55s/it]                                                   {'loss': 0.8406, 'grad_norm': 1.509466290473938, 'learning_rate': 4.450000000000001e-06, 'epoch': 0.03}
  3%|▎         | 90/2906 [17:48<9:01:58, 11.55s/it]  3%|▎         | 91/2906 [17:59<9:01:03, 11.53s/it]                                                   {'loss': 0.8538, 'grad_norm': 1.7752113342285156, 'learning_rate': 4.5e-06, 'epoch': 0.03}
  3%|▎         | 91/2906 [17:59<9:01:03, 11.53s/it]  3%|▎         | 92/2906 [18:11<9:04:36, 11.61s/it]                                                   {'loss': 0.8393, 'grad_norm': 1.4373077154159546, 'learning_rate': 4.5500000000000005e-06, 'epoch': 0.03}
  3%|▎         | 92/2906 [18:11<9:04:36, 11.61s/it]  3%|▎         | 93/2906 [18:23<9:05:52, 11.64s/it]                                                   {'loss': 0.7844, 'grad_norm': 1.5721004009246826, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.03}
  3%|▎         | 93/2906 [18:23<9:05:52, 11.64s/it]  3%|▎         | 94/2906 [18:35<9:09:37, 11.73s/it]                                                   {'loss': 0.8185, 'grad_norm': 1.3848990201950073, 'learning_rate': 4.65e-06, 'epoch': 0.03}
  3%|▎         | 94/2906 [18:35<9:09:37, 11.73s/it]  3%|▎         | 95/2906 [18:47<9:13:43, 11.82s/it]                                                   {'loss': 0.8257, 'grad_norm': 2.0231094360351562, 'learning_rate': 4.7e-06, 'epoch': 0.03}
  3%|▎         | 95/2906 [18:47<9:13:43, 11.82s/it]  3%|▎         | 96/2906 [18:58<9:09:58, 11.74s/it]                                                   {'loss': 0.7721, 'grad_norm': 1.5263499021530151, 'learning_rate': 4.75e-06, 'epoch': 0.03}
  3%|▎         | 96/2906 [18:58<9:09:58, 11.74s/it]  3%|▎         | 97/2906 [19:10<9:11:28, 11.78s/it]                                                   {'loss': 0.788, 'grad_norm': 1.6645203828811646, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.03}
  3%|▎         | 97/2906 [19:10<9:11:28, 11.78s/it]  3%|▎         | 98/2906 [19:21<9:07:07, 11.69s/it]                                                   {'loss': 0.8573, 'grad_norm': 1.7986407279968262, 'learning_rate': 4.85e-06, 'epoch': 0.03}
  3%|▎         | 98/2906 [19:21<9:07:07, 11.69s/it]  3%|▎         | 99/2906 [19:34<9:12:01, 11.80s/it]                                                   {'loss': 0.8312, 'grad_norm': 1.6697170734405518, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.03}
  3%|▎         | 99/2906 [19:34<9:12:01, 11.80s/it]  3%|▎         | 100/2906 [19:45<9:12:13, 11.81s/it]                                                    {'loss': 0.8583, 'grad_norm': 1.4408382177352905, 'learning_rate': 4.95e-06, 'epoch': 0.03}
  3%|▎         | 100/2906 [19:45<9:12:13, 11.81s/it]  3%|▎         | 101/2906 [19:57<9:09:43, 11.76s/it]                                                    {'loss': 0.834, 'grad_norm': 1.4060951471328735, 'learning_rate': 5e-06, 'epoch': 0.03}
  3%|▎         | 101/2906 [19:57<9:09:43, 11.76s/it]  4%|▎         | 102/2906 [20:09<9:07:58, 11.73s/it]                                                    {'loss': 0.8095, 'grad_norm': 1.505071759223938, 'learning_rate': 4.9999984331248985e-06, 'epoch': 0.04}
  4%|▎         | 102/2906 [20:09<9:07:58, 11.73s/it]  4%|▎         | 103/2906 [20:20<9:01:39, 11.59s/it]                                                    {'loss': 0.7825, 'grad_norm': 1.34445321559906, 'learning_rate': 4.9999937325015554e-06, 'epoch': 0.04}
  4%|▎         | 103/2906 [20:20<9:01:39, 11.59s/it]  4%|▎         | 104/2906 [20:32<9:09:57, 11.78s/it]                                                    {'loss': 0.9042, 'grad_norm': 1.786203145980835, 'learning_rate': 4.999985898135865e-06, 'epoch': 0.04}
  4%|▎         | 104/2906 [20:32<9:09:57, 11.78s/it]  4%|▎         | 105/2906 [20:44<9:08:24, 11.75s/it]                                                    {'loss': 0.8539, 'grad_norm': 1.4544520378112793, 'learning_rate': 4.999974930037645e-06, 'epoch': 0.04}
  4%|▎         | 105/2906 [20:44<9:08:24, 11.75s/it]  4%|▎         | 106/2906 [20:56<9:07:26, 11.73s/it]                                                    {'loss': 0.8459, 'grad_norm': 2.0168700218200684, 'learning_rate': 4.999960828220648e-06, 'epoch': 0.04}
  4%|▎         | 106/2906 [20:56<9:07:26, 11.73s/it]  4%|▎         | 107/2906 [21:07<9:04:03, 11.66s/it]                                                    {'loss': 0.8606, 'grad_norm': 1.6363627910614014, 'learning_rate': 4.999943592702547e-06, 'epoch': 0.04}
  4%|▎         | 107/2906 [21:07<9:04:03, 11.66s/it]  4%|▎         | 108/2906 [21:19<9:11:28, 11.83s/it]                                                    {'loss': 0.8124, 'grad_norm': 2.694786548614502, 'learning_rate': 4.999923223504948e-06, 'epoch': 0.04}
  4%|▎         | 108/2906 [21:19<9:11:28, 11.83s/it]  4%|▍         | 109/2906 [21:31<9:10:40, 11.81s/it]                                                    {'loss': 0.8007, 'grad_norm': 1.5635206699371338, 'learning_rate': 4.999899720653384e-06, 'epoch': 0.04}
  4%|▍         | 109/2906 [21:31<9:10:40, 11.81s/it]  4%|▍         | 110/2906 [21:43<9:07:54, 11.76s/it]                                                    {'loss': 0.9033, 'grad_norm': 1.5091685056686401, 'learning_rate': 4.999873084177316e-06, 'epoch': 0.04}
  4%|▍         | 110/2906 [21:43<9:07:54, 11.76s/it]  4%|▍         | 111/2906 [21:55<9:10:17, 11.81s/it]                                                    {'loss': 0.8024, 'grad_norm': 1.5883252620697021, 'learning_rate': 4.999843314110132e-06, 'epoch': 0.04}
  4%|▍         | 111/2906 [21:55<9:10:17, 11.81s/it]  4%|▍         | 112/2906 [22:06<9:03:51, 11.68s/it]                                                    {'loss': 0.8016, 'grad_norm': 1.4949100017547607, 'learning_rate': 4.99981041048915e-06, 'epoch': 0.04}
  4%|▍         | 112/2906 [22:06<9:03:51, 11.68s/it]  4%|▍         | 113/2906 [22:18<9:02:58, 11.66s/it]                                                    {'loss': 0.8575, 'grad_norm': 1.6049048900604248, 'learning_rate': 4.999774373355613e-06, 'epoch': 0.04}
  4%|▍         | 113/2906 [22:18<9:02:58, 11.66s/it]  4%|▍         | 114/2906 [22:29<9:01:32, 11.64s/it]                                                    {'loss': 0.7952, 'grad_norm': 1.6472147703170776, 'learning_rate': 4.9997352027546955e-06, 'epoch': 0.04}
  4%|▍         | 114/2906 [22:29<9:01:32, 11.64s/it]  4%|▍         | 115/2906 [22:41<9:02:17, 11.66s/it]                                                    {'loss': 0.8351, 'grad_norm': 1.3901973962783813, 'learning_rate': 4.999692898735496e-06, 'epoch': 0.04}
  4%|▍         | 115/2906 [22:41<9:02:17, 11.66s/it]  4%|▍         | 116/2906 [22:53<9:04:24, 11.71s/it]                                                    {'loss': 0.8112, 'grad_norm': 1.7385714054107666, 'learning_rate': 4.999647461351044e-06, 'epoch': 0.04}
  4%|▍         | 116/2906 [22:53<9:04:24, 11.71s/it]  4%|▍         | 117/2906 [23:04<9:01:56, 11.66s/it]                                                    {'loss': 0.8784, 'grad_norm': 1.4983140230178833, 'learning_rate': 4.999598890658294e-06, 'epoch': 0.04}
  4%|▍         | 117/2906 [23:04<9:01:56, 11.66s/it]  4%|▍         | 118/2906 [23:16<9:05:56, 11.75s/it]                                                    {'loss': 0.7905, 'grad_norm': 1.4452917575836182, 'learning_rate': 4.999547186718131e-06, 'epoch': 0.04}
  4%|▍         | 118/2906 [23:16<9:05:56, 11.75s/it]  4%|▍         | 119/2906 [23:28<9:07:55, 11.80s/it]                                                    {'loss': 0.8685, 'grad_norm': 1.600330114364624, 'learning_rate': 4.999492349595364e-06, 'epoch': 0.04}
  4%|▍         | 119/2906 [23:28<9:07:55, 11.80s/it]  4%|▍         | 120/2906 [23:40<9:08:40, 11.82s/it]                                                    {'loss': 0.7972, 'grad_norm': 2.360445022583008, 'learning_rate': 4.999434379358733e-06, 'epoch': 0.04}
  4%|▍         | 120/2906 [23:40<9:08:40, 11.82s/it]  4%|▍         | 121/2906 [23:52<9:10:44, 11.87s/it]                                                    {'loss': 0.8242, 'grad_norm': 1.436421275138855, 'learning_rate': 4.999373276080902e-06, 'epoch': 0.04}
  4%|▍         | 121/2906 [23:52<9:10:44, 11.87s/it]  4%|▍         | 122/2906 [24:04<9:07:40, 11.80s/it]                                                    {'loss': 0.7726, 'grad_norm': 1.468898892402649, 'learning_rate': 4.999309039838466e-06, 'epoch': 0.04}
  4%|▍         | 122/2906 [24:04<9:07:40, 11.80s/it]  4%|▍         | 123/2906 [24:15<9:06:25, 11.78s/it]                                                    {'loss': 0.8208, 'grad_norm': 1.5335010290145874, 'learning_rate': 4.999241670711944e-06, 'epoch': 0.04}
  4%|▍         | 123/2906 [24:15<9:06:25, 11.78s/it]  4%|▍         | 124/2906 [24:27<9:06:31, 11.79s/it]                                                    {'loss': 0.8446, 'grad_norm': 1.4624109268188477, 'learning_rate': 4.999171168785783e-06, 'epoch': 0.04}
  4%|▍         | 124/2906 [24:27<9:06:31, 11.79s/it]  4%|▍         | 125/2906 [24:39<9:03:15, 11.72s/it]                                                    {'loss': 0.8514, 'grad_norm': 1.4958165884017944, 'learning_rate': 4.999097534148358e-06, 'epoch': 0.04}
  4%|▍         | 125/2906 [24:39<9:03:15, 11.72s/it]  4%|▍         | 126/2906 [24:50<8:56:59, 11.59s/it]                                                    {'loss': 0.875, 'grad_norm': 1.841851830482483, 'learning_rate': 4.999020766891969e-06, 'epoch': 0.04}
  4%|▍         | 126/2906 [24:50<8:56:59, 11.59s/it]  4%|▍         | 127/2906 [25:02<8:56:10, 11.58s/it]                                                    {'loss': 0.8349, 'grad_norm': 1.7489218711853027, 'learning_rate': 4.998940867112844e-06, 'epoch': 0.04}
  4%|▍         | 127/2906 [25:02<8:56:10, 11.58s/it]  4%|▍         | 128/2906 [25:13<8:57:11, 11.60s/it]                                                    {'loss': 0.8343, 'grad_norm': 1.7162271738052368, 'learning_rate': 4.998857834911138e-06, 'epoch': 0.04}
  4%|▍         | 128/2906 [25:13<8:57:11, 11.60s/it]  4%|▍         | 129/2906 [25:25<8:59:41, 11.66s/it]                                                    {'loss': 0.8392, 'grad_norm': 1.3908721208572388, 'learning_rate': 4.998771670390931e-06, 'epoch': 0.04}
  4%|▍         | 129/2906 [25:25<8:59:41, 11.66s/it]  4%|▍         | 130/2906 [25:37<9:03:36, 11.75s/it]                                                    {'loss': 0.8488, 'grad_norm': 2.928842067718506, 'learning_rate': 4.998682373660232e-06, 'epoch': 0.04}
  4%|▍         | 130/2906 [25:37<9:03:36, 11.75s/it]  5%|▍         | 131/2906 [25:49<9:08:15, 11.85s/it]                                                    {'loss': 0.8098, 'grad_norm': 1.5660914182662964, 'learning_rate': 4.998589944830973e-06, 'epoch': 0.05}
  5%|▍         | 131/2906 [25:49<9:08:15, 11.85s/it]  5%|▍         | 132/2906 [26:01<9:08:27, 11.86s/it]                                                    {'loss': 0.7788, 'grad_norm': 1.5049266815185547, 'learning_rate': 4.998494384019013e-06, 'epoch': 0.05}
  5%|▍         | 132/2906 [26:01<9:08:27, 11.86s/it]  5%|▍         | 133/2906 [26:13<9:14:22, 12.00s/it]                                                    {'loss': 0.8712, 'grad_norm': 1.409360408782959, 'learning_rate': 4.998395691344138e-06, 'epoch': 0.05}
  5%|▍         | 133/2906 [26:13<9:14:22, 12.00s/it]  5%|▍         | 134/2906 [26:25<9:08:40, 11.88s/it]                                                    {'loss': 0.8347, 'grad_norm': 1.4581005573272705, 'learning_rate': 4.9982938669300604e-06, 'epoch': 0.05}
  5%|▍         | 134/2906 [26:25<9:08:40, 11.88s/it]  5%|▍         | 135/2906 [26:36<9:04:51, 11.80s/it]                                                    {'loss': 0.82, 'grad_norm': 1.508726716041565, 'learning_rate': 4.998188910904416e-06, 'epoch': 0.05}
  5%|▍         | 135/2906 [26:36<9:04:51, 11.80s/it]  5%|▍         | 136/2906 [26:48<9:05:17, 11.81s/it]                                                    {'loss': 0.8477, 'grad_norm': 2.3427696228027344, 'learning_rate': 4.998080823398766e-06, 'epoch': 0.05}
  5%|▍         | 136/2906 [26:48<9:05:17, 11.81s/it]  5%|▍         | 137/2906 [27:00<9:03:30, 11.78s/it]                                                    {'loss': 0.8499, 'grad_norm': 1.8026096820831299, 'learning_rate': 4.997969604548602e-06, 'epoch': 0.05}
  5%|▍         | 137/2906 [27:00<9:03:30, 11.78s/it]  5%|▍         | 138/2906 [27:12<9:01:23, 11.74s/it]                                                    {'loss': 0.8207, 'grad_norm': 1.7012224197387695, 'learning_rate': 4.997855254493332e-06, 'epoch': 0.05}
  5%|▍         | 138/2906 [27:12<9:01:23, 11.74s/it]  5%|▍         | 139/2906 [27:23<8:58:51, 11.68s/it]                                                    {'loss': 0.8309, 'grad_norm': 1.485289454460144, 'learning_rate': 4.997737773376298e-06, 'epoch': 0.05}
  5%|▍         | 139/2906 [27:23<8:58:51, 11.68s/it]  5%|▍         | 140/2906 [27:35<9:00:09, 11.72s/it]                                                    {'loss': 0.7609, 'grad_norm': 1.4446669816970825, 'learning_rate': 4.9976171613447595e-06, 'epoch': 0.05}
  5%|▍         | 140/2906 [27:35<9:00:09, 11.72s/it]  5%|▍         | 141/2906 [27:46<8:55:50, 11.63s/it]                                                    {'loss': 0.8812, 'grad_norm': 2.4187347888946533, 'learning_rate': 4.997493418549905e-06, 'epoch': 0.05}
  5%|▍         | 141/2906 [27:46<8:55:50, 11.63s/it]  5%|▍         | 142/2906 [27:58<8:58:56, 11.70s/it]                                                    {'loss': 0.7945, 'grad_norm': 1.584991455078125, 'learning_rate': 4.997366545146847e-06, 'epoch': 0.05}
  5%|▍         | 142/2906 [27:58<8:58:56, 11.70s/it]  5%|▍         | 143/2906 [28:10<8:58:10, 11.69s/it]                                                    {'loss': 0.7651, 'grad_norm': 2.4118599891662598, 'learning_rate': 4.99723654129462e-06, 'epoch': 0.05}
  5%|▍         | 143/2906 [28:10<8:58:10, 11.69s/it]  5%|▍         | 144/2906 [28:22<8:56:54, 11.66s/it]                                                    {'loss': 0.7958, 'grad_norm': 1.5628056526184082, 'learning_rate': 4.997103407156183e-06, 'epoch': 0.05}
  5%|▍         | 144/2906 [28:22<8:56:54, 11.66s/it]  5%|▍         | 145/2906 [28:33<8:59:09, 11.72s/it]                                                    {'loss': 0.8906, 'grad_norm': 1.9920929670333862, 'learning_rate': 4.996967142898423e-06, 'epoch': 0.05}
  5%|▍         | 145/2906 [28:33<8:59:09, 11.72s/it]  5%|▌         | 146/2906 [28:45<8:58:58, 11.72s/it]                                                    {'loss': 0.8652, 'grad_norm': 1.6311274766921997, 'learning_rate': 4.996827748692143e-06, 'epoch': 0.05}
  5%|▌         | 146/2906 [28:45<8:58:58, 11.72s/it]  5%|▌         | 147/2906 [28:57<8:58:26, 11.71s/it]                                                    {'loss': 0.8445, 'grad_norm': 1.6035910844802856, 'learning_rate': 4.996685224712077e-06, 'epoch': 0.05}
  5%|▌         | 147/2906 [28:57<8:58:26, 11.71s/it]  5%|▌         | 148/2906 [29:08<8:55:21, 11.65s/it]                                                    {'loss': 0.8723, 'grad_norm': 1.687173843383789, 'learning_rate': 4.996539571136877e-06, 'epoch': 0.05}
  5%|▌         | 148/2906 [29:08<8:55:21, 11.65s/it]  5%|▌         | 149/2906 [29:20<8:53:26, 11.61s/it]                                                    {'loss': 0.805, 'grad_norm': 1.3859847784042358, 'learning_rate': 4.99639078814912e-06, 'epoch': 0.05}
  5%|▌         | 149/2906 [29:20<8:53:26, 11.61s/it]  5%|▌         | 150/2906 [29:32<9:01:09, 11.78s/it]                                                    {'loss': 0.8081, 'grad_norm': 1.5253664255142212, 'learning_rate': 4.996238875935307e-06, 'epoch': 0.05}
  5%|▌         | 150/2906 [29:32<9:01:09, 11.78s/it]  5%|▌         | 151/2906 [29:44<8:59:57, 11.76s/it]                                                    {'loss': 0.8807, 'grad_norm': 1.6775808334350586, 'learning_rate': 4.996083834685858e-06, 'epoch': 0.05}
  5%|▌         | 151/2906 [29:44<8:59:57, 11.76s/it]  5%|▌         | 152/2906 [29:56<9:02:32, 11.82s/it]                                                    {'loss': 0.8198, 'grad_norm': 1.5134385824203491, 'learning_rate': 4.995925664595118e-06, 'epoch': 0.05}
  5%|▌         | 152/2906 [29:56<9:02:32, 11.82s/it]  5%|▌         | 153/2906 [30:07<9:02:37, 11.83s/it]                                                    {'loss': 0.834, 'grad_norm': 1.3876450061798096, 'learning_rate': 4.995764365861354e-06, 'epoch': 0.05}
  5%|▌         | 153/2906 [30:07<9:02:37, 11.83s/it]  5%|▌         | 154/2906 [30:19<8:54:31, 11.65s/it]                                                    {'loss': 0.8466, 'grad_norm': 1.346498727798462, 'learning_rate': 4.995599938686753e-06, 'epoch': 0.05}
  5%|▌         | 154/2906 [30:19<8:54:31, 11.65s/it]  5%|▌         | 155/2906 [30:31<8:57:31, 11.72s/it]                                                    {'loss': 0.8195, 'grad_norm': 1.4462045431137085, 'learning_rate': 4.9954323832774235e-06, 'epoch': 0.05}
  5%|▌         | 155/2906 [30:31<8:57:31, 11.72s/it]  5%|▌         | 156/2906 [30:43<9:00:59, 11.80s/it]                                                    {'loss': 0.8411, 'grad_norm': 1.4402368068695068, 'learning_rate': 4.995261699843399e-06, 'epoch': 0.05}
  5%|▌         | 156/2906 [30:43<9:00:59, 11.80s/it]  5%|▌         | 157/2906 [30:54<8:55:53, 11.70s/it]                                                    {'loss': 0.8015, 'grad_norm': 1.3039556741714478, 'learning_rate': 4.995087888598629e-06, 'epoch': 0.05}
  5%|▌         | 157/2906 [30:54<8:55:53, 11.70s/it]  5%|▌         | 158/2906 [31:06<8:54:45, 11.68s/it]                                                    {'loss': 0.8606, 'grad_norm': 1.486351490020752, 'learning_rate': 4.994910949760986e-06, 'epoch': 0.05}
  5%|▌         | 158/2906 [31:06<8:54:45, 11.68s/it]  5%|▌         | 159/2906 [31:17<8:48:59, 11.55s/it]                                                    {'loss': 0.8164, 'grad_norm': 1.6211388111114502, 'learning_rate': 4.994730883552263e-06, 'epoch': 0.05}
  5%|▌         | 159/2906 [31:17<8:48:59, 11.55s/it]  6%|▌         | 160/2906 [31:29<8:49:08, 11.56s/it]                                                    {'loss': 0.8587, 'grad_norm': 1.3181716203689575, 'learning_rate': 4.9945476901981746e-06, 'epoch': 0.06}
  6%|▌         | 160/2906 [31:29<8:49:08, 11.56s/it]  6%|▌         | 161/2906 [31:40<8:47:21, 11.53s/it]                                                    {'loss': 0.8194, 'grad_norm': 1.4564844369888306, 'learning_rate': 4.994361369928352e-06, 'epoch': 0.06}
  6%|▌         | 161/2906 [31:40<8:47:21, 11.53s/it]  6%|▌         | 162/2906 [31:52<8:48:01, 11.55s/it]                                                    {'loss': 0.8581, 'grad_norm': 1.4716190099716187, 'learning_rate': 4.994171922976349e-06, 'epoch': 0.06}
  6%|▌         | 162/2906 [31:52<8:48:01, 11.55s/it]  6%|▌         | 163/2906 [32:03<8:47:16, 11.53s/it]                                                    {'loss': 0.8077, 'grad_norm': 1.5290424823760986, 'learning_rate': 4.993979349579635e-06, 'epoch': 0.06}
  6%|▌         | 163/2906 [32:03<8:47:16, 11.53s/it]  6%|▌         | 164/2906 [32:15<8:47:55, 11.55s/it]                                                    {'loss': 0.8221, 'grad_norm': 1.507839322090149, 'learning_rate': 4.993783649979604e-06, 'epoch': 0.06}
  6%|▌         | 164/2906 [32:15<8:47:55, 11.55s/it]  6%|▌         | 165/2906 [32:27<8:52:35, 11.66s/it]                                                    {'loss': 0.8576, 'grad_norm': 1.376997947692871, 'learning_rate': 4.9935848244215615e-06, 'epoch': 0.06}
  6%|▌         | 165/2906 [32:27<8:52:35, 11.66s/it]  6%|▌         | 166/2906 [32:38<8:48:55, 11.58s/it]                                                    {'loss': 0.806, 'grad_norm': 1.6096755266189575, 'learning_rate': 4.993382873154739e-06, 'epoch': 0.06}
  6%|▌         | 166/2906 [32:38<8:48:55, 11.58s/it]  6%|▌         | 167/2906 [32:50<8:49:33, 11.60s/it]                                                    {'loss': 0.7616, 'grad_norm': 1.3857983350753784, 'learning_rate': 4.993177796432281e-06, 'epoch': 0.06}
  6%|▌         | 167/2906 [32:50<8:49:33, 11.60s/it]  6%|▌         | 168/2906 [33:01<8:50:57, 11.64s/it]                                                    {'loss': 0.8431, 'grad_norm': 1.4067729711532593, 'learning_rate': 4.992969594511251e-06, 'epoch': 0.06}
  6%|▌         | 168/2906 [33:01<8:50:57, 11.64s/it]  6%|▌         | 169/2906 [33:13<8:50:34, 11.63s/it]                                                    {'loss': 0.8248, 'grad_norm': 1.5531072616577148, 'learning_rate': 4.99275826765263e-06, 'epoch': 0.06}
  6%|▌         | 169/2906 [33:13<8:50:34, 11.63s/it]  6%|▌         | 170/2906 [33:25<8:50:42, 11.64s/it]                                                    {'loss': 0.8046, 'grad_norm': 1.539242148399353, 'learning_rate': 4.992543816121317e-06, 'epoch': 0.06}
  6%|▌         | 170/2906 [33:25<8:50:42, 11.64s/it]  6%|▌         | 171/2906 [33:36<8:51:06, 11.65s/it]                                                    {'loss': 0.8855, 'grad_norm': 3.143825054168701, 'learning_rate': 4.992326240186127e-06, 'epoch': 0.06}
  6%|▌         | 171/2906 [33:36<8:51:06, 11.65s/it]  6%|▌         | 172/2906 [33:48<8:48:54, 11.61s/it]                                                    {'loss': 0.8027, 'grad_norm': 1.441386342048645, 'learning_rate': 4.99210554011979e-06, 'epoch': 0.06}
  6%|▌         | 172/2906 [33:48<8:48:54, 11.61s/it]  6%|▌         | 173/2906 [34:00<8:53:12, 11.71s/it]                                                    {'loss': 0.8308, 'grad_norm': 1.3412443399429321, 'learning_rate': 4.991881716198955e-06, 'epoch': 0.06}
  6%|▌         | 173/2906 [34:00<8:53:12, 11.71s/it]  6%|▌         | 174/2906 [34:11<8:51:34, 11.67s/it]                                                    {'loss': 0.8419, 'grad_norm': 1.4673618078231812, 'learning_rate': 4.991654768704185e-06, 'epoch': 0.06}
  6%|▌         | 174/2906 [34:11<8:51:34, 11.67s/it]  6%|▌         | 175/2906 [34:23<8:52:07, 11.69s/it]                                                    {'loss': 0.8628, 'grad_norm': 1.9011980295181274, 'learning_rate': 4.9914246979199586e-06, 'epoch': 0.06}
  6%|▌         | 175/2906 [34:23<8:52:07, 11.69s/it]  6%|▌         | 176/2906 [34:35<8:54:52, 11.76s/it]                                                    {'loss': 0.8475, 'grad_norm': 1.4851763248443604, 'learning_rate': 4.99119150413467e-06, 'epoch': 0.06}
  6%|▌         | 176/2906 [34:35<8:54:52, 11.76s/it]  6%|▌         | 177/2906 [34:47<8:55:00, 11.76s/it]                                                    {'loss': 0.7335, 'grad_norm': 1.3227206468582153, 'learning_rate': 4.990955187640627e-06, 'epoch': 0.06}
  6%|▌         | 177/2906 [34:47<8:55:00, 11.76s/it]  6%|▌         | 178/2906 [34:59<8:59:27, 11.86s/it]                                                    {'loss': 0.7739, 'grad_norm': 1.3707131147384644, 'learning_rate': 4.990715748734052e-06, 'epoch': 0.06}
  6%|▌         | 178/2906 [34:59<8:59:27, 11.86s/it]  6%|▌         | 179/2906 [35:10<8:52:51, 11.72s/it]                                                    {'loss': 0.8156, 'grad_norm': 1.412406086921692, 'learning_rate': 4.990473187715082e-06, 'epoch': 0.06}
  6%|▌         | 179/2906 [35:10<8:52:51, 11.72s/it]  6%|▌         | 180/2906 [35:22<8:53:58, 11.75s/it]                                                    {'loss': 0.7917, 'grad_norm': 1.5439528226852417, 'learning_rate': 4.990227504887768e-06, 'epoch': 0.06}
  6%|▌         | 180/2906 [35:22<8:53:58, 11.75s/it]  6%|▌         | 181/2906 [35:34<8:52:19, 11.72s/it]                                                    {'loss': 0.7832, 'grad_norm': 1.3202565908432007, 'learning_rate': 4.989978700560073e-06, 'epoch': 0.06}
  6%|▌         | 181/2906 [35:34<8:52:19, 11.72s/it]  6%|▋         | 182/2906 [35:45<8:50:30, 11.69s/it]                                                    {'loss': 0.8077, 'grad_norm': 1.5586522817611694, 'learning_rate': 4.989726775043873e-06, 'epoch': 0.06}
  6%|▋         | 182/2906 [35:45<8:50:30, 11.69s/it]  6%|▋         | 183/2906 [35:57<8:45:46, 11.59s/it]                                                    {'loss': 0.7951, 'grad_norm': 1.3846094608306885, 'learning_rate': 4.9894717286549566e-06, 'epoch': 0.06}
  6%|▋         | 183/2906 [35:57<8:45:46, 11.59s/it]  6%|▋         | 184/2906 [36:08<8:48:13, 11.64s/it]                                                    {'loss': 0.8425, 'grad_norm': 1.3077147006988525, 'learning_rate': 4.989213561713025e-06, 'epoch': 0.06}
  6%|▋         | 184/2906 [36:08<8:48:13, 11.64s/it]  6%|▋         | 185/2906 [36:20<8:43:52, 11.55s/it]                                                    {'loss': 0.8696, 'grad_norm': 1.982406497001648, 'learning_rate': 4.98895227454169e-06, 'epoch': 0.06}
  6%|▋         | 185/2906 [36:20<8:43:52, 11.55s/it]  6%|▋         | 186/2906 [36:31<8:45:04, 11.58s/it]                                                    {'loss': 0.8193, 'grad_norm': 1.6021101474761963, 'learning_rate': 4.988687867468475e-06, 'epoch': 0.06}
  6%|▋         | 186/2906 [36:31<8:45:04, 11.58s/it]  6%|▋         | 187/2906 [36:43<8:42:52, 11.54s/it]                                                    {'loss': 0.8712, 'grad_norm': 1.4928785562515259, 'learning_rate': 4.9884203408248145e-06, 'epoch': 0.06}
  6%|▋         | 187/2906 [36:43<8:42:52, 11.54s/it]  6%|▋         | 188/2906 [36:55<8:45:43, 11.61s/it]                                                    {'loss': 0.8189, 'grad_norm': 1.6317436695098877, 'learning_rate': 4.9881496949460534e-06, 'epoch': 0.06}
  6%|▋         | 188/2906 [36:55<8:45:43, 11.61s/it]  7%|▋         | 189/2906 [37:06<8:48:27, 11.67s/it]                                                    {'loss': 0.8017, 'grad_norm': 1.5691334009170532, 'learning_rate': 4.987875930171446e-06, 'epoch': 0.07}
  7%|▋         | 189/2906 [37:06<8:48:27, 11.67s/it]  7%|▋         | 190/2906 [37:18<8:50:59, 11.73s/it]                                                    {'loss': 0.892, 'grad_norm': 1.3795839548110962, 'learning_rate': 4.987599046844157e-06, 'epoch': 0.07}
  7%|▋         | 190/2906 [37:18<8:50:59, 11.73s/it]  7%|▋         | 191/2906 [37:30<8:48:07, 11.67s/it]                                                    {'loss': 0.8802, 'grad_norm': 1.4920238256454468, 'learning_rate': 4.987319045311259e-06, 'epoch': 0.07}
  7%|▋         | 191/2906 [37:30<8:48:07, 11.67s/it]  7%|▋         | 192/2906 [37:41<8:46:35, 11.64s/it]                                                    {'loss': 0.8122, 'grad_norm': 1.498570442199707, 'learning_rate': 4.987035925923735e-06, 'epoch': 0.07}
  7%|▋         | 192/2906 [37:41<8:46:35, 11.64s/it]  7%|▋         | 193/2906 [37:53<8:49:57, 11.72s/it]                                                    {'loss': 0.821, 'grad_norm': 1.5525317192077637, 'learning_rate': 4.9867496890364734e-06, 'epoch': 0.07}
  7%|▋         | 193/2906 [37:53<8:49:57, 11.72s/it]  7%|▋         | 194/2906 [38:05<8:52:17, 11.78s/it]                                                    {'loss': 0.8044, 'grad_norm': 1.358844518661499, 'learning_rate': 4.986460335008273e-06, 'epoch': 0.07}
  7%|▋         | 194/2906 [38:05<8:52:17, 11.78s/it]  7%|▋         | 195/2906 [38:17<8:53:32, 11.81s/it]                                                    {'loss': 0.8036, 'grad_norm': 1.4061609506607056, 'learning_rate': 4.98616786420184e-06, 'epoch': 0.07}
  7%|▋         | 195/2906 [38:17<8:53:32, 11.81s/it]  7%|▋         | 196/2906 [38:29<8:59:04, 11.94s/it]                                                    {'loss': 0.7925, 'grad_norm': 1.3198193311691284, 'learning_rate': 4.985872276983785e-06, 'epoch': 0.07}
  7%|▋         | 196/2906 [38:29<8:59:04, 11.94s/it]  7%|▋         | 197/2906 [38:41<8:50:29, 11.75s/it]                                                    {'loss': 0.8728, 'grad_norm': 4.794192790985107, 'learning_rate': 4.985573573724628e-06, 'epoch': 0.07}
  7%|▋         | 197/2906 [38:41<8:50:29, 11.75s/it]  7%|▋         | 198/2906 [38:52<8:49:55, 11.74s/it]                                                    {'loss': 0.8216, 'grad_norm': 1.453120470046997, 'learning_rate': 4.985271754798793e-06, 'epoch': 0.07}
  7%|▋         | 198/2906 [38:52<8:49:55, 11.74s/it]  7%|▋         | 199/2906 [39:04<8:48:54, 11.72s/it]                                                    {'loss': 0.8251, 'grad_norm': 1.7021498680114746, 'learning_rate': 4.98496682058461e-06, 'epoch': 0.07}
  7%|▋         | 199/2906 [39:04<8:48:54, 11.72s/it]  7%|▋         | 200/2906 [39:16<8:45:24, 11.65s/it]                                                    {'loss': 0.8449, 'grad_norm': 1.3536841869354248, 'learning_rate': 4.984658771464314e-06, 'epoch': 0.07}
  7%|▋         | 200/2906 [39:16<8:45:24, 11.65s/it]  7%|▋         | 201/2906 [39:27<8:48:58, 11.73s/it]                                                    {'loss': 0.7691, 'grad_norm': 1.3433258533477783, 'learning_rate': 4.984347607824045e-06, 'epoch': 0.07}
  7%|▋         | 201/2906 [39:27<8:48:58, 11.73s/it]  7%|▋         | 202/2906 [39:39<8:46:36, 11.69s/it]                                                    {'loss': 0.8764, 'grad_norm': 1.5950196981430054, 'learning_rate': 4.984033330053846e-06, 'epoch': 0.07}
  7%|▋         | 202/2906 [39:39<8:46:36, 11.69s/it]  7%|▋         | 203/2906 [39:51<8:49:38, 11.76s/it]                                                    {'loss': 0.8632, 'grad_norm': 1.3219976425170898, 'learning_rate': 4.9837159385476655e-06, 'epoch': 0.07}
  7%|▋         | 203/2906 [39:51<8:49:38, 11.76s/it]  7%|▋         | 204/2906 [40:02<8:44:26, 11.65s/it]                                                    {'loss': 0.8627, 'grad_norm': 3.583430767059326, 'learning_rate': 4.983395433703351e-06, 'epoch': 0.07}
  7%|▋         | 204/2906 [40:02<8:44:26, 11.65s/it]  7%|▋         | 205/2906 [40:14<8:49:09, 11.75s/it]                                                    {'loss': 0.8407, 'grad_norm': 2.3629744052886963, 'learning_rate': 4.983071815922659e-06, 'epoch': 0.07}
  7%|▋         | 205/2906 [40:14<8:49:09, 11.75s/it]  7%|▋         | 206/2906 [40:26<8:45:26, 11.68s/it]                                                    {'loss': 0.813, 'grad_norm': 1.3206595182418823, 'learning_rate': 4.9827450856112416e-06, 'epoch': 0.07}
  7%|▋         | 206/2906 [40:26<8:45:26, 11.68s/it]  7%|▋         | 207/2906 [40:38<8:52:54, 11.85s/it]                                                    {'loss': 0.822, 'grad_norm': 1.325393795967102, 'learning_rate': 4.9824152431786565e-06, 'epoch': 0.07}
  7%|▋         | 207/2906 [40:38<8:52:54, 11.85s/it]  7%|▋         | 208/2906 [40:50<8:50:04, 11.79s/it]                                                    {'loss': 0.8279, 'grad_norm': 1.3772261142730713, 'learning_rate': 4.982082289038361e-06, 'epoch': 0.07}
  7%|▋         | 208/2906 [40:50<8:50:04, 11.79s/it]  7%|▋         | 209/2906 [41:02<8:49:29, 11.78s/it]                                                    {'loss': 0.7946, 'grad_norm': 1.3469152450561523, 'learning_rate': 4.981746223607713e-06, 'epoch': 0.07}
  7%|▋         | 209/2906 [41:02<8:49:29, 11.78s/it]  7%|▋         | 210/2906 [41:13<8:48:00, 11.75s/it]                                                    {'loss': 0.8462, 'grad_norm': 1.2398840188980103, 'learning_rate': 4.981407047307971e-06, 'epoch': 0.07}
  7%|▋         | 210/2906 [41:13<8:48:00, 11.75s/it]  7%|▋         | 211/2906 [41:25<8:49:44, 11.79s/it]                                                    {'loss': 0.8129, 'grad_norm': 1.27407968044281, 'learning_rate': 4.981064760564292e-06, 'epoch': 0.07}
  7%|▋         | 211/2906 [41:25<8:49:44, 11.79s/it]  7%|▋         | 212/2906 [41:37<8:47:08, 11.74s/it]                                                    {'loss': 0.7851, 'grad_norm': 1.179007887840271, 'learning_rate': 4.980719363805733e-06, 'epoch': 0.07}
  7%|▋         | 212/2906 [41:37<8:47:08, 11.74s/it]  7%|▋         | 213/2906 [41:48<8:46:01, 11.72s/it]                                                    {'loss': 0.7974, 'grad_norm': 1.2284822463989258, 'learning_rate': 4.9803708574652475e-06, 'epoch': 0.07}
  7%|▋         | 213/2906 [41:48<8:46:01, 11.72s/it]  7%|▋         | 214/2906 [42:00<8:46:03, 11.73s/it]                                                    {'loss': 0.8425, 'grad_norm': 1.2418866157531738, 'learning_rate': 4.9800192419796906e-06, 'epoch': 0.07}
  7%|▋         | 214/2906 [42:00<8:46:03, 11.73s/it]  7%|▋         | 215/2906 [42:11<8:41:02, 11.62s/it]                                                    {'loss': 0.8556, 'grad_norm': 1.412905216217041, 'learning_rate': 4.979664517789811e-06, 'epoch': 0.07}
  7%|▋         | 215/2906 [42:12<8:41:02, 11.62s/it]  7%|▋         | 216/2906 [42:23<8:45:43, 11.73s/it]                                                    {'loss': 0.8079, 'grad_norm': 1.225096344947815, 'learning_rate': 4.9793066853402535e-06, 'epoch': 0.07}
  7%|▋         | 216/2906 [42:23<8:45:43, 11.73s/it]  7%|▋         | 217/2906 [42:35<8:46:56, 11.76s/it]                                                    {'loss': 0.8475, 'grad_norm': 1.3743207454681396, 'learning_rate': 4.978945745079565e-06, 'epoch': 0.07}
  7%|▋         | 217/2906 [42:35<8:46:56, 11.76s/it]  8%|▊         | 218/2906 [42:48<8:53:19, 11.90s/it]                                                    {'loss': 0.8451, 'grad_norm': 1.34537935256958, 'learning_rate': 4.978581697460182e-06, 'epoch': 0.08}
  8%|▊         | 218/2906 [42:48<8:53:19, 11.90s/it]  8%|▊         | 219/2906 [42:59<8:46:20, 11.75s/it]                                                    {'loss': 0.813, 'grad_norm': 1.2881971597671509, 'learning_rate': 4.978214542938438e-06, 'epoch': 0.08}
  8%|▊         | 219/2906 [42:59<8:46:20, 11.75s/it]  8%|▊         | 220/2906 [43:11<8:47:11, 11.78s/it]                                                    {'loss': 0.8303, 'grad_norm': 1.3540658950805664, 'learning_rate': 4.977844281974562e-06, 'epoch': 0.08}
  8%|▊         | 220/2906 [43:11<8:47:11, 11.78s/it]  8%|▊         | 221/2906 [43:23<8:48:38, 11.81s/it]                                                    {'loss': 0.8137, 'grad_norm': 1.3010082244873047, 'learning_rate': 4.977470915032676e-06, 'epoch': 0.08}
  8%|▊         | 221/2906 [43:23<8:48:38, 11.81s/it]  8%|▊         | 222/2906 [43:35<8:48:55, 11.82s/it]                                                    {'loss': 0.8095, 'grad_norm': 1.2524338960647583, 'learning_rate': 4.9770944425807945e-06, 'epoch': 0.08}
  8%|▊         | 222/2906 [43:35<8:48:55, 11.82s/it]  8%|▊         | 223/2906 [43:47<8:52:50, 11.92s/it]                                                    {'loss': 0.7509, 'grad_norm': 1.3009905815124512, 'learning_rate': 4.976714865090827e-06, 'epoch': 0.08}
  8%|▊         | 223/2906 [43:47<8:52:50, 11.92s/it]  8%|▊         | 224/2906 [43:59<8:54:28, 11.96s/it]                                                    {'loss': 0.7962, 'grad_norm': 1.248295783996582, 'learning_rate': 4.9763321830385735e-06, 'epoch': 0.08}
  8%|▊         | 224/2906 [43:59<8:54:28, 11.96s/it]  8%|▊         | 225/2906 [44:11<8:54:33, 11.96s/it]                                                    {'loss': 0.7772, 'grad_norm': 1.238142490386963, 'learning_rate': 4.975946396903727e-06, 'epoch': 0.08}
  8%|▊         | 225/2906 [44:11<8:54:33, 11.96s/it]  8%|▊         | 226/2906 [44:22<8:44:40, 11.75s/it]                                                    {'loss': 0.8273, 'grad_norm': 1.2725423574447632, 'learning_rate': 4.975557507169868e-06, 'epoch': 0.08}
  8%|▊         | 226/2906 [44:22<8:44:40, 11.75s/it]  8%|▊         | 227/2906 [44:33<8:39:26, 11.63s/it]                                                    {'loss': 0.7999, 'grad_norm': 1.275458574295044, 'learning_rate': 4.9751655143244715e-06, 'epoch': 0.08}
  8%|▊         | 227/2906 [44:33<8:39:26, 11.63s/it]  8%|▊         | 228/2906 [44:45<8:34:07, 11.52s/it]                                                    {'loss': 0.8091, 'grad_norm': 1.23897385597229, 'learning_rate': 4.974770418858901e-06, 'epoch': 0.08}
  8%|▊         | 228/2906 [44:45<8:34:07, 11.52s/it]  8%|▊         | 229/2906 [44:56<8:32:20, 11.48s/it]                                                    {'loss': 0.8144, 'grad_norm': 1.352178931236267, 'learning_rate': 4.974372221268408e-06, 'epoch': 0.08}
  8%|▊         | 229/2906 [44:56<8:32:20, 11.48s/it]  8%|▊         | 230/2906 [45:08<8:33:50, 11.52s/it]                                                    {'loss': 0.8148, 'grad_norm': 1.2680199146270752, 'learning_rate': 4.973970922052132e-06, 'epoch': 0.08}
  8%|▊         | 230/2906 [45:08<8:33:50, 11.52s/it]  8%|▊         | 231/2906 [45:19<8:36:50, 11.59s/it]                                                    {'loss': 0.821, 'grad_norm': 1.279934287071228, 'learning_rate': 4.973566521713104e-06, 'epoch': 0.08}
  8%|▊         | 231/2906 [45:19<8:36:50, 11.59s/it]  8%|▊         | 232/2906 [45:31<8:37:46, 11.62s/it]                                                    {'loss': 0.8242, 'grad_norm': 1.385524034500122, 'learning_rate': 4.973159020758238e-06, 'epoch': 0.08}
  8%|▊         | 232/2906 [45:31<8:37:46, 11.62s/it]  8%|▊         | 233/2906 [45:44<8:55:57, 12.03s/it]                                                    {'loss': 0.7844, 'grad_norm': 1.3082879781723022, 'learning_rate': 4.972748419698337e-06, 'epoch': 0.08}
  8%|▊         | 233/2906 [45:44<8:55:57, 12.03s/it]  8%|▊         | 234/2906 [45:56<8:51:06, 11.93s/it]                                                    {'loss': 0.7775, 'grad_norm': 1.3100677728652954, 'learning_rate': 4.972334719048091e-06, 'epoch': 0.08}
  8%|▊         | 234/2906 [45:56<8:51:06, 11.93s/it]  8%|▊         | 235/2906 [46:08<8:52:38, 11.97s/it]                                                    {'loss': 0.7839, 'grad_norm': 1.3322652578353882, 'learning_rate': 4.971917919326071e-06, 'epoch': 0.08}
  8%|▊         | 235/2906 [46:08<8:52:38, 11.97s/it]  8%|▊         | 236/2906 [46:19<8:49:07, 11.89s/it]                                                    {'loss': 0.8149, 'grad_norm': 1.328202247619629, 'learning_rate': 4.971498021054737e-06, 'epoch': 0.08}
  8%|▊         | 236/2906 [46:19<8:49:07, 11.89s/it]  8%|▊         | 237/2906 [46:31<8:41:58, 11.73s/it]                                                    {'loss': 0.7859, 'grad_norm': 1.3557490110397339, 'learning_rate': 4.971075024760432e-06, 'epoch': 0.08}
  8%|▊         | 237/2906 [46:31<8:41:58, 11.73s/it]  8%|▊         | 238/2906 [46:43<8:45:52, 11.83s/it]                                                    {'loss': 0.7756, 'grad_norm': 1.4217681884765625, 'learning_rate': 4.970648930973381e-06, 'epoch': 0.08}
  8%|▊         | 238/2906 [46:43<8:45:52, 11.83s/it]  8%|▊         | 239/2906 [46:55<8:48:10, 11.88s/it]                                                    {'loss': 0.8188, 'grad_norm': 1.3465139865875244, 'learning_rate': 4.970219740227693e-06, 'epoch': 0.08}
  8%|▊         | 239/2906 [46:55<8:48:10, 11.88s/it]  8%|▊         | 240/2906 [47:06<8:43:19, 11.78s/it]                                                    {'loss': 0.826, 'grad_norm': 1.3830487728118896, 'learning_rate': 4.969787453061359e-06, 'epoch': 0.08}
  8%|▊         | 240/2906 [47:06<8:43:19, 11.78s/it]  8%|▊         | 241/2906 [47:18<8:44:37, 11.81s/it]                                                    {'loss': 0.8333, 'grad_norm': 1.331875205039978, 'learning_rate': 4.96935207001625e-06, 'epoch': 0.08}
  8%|▊         | 241/2906 [47:18<8:44:37, 11.81s/it]  8%|▊         | 242/2906 [47:31<8:50:24, 11.95s/it]                                                    {'loss': 0.8053, 'grad_norm': 1.4425686597824097, 'learning_rate': 4.968913591638119e-06, 'epoch': 0.08}
  8%|▊         | 242/2906 [47:31<8:50:24, 11.95s/it]  8%|▊         | 243/2906 [47:42<8:41:48, 11.76s/it]                                                    {'loss': 0.8269, 'grad_norm': 1.2675325870513916, 'learning_rate': 4.968472018476599e-06, 'epoch': 0.08}
  8%|▊         | 243/2906 [47:42<8:41:48, 11.76s/it]  8%|▊         | 244/2906 [47:54<8:44:44, 11.83s/it]                                                    {'loss': 0.8614, 'grad_norm': 1.3175251483917236, 'learning_rate': 4.9680273510852025e-06, 'epoch': 0.08}
  8%|▊         | 244/2906 [47:54<8:44:44, 11.83s/it]  8%|▊         | 245/2906 [48:06<8:46:14, 11.87s/it]                                                    {'loss': 0.8683, 'grad_norm': 1.3374550342559814, 'learning_rate': 4.967579590021319e-06, 'epoch': 0.08}
  8%|▊         | 245/2906 [48:06<8:46:14, 11.87s/it]  8%|▊         | 246/2906 [48:18<8:46:50, 11.88s/it]                                                    {'loss': 0.8001, 'grad_norm': 1.3614252805709839, 'learning_rate': 4.967128735846218e-06, 'epoch': 0.08}
  8%|▊         | 246/2906 [48:18<8:46:50, 11.88s/it]  8%|▊         | 247/2906 [48:30<8:47:14, 11.90s/it]                                                    {'loss': 0.8034, 'grad_norm': 1.3521606922149658, 'learning_rate': 4.966674789125044e-06, 'epoch': 0.08}
  8%|▊         | 247/2906 [48:30<8:47:14, 11.90s/it]  9%|▊         | 248/2906 [48:42<8:46:08, 11.88s/it]                                                    {'loss': 0.8765, 'grad_norm': 1.3250861167907715, 'learning_rate': 4.96621775042682e-06, 'epoch': 0.09}
  9%|▊         | 248/2906 [48:42<8:46:08, 11.88s/it]  9%|▊         | 249/2906 [48:53<8:38:30, 11.71s/it]                                                    {'loss': 0.8033, 'grad_norm': 1.3943462371826172, 'learning_rate': 4.965757620324445e-06, 'epoch': 0.09}
  9%|▊         | 249/2906 [48:53<8:38:30, 11.71s/it]  9%|▊         | 250/2906 [49:04<8:33:53, 11.61s/it]                                                    {'loss': 0.9147, 'grad_norm': 1.3315695524215698, 'learning_rate': 4.965294399394691e-06, 'epoch': 0.09}
  9%|▊         | 250/2906 [49:04<8:33:53, 11.61s/it]  9%|▊         | 251/2906 [49:16<8:31:03, 11.55s/it]                                                    {'loss': 0.8366, 'grad_norm': 1.2908011674880981, 'learning_rate': 4.9648280882182056e-06, 'epoch': 0.09}
  9%|▊         | 251/2906 [49:16<8:31:03, 11.55s/it]  9%|▊         | 252/2906 [49:27<8:32:00, 11.58s/it]                                                    {'loss': 0.8097, 'grad_norm': 1.2835824489593506, 'learning_rate': 4.96435868737951e-06, 'epoch': 0.09}
  9%|▊         | 252/2906 [49:27<8:32:00, 11.58s/it]  9%|▊         | 253/2906 [49:38<8:25:03, 11.42s/it]                                                    {'loss': 0.8471, 'grad_norm': 1.329115867614746, 'learning_rate': 4.963886197466998e-06, 'epoch': 0.09}
  9%|▊         | 253/2906 [49:38<8:25:03, 11.42s/it]  9%|▊         | 254/2906 [49:50<8:29:47, 11.53s/it]                                                    {'loss': 0.7929, 'grad_norm': 1.2486459016799927, 'learning_rate': 4.963410619072936e-06, 'epoch': 0.09}
  9%|▊         | 254/2906 [49:50<8:29:47, 11.53s/it]  9%|▉         | 255/2906 [50:02<8:32:42, 11.60s/it]                                                    {'loss': 0.8494, 'grad_norm': 1.395290732383728, 'learning_rate': 4.962931952793461e-06, 'epoch': 0.09}
  9%|▉         | 255/2906 [50:02<8:32:42, 11.60s/it]  9%|▉         | 256/2906 [50:13<8:29:39, 11.54s/it]                                                    {'loss': 0.9132, 'grad_norm': 1.3451261520385742, 'learning_rate': 4.962450199228583e-06, 'epoch': 0.09}
  9%|▉         | 256/2906 [50:13<8:29:39, 11.54s/it]  9%|▉         | 257/2906 [50:25<8:26:54, 11.48s/it]                                                    {'loss': 0.8591, 'grad_norm': 1.302500605583191, 'learning_rate': 4.961965358982177e-06, 'epoch': 0.09}
  9%|▉         | 257/2906 [50:25<8:26:54, 11.48s/it]  9%|▉         | 258/2906 [50:36<8:25:02, 11.44s/it]                                                    {'loss': 0.7663, 'grad_norm': 1.3564952611923218, 'learning_rate': 4.961477432661993e-06, 'epoch': 0.09}
  9%|▉         | 258/2906 [50:36<8:25:02, 11.44s/it]  9%|▉         | 259/2906 [50:48<8:27:56, 11.51s/it]                                                    {'loss': 0.8439, 'grad_norm': 1.3373945951461792, 'learning_rate': 4.960986420879645e-06, 'epoch': 0.09}
  9%|▉         | 259/2906 [50:48<8:27:56, 11.51s/it]  9%|▉         | 260/2906 [50:59<8:28:17, 11.53s/it]                                                    {'loss': 0.7893, 'grad_norm': 1.3138821125030518, 'learning_rate': 4.960492324250618e-06, 'epoch': 0.09}
  9%|▉         | 260/2906 [50:59<8:28:17, 11.53s/it]  9%|▉         | 261/2906 [51:10<8:24:36, 11.45s/it]                                                    {'loss': 0.831, 'grad_norm': 1.3329519033432007, 'learning_rate': 4.9599951433942614e-06, 'epoch': 0.09}
  9%|▉         | 261/2906 [51:10<8:24:36, 11.45s/it]  9%|▉         | 262/2906 [51:22<8:26:08, 11.49s/it]                                                    {'loss': 0.8224, 'grad_norm': 1.416269063949585, 'learning_rate': 4.959494878933792e-06, 'epoch': 0.09}
  9%|▉         | 262/2906 [51:22<8:26:08, 11.49s/it]  9%|▉         | 263/2906 [51:34<8:26:04, 11.49s/it]                                                    {'loss': 0.7969, 'grad_norm': 1.2847177982330322, 'learning_rate': 4.958991531496289e-06, 'epoch': 0.09}
  9%|▉         | 263/2906 [51:34<8:26:04, 11.49s/it]  9%|▉         | 264/2906 [51:45<8:29:32, 11.57s/it]                                                    {'loss': 0.7802, 'grad_norm': 1.3020210266113281, 'learning_rate': 4.958485101712701e-06, 'epoch': 0.09}
  9%|▉         | 264/2906 [51:45<8:29:32, 11.57s/it]  9%|▉         | 265/2906 [51:57<8:30:15, 11.59s/it]                                                    {'loss': 0.753, 'grad_norm': 1.1807832717895508, 'learning_rate': 4.957975590217836e-06, 'epoch': 0.09}
  9%|▉         | 265/2906 [51:57<8:30:15, 11.59s/it]  9%|▉         | 266/2906 [52:09<8:30:19, 11.60s/it]                                                    {'loss': 0.8016, 'grad_norm': 1.2484524250030518, 'learning_rate': 4.957462997650369e-06, 'epoch': 0.09}
  9%|▉         | 266/2906 [52:09<8:30:19, 11.60s/it]  9%|▉         | 267/2906 [52:20<8:31:12, 11.62s/it]                                                    {'loss': 0.7493, 'grad_norm': 1.2105246782302856, 'learning_rate': 4.956947324652832e-06, 'epoch': 0.09}
  9%|▉         | 267/2906 [52:20<8:31:12, 11.62s/it]  9%|▉         | 268/2906 [52:32<8:32:51, 11.66s/it]                                                    {'loss': 0.8265, 'grad_norm': 1.1915799379348755, 'learning_rate': 4.956428571871623e-06, 'epoch': 0.09}
  9%|▉         | 268/2906 [52:32<8:32:51, 11.66s/it]  9%|▉         | 269/2906 [52:43<8:24:19, 11.47s/it]                                                    {'loss': 0.8254, 'grad_norm': 1.3235564231872559, 'learning_rate': 4.955906739956999e-06, 'epoch': 0.09}
  9%|▉         | 269/2906 [52:43<8:24:19, 11.47s/it]  9%|▉         | 270/2906 [52:55<8:35:42, 11.74s/it]                                                    {'loss': 0.8675, 'grad_norm': 1.3860104084014893, 'learning_rate': 4.955381829563075e-06, 'epoch': 0.09}
  9%|▉         | 270/2906 [52:55<8:35:42, 11.74s/it]  9%|▉         | 271/2906 [53:07<8:35:54, 11.75s/it]                                                    {'loss': 0.8336, 'grad_norm': 1.2776482105255127, 'learning_rate': 4.954853841347827e-06, 'epoch': 0.09}
  9%|▉         | 271/2906 [53:07<8:35:54, 11.75s/it]  9%|▉         | 272/2906 [53:19<8:36:04, 11.76s/it]                                                    {'loss': 0.8247, 'grad_norm': 1.3292354345321655, 'learning_rate': 4.954322775973087e-06, 'epoch': 0.09}
  9%|▉         | 272/2906 [53:19<8:36:04, 11.76s/it]  9%|▉         | 273/2906 [53:30<8:32:07, 11.67s/it]                                                    {'loss': 0.765, 'grad_norm': 1.3195983171463013, 'learning_rate': 4.9537886341045475e-06, 'epoch': 0.09}
  9%|▉         | 273/2906 [53:30<8:32:07, 11.67s/it]  9%|▉         | 274/2906 [53:42<8:35:09, 11.74s/it]                                                    {'loss': 0.7386, 'grad_norm': 1.2065635919570923, 'learning_rate': 4.953251416411754e-06, 'epoch': 0.09}
  9%|▉         | 274/2906 [53:42<8:35:09, 11.74s/it]  9%|▉         | 275/2906 [53:54<8:35:45, 11.76s/it]                                                    {'loss': 0.8503, 'grad_norm': 1.3688952922821045, 'learning_rate': 4.95271112356811e-06, 'epoch': 0.09}
  9%|▉         | 275/2906 [53:54<8:35:45, 11.76s/it]  9%|▉         | 276/2906 [54:06<8:38:06, 11.82s/it]                                                    {'loss': 0.9275, 'grad_norm': 1.4274410009384155, 'learning_rate': 4.952167756250872e-06, 'epoch': 0.09}
  9%|▉         | 276/2906 [54:06<8:38:06, 11.82s/it] 10%|▉         | 277/2906 [54:18<8:37:08, 11.80s/it]                                                    {'loss': 0.8496, 'grad_norm': 1.3061951398849487, 'learning_rate': 4.951621315141149e-06, 'epoch': 0.1}
 10%|▉         | 277/2906 [54:18<8:37:08, 11.80s/it] 10%|▉         | 278/2906 [54:30<8:40:14, 11.88s/it]                                                    {'loss': 0.8411, 'grad_norm': 1.2908976078033447, 'learning_rate': 4.951071800923909e-06, 'epoch': 0.1}
 10%|▉         | 278/2906 [54:30<8:40:14, 11.88s/it] 10%|▉         | 279/2906 [54:42<8:37:40, 11.82s/it]                                                    {'loss': 0.7996, 'grad_norm': 1.3002986907958984, 'learning_rate': 4.950519214287966e-06, 'epoch': 0.1}
 10%|▉         | 279/2906 [54:42<8:37:40, 11.82s/it] 10%|▉         | 280/2906 [54:54<8:42:00, 11.93s/it]                                                    {'loss': 0.8079, 'grad_norm': 1.3028509616851807, 'learning_rate': 4.949963555925986e-06, 'epoch': 0.1}
 10%|▉         | 280/2906 [54:54<8:42:00, 11.93s/it] 10%|▉         | 281/2906 [55:06<8:45:27, 12.01s/it]                                                    {'loss': 0.7893, 'grad_norm': 1.2930065393447876, 'learning_rate': 4.9494048265344896e-06, 'epoch': 0.1}
 10%|▉         | 281/2906 [55:06<8:45:27, 12.01s/it] 10%|▉         | 282/2906 [55:18<8:44:20, 11.99s/it]                                                    {'loss': 0.8251, 'grad_norm': 1.3228118419647217, 'learning_rate': 4.948843026813842e-06, 'epoch': 0.1}
 10%|▉         | 282/2906 [55:18<8:44:20, 11.99s/it] 10%|▉         | 283/2906 [55:29<8:38:42, 11.87s/it]                                                    {'loss': 0.8747, 'grad_norm': 1.2758444547653198, 'learning_rate': 4.94827815746826e-06, 'epoch': 0.1}
 10%|▉         | 283/2906 [55:29<8:38:42, 11.87s/it] 10%|▉         | 284/2906 [55:41<8:35:09, 11.79s/it]                                                    {'loss': 0.7892, 'grad_norm': 1.3026297092437744, 'learning_rate': 4.947710219205808e-06, 'epoch': 0.1}
 10%|▉         | 284/2906 [55:41<8:35:09, 11.79s/it] 10%|▉         | 285/2906 [55:53<8:34:23, 11.78s/it]                                                    {'loss': 0.8282, 'grad_norm': 1.306138515472412, 'learning_rate': 4.947139212738395e-06, 'epoch': 0.1}
 10%|▉         | 285/2906 [55:53<8:34:23, 11.78s/it] 10%|▉         | 286/2906 [56:04<8:26:38, 11.60s/it]                                                    {'loss': 0.8437, 'grad_norm': 1.3091833591461182, 'learning_rate': 4.946565138781779e-06, 'epoch': 0.1}
 10%|▉         | 286/2906 [56:04<8:26:38, 11.60s/it] 10%|▉         | 287/2906 [56:16<8:25:17, 11.58s/it]                                                    {'loss': 0.8324, 'grad_norm': 1.2234090566635132, 'learning_rate': 4.945987998055562e-06, 'epoch': 0.1}
 10%|▉         | 287/2906 [56:16<8:25:17, 11.58s/it] 10%|▉         | 288/2906 [56:28<8:34:58, 11.80s/it]                                                    {'loss': 0.8957, 'grad_norm': 1.4238959550857544, 'learning_rate': 4.945407791283189e-06, 'epoch': 0.1}
 10%|▉         | 288/2906 [56:28<8:34:58, 11.80s/it] 10%|▉         | 289/2906 [56:39<8:28:34, 11.66s/it]                                                    {'loss': 0.7927, 'grad_norm': 1.2246068716049194, 'learning_rate': 4.944824519191949e-06, 'epoch': 0.1}
 10%|▉         | 289/2906 [56:39<8:28:34, 11.66s/it] 10%|▉         | 290/2906 [56:51<8:26:24, 11.61s/it]                                                    {'loss': 0.8701, 'grad_norm': 1.2568103075027466, 'learning_rate': 4.944238182512974e-06, 'epoch': 0.1}
 10%|▉         | 290/2906 [56:51<8:26:24, 11.61s/it] 10%|█         | 291/2906 [57:03<8:30:58, 11.72s/it]                                                    {'loss': 0.7896, 'grad_norm': 1.3261274099349976, 'learning_rate': 4.943648781981239e-06, 'epoch': 0.1}
 10%|█         | 291/2906 [57:03<8:30:58, 11.72s/it] 10%|█         | 292/2906 [57:15<8:37:55, 11.89s/it]                                                    {'loss': 0.8365, 'grad_norm': 1.2868449687957764, 'learning_rate': 4.943056318335554e-06, 'epoch': 0.1}
 10%|█         | 292/2906 [57:15<8:37:55, 11.89s/it] 10%|█         | 293/2906 [57:27<8:41:13, 11.97s/it]                                                    {'loss': 0.8748, 'grad_norm': 1.357261061668396, 'learning_rate': 4.942460792318575e-06, 'epoch': 0.1}
 10%|█         | 293/2906 [57:27<8:41:13, 11.97s/it] 10%|█         | 294/2906 [57:39<8:40:48, 11.96s/it]                                                    {'loss': 0.7892, 'grad_norm': 1.387803554534912, 'learning_rate': 4.941862204676793e-06, 'epoch': 0.1}
 10%|█         | 294/2906 [57:39<8:40:48, 11.96s/it] 10%|█         | 295/2906 [57:51<8:34:45, 11.83s/it]                                                    {'loss': 0.8059, 'grad_norm': 1.2268744707107544, 'learning_rate': 4.9412605561605365e-06, 'epoch': 0.1}
 10%|█         | 295/2906 [57:51<8:34:45, 11.83s/it] 10%|█         | 296/2906 [58:02<8:28:06, 11.68s/it]                                                    {'loss': 0.8129, 'grad_norm': 1.3382818698883057, 'learning_rate': 4.940655847523974e-06, 'epoch': 0.1}
 10%|█         | 296/2906 [58:02<8:28:06, 11.68s/it] 10%|█         | 297/2906 [58:14<8:28:37, 11.70s/it]                                                    {'loss': 0.7988, 'grad_norm': 1.3561220169067383, 'learning_rate': 4.940048079525108e-06, 'epoch': 0.1}
 10%|█         | 297/2906 [58:14<8:28:37, 11.70s/it] 10%|█         | 298/2906 [58:25<8:26:50, 11.66s/it]                                                    {'loss': 0.8411, 'grad_norm': 1.4064857959747314, 'learning_rate': 4.939437252925774e-06, 'epoch': 0.1}
 10%|█         | 298/2906 [58:25<8:26:50, 11.66s/it] 10%|█         | 299/2906 [58:37<8:24:09, 11.60s/it]                                                    {'loss': 0.8503, 'grad_norm': 1.3509178161621094, 'learning_rate': 4.9388233684916434e-06, 'epoch': 0.1}
 10%|█         | 299/2906 [58:37<8:24:09, 11.60s/it] 10%|█         | 300/2906 [58:48<8:24:39, 11.62s/it]                                                    {'loss': 0.8081, 'grad_norm': 1.2725180387496948, 'learning_rate': 4.938206426992221e-06, 'epoch': 0.1}
 10%|█         | 300/2906 [58:48<8:24:39, 11.62s/it] 10%|█         | 301/2906 [58:59<8:17:09, 11.45s/it]                                                    {'loss': 0.6926, 'grad_norm': 1.2792561054229736, 'learning_rate': 4.937586429200842e-06, 'epoch': 0.1}
 10%|█         | 301/2906 [58:59<8:17:09, 11.45s/it] 10%|█         | 302/2906 [59:11<8:17:52, 11.47s/it]                                                    {'loss': 0.8011, 'grad_norm': 1.241578459739685, 'learning_rate': 4.936963375894677e-06, 'epoch': 0.1}
 10%|█         | 302/2906 [59:11<8:17:52, 11.47s/it] 10%|█         | 303/2906 [59:23<8:26:21, 11.67s/it]                                                    {'loss': 0.8188, 'grad_norm': 1.275029182434082, 'learning_rate': 4.936337267854719e-06, 'epoch': 0.1}
 10%|█         | 303/2906 [59:23<8:26:21, 11.67s/it] 10%|█         | 304/2906 [59:34<8:22:20, 11.58s/it]                                                    {'loss': 0.8432, 'grad_norm': 1.2860000133514404, 'learning_rate': 4.935708105865797e-06, 'epoch': 0.1}
 10%|█         | 304/2906 [59:34<8:22:20, 11.58s/it] 10%|█         | 305/2906 [59:46<8:22:54, 11.60s/it]                                                    {'loss': 0.7493, 'grad_norm': 1.2362046241760254, 'learning_rate': 4.935075890716565e-06, 'epoch': 0.1}
 10%|█         | 305/2906 [59:46<8:22:54, 11.60s/it] 11%|█         | 306/2906 [59:58<8:28:08, 11.73s/it]                                                    {'loss': 0.7935, 'grad_norm': 1.2618156671524048, 'learning_rate': 4.9344406231995044e-06, 'epoch': 0.11}
 11%|█         | 306/2906 [59:58<8:28:08, 11.73s/it] 11%|█         | 307/2906 [1:00:10<8:24:50, 11.65s/it]                                                      {'loss': 0.8735, 'grad_norm': 1.4033313989639282, 'learning_rate': 4.933802304110925e-06, 'epoch': 0.11}
 11%|█         | 307/2906 [1:00:10<8:24:50, 11.65s/it] 11%|█         | 308/2906 [1:00:21<8:22:18, 11.60s/it]                                                      {'loss': 0.8384, 'grad_norm': 1.5072993040084839, 'learning_rate': 4.933160934250957e-06, 'epoch': 0.11}
 11%|█         | 308/2906 [1:00:21<8:22:18, 11.60s/it] 11%|█         | 309/2906 [1:00:33<8:21:39, 11.59s/it]                                                      {'loss': 0.8682, 'grad_norm': 1.4408501386642456, 'learning_rate': 4.932516514423559e-06, 'epoch': 0.11}
 11%|█         | 309/2906 [1:00:33<8:21:39, 11.59s/it] 11%|█         | 310/2906 [1:00:45<8:26:56, 11.72s/it]                                                      {'loss': 0.7289, 'grad_norm': 1.3163695335388184, 'learning_rate': 4.931869045436511e-06, 'epoch': 0.11}
 11%|█         | 310/2906 [1:00:45<8:26:56, 11.72s/it] 11%|█         | 311/2906 [1:00:56<8:18:58, 11.54s/it]                                                      {'loss': 0.842, 'grad_norm': 1.4171788692474365, 'learning_rate': 4.931218528101416e-06, 'epoch': 0.11}
 11%|█         | 311/2906 [1:00:56<8:18:58, 11.54s/it] 11%|█         | 312/2906 [1:01:07<8:14:59, 11.45s/it]                                                      {'loss': 0.7902, 'grad_norm': 1.2196863889694214, 'learning_rate': 4.930564963233696e-06, 'epoch': 0.11}
 11%|█         | 312/2906 [1:01:07<8:14:59, 11.45s/it] 11%|█         | 313/2906 [1:01:19<8:25:43, 11.70s/it]                                                      {'loss': 0.8151, 'grad_norm': 1.2204612493515015, 'learning_rate': 4.929908351652598e-06, 'epoch': 0.11}
 11%|█         | 313/2906 [1:01:19<8:25:43, 11.70s/it] 11%|█         | 314/2906 [1:01:31<8:23:41, 11.66s/it]                                                      {'loss': 0.7172, 'grad_norm': 1.3274067640304565, 'learning_rate': 4.92924869418118e-06, 'epoch': 0.11}
 11%|█         | 314/2906 [1:01:31<8:23:41, 11.66s/it] 11%|█         | 315/2906 [1:01:42<8:19:19, 11.56s/it]                                                      {'loss': 0.8048, 'grad_norm': 1.239346981048584, 'learning_rate': 4.928585991646327e-06, 'epoch': 0.11}
 11%|█         | 315/2906 [1:01:42<8:19:19, 11.56s/it] 11%|█         | 316/2906 [1:01:54<8:24:04, 11.68s/it]                                                      {'loss': 0.8011, 'grad_norm': 1.232113242149353, 'learning_rate': 4.927920244878734e-06, 'epoch': 0.11}
 11%|█         | 316/2906 [1:01:54<8:24:04, 11.68s/it] 11%|█         | 317/2906 [1:02:06<8:22:38, 11.65s/it]                                                      {'loss': 0.8068, 'grad_norm': 1.3631706237792969, 'learning_rate': 4.927251454712915e-06, 'epoch': 0.11}
 11%|█         | 317/2906 [1:02:06<8:22:38, 11.65s/it] 11%|█         | 318/2906 [1:02:17<8:23:10, 11.67s/it]                                                      {'loss': 0.8504, 'grad_norm': 1.366019606590271, 'learning_rate': 4.9265796219872e-06, 'epoch': 0.11}
 11%|█         | 318/2906 [1:02:17<8:23:10, 11.67s/it] 11%|█         | 319/2906 [1:02:29<8:23:35, 11.68s/it]                                                      {'loss': 0.7788, 'grad_norm': 1.213442087173462, 'learning_rate': 4.925904747543729e-06, 'epoch': 0.11}
 11%|█         | 319/2906 [1:02:29<8:23:35, 11.68s/it] 11%|█         | 320/2906 [1:02:41<8:21:12, 11.63s/it]                                                      {'loss': 0.785, 'grad_norm': 1.3781381845474243, 'learning_rate': 4.92522683222846e-06, 'epoch': 0.11}
 11%|█         | 320/2906 [1:02:41<8:21:12, 11.63s/it] 11%|█         | 321/2906 [1:02:52<8:17:23, 11.54s/it]                                                      {'loss': 0.9287, 'grad_norm': 1.4309073686599731, 'learning_rate': 4.924545876891157e-06, 'epoch': 0.11}
 11%|█         | 321/2906 [1:02:52<8:17:23, 11.54s/it] 11%|█         | 322/2906 [1:03:04<8:22:44, 11.67s/it]                                                      {'loss': 0.8226, 'grad_norm': 1.4210305213928223, 'learning_rate': 4.9238618823854e-06, 'epoch': 0.11}
 11%|█         | 322/2906 [1:03:04<8:22:44, 11.67s/it] 11%|█         | 323/2906 [1:03:16<8:26:20, 11.76s/it]                                                      {'loss': 0.8116, 'grad_norm': 1.2601834535598755, 'learning_rate': 4.9231748495685745e-06, 'epoch': 0.11}
 11%|█         | 323/2906 [1:03:16<8:26:20, 11.76s/it] 11%|█         | 324/2906 [1:03:27<8:20:54, 11.64s/it]                                                      {'loss': 0.8227, 'grad_norm': 1.244708776473999, 'learning_rate': 4.922484779301877e-06, 'epoch': 0.11}
 11%|█         | 324/2906 [1:03:27<8:20:54, 11.64s/it] 11%|█         | 325/2906 [1:03:39<8:22:29, 11.68s/it]                                                      {'loss': 0.8121, 'grad_norm': 1.2553764581680298, 'learning_rate': 4.921791672450311e-06, 'epoch': 0.11}
 11%|█         | 325/2906 [1:03:39<8:22:29, 11.68s/it] 11%|█         | 326/2906 [1:03:51<8:20:25, 11.64s/it]                                                      {'loss': 0.8078, 'grad_norm': 1.301926851272583, 'learning_rate': 4.921095529882685e-06, 'epoch': 0.11}
 11%|█         | 326/2906 [1:03:51<8:20:25, 11.64s/it] 11%|█▏        | 327/2906 [1:04:03<8:25:29, 11.76s/it]                                                      {'loss': 0.7884, 'grad_norm': 1.3379124402999878, 'learning_rate': 4.920396352471613e-06, 'epoch': 0.11}
 11%|█▏        | 327/2906 [1:04:03<8:25:29, 11.76s/it] 11%|█▏        | 328/2906 [1:04:15<8:28:24, 11.83s/it]                                                      {'loss': 0.8702, 'grad_norm': 1.4422143697738647, 'learning_rate': 4.919694141093517e-06, 'epoch': 0.11}
 11%|█▏        | 328/2906 [1:04:15<8:28:24, 11.83s/it] 11%|█▏        | 329/2906 [1:04:27<8:30:04, 11.88s/it]                                                      {'loss': 0.8475, 'grad_norm': 1.3388053178787231, 'learning_rate': 4.918988896628617e-06, 'epoch': 0.11}
 11%|█▏        | 329/2906 [1:04:27<8:30:04, 11.88s/it] 11%|█▏        | 330/2906 [1:04:38<8:25:53, 11.78s/it]                                                      {'loss': 0.8239, 'grad_norm': 1.2919806241989136, 'learning_rate': 4.918280619960937e-06, 'epoch': 0.11}
 11%|█▏        | 330/2906 [1:04:38<8:25:53, 11.78s/it] 11%|█▏        | 331/2906 [1:04:50<8:31:33, 11.92s/it]                                                      {'loss': 0.7912, 'grad_norm': 1.2727279663085938, 'learning_rate': 4.917569311978301e-06, 'epoch': 0.11}
 11%|█▏        | 331/2906 [1:04:50<8:31:33, 11.92s/it] 11%|█▏        | 332/2906 [1:05:02<8:31:47, 11.93s/it]                                                      {'loss': 0.7766, 'grad_norm': 1.3164182901382446, 'learning_rate': 4.916854973572336e-06, 'epoch': 0.11}
 11%|█▏        | 332/2906 [1:05:02<8:31:47, 11.93s/it] 11%|█▏        | 333/2906 [1:05:14<8:31:54, 11.94s/it]                                                      {'loss': 0.8317, 'grad_norm': 1.2758878469467163, 'learning_rate': 4.916137605638463e-06, 'epoch': 0.11}
 11%|█▏        | 333/2906 [1:05:14<8:31:54, 11.94s/it] 11%|█▏        | 334/2906 [1:05:26<8:25:50, 11.80s/it]                                                      {'loss': 0.7458, 'grad_norm': 1.2621874809265137, 'learning_rate': 4.915417209075905e-06, 'epoch': 0.11}
 11%|█▏        | 334/2906 [1:05:26<8:25:50, 11.80s/it] 12%|█▏        | 335/2906 [1:05:38<8:24:16, 11.77s/it]                                                      {'loss': 0.8745, 'grad_norm': 1.342561960220337, 'learning_rate': 4.914693784787676e-06, 'epoch': 0.12}
 12%|█▏        | 335/2906 [1:05:38<8:24:16, 11.77s/it] 12%|█▏        | 336/2906 [1:05:49<8:18:18, 11.63s/it]                                                      {'loss': 0.8188, 'grad_norm': 1.2148767709732056, 'learning_rate': 4.913967333680591e-06, 'epoch': 0.12}
 12%|█▏        | 336/2906 [1:05:49<8:18:18, 11.63s/it] 12%|█▏        | 337/2906 [1:06:00<8:09:29, 11.43s/it]                                                      {'loss': 0.8547, 'grad_norm': 1.323501706123352, 'learning_rate': 4.913237856665256e-06, 'epoch': 0.12}
 12%|█▏        | 337/2906 [1:06:00<8:09:29, 11.43s/it] 12%|█▏        | 338/2906 [1:06:12<8:15:52, 11.59s/it]                                                      {'loss': 0.8403, 'grad_norm': 1.3342982530593872, 'learning_rate': 4.91250535465607e-06, 'epoch': 0.12}
 12%|█▏        | 338/2906 [1:06:12<8:15:52, 11.59s/it] 12%|█▏        | 339/2906 [1:06:24<8:20:17, 11.69s/it]                                                      {'loss': 0.7514, 'grad_norm': 1.3224966526031494, 'learning_rate': 4.911769828571224e-06, 'epoch': 0.12}
 12%|█▏        | 339/2906 [1:06:24<8:20:17, 11.69s/it] 12%|█▏        | 340/2906 [1:06:35<8:13:54, 11.55s/it]                                                      {'loss': 0.8175, 'grad_norm': 1.3418874740600586, 'learning_rate': 4.9110312793327016e-06, 'epoch': 0.12}
 12%|█▏        | 340/2906 [1:06:35<8:13:54, 11.55s/it] 12%|█▏        | 341/2906 [1:06:46<8:11:44, 11.50s/it]                                                      {'loss': 0.8575, 'grad_norm': 1.3117374181747437, 'learning_rate': 4.910289707866273e-06, 'epoch': 0.12}
 12%|█▏        | 341/2906 [1:06:46<8:11:44, 11.50s/it] 12%|█▏        | 342/2906 [1:06:58<8:11:12, 11.49s/it]                                                      {'loss': 0.8099, 'grad_norm': 1.333466649055481, 'learning_rate': 4.909545115101499e-06, 'epoch': 0.12}
 12%|█▏        | 342/2906 [1:06:58<8:11:12, 11.49s/it] 12%|█▏        | 343/2906 [1:07:10<8:18:11, 11.66s/it]                                                      {'loss': 0.775, 'grad_norm': 1.2870885133743286, 'learning_rate': 4.908797501971725e-06, 'epoch': 0.12}
 12%|█▏        | 343/2906 [1:07:10<8:18:11, 11.66s/it] 12%|█▏        | 344/2906 [1:07:21<8:09:25, 11.46s/it]                                                      {'loss': 0.8101, 'grad_norm': 1.2449923753738403, 'learning_rate': 4.9080468694140855e-06, 'epoch': 0.12}
 12%|█▏        | 344/2906 [1:07:21<8:09:25, 11.46s/it] 12%|█▏        | 345/2906 [1:07:33<8:13:35, 11.56s/it]                                                      {'loss': 0.8251, 'grad_norm': 1.3033511638641357, 'learning_rate': 4.907293218369499e-06, 'epoch': 0.12}
 12%|█▏        | 345/2906 [1:07:33<8:13:35, 11.56s/it] 12%|█▏        | 346/2906 [1:07:44<8:14:10, 11.58s/it]                                                      {'loss': 0.834, 'grad_norm': 1.3885554075241089, 'learning_rate': 4.906536549782666e-06, 'epoch': 0.12}
 12%|█▏        | 346/2906 [1:07:44<8:14:10, 11.58s/it] 12%|█▏        | 347/2906 [1:07:56<8:20:47, 11.74s/it]                                                      {'loss': 0.7862, 'grad_norm': 1.2689650058746338, 'learning_rate': 4.90577686460207e-06, 'epoch': 0.12}
 12%|█▏        | 347/2906 [1:07:56<8:20:47, 11.74s/it] 12%|█▏        | 348/2906 [1:08:08<8:14:26, 11.60s/it]                                                      {'loss': 0.8266, 'grad_norm': 1.4125189781188965, 'learning_rate': 4.905014163779978e-06, 'epoch': 0.12}
 12%|█▏        | 348/2906 [1:08:08<8:14:26, 11.60s/it] 12%|█▏        | 349/2906 [1:08:19<8:13:23, 11.58s/it]                                                      {'loss': 0.7792, 'grad_norm': 1.2380049228668213, 'learning_rate': 4.904248448272435e-06, 'epoch': 0.12}
 12%|█▏        | 349/2906 [1:08:19<8:13:23, 11.58s/it] 12%|█▏        | 350/2906 [1:08:31<8:12:29, 11.56s/it]                                                      {'loss': 0.8459, 'grad_norm': 1.355433702468872, 'learning_rate': 4.9034797190392654e-06, 'epoch': 0.12}
 12%|█▏        | 350/2906 [1:08:31<8:12:29, 11.56s/it] 12%|█▏        | 351/2906 [1:08:42<8:11:04, 11.53s/it]                                                      {'loss': 0.819, 'grad_norm': 1.2255308628082275, 'learning_rate': 4.902707977044071e-06, 'epoch': 0.12}
 12%|█▏        | 351/2906 [1:08:42<8:11:04, 11.53s/it] 12%|█▏        | 352/2906 [1:08:53<8:05:59, 11.42s/it]                                                      {'loss': 0.7701, 'grad_norm': 1.3600083589553833, 'learning_rate': 4.901933223254231e-06, 'epoch': 0.12}
 12%|█▏        | 352/2906 [1:08:53<8:05:59, 11.42s/it] 12%|█▏        | 353/2906 [1:09:05<8:11:25, 11.55s/it]                                                      {'loss': 0.7875, 'grad_norm': 1.2804341316223145, 'learning_rate': 4.9011554586409005e-06, 'epoch': 0.12}
 12%|█▏        | 353/2906 [1:09:05<8:11:25, 11.55s/it] 12%|█▏        | 354/2906 [1:09:17<8:17:57, 11.71s/it]                                                      {'loss': 0.7509, 'grad_norm': 1.2922227382659912, 'learning_rate': 4.900374684179005e-06, 'epoch': 0.12}
 12%|█▏        | 354/2906 [1:09:17<8:17:57, 11.71s/it] 12%|█▏        | 355/2906 [1:09:28<8:11:06, 11.55s/it]                                                      {'loss': 0.8212, 'grad_norm': 1.401485800743103, 'learning_rate': 4.8995909008472465e-06, 'epoch': 0.12}
 12%|█▏        | 355/2906 [1:09:28<8:11:06, 11.55s/it] 12%|█▏        | 356/2906 [1:09:40<8:08:11, 11.49s/it]                                                      {'loss': 0.7887, 'grad_norm': 1.2135517597198486, 'learning_rate': 4.898804109628098e-06, 'epoch': 0.12}
 12%|█▏        | 356/2906 [1:09:40<8:08:11, 11.49s/it] 12%|█▏        | 357/2906 [1:09:51<8:10:04, 11.54s/it]                                                      {'loss': 0.7844, 'grad_norm': 1.3049070835113525, 'learning_rate': 4.898014311507801e-06, 'epoch': 0.12}
 12%|█▏        | 357/2906 [1:09:51<8:10:04, 11.54s/it] 12%|█▏        | 358/2906 [1:10:03<8:08:13, 11.50s/it]                                                      {'loss': 0.8116, 'grad_norm': 1.2497498989105225, 'learning_rate': 4.8972215074763684e-06, 'epoch': 0.12}
 12%|█▏        | 358/2906 [1:10:03<8:08:13, 11.50s/it] 12%|█▏        | 359/2906 [1:10:15<8:11:13, 11.57s/it]                                                      {'loss': 0.7475, 'grad_norm': 1.1966614723205566, 'learning_rate': 4.8964256985275805e-06, 'epoch': 0.12}
 12%|█▏        | 359/2906 [1:10:15<8:11:13, 11.57s/it] 12%|█▏        | 360/2906 [1:10:26<8:12:03, 11.60s/it]                                                      {'loss': 0.7974, 'grad_norm': 1.3016092777252197, 'learning_rate': 4.895626885658983e-06, 'epoch': 0.12}
 12%|█▏        | 360/2906 [1:10:26<8:12:03, 11.60s/it] 12%|█▏        | 361/2906 [1:10:38<8:10:34, 11.57s/it]                                                      {'loss': 0.8498, 'grad_norm': 1.365493655204773, 'learning_rate': 4.8948250698718895e-06, 'epoch': 0.12}
 12%|█▏        | 361/2906 [1:10:38<8:10:34, 11.57s/it] 12%|█▏        | 362/2906 [1:10:50<8:17:24, 11.73s/it]                                                      {'loss': 0.7839, 'grad_norm': 1.2802273035049438, 'learning_rate': 4.894020252171374e-06, 'epoch': 0.12}
 12%|█▏        | 362/2906 [1:10:50<8:17:24, 11.73s/it] 12%|█▏        | 363/2906 [1:11:01<8:09:48, 11.56s/it]                                                      {'loss': 0.7883, 'grad_norm': 1.2752964496612549, 'learning_rate': 4.893212433566277e-06, 'epoch': 0.12}
 12%|█▏        | 363/2906 [1:11:01<8:09:48, 11.56s/it] 13%|█▎        | 364/2906 [1:11:13<8:17:21, 11.74s/it]                                                      {'loss': 0.8257, 'grad_norm': 1.3357142210006714, 'learning_rate': 4.892401615069198e-06, 'epoch': 0.13}
 13%|█▎        | 364/2906 [1:11:13<8:17:21, 11.74s/it] 13%|█▎        | 365/2906 [1:11:24<8:09:56, 11.57s/it]                                                      {'loss': 0.7977, 'grad_norm': 1.3455140590667725, 'learning_rate': 4.8915877976964995e-06, 'epoch': 0.13}
 13%|█▎        | 365/2906 [1:11:24<8:09:56, 11.57s/it] 13%|█▎        | 366/2906 [1:11:36<8:10:55, 11.60s/it]                                                      {'loss': 0.8266, 'grad_norm': 1.3922315835952759, 'learning_rate': 4.890770982468301e-06, 'epoch': 0.13}
 13%|█▎        | 366/2906 [1:11:36<8:10:55, 11.60s/it] 13%|█▎        | 367/2906 [1:11:48<8:11:44, 11.62s/it]                                                      {'loss': 0.8586, 'grad_norm': 1.3553177118301392, 'learning_rate': 4.889951170408479e-06, 'epoch': 0.13}
 13%|█▎        | 367/2906 [1:11:48<8:11:44, 11.62s/it] 13%|█▎        | 368/2906 [1:11:59<8:14:37, 11.69s/it]                                                      {'loss': 0.8208, 'grad_norm': 1.3122979402542114, 'learning_rate': 4.889128362544671e-06, 'epoch': 0.13}
 13%|█▎        | 368/2906 [1:12:00<8:14:37, 11.69s/it] 13%|█▎        | 369/2906 [1:12:11<8:12:01, 11.64s/it]                                                      {'loss': 0.8103, 'grad_norm': 1.3339203596115112, 'learning_rate': 4.888302559908265e-06, 'epoch': 0.13}
 13%|█▎        | 369/2906 [1:12:11<8:12:01, 11.64s/it] 13%|█▎        | 370/2906 [1:12:22<8:09:19, 11.58s/it]                                                      {'loss': 0.8066, 'grad_norm': 1.298087239265442, 'learning_rate': 4.887473763534404e-06, 'epoch': 0.13}
 13%|█▎        | 370/2906 [1:12:22<8:09:19, 11.58s/it] 13%|█▎        | 371/2906 [1:12:33<8:01:11, 11.39s/it]                                                      {'loss': 0.7823, 'grad_norm': 1.2934398651123047, 'learning_rate': 4.886641974461985e-06, 'epoch': 0.13}
 13%|█▎        | 371/2906 [1:12:33<8:01:11, 11.39s/it] 13%|█▎        | 372/2906 [1:12:45<8:00:49, 11.38s/it]                                                      {'loss': 0.8154, 'grad_norm': 2.4395108222961426, 'learning_rate': 4.885807193733657e-06, 'epoch': 0.13}
 13%|█▎        | 372/2906 [1:12:45<8:00:49, 11.38s/it] 13%|█▎        | 373/2906 [1:12:57<8:08:23, 11.57s/it]                                                      {'loss': 0.8483, 'grad_norm': 1.3741297721862793, 'learning_rate': 4.884969422395815e-06, 'epoch': 0.13}
 13%|█▎        | 373/2906 [1:12:57<8:08:23, 11.57s/it] 13%|█▎        | 374/2906 [1:13:08<8:07:13, 11.55s/it]                                                      {'loss': 0.8042, 'grad_norm': 1.303053855895996, 'learning_rate': 4.884128661498608e-06, 'epoch': 0.13}
 13%|█▎        | 374/2906 [1:13:08<8:07:13, 11.55s/it] 13%|█▎        | 375/2906 [1:13:20<8:12:50, 11.68s/it]                                                      {'loss': 0.8196, 'grad_norm': 1.246871829032898, 'learning_rate': 4.883284912095928e-06, 'epoch': 0.13}
 13%|█▎        | 375/2906 [1:13:20<8:12:50, 11.68s/it] 13%|█▎        | 376/2906 [1:13:32<8:17:08, 11.79s/it]                                                      {'loss': 0.7799, 'grad_norm': 1.2463513612747192, 'learning_rate': 4.882438175245416e-06, 'epoch': 0.13}
 13%|█▎        | 376/2906 [1:13:32<8:17:08, 11.79s/it] 13%|█▎        | 377/2906 [1:13:44<8:17:15, 11.80s/it]                                                      {'loss': 0.8183, 'grad_norm': 1.3130054473876953, 'learning_rate': 4.881588452008457e-06, 'epoch': 0.13}
 13%|█▎        | 377/2906 [1:13:44<8:17:15, 11.80s/it] 13%|█▎        | 378/2906 [1:13:56<8:15:58, 11.77s/it]                                                      {'loss': 0.8208, 'grad_norm': 1.2651971578598022, 'learning_rate': 4.880735743450178e-06, 'epoch': 0.13}
 13%|█▎        | 378/2906 [1:13:56<8:15:58, 11.77s/it] 13%|█▎        | 379/2906 [1:14:07<8:11:46, 11.68s/it]                                                      {'loss': 0.8183, 'grad_norm': 1.3730707168579102, 'learning_rate': 4.87988005063945e-06, 'epoch': 0.13}
 13%|█▎        | 379/2906 [1:14:07<8:11:46, 11.68s/it] 13%|█▎        | 380/2906 [1:14:19<8:16:56, 11.80s/it]                                                      {'loss': 0.8679, 'grad_norm': 1.3514155149459839, 'learning_rate': 4.879021374648883e-06, 'epoch': 0.13}
 13%|█▎        | 380/2906 [1:14:19<8:16:56, 11.80s/it] 13%|█▎        | 381/2906 [1:14:31<8:17:04, 11.81s/it]                                                      {'loss': 0.772, 'grad_norm': 1.2652517557144165, 'learning_rate': 4.87815971655483e-06, 'epoch': 0.13}
 13%|█▎        | 381/2906 [1:14:31<8:17:04, 11.81s/it] 13%|█▎        | 382/2906 [1:14:43<8:16:48, 11.81s/it]                                                      {'loss': 0.7996, 'grad_norm': 1.2626374959945679, 'learning_rate': 4.877295077437376e-06, 'epoch': 0.13}
 13%|█▎        | 382/2906 [1:14:43<8:16:48, 11.81s/it] 13%|█▎        | 383/2906 [1:14:55<8:15:52, 11.79s/it]                                                      {'loss': 0.8093, 'grad_norm': 1.343178153038025, 'learning_rate': 4.876427458380349e-06, 'epoch': 0.13}
 13%|█▎        | 383/2906 [1:14:55<8:15:52, 11.79s/it] 13%|█▎        | 384/2906 [1:15:06<8:08:46, 11.63s/it]                                                      {'loss': 0.8113, 'grad_norm': 1.576541543006897, 'learning_rate': 4.875556860471308e-06, 'epoch': 0.13}
 13%|█▎        | 384/2906 [1:15:06<8:08:46, 11.63s/it] 13%|█▎        | 385/2906 [1:15:17<8:06:25, 11.58s/it]                                                      {'loss': 0.8328, 'grad_norm': 1.3394038677215576, 'learning_rate': 4.874683284801548e-06, 'epoch': 0.13}
 13%|█▎        | 385/2906 [1:15:17<8:06:25, 11.58s/it] 13%|█▎        | 386/2906 [1:15:29<8:09:02, 11.64s/it]                                                      {'loss': 0.7976, 'grad_norm': 1.3677150011062622, 'learning_rate': 4.873806732466096e-06, 'epoch': 0.13}
 13%|█▎        | 386/2906 [1:15:29<8:09:02, 11.64s/it] 13%|█▎        | 387/2906 [1:15:41<8:08:47, 11.64s/it]                                                      {'loss': 0.8257, 'grad_norm': 1.3343712091445923, 'learning_rate': 4.872927204563712e-06, 'epoch': 0.13}
 13%|█▎        | 387/2906 [1:15:41<8:08:47, 11.64s/it] 13%|█▎        | 388/2906 [1:15:52<7:57:49, 11.39s/it]                                                      {'loss': 0.7329, 'grad_norm': 1.2324849367141724, 'learning_rate': 4.872044702196882e-06, 'epoch': 0.13}
 13%|█▎        | 388/2906 [1:15:52<7:57:49, 11.39s/it] 13%|█▎        | 389/2906 [1:16:04<8:07:12, 11.61s/it]                                                      {'loss': 0.8349, 'grad_norm': 1.370469093322754, 'learning_rate': 4.871159226471825e-06, 'epoch': 0.13}
 13%|█▎        | 389/2906 [1:16:04<8:07:12, 11.61s/it] 13%|█▎        | 390/2906 [1:16:15<8:01:46, 11.49s/it]                                                      {'loss': 0.8049, 'grad_norm': 1.2629261016845703, 'learning_rate': 4.870270778498482e-06, 'epoch': 0.13}
 13%|█▎        | 390/2906 [1:16:15<8:01:46, 11.49s/it] 13%|█▎        | 391/2906 [1:16:26<7:56:50, 11.38s/it]                                                      {'loss': 0.8673, 'grad_norm': 1.3058758974075317, 'learning_rate': 4.869379359390524e-06, 'epoch': 0.13}
 13%|█▎        | 391/2906 [1:16:26<7:56:50, 11.38s/it] 13%|█▎        | 392/2906 [1:16:38<8:01:54, 11.50s/it]                                                      {'loss': 0.8659, 'grad_norm': 1.4315987825393677, 'learning_rate': 4.868484970265346e-06, 'epoch': 0.13}
 13%|█▎        | 392/2906 [1:16:38<8:01:54, 11.50s/it] 14%|█▎        | 393/2906 [1:16:49<8:01:20, 11.49s/it]                                                      {'loss': 0.7817, 'grad_norm': 1.2473145723342896, 'learning_rate': 4.867587612244064e-06, 'epoch': 0.14}
 14%|█▎        | 393/2906 [1:16:49<8:01:20, 11.49s/it] 14%|█▎        | 394/2906 [1:17:02<8:09:44, 11.70s/it]                                                      {'loss': 0.8474, 'grad_norm': 1.2897932529449463, 'learning_rate': 4.866687286451516e-06, 'epoch': 0.14}
 14%|█▎        | 394/2906 [1:17:02<8:09:44, 11.70s/it] 14%|█▎        | 395/2906 [1:17:12<7:58:59, 11.45s/it]                                                      {'loss': 0.9104, 'grad_norm': 1.446357011795044, 'learning_rate': 4.865783994016261e-06, 'epoch': 0.14}
 14%|█▎        | 395/2906 [1:17:12<7:58:59, 11.45s/it] 14%|█▎        | 396/2906 [1:17:24<7:59:36, 11.46s/it]                                                      {'loss': 0.8672, 'grad_norm': 1.3129445314407349, 'learning_rate': 4.864877736070577e-06, 'epoch': 0.14}
 14%|█▎        | 396/2906 [1:17:24<7:59:36, 11.46s/it] 14%|█▎        | 397/2906 [1:17:36<8:02:16, 11.53s/it]                                                      {'loss': 0.8448, 'grad_norm': 1.2540361881256104, 'learning_rate': 4.863968513750456e-06, 'epoch': 0.14}
 14%|█▎        | 397/2906 [1:17:36<8:02:16, 11.53s/it] 14%|█▎        | 398/2906 [1:17:47<8:05:46, 11.62s/it]                                                      {'loss': 0.7993, 'grad_norm': 1.3003804683685303, 'learning_rate': 4.86305632819561e-06, 'epoch': 0.14}
 14%|█▎        | 398/2906 [1:17:47<8:05:46, 11.62s/it] 14%|█▎        | 399/2906 [1:17:59<8:07:48, 11.67s/it]                                                      {'loss': 0.8647, 'grad_norm': 1.3593227863311768, 'learning_rate': 4.862141180549464e-06, 'epoch': 0.14}
 14%|█▎        | 399/2906 [1:17:59<8:07:48, 11.67s/it] 14%|█▍        | 400/2906 [1:18:11<8:02:40, 11.56s/it]                                                      {'loss': 0.8391, 'grad_norm': 1.3047621250152588, 'learning_rate': 4.8612230719591535e-06, 'epoch': 0.14}
 14%|█▍        | 400/2906 [1:18:11<8:02:40, 11.56s/it] 14%|█▍        | 401/2906 [1:18:22<8:02:46, 11.56s/it]                                                      {'loss': 0.7571, 'grad_norm': 1.2886075973510742, 'learning_rate': 4.86030200357553e-06, 'epoch': 0.14}
 14%|█▍        | 401/2906 [1:18:22<8:02:46, 11.56s/it] 14%|█▍        | 402/2906 [1:18:34<8:02:48, 11.57s/it]                                                      {'loss': 0.7958, 'grad_norm': 1.2720105648040771, 'learning_rate': 4.859377976553152e-06, 'epoch': 0.14}
 14%|█▍        | 402/2906 [1:18:34<8:02:48, 11.57s/it] 14%|█▍        | 403/2906 [1:18:45<8:03:40, 11.59s/it]                                                      {'loss': 0.7653, 'grad_norm': 1.3330663442611694, 'learning_rate': 4.858450992050287e-06, 'epoch': 0.14}
 14%|█▍        | 403/2906 [1:18:45<8:03:40, 11.59s/it] 14%|█▍        | 404/2906 [1:18:57<8:04:01, 11.61s/it]                                                      {'loss': 0.825, 'grad_norm': 1.298992395401001, 'learning_rate': 4.8575210512289105e-06, 'epoch': 0.14}
 14%|█▍        | 404/2906 [1:18:57<8:04:01, 11.61s/it] 14%|█▍        | 405/2906 [1:19:08<8:00:59, 11.54s/it]                                                      {'loss': 0.8249, 'grad_norm': 1.3291258811950684, 'learning_rate': 4.856588155254704e-06, 'epoch': 0.14}
 14%|█▍        | 405/2906 [1:19:08<8:00:59, 11.54s/it] 14%|█▍        | 406/2906 [1:19:20<8:05:28, 11.65s/it]                                                      {'loss': 0.8429, 'grad_norm': 1.3188741207122803, 'learning_rate': 4.855652305297052e-06, 'epoch': 0.14}
 14%|█▍        | 406/2906 [1:19:20<8:05:28, 11.65s/it] 14%|█▍        | 407/2906 [1:19:31<7:57:33, 11.47s/it]                                                      {'loss': 0.7929, 'grad_norm': 1.4292072057724, 'learning_rate': 4.854713502529042e-06, 'epoch': 0.14}
 14%|█▍        | 407/2906 [1:19:31<7:57:33, 11.47s/it] 14%|█▍        | 408/2906 [1:19:43<7:57:37, 11.47s/it]                                                      {'loss': 0.8095, 'grad_norm': 1.2861182689666748, 'learning_rate': 4.8537717481274645e-06, 'epoch': 0.14}
 14%|█▍        | 408/2906 [1:19:43<7:57:37, 11.47s/it] 14%|█▍        | 409/2906 [1:19:54<7:55:59, 11.44s/it]                                                      {'loss': 0.8203, 'grad_norm': 1.3069077730178833, 'learning_rate': 4.852827043272808e-06, 'epoch': 0.14}
 14%|█▍        | 409/2906 [1:19:54<7:55:59, 11.44s/it] 14%|█▍        | 410/2906 [1:20:06<8:00:17, 11.55s/it]                                                      {'loss': 0.8007, 'grad_norm': 1.52114737033844, 'learning_rate': 4.85187938914926e-06, 'epoch': 0.14}
 14%|█▍        | 410/2906 [1:20:06<8:00:17, 11.55s/it] 14%|█▍        | 411/2906 [1:20:18<8:01:50, 11.59s/it]                                                      {'loss': 0.8626, 'grad_norm': 1.3034363985061646, 'learning_rate': 4.850928786944706e-06, 'epoch': 0.14}
 14%|█▍        | 411/2906 [1:20:18<8:01:50, 11.59s/it] 14%|█▍        | 412/2906 [1:20:30<8:05:31, 11.68s/it]                                                      {'loss': 0.8056, 'grad_norm': 1.2851234674453735, 'learning_rate': 4.849975237850724e-06, 'epoch': 0.14}
 14%|█▍        | 412/2906 [1:20:30<8:05:31, 11.68s/it] 14%|█▍        | 413/2906 [1:20:41<8:02:07, 11.60s/it]                                                      {'loss': 0.7399, 'grad_norm': 1.2632699012756348, 'learning_rate': 4.84901874306259e-06, 'epoch': 0.14}
 14%|█▍        | 413/2906 [1:20:41<8:02:07, 11.60s/it] 14%|█▍        | 414/2906 [1:20:53<8:04:29, 11.67s/it]                                                      {'loss': 0.8006, 'grad_norm': 1.460569977760315, 'learning_rate': 4.848059303779269e-06, 'epoch': 0.14}
 14%|█▍        | 414/2906 [1:20:53<8:04:29, 11.67s/it] 14%|█▍        | 415/2906 [1:21:05<8:10:03, 11.80s/it]                                                      {'loss': 0.7901, 'grad_norm': 1.3870214223861694, 'learning_rate': 4.847096921203419e-06, 'epoch': 0.14}
 14%|█▍        | 415/2906 [1:21:05<8:10:03, 11.80s/it] 14%|█▍        | 416/2906 [1:21:16<8:06:04, 11.71s/it]                                                      {'loss': 0.8069, 'grad_norm': 1.3623063564300537, 'learning_rate': 4.846131596541387e-06, 'epoch': 0.14}
 14%|█▍        | 416/2906 [1:21:16<8:06:04, 11.71s/it] 14%|█▍        | 417/2906 [1:21:28<8:05:20, 11.70s/it]                                                      {'loss': 0.8215, 'grad_norm': 1.3716397285461426, 'learning_rate': 4.845163331003205e-06, 'epoch': 0.14}
 14%|█▍        | 417/2906 [1:21:28<8:05:20, 11.70s/it] 14%|█▍        | 418/2906 [1:21:40<8:02:57, 11.65s/it]                                                      {'loss': 0.7799, 'grad_norm': 1.2567840814590454, 'learning_rate': 4.844192125802597e-06, 'epoch': 0.14}
 14%|█▍        | 418/2906 [1:21:40<8:02:57, 11.65s/it] 14%|█▍        | 419/2906 [1:21:51<8:02:48, 11.65s/it]                                                      {'loss': 0.8888, 'grad_norm': 1.3800753355026245, 'learning_rate': 4.843217982156968e-06, 'epoch': 0.14}
 14%|█▍        | 419/2906 [1:21:51<8:02:48, 11.65s/it] 14%|█▍        | 420/2906 [1:22:03<8:07:00, 11.75s/it]                                                      {'loss': 0.8763, 'grad_norm': 1.4225287437438965, 'learning_rate': 4.842240901287406e-06, 'epoch': 0.14}
 14%|█▍        | 420/2906 [1:22:03<8:07:00, 11.75s/it] 14%|█▍        | 421/2906 [1:22:15<8:12:16, 11.89s/it]                                                      {'loss': 0.7911, 'grad_norm': 1.2510558366775513, 'learning_rate': 4.841260884418682e-06, 'epoch': 0.14}
 14%|█▍        | 421/2906 [1:22:15<8:12:16, 11.89s/it] 15%|█▍        | 422/2906 [1:22:27<8:08:09, 11.79s/it]                                                      {'loss': 0.7823, 'grad_norm': 1.281581163406372, 'learning_rate': 4.840277932779248e-06, 'epoch': 0.15}
 15%|█▍        | 422/2906 [1:22:27<8:08:09, 11.79s/it] 15%|█▍        | 423/2906 [1:22:39<8:07:20, 11.78s/it]                                                      {'loss': 0.8413, 'grad_norm': 1.3812534809112549, 'learning_rate': 4.839292047601234e-06, 'epoch': 0.15}
 15%|█▍        | 423/2906 [1:22:39<8:07:20, 11.78s/it] 15%|█▍        | 424/2906 [1:22:51<8:10:26, 11.86s/it]                                                      {'loss': 0.8738, 'grad_norm': 1.4052106142044067, 'learning_rate': 4.838303230120448e-06, 'epoch': 0.15}
 15%|█▍        | 424/2906 [1:22:51<8:10:26, 11.86s/it] 15%|█▍        | 425/2906 [1:23:02<8:04:22, 11.71s/it]                                                      {'loss': 0.8672, 'grad_norm': 1.3067666292190552, 'learning_rate': 4.83731148157637e-06, 'epoch': 0.15}
 15%|█▍        | 425/2906 [1:23:02<8:04:22, 11.71s/it] 15%|█▍        | 426/2906 [1:23:14<8:01:54, 11.66s/it]                                                      {'loss': 0.7526, 'grad_norm': 1.2777683734893799, 'learning_rate': 4.8363168032121596e-06, 'epoch': 0.15}
 15%|█▍        | 426/2906 [1:23:14<8:01:54, 11.66s/it] 15%|█▍        | 427/2906 [1:23:25<7:56:24, 11.53s/it]                                                      {'loss': 0.8138, 'grad_norm': 1.3399380445480347, 'learning_rate': 4.835319196274646e-06, 'epoch': 0.15}
 15%|█▍        | 427/2906 [1:23:25<7:56:24, 11.53s/it] 15%|█▍        | 428/2906 [1:23:37<8:02:36, 11.69s/it]                                                      {'loss': 0.8143, 'grad_norm': 1.29169499874115, 'learning_rate': 4.834318662014328e-06, 'epoch': 0.15}
 15%|█▍        | 428/2906 [1:23:37<8:02:36, 11.69s/it] 15%|█▍        | 429/2906 [1:23:49<8:00:16, 11.63s/it]                                                      {'loss': 0.7057, 'grad_norm': 1.2461403608322144, 'learning_rate': 4.833315201685375e-06, 'epoch': 0.15}
 15%|█▍        | 429/2906 [1:23:49<8:00:16, 11.63s/it] 15%|█▍        | 430/2906 [1:24:00<7:54:07, 11.49s/it]                                                      {'loss': 0.7874, 'grad_norm': 1.2325825691223145, 'learning_rate': 4.832308816545627e-06, 'epoch': 0.15}
 15%|█▍        | 430/2906 [1:24:00<7:54:07, 11.49s/it] 15%|█▍        | 431/2906 [1:24:11<7:48:37, 11.36s/it]                                                      {'loss': 0.8659, 'grad_norm': 1.276173710823059, 'learning_rate': 4.831299507856587e-06, 'epoch': 0.15}
 15%|█▍        | 431/2906 [1:24:11<7:48:37, 11.36s/it] 15%|█▍        | 432/2906 [1:24:22<7:45:35, 11.29s/it]                                                      {'loss': 0.8256, 'grad_norm': 1.2893162965774536, 'learning_rate': 4.830287276883423e-06, 'epoch': 0.15}
 15%|█▍        | 432/2906 [1:24:22<7:45:35, 11.29s/it] 15%|█▍        | 433/2906 [1:24:33<7:46:59, 11.33s/it]                                                      {'loss': 0.8199, 'grad_norm': 1.3230024576187134, 'learning_rate': 4.829272124894967e-06, 'epoch': 0.15}
 15%|█▍        | 433/2906 [1:24:33<7:46:59, 11.33s/it] 15%|█▍        | 434/2906 [1:24:45<7:46:58, 11.33s/it]                                                      {'loss': 0.8319, 'grad_norm': 1.2511024475097656, 'learning_rate': 4.828254053163711e-06, 'epoch': 0.15}
 15%|█▍        | 434/2906 [1:24:45<7:46:58, 11.33s/it] 15%|█▍        | 435/2906 [1:24:56<7:45:45, 11.31s/it]                                                      {'loss': 0.759, 'grad_norm': 1.311082363128662, 'learning_rate': 4.827233062965811e-06, 'epoch': 0.15}
 15%|█▍        | 435/2906 [1:24:56<7:45:45, 11.31s/it] 15%|█▌        | 436/2906 [1:25:07<7:47:15, 11.35s/it]                                                      {'loss': 0.7882, 'grad_norm': 1.2536653280258179, 'learning_rate': 4.826209155581074e-06, 'epoch': 0.15}
 15%|█▌        | 436/2906 [1:25:07<7:47:15, 11.35s/it] 15%|█▌        | 437/2906 [1:25:18<7:42:09, 11.23s/it]                                                      {'loss': 0.7967, 'grad_norm': 1.3091198205947876, 'learning_rate': 4.82518233229297e-06, 'epoch': 0.15}
 15%|█▌        | 437/2906 [1:25:18<7:42:09, 11.23s/it] 15%|█▌        | 438/2906 [1:25:29<7:41:44, 11.23s/it]                                                      {'loss': 0.7934, 'grad_norm': 1.303895115852356, 'learning_rate': 4.824152594388624e-06, 'epoch': 0.15}
 15%|█▌        | 438/2906 [1:25:30<7:41:44, 11.23s/it] 15%|█▌        | 439/2906 [1:25:41<7:44:29, 11.30s/it]                                                      {'loss': 0.8247, 'grad_norm': 1.2757431268692017, 'learning_rate': 4.823119943158809e-06, 'epoch': 0.15}
 15%|█▌        | 439/2906 [1:25:41<7:44:29, 11.30s/it] 15%|█▌        | 440/2906 [1:25:52<7:47:05, 11.36s/it]                                                      {'loss': 0.7677, 'grad_norm': 1.313349962234497, 'learning_rate': 4.822084379897957e-06, 'epoch': 0.15}
 15%|█▌        | 440/2906 [1:25:52<7:47:05, 11.36s/it] 15%|█▌        | 441/2906 [1:26:04<7:52:29, 11.50s/it]                                                      {'loss': 0.8247, 'grad_norm': 1.3386894464492798, 'learning_rate': 4.821045905904143e-06, 'epoch': 0.15}
 15%|█▌        | 441/2906 [1:26:04<7:52:29, 11.50s/it] 15%|█▌        | 442/2906 [1:26:15<7:48:08, 11.40s/it]                                                      {'loss': 0.8269, 'grad_norm': 1.293320655822754, 'learning_rate': 4.820004522479097e-06, 'epoch': 0.15}
 15%|█▌        | 442/2906 [1:26:15<7:48:08, 11.40s/it] 15%|█▌        | 443/2906 [1:26:27<7:53:36, 11.54s/it]                                                      {'loss': 0.819, 'grad_norm': 1.338582992553711, 'learning_rate': 4.818960230928192e-06, 'epoch': 0.15}
 15%|█▌        | 443/2906 [1:26:27<7:53:36, 11.54s/it] 15%|█▌        | 444/2906 [1:26:39<7:50:43, 11.47s/it]                                                      {'loss': 0.7943, 'grad_norm': 1.2282745838165283, 'learning_rate': 4.8179130325604486e-06, 'epoch': 0.15}
 15%|█▌        | 444/2906 [1:26:39<7:50:43, 11.47s/it] 15%|█▌        | 445/2906 [1:26:50<7:51:37, 11.50s/it]                                                      {'loss': 0.8318, 'grad_norm': 1.3525017499923706, 'learning_rate': 4.816862928688528e-06, 'epoch': 0.15}
 15%|█▌        | 445/2906 [1:26:50<7:51:37, 11.50s/it] 15%|█▌        | 446/2906 [1:27:01<7:45:22, 11.35s/it]                                                      {'loss': 0.7612, 'grad_norm': 1.2802324295043945, 'learning_rate': 4.815809920628738e-06, 'epoch': 0.15}
 15%|█▌        | 446/2906 [1:27:01<7:45:22, 11.35s/it] 15%|█▌        | 447/2906 [1:27:13<7:44:56, 11.34s/it]                                                      {'loss': 0.7834, 'grad_norm': 1.2568777799606323, 'learning_rate': 4.814754009701023e-06, 'epoch': 0.15}
 15%|█▌        | 447/2906 [1:27:13<7:44:56, 11.34s/it] 15%|█▌        | 448/2906 [1:27:24<7:45:21, 11.36s/it]                                                      {'loss': 0.7477, 'grad_norm': 1.3223044872283936, 'learning_rate': 4.813695197228966e-06, 'epoch': 0.15}
 15%|█▌        | 448/2906 [1:27:24<7:45:21, 11.36s/it] 15%|█▌        | 449/2906 [1:27:35<7:46:30, 11.39s/it]                                                      {'loss': 0.7637, 'grad_norm': 1.171745777130127, 'learning_rate': 4.8126334845397914e-06, 'epoch': 0.15}
 15%|█▌        | 449/2906 [1:27:35<7:46:30, 11.39s/it] 15%|█▌        | 450/2906 [1:27:47<7:50:51, 11.50s/it]                                                      {'loss': 0.7949, 'grad_norm': 1.319452166557312, 'learning_rate': 4.811568872964354e-06, 'epoch': 0.15}
 15%|█▌        | 450/2906 [1:27:47<7:50:51, 11.50s/it] 16%|█▌        | 451/2906 [1:27:58<7:46:27, 11.40s/it]                                                      {'loss': 0.7906, 'grad_norm': 1.27665114402771, 'learning_rate': 4.8105013638371454e-06, 'epoch': 0.16}
 16%|█▌        | 451/2906 [1:27:58<7:46:27, 11.40s/it] 16%|█▌        | 452/2906 [1:28:10<7:51:53, 11.54s/it]                                                      {'loss': 0.7949, 'grad_norm': 1.332524299621582, 'learning_rate': 4.809430958496288e-06, 'epoch': 0.16}
 16%|█▌        | 452/2906 [1:28:10<7:51:53, 11.54s/it] 16%|█▌        | 453/2906 [1:28:22<8:01:06, 11.77s/it]                                                      {'loss': 0.7798, 'grad_norm': 1.3170276880264282, 'learning_rate': 4.8083576582835366e-06, 'epoch': 0.16}
 16%|█▌        | 453/2906 [1:28:23<8:01:06, 11.77s/it] 16%|█▌        | 454/2906 [1:28:34<8:00:47, 11.76s/it]                                                      {'loss': 0.8314, 'grad_norm': 1.334268569946289, 'learning_rate': 4.80728146454427e-06, 'epoch': 0.16}
 16%|█▌        | 454/2906 [1:28:34<8:00:47, 11.76s/it] 16%|█▌        | 455/2906 [1:28:46<7:59:13, 11.73s/it]                                                      {'loss': 0.719, 'grad_norm': 1.2570250034332275, 'learning_rate': 4.8062023786274996e-06, 'epoch': 0.16}
 16%|█▌        | 455/2906 [1:28:46<7:59:13, 11.73s/it] 16%|█▌        | 456/2906 [1:28:58<8:03:03, 11.83s/it]                                                      {'loss': 0.8135, 'grad_norm': 1.3957284688949585, 'learning_rate': 4.805120401885859e-06, 'epoch': 0.16}
 16%|█▌        | 456/2906 [1:28:58<8:03:03, 11.83s/it] 16%|█▌        | 457/2906 [1:29:10<8:06:56, 11.93s/it]                                                      {'loss': 0.7962, 'grad_norm': 1.2964491844177246, 'learning_rate': 4.804035535675606e-06, 'epoch': 0.16}
 16%|█▌        | 457/2906 [1:29:10<8:06:56, 11.93s/it] 16%|█▌        | 458/2906 [1:29:22<8:02:08, 11.82s/it]                                                      {'loss': 0.8806, 'grad_norm': 1.3290250301361084, 'learning_rate': 4.80294778135662e-06, 'epoch': 0.16}
 16%|█▌        | 458/2906 [1:29:22<8:02:08, 11.82s/it] 16%|█▌        | 459/2906 [1:29:33<7:56:57, 11.70s/it]                                                      {'loss': 0.7106, 'grad_norm': 1.2395052909851074, 'learning_rate': 4.801857140292402e-06, 'epoch': 0.16}
 16%|█▌        | 459/2906 [1:29:33<7:56:57, 11.70s/it] 16%|█▌        | 460/2906 [1:29:44<7:52:12, 11.58s/it]                                                      {'loss': 0.8002, 'grad_norm': 1.4898459911346436, 'learning_rate': 4.80076361385007e-06, 'epoch': 0.16}
 16%|█▌        | 460/2906 [1:29:44<7:52:12, 11.58s/it] 16%|█▌        | 461/2906 [1:29:55<7:45:56, 11.43s/it]                                                      {'loss': 0.799, 'grad_norm': 1.2782076597213745, 'learning_rate': 4.799667203400361e-06, 'epoch': 0.16}
 16%|█▌        | 461/2906 [1:29:55<7:45:56, 11.43s/it] 16%|█▌        | 462/2906 [1:30:07<7:46:22, 11.45s/it]                                                      {'loss': 0.8692, 'grad_norm': 1.3408123254776, 'learning_rate': 4.798567910317623e-06, 'epoch': 0.16}
 16%|█▌        | 462/2906 [1:30:07<7:46:22, 11.45s/it] 16%|█▌        | 463/2906 [1:30:18<7:41:43, 11.34s/it]                                                      {'loss': 0.8003, 'grad_norm': 1.3904775381088257, 'learning_rate': 4.7974657359798224e-06, 'epoch': 0.16}
 16%|█▌        | 463/2906 [1:30:18<7:41:43, 11.34s/it] 16%|█▌        | 464/2906 [1:30:29<7:39:06, 11.28s/it]                                                      {'loss': 0.8265, 'grad_norm': 1.3021773099899292, 'learning_rate': 4.796360681768533e-06, 'epoch': 0.16}
 16%|█▌        | 464/2906 [1:30:29<7:39:06, 11.28s/it] 16%|█▌        | 465/2906 [1:30:41<7:43:37, 11.40s/it]                                                      {'loss': 0.8569, 'grad_norm': 1.2364120483398438, 'learning_rate': 4.795252749068942e-06, 'epoch': 0.16}
 16%|█▌        | 465/2906 [1:30:41<7:43:37, 11.40s/it] 16%|█▌        | 466/2906 [1:30:52<7:39:29, 11.30s/it]                                                      {'loss': 0.8442, 'grad_norm': 1.2054150104522705, 'learning_rate': 4.794141939269842e-06, 'epoch': 0.16}
 16%|█▌        | 466/2906 [1:30:52<7:39:29, 11.30s/it] 16%|█▌        | 467/2906 [1:31:04<7:43:33, 11.40s/it]                                                      {'loss': 0.7937, 'grad_norm': 1.285903811454773, 'learning_rate': 4.793028253763633e-06, 'epoch': 0.16}
 16%|█▌        | 467/2906 [1:31:04<7:43:33, 11.40s/it] 16%|█▌        | 468/2906 [1:31:15<7:44:32, 11.43s/it]                                                      {'loss': 0.7622, 'grad_norm': 1.2707715034484863, 'learning_rate': 4.79191169394632e-06, 'epoch': 0.16}
 16%|█▌        | 468/2906 [1:31:15<7:44:32, 11.43s/it] 16%|█▌        | 469/2906 [1:31:26<7:42:14, 11.38s/it]                                                      {'loss': 0.8668, 'grad_norm': 1.3453547954559326, 'learning_rate': 4.790792261217513e-06, 'epoch': 0.16}
 16%|█▌        | 469/2906 [1:31:26<7:42:14, 11.38s/it] 16%|█▌        | 470/2906 [1:31:38<7:49:08, 11.56s/it]                                                      {'loss': 0.8554, 'grad_norm': 1.3302929401397705, 'learning_rate': 4.789669956980417e-06, 'epoch': 0.16}
 16%|█▌        | 470/2906 [1:31:38<7:49:08, 11.56s/it] 16%|█▌        | 471/2906 [1:31:50<7:47:24, 11.52s/it]                                                      {'loss': 0.8448, 'grad_norm': 1.2567604780197144, 'learning_rate': 4.7885447826418435e-06, 'epoch': 0.16}
 16%|█▌        | 471/2906 [1:31:50<7:47:24, 11.52s/it] 16%|█▌        | 472/2906 [1:32:02<7:50:37, 11.60s/it]                                                      {'loss': 0.7816, 'grad_norm': 1.2356263399124146, 'learning_rate': 4.787416739612198e-06, 'epoch': 0.16}
 16%|█▌        | 472/2906 [1:32:02<7:50:37, 11.60s/it] 16%|█▋        | 473/2906 [1:32:13<7:52:38, 11.66s/it]                                                      {'loss': 0.7663, 'grad_norm': 1.3627867698669434, 'learning_rate': 4.786285829305481e-06, 'epoch': 0.16}
 16%|█▋        | 473/2906 [1:32:13<7:52:38, 11.66s/it] 16%|█▋        | 474/2906 [1:32:25<7:51:40, 11.64s/it]                                                      {'loss': 0.8102, 'grad_norm': 1.2909291982650757, 'learning_rate': 4.785152053139291e-06, 'epoch': 0.16}
 16%|█▋        | 474/2906 [1:32:25<7:51:40, 11.64s/it] 16%|█▋        | 475/2906 [1:32:37<7:52:35, 11.66s/it]                                                      {'loss': 0.7556, 'grad_norm': 1.2434989213943481, 'learning_rate': 4.784015412534816e-06, 'epoch': 0.16}
 16%|█▋        | 475/2906 [1:32:37<7:52:35, 11.66s/it] 16%|█▋        | 476/2906 [1:32:48<7:43:42, 11.45s/it]                                                      {'loss': 0.7803, 'grad_norm': 1.2924367189407349, 'learning_rate': 4.782875908916834e-06, 'epoch': 0.16}
 16%|█▋        | 476/2906 [1:32:48<7:43:42, 11.45s/it] 16%|█▋        | 477/2906 [1:32:59<7:47:07, 11.54s/it]                                                      {'loss': 0.6864, 'grad_norm': 1.256507396697998, 'learning_rate': 4.781733543713714e-06, 'epoch': 0.16}
 16%|█▋        | 477/2906 [1:32:59<7:47:07, 11.54s/it] 16%|█▋        | 478/2906 [1:33:11<7:47:30, 11.55s/it]                                                      {'loss': 0.8521, 'grad_norm': 1.235907793045044, 'learning_rate': 4.780588318357409e-06, 'epoch': 0.16}
 16%|█▋        | 478/2906 [1:33:11<7:47:30, 11.55s/it] 16%|█▋        | 479/2906 [1:33:22<7:45:50, 11.52s/it]                                                      {'loss': 0.8378, 'grad_norm': 1.2552669048309326, 'learning_rate': 4.779440234283461e-06, 'epoch': 0.16}
 16%|█▋        | 479/2906 [1:33:22<7:45:50, 11.52s/it] 17%|█▋        | 480/2906 [1:33:34<7:48:31, 11.59s/it]                                                      {'loss': 0.8281, 'grad_norm': 1.3200634717941284, 'learning_rate': 4.778289292930993e-06, 'epoch': 0.17}
 17%|█▋        | 480/2906 [1:33:34<7:48:31, 11.59s/it] 17%|█▋        | 481/2906 [1:33:46<7:51:38, 11.67s/it]                                                      {'loss': 0.8185, 'grad_norm': 1.3624529838562012, 'learning_rate': 4.77713549574271e-06, 'epoch': 0.17}
 17%|█▋        | 481/2906 [1:33:46<7:51:38, 11.67s/it] 17%|█▋        | 482/2906 [1:33:58<7:54:50, 11.75s/it]                                                      {'loss': 0.7957, 'grad_norm': 1.3651776313781738, 'learning_rate': 4.775978844164896e-06, 'epoch': 0.17}
 17%|█▋        | 482/2906 [1:33:58<7:54:50, 11.75s/it] 17%|█▋        | 483/2906 [1:34:09<7:51:57, 11.69s/it]                                                      {'loss': 0.7835, 'grad_norm': 1.2402966022491455, 'learning_rate': 4.774819339647415e-06, 'epoch': 0.17}
 17%|█▋        | 483/2906 [1:34:09<7:51:57, 11.69s/it] 17%|█▋        | 484/2906 [1:34:21<7:48:32, 11.61s/it]                                                      {'loss': 0.7938, 'grad_norm': 1.2326648235321045, 'learning_rate': 4.773656983643706e-06, 'epoch': 0.17}
 17%|█▋        | 484/2906 [1:34:21<7:48:32, 11.61s/it] 17%|█▋        | 485/2906 [1:34:33<7:48:42, 11.62s/it]                                                      {'loss': 0.8096, 'grad_norm': 1.2816479206085205, 'learning_rate': 4.772491777610782e-06, 'epoch': 0.17}
 17%|█▋        | 485/2906 [1:34:33<7:48:42, 11.62s/it] 17%|█▋        | 486/2906 [1:34:44<7:49:56, 11.65s/it]                                                      {'loss': 0.8287, 'grad_norm': 1.3191161155700684, 'learning_rate': 4.7713237230092286e-06, 'epoch': 0.17}
 17%|█▋        | 486/2906 [1:34:44<7:49:56, 11.65s/it] 17%|█▋        | 487/2906 [1:34:56<7:51:55, 11.71s/it]                                                      {'loss': 0.8055, 'grad_norm': 1.3064863681793213, 'learning_rate': 4.770152821303203e-06, 'epoch': 0.17}
 17%|█▋        | 487/2906 [1:34:56<7:51:55, 11.71s/it] 17%|█▋        | 488/2906 [1:35:07<7:44:59, 11.54s/it]                                                      {'loss': 0.8624, 'grad_norm': 1.2732549905776978, 'learning_rate': 4.76897907396043e-06, 'epoch': 0.17}
 17%|█▋        | 488/2906 [1:35:07<7:44:59, 11.54s/it] 17%|█▋        | 489/2906 [1:35:19<7:42:17, 11.48s/it]                                                      {'loss': 0.8818, 'grad_norm': 1.3823215961456299, 'learning_rate': 4.767802482452202e-06, 'epoch': 0.17}
 17%|█▋        | 489/2906 [1:35:19<7:42:17, 11.48s/it] 17%|█▋        | 490/2906 [1:35:30<7:46:39, 11.59s/it]                                                      {'loss': 0.7917, 'grad_norm': 1.3303335905075073, 'learning_rate': 4.766623048253376e-06, 'epoch': 0.17}
 17%|█▋        | 490/2906 [1:35:30<7:46:39, 11.59s/it] 17%|█▋        | 491/2906 [1:35:42<7:50:16, 11.68s/it]                                                      {'loss': 0.7419, 'grad_norm': 1.1981145143508911, 'learning_rate': 4.7654407728423745e-06, 'epoch': 0.17}
 17%|█▋        | 491/2906 [1:35:42<7:50:16, 11.68s/it] 17%|█▋        | 492/2906 [1:35:54<7:50:56, 11.71s/it]                                                      {'loss': 0.7414, 'grad_norm': 1.2761512994766235, 'learning_rate': 4.764255657701179e-06, 'epoch': 0.17}
 17%|█▋        | 492/2906 [1:35:54<7:50:56, 11.71s/it] 17%|█▋        | 493/2906 [1:36:05<7:44:57, 11.56s/it]                                                      {'loss': 0.8135, 'grad_norm': 1.3420262336730957, 'learning_rate': 4.763067704315331e-06, 'epoch': 0.17}
 17%|█▋        | 493/2906 [1:36:05<7:44:57, 11.56s/it] 17%|█▋        | 494/2906 [1:36:17<7:46:36, 11.61s/it]                                                      {'loss': 0.7972, 'grad_norm': 1.294713020324707, 'learning_rate': 4.761876914173931e-06, 'epoch': 0.17}
 17%|█▋        | 494/2906 [1:36:17<7:46:36, 11.61s/it] 17%|█▋        | 495/2906 [1:36:29<7:46:22, 11.61s/it]                                                      {'loss': 0.8563, 'grad_norm': 1.3426593542099, 'learning_rate': 4.760683288769634e-06, 'epoch': 0.17}
 17%|█▋        | 495/2906 [1:36:29<7:46:22, 11.61s/it] 17%|█▋        | 496/2906 [1:36:40<7:46:07, 11.60s/it]                                                      {'loss': 0.8395, 'grad_norm': 1.365051507949829, 'learning_rate': 4.7594868295986485e-06, 'epoch': 0.17}
 17%|█▋        | 496/2906 [1:36:40<7:46:07, 11.60s/it] 17%|█▋        | 497/2906 [1:36:52<7:50:44, 11.72s/it]                                                      {'loss': 0.805, 'grad_norm': 1.34610116481781, 'learning_rate': 4.758287538160738e-06, 'epoch': 0.17}
 17%|█▋        | 497/2906 [1:36:52<7:50:44, 11.72s/it] 17%|█▋        | 498/2906 [1:37:04<7:54:30, 11.82s/it]                                                      {'loss': 0.8594, 'grad_norm': 1.3637373447418213, 'learning_rate': 4.757085415959214e-06, 'epoch': 0.17}
 17%|█▋        | 498/2906 [1:37:04<7:54:30, 11.82s/it] 17%|█▋        | 499/2906 [1:37:16<7:50:13, 11.72s/it]                                                      {'loss': 0.8266, 'grad_norm': 1.3168845176696777, 'learning_rate': 4.755880464500936e-06, 'epoch': 0.17}
 17%|█▋        | 499/2906 [1:37:16<7:50:13, 11.72s/it] 17%|█▋        | 500/2906 [1:37:27<7:47:53, 11.67s/it]                                                      {'loss': 0.8902, 'grad_norm': 1.3367371559143066, 'learning_rate': 4.754672685296311e-06, 'epoch': 0.17}
 17%|█▋        | 500/2906 [1:37:27<7:47:53, 11.67s/it] 17%|█▋        | 501/2906 [1:37:39<7:48:49, 11.70s/it]                                                      {'loss': 0.7702, 'grad_norm': 1.2380658388137817, 'learning_rate': 4.753462079859291e-06, 'epoch': 0.17}
 17%|█▋        | 501/2906 [1:37:39<7:48:49, 11.70s/it] 17%|█▋        | 502/2906 [1:37:51<7:45:57, 11.63s/it]                                                      {'loss': 0.8128, 'grad_norm': 1.39287531375885, 'learning_rate': 4.75224864970737e-06, 'epoch': 0.17}
 17%|█▋        | 502/2906 [1:37:51<7:45:57, 11.63s/it] 17%|█▋        | 503/2906 [1:38:02<7:46:36, 11.65s/it]                                                      {'loss': 0.827, 'grad_norm': 1.4149523973464966, 'learning_rate': 4.7510323963615815e-06, 'epoch': 0.17}
 17%|█▋        | 503/2906 [1:38:02<7:46:36, 11.65s/it] 17%|█▋        | 504/2906 [1:38:14<7:48:06, 11.69s/it]                                                      {'loss': 0.8062, 'grad_norm': 1.2105571031570435, 'learning_rate': 4.7498133213465e-06, 'epoch': 0.17}
 17%|█▋        | 504/2906 [1:38:14<7:48:06, 11.69s/it] 17%|█▋        | 505/2906 [1:38:26<7:50:39, 11.76s/it]                                                      {'loss': 0.8722, 'grad_norm': 1.468752384185791, 'learning_rate': 4.748591426190237e-06, 'epoch': 0.17}
 17%|█▋        | 505/2906 [1:38:26<7:50:39, 11.76s/it] 17%|█▋        | 506/2906 [1:38:38<7:58:21, 11.96s/it]                                                      {'loss': 0.8553, 'grad_norm': 1.3588453531265259, 'learning_rate': 4.747366712424436e-06, 'epoch': 0.17}
 17%|█▋        | 506/2906 [1:38:38<7:58:21, 11.96s/it] 17%|█▋        | 507/2906 [1:38:50<7:52:58, 11.83s/it]                                                      {'loss': 0.8114, 'grad_norm': 1.3735014200210571, 'learning_rate': 4.746139181584278e-06, 'epoch': 0.17}
 17%|█▋        | 507/2906 [1:38:50<7:52:58, 11.83s/it] 17%|█▋        | 508/2906 [1:39:01<7:49:01, 11.74s/it]                                                      {'loss': 0.8277, 'grad_norm': 1.279831886291504, 'learning_rate': 4.744908835208472e-06, 'epoch': 0.17}
 17%|█▋        | 508/2906 [1:39:01<7:49:01, 11.74s/it] 18%|█▊        | 509/2906 [1:39:13<7:44:48, 11.63s/it]                                                      {'loss': 0.8679, 'grad_norm': 1.3992968797683716, 'learning_rate': 4.743675674839258e-06, 'epoch': 0.18}
 18%|█▊        | 509/2906 [1:39:13<7:44:48, 11.63s/it] 18%|█▊        | 510/2906 [1:39:25<7:49:41, 11.76s/it]                                                      {'loss': 0.7483, 'grad_norm': 1.394028663635254, 'learning_rate': 4.7424397020224006e-06, 'epoch': 0.18}
 18%|█▊        | 510/2906 [1:39:25<7:49:41, 11.76s/it] 18%|█▊        | 511/2906 [1:39:37<7:48:53, 11.75s/it]                                                      {'loss': 0.8057, 'grad_norm': 1.286387324333191, 'learning_rate': 4.741200918307194e-06, 'epoch': 0.18}
 18%|█▊        | 511/2906 [1:39:37<7:48:53, 11.75s/it] 18%|█▊        | 512/2906 [1:39:48<7:44:01, 11.63s/it]                                                      {'loss': 0.8024, 'grad_norm': 1.2409065961837769, 'learning_rate': 4.739959325246453e-06, 'epoch': 0.18}
 18%|█▊        | 512/2906 [1:39:48<7:44:01, 11.63s/it] 18%|█▊        | 513/2906 [1:39:59<7:42:58, 11.61s/it]                                                      {'loss': 0.7634, 'grad_norm': 1.2722008228302002, 'learning_rate': 4.738714924396514e-06, 'epoch': 0.18}
 18%|█▊        | 513/2906 [1:40:00<7:42:58, 11.61s/it] 18%|█▊        | 514/2906 [1:40:11<7:43:09, 11.62s/it]                                                      {'loss': 0.7808, 'grad_norm': 1.2298191785812378, 'learning_rate': 4.7374677173172355e-06, 'epoch': 0.18}
 18%|█▊        | 514/2906 [1:40:11<7:43:09, 11.62s/it] 18%|█▊        | 515/2906 [1:40:23<7:44:02, 11.64s/it]                                                      {'loss': 0.8361, 'grad_norm': 1.385099172592163, 'learning_rate': 4.736217705571989e-06, 'epoch': 0.18}
 18%|█▊        | 515/2906 [1:40:23<7:44:02, 11.64s/it] 18%|█▊        | 516/2906 [1:40:35<7:46:32, 11.71s/it]                                                      {'loss': 0.7626, 'grad_norm': 1.2558408975601196, 'learning_rate': 4.734964890727667e-06, 'epoch': 0.18}
 18%|█▊        | 516/2906 [1:40:35<7:46:32, 11.71s/it] 18%|█▊        | 517/2906 [1:40:47<7:56:42, 11.97s/it]                                                      {'loss': 0.8083, 'grad_norm': 1.3272104263305664, 'learning_rate': 4.73370927435467e-06, 'epoch': 0.18}
 18%|█▊        | 517/2906 [1:40:47<7:56:42, 11.97s/it] 18%|█▊        | 518/2906 [1:40:59<7:47:55, 11.76s/it]                                                      {'loss': 0.7824, 'grad_norm': 1.2532333135604858, 'learning_rate': 4.7324508580269156e-06, 'epoch': 0.18}
 18%|█▊        | 518/2906 [1:40:59<7:47:55, 11.76s/it] 18%|█▊        | 519/2906 [1:41:10<7:44:40, 11.68s/it]                                                      {'loss': 0.8418, 'grad_norm': 1.3146809339523315, 'learning_rate': 4.731189643321829e-06, 'epoch': 0.18}
 18%|█▊        | 519/2906 [1:41:10<7:44:40, 11.68s/it] 18%|█▊        | 520/2906 [1:41:21<7:38:07, 11.52s/it]                                                      {'loss': 0.8279, 'grad_norm': 1.3447762727737427, 'learning_rate': 4.72992563182034e-06, 'epoch': 0.18}
 18%|█▊        | 520/2906 [1:41:21<7:38:07, 11.52s/it] 18%|█▊        | 521/2906 [1:41:33<7:36:48, 11.49s/it]                                                      {'loss': 0.8019, 'grad_norm': 1.3539116382598877, 'learning_rate': 4.728658825106891e-06, 'epoch': 0.18}
 18%|█▊        | 521/2906 [1:41:33<7:36:48, 11.49s/it] 18%|█▊        | 522/2906 [1:41:44<7:39:09, 11.56s/it]                                                      {'loss': 0.767, 'grad_norm': 1.2523256540298462, 'learning_rate': 4.727389224769421e-06, 'epoch': 0.18}
 18%|█▊        | 522/2906 [1:41:44<7:39:09, 11.56s/it] 18%|█▊        | 523/2906 [1:41:56<7:41:09, 11.61s/it]                                                      {'loss': 0.8133, 'grad_norm': 1.2570853233337402, 'learning_rate': 4.726116832399376e-06, 'epoch': 0.18}
 18%|█▊        | 523/2906 [1:41:56<7:41:09, 11.61s/it] 18%|█▊        | 524/2906 [1:42:08<7:45:29, 11.73s/it]                                                      {'loss': 0.7709, 'grad_norm': 1.2714883089065552, 'learning_rate': 4.724841649591699e-06, 'epoch': 0.18}
 18%|█▊        | 524/2906 [1:42:08<7:45:29, 11.73s/it] 18%|█▊        | 525/2906 [1:42:20<7:52:24, 11.90s/it]                                                      {'loss': 0.7854, 'grad_norm': 1.2123178243637085, 'learning_rate': 4.723563677944833e-06, 'epoch': 0.18}
 18%|█▊        | 525/2906 [1:42:20<7:52:24, 11.90s/it] 18%|█▊        | 526/2906 [1:42:32<7:47:47, 11.79s/it]                                                      {'loss': 0.793, 'grad_norm': 1.3887295722961426, 'learning_rate': 4.7222829190607145e-06, 'epoch': 0.18}
 18%|█▊        | 526/2906 [1:42:32<7:47:47, 11.79s/it] 18%|█▊        | 527/2906 [1:42:44<7:46:06, 11.76s/it]                                                      {'loss': 0.8015, 'grad_norm': 1.318551778793335, 'learning_rate': 4.720999374544776e-06, 'epoch': 0.18}
 18%|█▊        | 527/2906 [1:42:44<7:46:06, 11.76s/it] 18%|█▊        | 528/2906 [1:42:55<7:42:42, 11.67s/it]                                                      {'loss': 0.7727, 'grad_norm': 1.2356736660003662, 'learning_rate': 4.7197130460059385e-06, 'epoch': 0.18}
 18%|█▊        | 528/2906 [1:42:55<7:42:42, 11.67s/it] 18%|█▊        | 529/2906 [1:43:07<7:44:07, 11.72s/it]                                                      {'loss': 0.8433, 'grad_norm': 1.279685378074646, 'learning_rate': 4.718423935056617e-06, 'epoch': 0.18}
 18%|█▊        | 529/2906 [1:43:07<7:44:07, 11.72s/it] 18%|█▊        | 530/2906 [1:43:19<7:44:05, 11.72s/it]                                                      {'loss': 0.8172, 'grad_norm': 1.2803317308425903, 'learning_rate': 4.7171320433127114e-06, 'epoch': 0.18}
 18%|█▊        | 530/2906 [1:43:19<7:44:05, 11.72s/it] 18%|█▊        | 531/2906 [1:43:30<7:44:39, 11.74s/it]                                                      {'loss': 0.8101, 'grad_norm': 1.273613691329956, 'learning_rate': 4.715837372393607e-06, 'epoch': 0.18}
 18%|█▊        | 531/2906 [1:43:30<7:44:39, 11.74s/it] 18%|█▊        | 532/2906 [1:43:42<7:47:27, 11.81s/it]                                                      {'loss': 0.7899, 'grad_norm': 1.4010511636734009, 'learning_rate': 4.714539923922177e-06, 'epoch': 0.18}
 18%|█▊        | 532/2906 [1:43:42<7:47:27, 11.81s/it] 18%|█▊        | 533/2906 [1:43:54<7:44:32, 11.75s/it]                                                      {'loss': 0.7882, 'grad_norm': 1.2629563808441162, 'learning_rate': 4.71323969952477e-06, 'epoch': 0.18}
 18%|█▊        | 533/2906 [1:43:54<7:44:32, 11.75s/it] 18%|█▊        | 534/2906 [1:44:06<7:46:01, 11.79s/it]                                                      {'loss': 0.846, 'grad_norm': 1.342944622039795, 'learning_rate': 4.7119367008312174e-06, 'epoch': 0.18}
 18%|█▊        | 534/2906 [1:44:06<7:46:01, 11.79s/it] 18%|█▊        | 535/2906 [1:44:18<7:47:27, 11.83s/it]                                                      {'loss': 0.813, 'grad_norm': 1.2804286479949951, 'learning_rate': 4.7106309294748315e-06, 'epoch': 0.18}
 18%|█▊        | 535/2906 [1:44:18<7:47:27, 11.83s/it] 18%|█▊        | 536/2906 [1:44:29<7:45:57, 11.80s/it]                                                      {'loss': 0.8023, 'grad_norm': 1.270182728767395, 'learning_rate': 4.7093223870923935e-06, 'epoch': 0.18}
 18%|█▊        | 536/2906 [1:44:30<7:45:57, 11.80s/it] 18%|█▊        | 537/2906 [1:44:41<7:47:51, 11.85s/it]                                                      {'loss': 0.7505, 'grad_norm': 1.2338777780532837, 'learning_rate': 4.708011075324163e-06, 'epoch': 0.18}
 18%|█▊        | 537/2906 [1:44:41<7:47:51, 11.85s/it] 19%|█▊        | 538/2906 [1:44:53<7:44:54, 11.78s/it]                                                      {'loss': 0.7962, 'grad_norm': 1.3275117874145508, 'learning_rate': 4.706696995813869e-06, 'epoch': 0.19}
 19%|█▊        | 538/2906 [1:44:53<7:44:54, 11.78s/it] 19%|█▊        | 539/2906 [1:45:05<7:42:08, 11.71s/it]                                                      {'loss': 0.7748, 'grad_norm': 1.3088842630386353, 'learning_rate': 4.70538015020871e-06, 'epoch': 0.19}
 19%|█▊        | 539/2906 [1:45:05<7:42:08, 11.71s/it] 19%|█▊        | 540/2906 [1:45:16<7:38:38, 11.63s/it]                                                      {'loss': 0.8065, 'grad_norm': 1.3227640390396118, 'learning_rate': 4.704060540159352e-06, 'epoch': 0.19}
 19%|█▊        | 540/2906 [1:45:16<7:38:38, 11.63s/it] 19%|█▊        | 541/2906 [1:45:27<7:33:01, 11.49s/it]                                                      {'loss': 0.7217, 'grad_norm': 1.3419294357299805, 'learning_rate': 4.702738167319927e-06, 'epoch': 0.19}
 19%|█▊        | 541/2906 [1:45:27<7:33:01, 11.49s/it] 19%|█▊        | 542/2906 [1:45:39<7:32:59, 11.50s/it]                                                      {'loss': 0.7475, 'grad_norm': 1.3038772344589233, 'learning_rate': 4.701413033348029e-06, 'epoch': 0.19}
 19%|█▊        | 542/2906 [1:45:39<7:32:59, 11.50s/it] 19%|█▊        | 543/2906 [1:45:51<7:38:30, 11.64s/it]                                                      {'loss': 0.788, 'grad_norm': 1.277198076248169, 'learning_rate': 4.700085139904714e-06, 'epoch': 0.19}
 19%|█▊        | 543/2906 [1:45:51<7:38:30, 11.64s/it] 19%|█▊        | 544/2906 [1:46:02<7:38:16, 11.64s/it]                                                      {'loss': 0.8603, 'grad_norm': 1.3414806127548218, 'learning_rate': 4.6987544886544955e-06, 'epoch': 0.19}
 19%|█▊        | 544/2906 [1:46:02<7:38:16, 11.64s/it] 19%|█▉        | 545/2906 [1:46:14<7:42:32, 11.75s/it]                                                      {'loss': 0.829, 'grad_norm': 1.4863133430480957, 'learning_rate': 4.697421081265346e-06, 'epoch': 0.19}
 19%|█▉        | 545/2906 [1:46:14<7:42:32, 11.75s/it] 19%|█▉        | 546/2906 [1:46:26<7:43:51, 11.79s/it]                                                      {'loss': 0.8127, 'grad_norm': 1.2928962707519531, 'learning_rate': 4.696084919408691e-06, 'epoch': 0.19}
 19%|█▉        | 546/2906 [1:46:26<7:43:51, 11.79s/it] 19%|█▉        | 547/2906 [1:46:37<7:36:53, 11.62s/it]                                                      {'loss': 0.8649, 'grad_norm': 1.3530811071395874, 'learning_rate': 4.6947460047594105e-06, 'epoch': 0.19}
 19%|█▉        | 547/2906 [1:46:38<7:36:53, 11.62s/it] 19%|█▉        | 548/2906 [1:46:49<7:37:15, 11.64s/it]                                                      {'loss': 0.7731, 'grad_norm': 1.2770345211029053, 'learning_rate': 4.693404338995833e-06, 'epoch': 0.19}
 19%|█▉        | 548/2906 [1:46:49<7:37:15, 11.64s/it] 19%|█▉        | 549/2906 [1:47:01<7:38:53, 11.68s/it]                                                      {'loss': 0.8274, 'grad_norm': 1.3114030361175537, 'learning_rate': 4.692059923799736e-06, 'epoch': 0.19}
 19%|█▉        | 549/2906 [1:47:01<7:38:53, 11.68s/it] 19%|█▉        | 550/2906 [1:47:13<7:46:10, 11.87s/it]                                                      {'loss': 0.8148, 'grad_norm': 1.268324613571167, 'learning_rate': 4.690712760856347e-06, 'epoch': 0.19}
 19%|█▉        | 550/2906 [1:47:13<7:46:10, 11.87s/it] 19%|█▉        | 551/2906 [1:47:25<7:49:55, 11.97s/it]                                                      {'loss': 0.7974, 'grad_norm': 1.4542478322982788, 'learning_rate': 4.689362851854333e-06, 'epoch': 0.19}
 19%|█▉        | 551/2906 [1:47:26<7:49:55, 11.97s/it] 19%|█▉        | 552/2906 [1:47:37<7:49:02, 11.96s/it]                                                      {'loss': 0.825, 'grad_norm': 1.332013487815857, 'learning_rate': 4.688010198485804e-06, 'epoch': 0.19}
 19%|█▉        | 552/2906 [1:47:37<7:49:02, 11.96s/it] 19%|█▉        | 553/2906 [1:47:49<7:45:20, 11.87s/it]                                                      {'loss': 0.8026, 'grad_norm': 1.424687385559082, 'learning_rate': 4.686654802446313e-06, 'epoch': 0.19}
 19%|█▉        | 553/2906 [1:47:49<7:45:20, 11.87s/it] 19%|█▉        | 554/2906 [1:48:01<7:42:19, 11.79s/it]                                                      {'loss': 0.7885, 'grad_norm': 1.2637046575546265, 'learning_rate': 4.685296665434847e-06, 'epoch': 0.19}
 19%|█▉        | 554/2906 [1:48:01<7:42:19, 11.79s/it] 19%|█▉        | 555/2906 [1:48:12<7:41:50, 11.79s/it]                                                      {'loss': 0.7795, 'grad_norm': 1.2467352151870728, 'learning_rate': 4.683935789153834e-06, 'epoch': 0.19}
 19%|█▉        | 555/2906 [1:48:12<7:41:50, 11.79s/it] 19%|█▉        | 556/2906 [1:48:25<7:45:44, 11.89s/it]                                                      {'loss': 0.8237, 'grad_norm': 1.3195650577545166, 'learning_rate': 4.68257217530913e-06, 'epoch': 0.19}
 19%|█▉        | 556/2906 [1:48:25<7:45:44, 11.89s/it] 19%|█▉        | 557/2906 [1:48:36<7:44:14, 11.86s/it]                                                      {'loss': 0.7765, 'grad_norm': 1.3390672206878662, 'learning_rate': 4.681205825610025e-06, 'epoch': 0.19}
 19%|█▉        | 557/2906 [1:48:36<7:44:14, 11.86s/it] 19%|█▉        | 558/2906 [1:48:48<7:43:17, 11.84s/it]                                                      {'loss': 0.8416, 'grad_norm': 1.335505723953247, 'learning_rate': 4.67983674176924e-06, 'epoch': 0.19}
 19%|█▉        | 558/2906 [1:48:48<7:43:17, 11.84s/it] 19%|█▉        | 559/2906 [1:49:00<7:46:07, 11.92s/it]                                                      {'loss': 0.7564, 'grad_norm': 1.3433886766433716, 'learning_rate': 4.67846492550292e-06, 'epoch': 0.19}
 19%|█▉        | 559/2906 [1:49:00<7:46:07, 11.92s/it] 19%|█▉        | 560/2906 [1:49:12<7:49:40, 12.01s/it]                                                      {'loss': 0.7352, 'grad_norm': 1.2859838008880615, 'learning_rate': 4.6770903785306375e-06, 'epoch': 0.19}
 19%|█▉        | 560/2906 [1:49:12<7:49:40, 12.01s/it] 19%|█▉        | 561/2906 [1:49:24<7:48:51, 12.00s/it]                                                      {'loss': 0.8089, 'grad_norm': 1.28559410572052, 'learning_rate': 4.675713102575389e-06, 'epoch': 0.19}
 19%|█▉        | 561/2906 [1:49:24<7:48:51, 12.00s/it] 19%|█▉        | 562/2906 [1:49:36<7:45:29, 11.92s/it]                                                      {'loss': 0.8023, 'grad_norm': 1.4014233350753784, 'learning_rate': 4.674333099363587e-06, 'epoch': 0.19}
 19%|█▉        | 562/2906 [1:49:36<7:45:29, 11.92s/it] 19%|█▉        | 563/2906 [1:49:48<7:41:24, 11.82s/it]                                                      {'loss': 0.7171, 'grad_norm': 1.1946955919265747, 'learning_rate': 4.672950370625067e-06, 'epoch': 0.19}
 19%|█▉        | 563/2906 [1:49:48<7:41:24, 11.82s/it] 19%|█▉        | 564/2906 [1:50:00<7:42:03, 11.84s/it]                                                      {'loss': 0.8326, 'grad_norm': 1.307792067527771, 'learning_rate': 4.671564918093081e-06, 'epoch': 0.19}
 19%|█▉        | 564/2906 [1:50:00<7:42:03, 11.84s/it] 19%|█▉        | 565/2906 [1:50:11<7:38:50, 11.76s/it]                                                      {'loss': 0.7858, 'grad_norm': 1.234026551246643, 'learning_rate': 4.670176743504291e-06, 'epoch': 0.19}
 19%|█▉        | 565/2906 [1:50:11<7:38:50, 11.76s/it] 19%|█▉        | 566/2906 [1:50:23<7:35:21, 11.68s/it]                                                      {'loss': 0.7781, 'grad_norm': 1.2495241165161133, 'learning_rate': 4.6687858485987765e-06, 'epoch': 0.19}
 19%|█▉        | 566/2906 [1:50:23<7:35:21, 11.68s/it] 20%|█▉        | 567/2906 [1:50:35<7:39:01, 11.77s/it]                                                      {'loss': 0.863, 'grad_norm': 1.3732362985610962, 'learning_rate': 4.667392235120023e-06, 'epoch': 0.2}
 20%|█▉        | 567/2906 [1:50:35<7:39:01, 11.77s/it] 20%|█▉        | 568/2906 [1:50:46<7:35:57, 11.70s/it]                                                      {'loss': 0.8534, 'grad_norm': 1.3669852018356323, 'learning_rate': 4.665995904814925e-06, 'epoch': 0.2}
 20%|█▉        | 568/2906 [1:50:46<7:35:57, 11.70s/it] 20%|█▉        | 569/2906 [1:50:58<7:35:43, 11.70s/it]                                                      {'loss': 0.87, 'grad_norm': 1.2693932056427002, 'learning_rate': 4.664596859433784e-06, 'epoch': 0.2}
 20%|█▉        | 569/2906 [1:50:58<7:35:43, 11.70s/it] 20%|█▉        | 570/2906 [1:51:10<7:40:58, 11.84s/it]                                                      {'loss': 0.8633, 'grad_norm': 1.4353065490722656, 'learning_rate': 4.663195100730303e-06, 'epoch': 0.2}
 20%|█▉        | 570/2906 [1:51:10<7:40:58, 11.84s/it] 20%|█▉        | 571/2906 [1:51:22<7:39:07, 11.80s/it]                                                      {'loss': 0.7853, 'grad_norm': 1.1742488145828247, 'learning_rate': 4.661790630461585e-06, 'epoch': 0.2}
 20%|█▉        | 571/2906 [1:51:22<7:39:07, 11.80s/it] 20%|█▉        | 572/2906 [1:51:33<7:36:29, 11.74s/it]                                                      {'loss': 0.8298, 'grad_norm': 1.324532389640808, 'learning_rate': 4.660383450388135e-06, 'epoch': 0.2}
 20%|█▉        | 572/2906 [1:51:33<7:36:29, 11.74s/it] 20%|█▉        | 573/2906 [1:51:45<7:35:21, 11.71s/it]                                                      {'loss': 0.8028, 'grad_norm': 1.2553138732910156, 'learning_rate': 4.658973562273853e-06, 'epoch': 0.2}
 20%|█▉        | 573/2906 [1:51:45<7:35:21, 11.71s/it] 20%|█▉        | 574/2906 [1:51:56<7:25:49, 11.47s/it]                                                      {'loss': 0.8577, 'grad_norm': 1.3078137636184692, 'learning_rate': 4.657560967886035e-06, 'epoch': 0.2}
 20%|█▉        | 574/2906 [1:51:56<7:25:49, 11.47s/it] 20%|█▉        | 575/2906 [1:52:08<7:27:00, 11.51s/it]                                                      {'loss': 0.8223, 'grad_norm': 1.2952651977539062, 'learning_rate': 4.6561456689953665e-06, 'epoch': 0.2}
 20%|█▉        | 575/2906 [1:52:08<7:27:00, 11.51s/it] 20%|█▉        | 576/2906 [1:52:19<7:29:37, 11.58s/it]                                                      {'loss': 0.794, 'grad_norm': 1.2795971632003784, 'learning_rate': 4.654727667375926e-06, 'epoch': 0.2}
 20%|█▉        | 576/2906 [1:52:19<7:29:37, 11.58s/it] 20%|█▉        | 577/2906 [1:52:31<7:31:20, 11.63s/it]                                                      {'loss': 0.7925, 'grad_norm': 1.3412407636642456, 'learning_rate': 4.653306964805178e-06, 'epoch': 0.2}
 20%|█▉        | 577/2906 [1:52:31<7:31:20, 11.63s/it] 20%|█▉        | 578/2906 [1:52:43<7:31:10, 11.63s/it]                                                      {'loss': 0.8531, 'grad_norm': 1.2977949380874634, 'learning_rate': 4.651883563063974e-06, 'epoch': 0.2}
 20%|█▉        | 578/2906 [1:52:43<7:31:10, 11.63s/it] 20%|█▉        | 579/2906 [1:52:54<7:33:00, 11.68s/it]                                                      {'loss': 0.7813, 'grad_norm': 1.3200470209121704, 'learning_rate': 4.650457463936547e-06, 'epoch': 0.2}
 20%|█▉        | 579/2906 [1:52:54<7:33:00, 11.68s/it] 20%|█▉        | 580/2906 [1:53:07<7:38:20, 11.82s/it]                                                      {'loss': 0.8259, 'grad_norm': 1.3006157875061035, 'learning_rate': 4.6490286692105135e-06, 'epoch': 0.2}
 20%|█▉        | 580/2906 [1:53:07<7:38:20, 11.82s/it] 20%|█▉        | 581/2906 [1:53:18<7:38:29, 11.83s/it]                                                      {'loss': 0.8818, 'grad_norm': 1.2944084405899048, 'learning_rate': 4.647597180676866e-06, 'epoch': 0.2}
 20%|█▉        | 581/2906 [1:53:18<7:38:29, 11.83s/it] 20%|██        | 582/2906 [1:53:30<7:37:40, 11.82s/it]                                                      {'loss': 0.743, 'grad_norm': 1.318970799446106, 'learning_rate': 4.646163000129978e-06, 'epoch': 0.2}
 20%|██        | 582/2906 [1:53:30<7:37:40, 11.82s/it] 20%|██        | 583/2906 [1:53:42<7:39:12, 11.86s/it]                                                      {'loss': 0.8113, 'grad_norm': 1.2790164947509766, 'learning_rate': 4.644726129367594e-06, 'epoch': 0.2}
 20%|██        | 583/2906 [1:53:42<7:39:12, 11.86s/it] 20%|██        | 584/2906 [1:53:54<7:36:02, 11.78s/it]                                                      {'loss': 0.7746, 'grad_norm': 1.1844639778137207, 'learning_rate': 4.643286570190832e-06, 'epoch': 0.2}
 20%|██        | 584/2906 [1:53:54<7:36:02, 11.78s/it] 20%|██        | 585/2906 [1:54:06<7:35:56, 11.79s/it]                                                      {'loss': 0.8366, 'grad_norm': 1.2962442636489868, 'learning_rate': 4.6418443244041775e-06, 'epoch': 0.2}
 20%|██        | 585/2906 [1:54:06<7:35:56, 11.79s/it] 20%|██        | 586/2906 [1:54:17<7:36:12, 11.80s/it]                                                      {'loss': 0.8316, 'grad_norm': 1.4602984189987183, 'learning_rate': 4.640399393815487e-06, 'epoch': 0.2}
 20%|██        | 586/2906 [1:54:17<7:36:12, 11.80s/it] 20%|██        | 587/2906 [1:54:29<7:28:50, 11.61s/it]                                                      {'loss': 0.7251, 'grad_norm': 1.342505693435669, 'learning_rate': 4.638951780235982e-06, 'epoch': 0.2}
 20%|██        | 587/2906 [1:54:29<7:28:50, 11.61s/it] 20%|██        | 588/2906 [1:54:40<7:30:17, 11.66s/it]                                                      {'loss': 0.7214, 'grad_norm': 1.264543890953064, 'learning_rate': 4.637501485480246e-06, 'epoch': 0.2}
 20%|██        | 588/2906 [1:54:40<7:30:17, 11.66s/it] 20%|██        | 589/2906 [1:54:52<7:28:59, 11.63s/it]                                                      {'loss': 0.8478, 'grad_norm': 1.4146983623504639, 'learning_rate': 4.636048511366222e-06, 'epoch': 0.2}
 20%|██        | 589/2906 [1:54:52<7:28:59, 11.63s/it] 20%|██        | 590/2906 [1:55:04<7:34:33, 11.78s/it]                                                      {'loss': 0.7851, 'grad_norm': 1.2865328788757324, 'learning_rate': 4.634592859715214e-06, 'epoch': 0.2}
 20%|██        | 590/2906 [1:55:04<7:34:33, 11.78s/it] 20%|██        | 591/2906 [1:55:16<7:36:04, 11.82s/it]                                                      {'loss': 0.8451, 'grad_norm': 1.3380216360092163, 'learning_rate': 4.633134532351883e-06, 'epoch': 0.2}
 20%|██        | 591/2906 [1:55:16<7:36:04, 11.82s/it] 20%|██        | 592/2906 [1:55:28<7:34:27, 11.78s/it]                                                      {'loss': 0.7255, 'grad_norm': 1.305100917816162, 'learning_rate': 4.631673531104241e-06, 'epoch': 0.2}
 20%|██        | 592/2906 [1:55:28<7:34:27, 11.78s/it] 20%|██        | 593/2906 [1:55:40<7:38:15, 11.89s/it]                                                      {'loss': 0.7818, 'grad_norm': 1.3156073093414307, 'learning_rate': 4.630209857803653e-06, 'epoch': 0.2}
 20%|██        | 593/2906 [1:55:40<7:38:15, 11.89s/it] 20%|██        | 594/2906 [1:55:51<7:34:03, 11.78s/it]                                                      {'loss': 0.8759, 'grad_norm': 1.2978644371032715, 'learning_rate': 4.628743514284834e-06, 'epoch': 0.2}
 20%|██        | 594/2906 [1:55:51<7:34:03, 11.78s/it] 20%|██        | 595/2906 [1:56:03<7:32:24, 11.75s/it]                                                      {'loss': 0.8787, 'grad_norm': 1.3685879707336426, 'learning_rate': 4.6272745023858445e-06, 'epoch': 0.2}
 20%|██        | 595/2906 [1:56:03<7:32:24, 11.75s/it] 21%|██        | 596/2906 [1:56:15<7:35:22, 11.83s/it]                                                      {'loss': 0.7512, 'grad_norm': 1.2466562986373901, 'learning_rate': 4.625802823948094e-06, 'epoch': 0.21}
 21%|██        | 596/2906 [1:56:15<7:35:22, 11.83s/it] 21%|██        | 597/2906 [1:56:26<7:28:51, 11.66s/it]                                                      {'loss': 0.8142, 'grad_norm': 1.3384923934936523, 'learning_rate': 4.624328480816329e-06, 'epoch': 0.21}
 21%|██        | 597/2906 [1:56:26<7:28:51, 11.66s/it] 21%|██        | 598/2906 [1:56:38<7:29:05, 11.67s/it]                                                      {'loss': 0.8142, 'grad_norm': 1.3321424722671509, 'learning_rate': 4.622851474838639e-06, 'epoch': 0.21}
 21%|██        | 598/2906 [1:56:38<7:29:05, 11.67s/it] 21%|██        | 599/2906 [1:56:50<7:29:23, 11.69s/it]                                                      {'loss': 0.7319, 'grad_norm': 1.2731044292449951, 'learning_rate': 4.621371807866452e-06, 'epoch': 0.21}
 21%|██        | 599/2906 [1:56:50<7:29:23, 11.69s/it] 21%|██        | 600/2906 [1:57:02<7:32:05, 11.76s/it]                                                      {'loss': 0.7715, 'grad_norm': 1.2266461849212646, 'learning_rate': 4.619889481754532e-06, 'epoch': 0.21}
 21%|██        | 600/2906 [1:57:02<7:32:05, 11.76s/it] 21%|██        | 601/2906 [1:57:14<7:36:22, 11.88s/it]                                                      {'loss': 0.7435, 'grad_norm': 1.294298529624939, 'learning_rate': 4.618404498360971e-06, 'epoch': 0.21}
 21%|██        | 601/2906 [1:57:14<7:36:22, 11.88s/it] 21%|██        | 602/2906 [1:57:25<7:33:37, 11.81s/it]                                                      {'loss': 0.8637, 'grad_norm': 1.3912640810012817, 'learning_rate': 4.616916859547199e-06, 'epoch': 0.21}
 21%|██        | 602/2906 [1:57:26<7:33:37, 11.81s/it] 21%|██        | 603/2906 [1:57:37<7:33:39, 11.82s/it]                                                      {'loss': 0.862, 'grad_norm': 1.406389594078064, 'learning_rate': 4.6154265671779695e-06, 'epoch': 0.21}
 21%|██        | 603/2906 [1:57:37<7:33:39, 11.82s/it] 21%|██        | 604/2906 [1:57:49<7:30:45, 11.75s/it]                                                      {'loss': 0.8339, 'grad_norm': 1.3707749843597412, 'learning_rate': 4.613933623121366e-06, 'epoch': 0.21}
 21%|██        | 604/2906 [1:57:49<7:30:45, 11.75s/it] 21%|██        | 605/2906 [1:58:01<7:34:25, 11.85s/it]                                                      {'loss': 0.8547, 'grad_norm': 1.3000233173370361, 'learning_rate': 4.612438029248792e-06, 'epoch': 0.21}
 21%|██        | 605/2906 [1:58:01<7:34:25, 11.85s/it] 21%|██        | 606/2906 [1:58:13<7:33:39, 11.83s/it]                                                      {'loss': 0.7401, 'grad_norm': 1.2182564735412598, 'learning_rate': 4.610939787434977e-06, 'epoch': 0.21}
 21%|██        | 606/2906 [1:58:13<7:33:39, 11.83s/it] 21%|██        | 607/2906 [1:58:24<7:29:27, 11.73s/it]                                                      {'loss': 0.8151, 'grad_norm': 1.3031585216522217, 'learning_rate': 4.609438899557964e-06, 'epoch': 0.21}
 21%|██        | 607/2906 [1:58:24<7:29:27, 11.73s/it] 21%|██        | 608/2906 [1:58:36<7:23:39, 11.58s/it]                                                      {'loss': 0.7793, 'grad_norm': 1.203239917755127, 'learning_rate': 4.607935367499119e-06, 'epoch': 0.21}
 21%|██        | 608/2906 [1:58:36<7:23:39, 11.58s/it] 21%|██        | 609/2906 [1:58:47<7:21:33, 11.53s/it]                                                      {'loss': 0.79, 'grad_norm': 1.229095220565796, 'learning_rate': 4.606429193143118e-06, 'epoch': 0.21}
 21%|██        | 609/2906 [1:58:47<7:21:33, 11.53s/it] 21%|██        | 610/2906 [1:58:59<7:22:16, 11.56s/it]                                                      {'loss': 0.8188, 'grad_norm': 1.3496780395507812, 'learning_rate': 4.604920378377952e-06, 'epoch': 0.21}
 21%|██        | 610/2906 [1:58:59<7:22:16, 11.56s/it] 21%|██        | 611/2906 [1:59:10<7:24:50, 11.63s/it]                                                      {'loss': 0.8217, 'grad_norm': 1.445135474205017, 'learning_rate': 4.6034089250949184e-06, 'epoch': 0.21}
 21%|██        | 611/2906 [1:59:10<7:24:50, 11.63s/it] 21%|██        | 612/2906 [1:59:22<7:20:39, 11.53s/it]                                                      {'loss': 0.8473, 'grad_norm': 1.3061102628707886, 'learning_rate': 4.601894835188625e-06, 'epoch': 0.21}
 21%|██        | 612/2906 [1:59:22<7:20:39, 11.53s/it] 21%|██        | 613/2906 [1:59:33<7:24:01, 11.62s/it]                                                      {'loss': 0.8531, 'grad_norm': 1.4074218273162842, 'learning_rate': 4.600378110556985e-06, 'epoch': 0.21}
 21%|██        | 613/2906 [1:59:33<7:24:01, 11.62s/it] 21%|██        | 614/2906 [1:59:45<7:22:55, 11.59s/it]                                                      {'loss': 0.7257, 'grad_norm': 1.147463321685791, 'learning_rate': 4.598858753101209e-06, 'epoch': 0.21}
 21%|██        | 614/2906 [1:59:45<7:22:55, 11.59s/it] 21%|██        | 615/2906 [1:59:57<7:21:42, 11.57s/it]                                                      {'loss': 0.821, 'grad_norm': 1.3043888807296753, 'learning_rate': 4.597336764725817e-06, 'epoch': 0.21}
 21%|██        | 615/2906 [1:59:57<7:21:42, 11.57s/it] 21%|██        | 616/2906 [2:00:08<7:18:23, 11.49s/it]                                                      {'loss': 0.8138, 'grad_norm': 1.3498682975769043, 'learning_rate': 4.595812147338618e-06, 'epoch': 0.21}
 21%|██        | 616/2906 [2:00:08<7:18:23, 11.49s/it] 21%|██        | 617/2906 [2:00:20<7:27:19, 11.73s/it]                                                      {'loss': 0.8088, 'grad_norm': 1.2787566184997559, 'learning_rate': 4.594284902850721e-06, 'epoch': 0.21}
 21%|██        | 617/2906 [2:00:20<7:27:19, 11.73s/it] 21%|██▏       | 618/2906 [2:00:33<7:36:10, 11.96s/it]                                                      {'loss': 0.7893, 'grad_norm': 1.323807954788208, 'learning_rate': 4.592755033176526e-06, 'epoch': 0.21}
 21%|██▏       | 618/2906 [2:00:33<7:36:10, 11.96s/it] 21%|██▏       | 619/2906 [2:00:44<7:31:26, 11.84s/it]                                                      {'loss': 0.7883, 'grad_norm': 1.186383843421936, 'learning_rate': 4.591222540233726e-06, 'epoch': 0.21}
 21%|██▏       | 619/2906 [2:00:44<7:31:26, 11.84s/it] 21%|██▏       | 620/2906 [2:00:56<7:26:07, 11.71s/it]                                                      {'loss': 0.8326, 'grad_norm': 1.3604339361190796, 'learning_rate': 4.5896874259433015e-06, 'epoch': 0.21}
 21%|██▏       | 620/2906 [2:00:56<7:26:07, 11.71s/it] 21%|██▏       | 621/2906 [2:01:08<7:29:22, 11.80s/it]                                                      {'loss': 0.8752, 'grad_norm': 1.3425700664520264, 'learning_rate': 4.5881496922295176e-06, 'epoch': 0.21}
 21%|██▏       | 621/2906 [2:01:08<7:29:22, 11.80s/it] 21%|██▏       | 622/2906 [2:01:19<7:26:47, 11.74s/it]                                                      {'loss': 0.7785, 'grad_norm': 1.3215020895004272, 'learning_rate': 4.586609341019923e-06, 'epoch': 0.21}
 21%|██▏       | 622/2906 [2:01:19<7:26:47, 11.74s/it] 21%|██▏       | 623/2906 [2:01:31<7:29:21, 11.81s/it]                                                      {'loss': 0.8077, 'grad_norm': 1.2623562812805176, 'learning_rate': 4.585066374245349e-06, 'epoch': 0.21}
 21%|██▏       | 623/2906 [2:01:31<7:29:21, 11.81s/it] 21%|██▏       | 624/2906 [2:01:43<7:33:38, 11.93s/it]                                                      {'loss': 0.791, 'grad_norm': 1.3082455396652222, 'learning_rate': 4.583520793839904e-06, 'epoch': 0.21}
 21%|██▏       | 624/2906 [2:01:43<7:33:38, 11.93s/it] 22%|██▏       | 625/2906 [2:01:55<7:33:02, 11.92s/it]                                                      {'loss': 0.8159, 'grad_norm': 1.363688349723816, 'learning_rate': 4.581972601740974e-06, 'epoch': 0.22}
 22%|██▏       | 625/2906 [2:01:55<7:33:02, 11.92s/it] 22%|██▏       | 626/2906 [2:02:07<7:36:13, 12.01s/it]                                                      {'loss': 0.831, 'grad_norm': 1.3091535568237305, 'learning_rate': 4.580421799889218e-06, 'epoch': 0.22}
 22%|██▏       | 626/2906 [2:02:07<7:36:13, 12.01s/it] 22%|██▏       | 627/2906 [2:02:19<7:30:25, 11.86s/it]                                                      {'loss': 0.8237, 'grad_norm': 1.3010883331298828, 'learning_rate': 4.5788683902285644e-06, 'epoch': 0.22}
 22%|██▏       | 627/2906 [2:02:19<7:30:25, 11.86s/it] 22%|██▏       | 628/2906 [2:02:31<7:29:31, 11.84s/it]                                                      {'loss': 0.8764, 'grad_norm': 1.365512490272522, 'learning_rate': 4.577312374706213e-06, 'epoch': 0.22}
 22%|██▏       | 628/2906 [2:02:31<7:29:31, 11.84s/it] 22%|██▏       | 629/2906 [2:02:43<7:32:38, 11.93s/it]                                                      {'loss': 0.8142, 'grad_norm': 1.3805367946624756, 'learning_rate': 4.5757537552726315e-06, 'epoch': 0.22}
 22%|██▏       | 629/2906 [2:02:43<7:32:38, 11.93s/it] 22%|██▏       | 630/2906 [2:02:54<7:28:37, 11.83s/it]                                                      {'loss': 0.8897, 'grad_norm': 1.3664984703063965, 'learning_rate': 4.574192533881547e-06, 'epoch': 0.22}
 22%|██▏       | 630/2906 [2:02:55<7:28:37, 11.83s/it] 22%|██▏       | 631/2906 [2:03:07<7:31:44, 11.91s/it]                                                      {'loss': 0.83, 'grad_norm': 1.3307327032089233, 'learning_rate': 4.572628712489953e-06, 'epoch': 0.22}
 22%|██▏       | 631/2906 [2:03:07<7:31:44, 11.91s/it] 22%|██▏       | 632/2906 [2:03:18<7:28:13, 11.83s/it]                                                      {'loss': 0.777, 'grad_norm': 1.2756463289260864, 'learning_rate': 4.571062293058098e-06, 'epoch': 0.22}
 22%|██▏       | 632/2906 [2:03:18<7:28:13, 11.83s/it] 22%|██▏       | 633/2906 [2:03:30<7:29:19, 11.86s/it]                                                      {'loss': 0.8341, 'grad_norm': 1.257602334022522, 'learning_rate': 4.569493277549487e-06, 'epoch': 0.22}
 22%|██▏       | 633/2906 [2:03:30<7:29:19, 11.86s/it] 22%|██▏       | 634/2906 [2:03:42<7:31:18, 11.92s/it]                                                      {'loss': 0.8915, 'grad_norm': 1.3881162405014038, 'learning_rate': 4.567921667930886e-06, 'epoch': 0.22}
 22%|██▏       | 634/2906 [2:03:42<7:31:18, 11.92s/it] 22%|██▏       | 635/2906 [2:03:54<7:26:42, 11.80s/it]                                                      {'loss': 0.8226, 'grad_norm': 1.2698110342025757, 'learning_rate': 4.566347466172303e-06, 'epoch': 0.22}
 22%|██▏       | 635/2906 [2:03:54<7:26:42, 11.80s/it] 22%|██▏       | 636/2906 [2:04:05<7:23:13, 11.72s/it]                                                      {'loss': 0.8555, 'grad_norm': 1.2071988582611084, 'learning_rate': 4.564770674247003e-06, 'epoch': 0.22}
 22%|██▏       | 636/2906 [2:04:05<7:23:13, 11.72s/it] 22%|██▏       | 637/2906 [2:04:17<7:19:32, 11.62s/it]                                                      {'loss': 0.7648, 'grad_norm': 1.2467156648635864, 'learning_rate': 4.563191294131494e-06, 'epoch': 0.22}
 22%|██▏       | 637/2906 [2:04:17<7:19:32, 11.62s/it] 22%|██▏       | 638/2906 [2:04:28<7:20:12, 11.65s/it]                                                      {'loss': 0.8265, 'grad_norm': 1.2661067247390747, 'learning_rate': 4.561609327805529e-06, 'epoch': 0.22}
 22%|██▏       | 638/2906 [2:04:28<7:20:12, 11.65s/it] 22%|██▏       | 639/2906 [2:04:40<7:20:49, 11.67s/it]                                                      {'loss': 0.815, 'grad_norm': 1.3709551095962524, 'learning_rate': 4.560024777252103e-06, 'epoch': 0.22}
 22%|██▏       | 639/2906 [2:04:40<7:20:49, 11.67s/it] 22%|██▏       | 640/2906 [2:04:52<7:24:14, 11.76s/it]                                                      {'loss': 0.838, 'grad_norm': 1.4023164510726929, 'learning_rate': 4.55843764445745e-06, 'epoch': 0.22}
 22%|██▏       | 640/2906 [2:04:52<7:24:14, 11.76s/it] 22%|██▏       | 641/2906 [2:05:04<7:23:03, 11.74s/it]                                                      {'loss': 0.8376, 'grad_norm': 1.3464186191558838, 'learning_rate': 4.556847931411042e-06, 'epoch': 0.22}
 22%|██▏       | 641/2906 [2:05:04<7:23:03, 11.74s/it] 22%|██▏       | 642/2906 [2:05:16<7:28:33, 11.89s/it]                                                      {'loss': 0.7919, 'grad_norm': 1.2787142992019653, 'learning_rate': 4.555255640105583e-06, 'epoch': 0.22}
 22%|██▏       | 642/2906 [2:05:16<7:28:33, 11.89s/it] 22%|██▏       | 643/2906 [2:05:28<7:27:23, 11.86s/it]                                                      {'loss': 0.8076, 'grad_norm': 1.2694751024246216, 'learning_rate': 4.553660772537011e-06, 'epoch': 0.22}
 22%|██▏       | 643/2906 [2:05:28<7:27:23, 11.86s/it] 22%|██▏       | 644/2906 [2:05:40<7:28:02, 11.88s/it]                                                      {'loss': 0.8413, 'grad_norm': 1.2452378273010254, 'learning_rate': 4.552063330704492e-06, 'epoch': 0.22}
 22%|██▏       | 644/2906 [2:05:40<7:28:02, 11.88s/it] 22%|██▏       | 645/2906 [2:05:52<7:31:29, 11.98s/it]                                                      {'loss': 0.7818, 'grad_norm': 1.3040060997009277, 'learning_rate': 4.550463316610422e-06, 'epoch': 0.22}
 22%|██▏       | 645/2906 [2:05:52<7:31:29, 11.98s/it] 22%|██▏       | 646/2906 [2:06:04<7:37:03, 12.13s/it]                                                      {'loss': 0.7744, 'grad_norm': 1.2358155250549316, 'learning_rate': 4.548860732260415e-06, 'epoch': 0.22}
 22%|██▏       | 646/2906 [2:06:04<7:37:03, 12.13s/it] 22%|██▏       | 647/2906 [2:06:16<7:35:32, 12.10s/it]                                                      {'loss': 0.8454, 'grad_norm': 1.3383170366287231, 'learning_rate': 4.547255579663314e-06, 'epoch': 0.22}
 22%|██▏       | 647/2906 [2:06:16<7:35:32, 12.10s/it] 22%|██▏       | 648/2906 [2:06:28<7:33:21, 12.05s/it]                                                      {'loss': 0.7983, 'grad_norm': 1.3083032369613647, 'learning_rate': 4.545647860831175e-06, 'epoch': 0.22}
 22%|██▏       | 648/2906 [2:06:28<7:33:21, 12.05s/it] 22%|██▏       | 649/2906 [2:06:40<7:32:37, 12.03s/it]                                                      {'loss': 0.755, 'grad_norm': 1.3620362281799316, 'learning_rate': 4.544037577779276e-06, 'epoch': 0.22}
 22%|██▏       | 649/2906 [2:06:40<7:32:37, 12.03s/it] 22%|██▏       | 650/2906 [2:06:52<7:28:31, 11.93s/it]                                                      {'loss': 0.8288, 'grad_norm': 1.2861108779907227, 'learning_rate': 4.542424732526105e-06, 'epoch': 0.22}
 22%|██▏       | 650/2906 [2:06:52<7:28:31, 11.93s/it] 22%|██▏       | 651/2906 [2:07:04<7:28:22, 11.93s/it]                                                      {'loss': 0.7516, 'grad_norm': 1.2658746242523193, 'learning_rate': 4.540809327093366e-06, 'epoch': 0.22}
 22%|██▏       | 651/2906 [2:07:04<7:28:22, 11.93s/it] 22%|██▏       | 652/2906 [2:07:15<7:20:47, 11.73s/it]                                                      {'loss': 0.7604, 'grad_norm': 1.3141839504241943, 'learning_rate': 4.539191363505968e-06, 'epoch': 0.22}
 22%|██▏       | 652/2906 [2:07:15<7:20:47, 11.73s/it] 22%|██▏       | 653/2906 [2:07:27<7:21:33, 11.76s/it]                                                      {'loss': 0.805, 'grad_norm': 1.2284795045852661, 'learning_rate': 4.537570843792028e-06, 'epoch': 0.22}
 22%|██▏       | 653/2906 [2:07:27<7:21:33, 11.76s/it] 23%|██▎       | 654/2906 [2:07:38<7:14:52, 11.59s/it]                                                      {'loss': 0.7838, 'grad_norm': 1.236141562461853, 'learning_rate': 4.53594776998287e-06, 'epoch': 0.23}
 23%|██▎       | 654/2906 [2:07:38<7:14:52, 11.59s/it] 23%|██▎       | 655/2906 [2:07:50<7:18:55, 11.70s/it]                                                      {'loss': 0.7893, 'grad_norm': 1.2371788024902344, 'learning_rate': 4.534322144113016e-06, 'epoch': 0.23}
 23%|██▎       | 655/2906 [2:07:50<7:18:55, 11.70s/it] 23%|██▎       | 656/2906 [2:08:02<7:21:31, 11.77s/it]                                                      {'loss': 0.7459, 'grad_norm': 1.2051873207092285, 'learning_rate': 4.532693968220187e-06, 'epoch': 0.23}
 23%|██▎       | 656/2906 [2:08:02<7:21:31, 11.77s/it] 23%|██▎       | 657/2906 [2:08:14<7:23:16, 11.83s/it]                                                      {'loss': 0.8466, 'grad_norm': 1.232545018196106, 'learning_rate': 4.531063244345303e-06, 'epoch': 0.23}
 23%|██▎       | 657/2906 [2:08:14<7:23:16, 11.83s/it] 23%|██▎       | 658/2906 [2:08:25<7:16:56, 11.66s/it]                                                      {'loss': 0.8225, 'grad_norm': 1.2986265420913696, 'learning_rate': 4.529429974532475e-06, 'epoch': 0.23}
 23%|██▎       | 658/2906 [2:08:25<7:16:56, 11.66s/it] 23%|██▎       | 659/2906 [2:08:37<7:21:13, 11.78s/it]                                                      {'loss': 0.8279, 'grad_norm': 1.48416268825531, 'learning_rate': 4.52779416082901e-06, 'epoch': 0.23}
 23%|██▎       | 659/2906 [2:08:37<7:21:13, 11.78s/it] 23%|██▎       | 660/2906 [2:08:49<7:18:21, 11.71s/it]                                                      {'loss': 0.8709, 'grad_norm': 1.380449891090393, 'learning_rate': 4.526155805285397e-06, 'epoch': 0.23}
 23%|██▎       | 660/2906 [2:08:49<7:18:21, 11.71s/it] 23%|██▎       | 661/2906 [2:09:01<7:17:14, 11.69s/it]                                                      {'loss': 0.7904, 'grad_norm': 1.3232179880142212, 'learning_rate': 4.524514909955316e-06, 'epoch': 0.23}
 23%|██▎       | 661/2906 [2:09:01<7:17:14, 11.69s/it] 23%|██▎       | 662/2906 [2:09:12<7:11:05, 11.53s/it]                                                      {'loss': 0.7825, 'grad_norm': 1.2516696453094482, 'learning_rate': 4.52287147689563e-06, 'epoch': 0.23}
 23%|██▎       | 662/2906 [2:09:12<7:11:05, 11.53s/it] 23%|██▎       | 663/2906 [2:09:23<7:12:30, 11.57s/it]                                                      {'loss': 0.7641, 'grad_norm': 1.3386180400848389, 'learning_rate': 4.521225508166383e-06, 'epoch': 0.23}
 23%|██▎       | 663/2906 [2:09:23<7:12:30, 11.57s/it] 23%|██▎       | 664/2906 [2:09:35<7:15:29, 11.65s/it]                                                      {'loss': 0.7662, 'grad_norm': 1.2960598468780518, 'learning_rate': 4.519577005830796e-06, 'epoch': 0.23}
 23%|██▎       | 664/2906 [2:09:35<7:15:29, 11.65s/it] 23%|██▎       | 665/2906 [2:09:47<7:14:40, 11.64s/it]                                                      {'loss': 0.8846, 'grad_norm': 1.348306655883789, 'learning_rate': 4.517925971955267e-06, 'epoch': 0.23}
 23%|██▎       | 665/2906 [2:09:47<7:14:40, 11.64s/it] 23%|██▎       | 666/2906 [2:09:58<7:12:10, 11.58s/it]                                                      {'loss': 0.8214, 'grad_norm': 1.4000651836395264, 'learning_rate': 4.516272408609367e-06, 'epoch': 0.23}
 23%|██▎       | 666/2906 [2:09:58<7:12:10, 11.58s/it] 23%|██▎       | 667/2906 [2:10:10<7:16:08, 11.69s/it]                                                      {'loss': 0.7227, 'grad_norm': 1.1644203662872314, 'learning_rate': 4.514616317865838e-06, 'epoch': 0.23}
 23%|██▎       | 667/2906 [2:10:10<7:16:08, 11.69s/it] 23%|██▎       | 668/2906 [2:10:23<7:24:35, 11.92s/it]                                                      {'loss': 0.8114, 'grad_norm': 1.303924560546875, 'learning_rate': 4.512957701800589e-06, 'epoch': 0.23}
 23%|██▎       | 668/2906 [2:10:23<7:24:35, 11.92s/it] 23%|██▎       | 669/2906 [2:10:35<7:29:12, 12.05s/it]                                                      {'loss': 0.8281, 'grad_norm': 1.286088466644287, 'learning_rate': 4.5112965624926965e-06, 'epoch': 0.23}
 23%|██▎       | 669/2906 [2:10:35<7:29:12, 12.05s/it] 23%|██▎       | 670/2906 [2:10:47<7:25:51, 11.96s/it]                                                      {'loss': 0.8057, 'grad_norm': 1.2455214262008667, 'learning_rate': 4.509632902024398e-06, 'epoch': 0.23}
 23%|██▎       | 670/2906 [2:10:47<7:25:51, 11.96s/it] 23%|██▎       | 671/2906 [2:10:58<7:20:25, 11.82s/it]                                                      {'loss': 0.8073, 'grad_norm': 1.3225228786468506, 'learning_rate': 4.507966722481093e-06, 'epoch': 0.23}
 23%|██▎       | 671/2906 [2:10:58<7:20:25, 11.82s/it] 23%|██▎       | 672/2906 [2:11:10<7:20:34, 11.83s/it]                                                      {'loss': 0.7808, 'grad_norm': 1.2785671949386597, 'learning_rate': 4.506298025951337e-06, 'epoch': 0.23}
 23%|██▎       | 672/2906 [2:11:10<7:20:34, 11.83s/it] 23%|██▎       | 673/2906 [2:11:22<7:20:48, 11.84s/it]                                                      {'loss': 0.8362, 'grad_norm': 1.3797179460525513, 'learning_rate': 4.504626814526841e-06, 'epoch': 0.23}
 23%|██▎       | 673/2906 [2:11:22<7:20:48, 11.84s/it] 23%|██▎       | 674/2906 [2:11:34<7:21:43, 11.87s/it]                                                      {'loss': 0.7826, 'grad_norm': 1.2978583574295044, 'learning_rate': 4.50295309030247e-06, 'epoch': 0.23}
 23%|██▎       | 674/2906 [2:11:34<7:21:43, 11.87s/it] 23%|██▎       | 675/2906 [2:11:45<7:16:34, 11.74s/it]                                                      {'loss': 0.8493, 'grad_norm': 1.361754298210144, 'learning_rate': 4.501276855376235e-06, 'epoch': 0.23}
 23%|██▎       | 675/2906 [2:11:45<7:16:34, 11.74s/it] 23%|██▎       | 676/2906 [2:11:57<7:13:45, 11.67s/it]                                                      {'loss': 0.8391, 'grad_norm': 1.3731930255889893, 'learning_rate': 4.499598111849299e-06, 'epoch': 0.23}
 23%|██▎       | 676/2906 [2:11:57<7:13:45, 11.67s/it] 23%|██▎       | 677/2906 [2:12:09<7:17:07, 11.77s/it]                                                      {'loss': 0.8096, 'grad_norm': 1.357053279876709, 'learning_rate': 4.497916861825966e-06, 'epoch': 0.23}
 23%|██▎       | 677/2906 [2:12:09<7:17:07, 11.77s/it] 23%|██▎       | 678/2906 [2:12:21<7:20:11, 11.85s/it]                                                      {'loss': 0.8779, 'grad_norm': 1.3223206996917725, 'learning_rate': 4.4962331074136834e-06, 'epoch': 0.23}
 23%|██▎       | 678/2906 [2:12:21<7:20:11, 11.85s/it] 23%|██▎       | 679/2906 [2:12:33<7:19:12, 11.83s/it]                                                      {'loss': 0.7782, 'grad_norm': 1.2897448539733887, 'learning_rate': 4.494546850723037e-06, 'epoch': 0.23}
 23%|██▎       | 679/2906 [2:12:33<7:19:12, 11.83s/it] 23%|██▎       | 680/2906 [2:12:44<7:14:01, 11.70s/it]                                                      {'loss': 0.8684, 'grad_norm': 1.3432646989822388, 'learning_rate': 4.49285809386775e-06, 'epoch': 0.23}
 23%|██▎       | 680/2906 [2:12:44<7:14:01, 11.70s/it] 23%|██▎       | 681/2906 [2:12:57<7:21:28, 11.91s/it]                                                      {'loss': 0.8061, 'grad_norm': 1.2741023302078247, 'learning_rate': 4.4911668389646795e-06, 'epoch': 0.23}
 23%|██▎       | 681/2906 [2:12:57<7:21:28, 11.91s/it] 23%|██▎       | 682/2906 [2:13:08<7:19:16, 11.85s/it]                                                      {'loss': 0.8116, 'grad_norm': 1.2337872982025146, 'learning_rate': 4.489473088133813e-06, 'epoch': 0.23}
 23%|██▎       | 682/2906 [2:13:08<7:19:16, 11.85s/it] 24%|██▎       | 683/2906 [2:13:20<7:19:30, 11.86s/it]                                                      {'loss': 0.7851, 'grad_norm': 1.1917964220046997, 'learning_rate': 4.487776843498268e-06, 'epoch': 0.24}
 24%|██▎       | 683/2906 [2:13:20<7:19:30, 11.86s/it] 24%|██▎       | 684/2906 [2:13:32<7:22:32, 11.95s/it]                                                      {'loss': 0.7614, 'grad_norm': 1.3731813430786133, 'learning_rate': 4.4860781071842886e-06, 'epoch': 0.24}
 24%|██▎       | 684/2906 [2:13:32<7:22:32, 11.95s/it] 24%|██▎       | 685/2906 [2:13:44<7:24:03, 12.00s/it]                                                      {'loss': 0.7893, 'grad_norm': 1.2914100885391235, 'learning_rate': 4.484376881321237e-06, 'epoch': 0.24}
 24%|██▎       | 685/2906 [2:13:44<7:24:03, 12.00s/it] 24%|██▎       | 686/2906 [2:13:56<7:17:10, 11.82s/it]                                                      {'loss': 0.7896, 'grad_norm': 1.358554482460022, 'learning_rate': 4.482673168041604e-06, 'epoch': 0.24}
 24%|██▎       | 686/2906 [2:13:56<7:17:10, 11.82s/it] 24%|██▎       | 687/2906 [2:14:07<7:14:18, 11.74s/it]                                                      {'loss': 0.7574, 'grad_norm': 1.3230643272399902, 'learning_rate': 4.480966969480992e-06, 'epoch': 0.24}
 24%|██▎       | 687/2906 [2:14:07<7:14:18, 11.74s/it] 24%|██▎       | 688/2906 [2:14:20<7:18:20, 11.86s/it]                                                      {'loss': 0.8636, 'grad_norm': 1.361325740814209, 'learning_rate': 4.479258287778122e-06, 'epoch': 0.24}
 24%|██▎       | 688/2906 [2:14:20<7:18:20, 11.86s/it] 24%|██▎       | 689/2906 [2:14:32<7:20:00, 11.91s/it]                                                      {'loss': 0.8253, 'grad_norm': 1.3453874588012695, 'learning_rate': 4.477547125074826e-06, 'epoch': 0.24}
 24%|██▎       | 689/2906 [2:14:32<7:20:00, 11.91s/it] 24%|██▎       | 690/2906 [2:14:44<7:20:56, 11.94s/it]                                                      {'loss': 0.8529, 'grad_norm': 1.3671977519989014, 'learning_rate': 4.475833483516046e-06, 'epoch': 0.24}
 24%|██▎       | 690/2906 [2:14:44<7:20:56, 11.94s/it] 24%|██▍       | 691/2906 [2:14:56<7:21:34, 11.96s/it]                                                      {'loss': 0.803, 'grad_norm': 1.3075484037399292, 'learning_rate': 4.474117365249835e-06, 'epoch': 0.24}
 24%|██▍       | 691/2906 [2:14:56<7:21:34, 11.96s/it] 24%|██▍       | 692/2906 [2:15:07<7:14:32, 11.78s/it]                                                      {'loss': 0.7558, 'grad_norm': 1.2809399366378784, 'learning_rate': 4.472398772427344e-06, 'epoch': 0.24}
 24%|██▍       | 692/2906 [2:15:07<7:14:32, 11.78s/it] 24%|██▍       | 693/2906 [2:15:19<7:13:32, 11.75s/it]                                                      {'loss': 0.8141, 'grad_norm': 1.3407819271087646, 'learning_rate': 4.4706777072028305e-06, 'epoch': 0.24}
 24%|██▍       | 693/2906 [2:15:19<7:13:32, 11.75s/it] 24%|██▍       | 694/2906 [2:15:30<7:11:23, 11.70s/it]                                                      {'loss': 0.9007, 'grad_norm': 1.3533508777618408, 'learning_rate': 4.468954171733649e-06, 'epoch': 0.24}
 24%|██▍       | 694/2906 [2:15:30<7:11:23, 11.70s/it] 24%|██▍       | 695/2906 [2:15:42<7:17:08, 11.86s/it]                                                      {'loss': 0.8241, 'grad_norm': 1.269804835319519, 'learning_rate': 4.4672281681802536e-06, 'epoch': 0.24}
 24%|██▍       | 695/2906 [2:15:42<7:17:08, 11.86s/it] 24%|██▍       | 696/2906 [2:15:55<7:20:40, 11.96s/it]                                                      {'loss': 0.8121, 'grad_norm': 1.3465044498443604, 'learning_rate': 4.465499698706187e-06, 'epoch': 0.24}
 24%|██▍       | 696/2906 [2:15:55<7:20:40, 11.96s/it] 24%|██▍       | 697/2906 [2:16:06<7:17:53, 11.89s/it]                                                      {'loss': 0.7649, 'grad_norm': 1.3543187379837036, 'learning_rate': 4.463768765478088e-06, 'epoch': 0.24}
 24%|██▍       | 697/2906 [2:16:06<7:17:53, 11.89s/it] 24%|██▍       | 698/2906 [2:16:18<7:18:45, 11.92s/it]                                                      {'loss': 0.8165, 'grad_norm': 1.283078908920288, 'learning_rate': 4.4620353706656815e-06, 'epoch': 0.24}
 24%|██▍       | 698/2906 [2:16:18<7:18:45, 11.92s/it] 24%|██▍       | 699/2906 [2:16:30<7:17:22, 11.89s/it]                                                      {'loss': 0.8589, 'grad_norm': 1.274316430091858, 'learning_rate': 4.460299516441777e-06, 'epoch': 0.24}
 24%|██▍       | 699/2906 [2:16:30<7:17:22, 11.89s/it] 24%|██▍       | 700/2906 [2:16:42<7:12:53, 11.77s/it]                                                      {'loss': 0.7826, 'grad_norm': 1.3585073947906494, 'learning_rate': 4.458561204982267e-06, 'epoch': 0.24}
 24%|██▍       | 700/2906 [2:16:42<7:12:53, 11.77s/it] 24%|██▍       | 701/2906 [2:16:54<7:15:07, 11.84s/it]                                                      {'loss': 0.8413, 'grad_norm': 1.2928791046142578, 'learning_rate': 4.456820438466127e-06, 'epoch': 0.24}
 24%|██▍       | 701/2906 [2:16:54<7:15:07, 11.84s/it] 24%|██▍       | 702/2906 [2:17:06<7:17:11, 11.90s/it]                                                      {'loss': 0.7664, 'grad_norm': 1.4884623289108276, 'learning_rate': 4.455077219075408e-06, 'epoch': 0.24}
 24%|██▍       | 702/2906 [2:17:06<7:17:11, 11.90s/it] 24%|██▍       | 703/2906 [2:17:17<7:12:27, 11.78s/it]                                                      {'loss': 0.7604, 'grad_norm': 1.4035277366638184, 'learning_rate': 4.453331548995235e-06, 'epoch': 0.24}
 24%|██▍       | 703/2906 [2:17:17<7:12:27, 11.78s/it] 24%|██▍       | 704/2906 [2:17:29<7:17:09, 11.91s/it]                                                      {'loss': 0.7917, 'grad_norm': 1.282405972480774, 'learning_rate': 4.451583430413805e-06, 'epoch': 0.24}
 24%|██▍       | 704/2906 [2:17:29<7:17:09, 11.91s/it] 24%|██▍       | 705/2906 [2:17:41<7:09:07, 11.70s/it]                                                      {'loss': 0.7203, 'grad_norm': 1.2752524614334106, 'learning_rate': 4.449832865522386e-06, 'epoch': 0.24}
 24%|██▍       | 705/2906 [2:17:41<7:09:07, 11.70s/it] 24%|██▍       | 706/2906 [2:17:52<7:08:14, 11.68s/it]                                                      {'loss': 0.7619, 'grad_norm': 1.2937606573104858, 'learning_rate': 4.448079856515309e-06, 'epoch': 0.24}
 24%|██▍       | 706/2906 [2:17:52<7:08:14, 11.68s/it] 24%|██▍       | 707/2906 [2:18:04<7:09:27, 11.72s/it]                                                      {'loss': 0.8367, 'grad_norm': 1.346888780593872, 'learning_rate': 4.446324405589973e-06, 'epoch': 0.24}
 24%|██▍       | 707/2906 [2:18:04<7:09:27, 11.72s/it] 24%|██▍       | 708/2906 [2:18:16<7:06:13, 11.63s/it]                                                      {'loss': 0.7999, 'grad_norm': 1.3226670026779175, 'learning_rate': 4.444566514946836e-06, 'epoch': 0.24}
 24%|██▍       | 708/2906 [2:18:16<7:06:13, 11.63s/it] 24%|██▍       | 709/2906 [2:18:27<7:05:31, 11.62s/it]                                                      {'loss': 0.836, 'grad_norm': 1.2161378860473633, 'learning_rate': 4.442806186789414e-06, 'epoch': 0.24}
 24%|██▍       | 709/2906 [2:18:27<7:05:31, 11.62s/it] 24%|██▍       | 710/2906 [2:18:38<7:02:24, 11.54s/it]                                                      {'loss': 0.775, 'grad_norm': 1.3474235534667969, 'learning_rate': 4.441043423324276e-06, 'epoch': 0.24}
 24%|██▍       | 710/2906 [2:18:38<7:02:24, 11.54s/it] 24%|██▍       | 711/2906 [2:18:50<7:06:54, 11.67s/it]                                                      {'loss': 0.7619, 'grad_norm': 1.2572859525680542, 'learning_rate': 4.43927822676105e-06, 'epoch': 0.24}
 24%|██▍       | 711/2906 [2:18:50<7:06:54, 11.67s/it] 25%|██▍       | 712/2906 [2:19:03<7:11:22, 11.80s/it]                                                      {'loss': 0.7743, 'grad_norm': 1.387030005455017, 'learning_rate': 4.437510599312407e-06, 'epoch': 0.25}
 25%|██▍       | 712/2906 [2:19:03<7:11:22, 11.80s/it] 25%|██▍       | 713/2906 [2:19:14<7:07:51, 11.71s/it]                                                      {'loss': 0.798, 'grad_norm': 1.3347920179367065, 'learning_rate': 4.43574054319407e-06, 'epoch': 0.25}
 25%|██▍       | 713/2906 [2:19:14<7:07:51, 11.71s/it] 25%|██▍       | 714/2906 [2:19:26<7:09:27, 11.76s/it]                                                      {'loss': 0.8808, 'grad_norm': 1.3893934488296509, 'learning_rate': 4.433968060624803e-06, 'epoch': 0.25}
 25%|██▍       | 714/2906 [2:19:26<7:09:27, 11.76s/it] 25%|██▍       | 715/2906 [2:19:38<7:10:37, 11.79s/it]                                                      {'loss': 0.8459, 'grad_norm': 1.3938829898834229, 'learning_rate': 4.432193153826414e-06, 'epoch': 0.25}
 25%|██▍       | 715/2906 [2:19:38<7:10:37, 11.79s/it] 25%|██▍       | 716/2906 [2:19:49<7:06:27, 11.68s/it]                                                      {'loss': 0.8244, 'grad_norm': 1.3341567516326904, 'learning_rate': 4.430415825023749e-06, 'epoch': 0.25}
 25%|██▍       | 716/2906 [2:19:49<7:06:27, 11.68s/it] 25%|██▍       | 717/2906 [2:20:01<7:11:18, 11.82s/it]                                                      {'loss': 0.8457, 'grad_norm': 1.304216742515564, 'learning_rate': 4.428636076444689e-06, 'epoch': 0.25}
 25%|██▍       | 717/2906 [2:20:01<7:11:18, 11.82s/it] 25%|██▍       | 718/2906 [2:20:13<7:11:01, 11.82s/it]                                                      {'loss': 0.8674, 'grad_norm': 1.5691545009613037, 'learning_rate': 4.4268539103201495e-06, 'epoch': 0.25}
 25%|██▍       | 718/2906 [2:20:13<7:11:01, 11.82s/it] 25%|██▍       | 719/2906 [2:20:25<7:12:18, 11.86s/it]                                                      {'loss': 0.8533, 'grad_norm': 1.3205420970916748, 'learning_rate': 4.425069328884076e-06, 'epoch': 0.25}
 25%|██▍       | 719/2906 [2:20:25<7:12:18, 11.86s/it] 25%|██▍       | 720/2906 [2:20:38<7:18:00, 12.02s/it]                                                      {'loss': 0.7185, 'grad_norm': 1.209505319595337, 'learning_rate': 4.423282334373441e-06, 'epoch': 0.25}
 25%|██▍       | 720/2906 [2:20:38<7:18:00, 12.02s/it] 25%|██▍       | 721/2906 [2:20:49<7:15:29, 11.96s/it]                                                      {'loss': 0.8623, 'grad_norm': 1.2675796747207642, 'learning_rate': 4.421492929028243e-06, 'epoch': 0.25}
 25%|██▍       | 721/2906 [2:20:49<7:15:29, 11.96s/it] 25%|██▍       | 722/2906 [2:21:01<7:11:04, 11.84s/it]                                                      {'loss': 0.7705, 'grad_norm': 1.2653089761734009, 'learning_rate': 4.4197011150915e-06, 'epoch': 0.25}
 25%|██▍       | 722/2906 [2:21:01<7:11:04, 11.84s/it] 25%|██▍       | 723/2906 [2:21:13<7:14:03, 11.93s/it]                                                      {'loss': 0.7658, 'grad_norm': 1.3160207271575928, 'learning_rate': 4.417906894809254e-06, 'epoch': 0.25}
 25%|██▍       | 723/2906 [2:21:13<7:14:03, 11.93s/it] 25%|██▍       | 724/2906 [2:21:26<7:20:39, 12.12s/it]                                                      {'loss': 0.8198, 'grad_norm': 1.2602356672286987, 'learning_rate': 4.416110270430557e-06, 'epoch': 0.25}
 25%|██▍       | 724/2906 [2:21:26<7:20:39, 12.12s/it] 25%|██▍       | 725/2906 [2:21:38<7:19:05, 12.08s/it]                                                      {'loss': 0.7936, 'grad_norm': 1.2766461372375488, 'learning_rate': 4.41431124420748e-06, 'epoch': 0.25}
 25%|██▍       | 725/2906 [2:21:38<7:19:05, 12.08s/it] 25%|██▍       | 726/2906 [2:21:49<7:16:56, 12.03s/it]                                                      {'loss': 0.8581, 'grad_norm': 1.3579236268997192, 'learning_rate': 4.412509818395101e-06, 'epoch': 0.25}
 25%|██▍       | 726/2906 [2:21:50<7:16:56, 12.03s/it] 25%|██▌       | 727/2906 [2:22:01<7:08:36, 11.80s/it]                                                      {'loss': 0.9016, 'grad_norm': 1.279096007347107, 'learning_rate': 4.410705995251509e-06, 'epoch': 0.25}
 25%|██▌       | 727/2906 [2:22:01<7:08:36, 11.80s/it] 25%|██▌       | 728/2906 [2:22:12<7:01:55, 11.62s/it]                                                      {'loss': 0.8137, 'grad_norm': 1.329740285873413, 'learning_rate': 4.408899777037795e-06, 'epoch': 0.25}
 25%|██▌       | 728/2906 [2:22:12<7:01:55, 11.62s/it] 25%|██▌       | 729/2906 [2:22:24<7:10:28, 11.86s/it]                                                      {'loss': 0.8349, 'grad_norm': 1.299745798110962, 'learning_rate': 4.4070911660180546e-06, 'epoch': 0.25}
 25%|██▌       | 729/2906 [2:22:24<7:10:28, 11.86s/it] 25%|██▌       | 730/2906 [2:22:36<7:06:16, 11.75s/it]                                                      {'loss': 0.8176, 'grad_norm': 1.3877865076065063, 'learning_rate': 4.405280164459382e-06, 'epoch': 0.25}
 25%|██▌       | 730/2906 [2:22:36<7:06:16, 11.75s/it] 25%|██▌       | 731/2906 [2:22:48<7:05:29, 11.74s/it]                                                      {'loss': 0.8515, 'grad_norm': 1.3943039178848267, 'learning_rate': 4.403466774631867e-06, 'epoch': 0.25}
 25%|██▌       | 731/2906 [2:22:48<7:05:29, 11.74s/it] 25%|██▌       | 732/2906 [2:22:59<7:02:30, 11.66s/it]                                                      {'loss': 0.8144, 'grad_norm': 1.3348139524459839, 'learning_rate': 4.401650998808595e-06, 'epoch': 0.25}
 25%|██▌       | 732/2906 [2:22:59<7:02:30, 11.66s/it] 25%|██▌       | 733/2906 [2:23:11<7:04:07, 11.71s/it]                                                      {'loss': 0.8503, 'grad_norm': 1.3098002672195435, 'learning_rate': 4.39983283926564e-06, 'epoch': 0.25}
 25%|██▌       | 733/2906 [2:23:11<7:04:07, 11.71s/it] 25%|██▌       | 734/2906 [2:23:23<7:05:44, 11.76s/it]                                                      {'loss': 0.8013, 'grad_norm': 1.3007031679153442, 'learning_rate': 4.398012298282065e-06, 'epoch': 0.25}
 25%|██▌       | 734/2906 [2:23:23<7:05:44, 11.76s/it] 25%|██▌       | 735/2906 [2:23:34<7:03:00, 11.69s/it]                                                      {'loss': 0.759, 'grad_norm': 1.296199083328247, 'learning_rate': 4.3961893781399186e-06, 'epoch': 0.25}
 25%|██▌       | 735/2906 [2:23:34<7:03:00, 11.69s/it] 25%|██▌       | 736/2906 [2:23:46<6:57:50, 11.55s/it]                                                      {'loss': 0.8562, 'grad_norm': 1.3352973461151123, 'learning_rate': 4.394364081124233e-06, 'epoch': 0.25}
 25%|██▌       | 736/2906 [2:23:46<6:57:50, 11.55s/it] 25%|██▌       | 737/2906 [2:23:57<6:56:38, 11.53s/it]                                                      {'loss': 0.8233, 'grad_norm': 1.3059015274047852, 'learning_rate': 4.392536409523015e-06, 'epoch': 0.25}
 25%|██▌       | 737/2906 [2:23:57<6:56:38, 11.53s/it] 25%|██▌       | 738/2906 [2:24:09<7:00:08, 11.63s/it]                                                      {'loss': 0.8091, 'grad_norm': 1.3123233318328857, 'learning_rate': 4.3907063656272544e-06, 'epoch': 0.25}
 25%|██▌       | 738/2906 [2:24:09<7:00:08, 11.63s/it] 25%|██▌       | 739/2906 [2:24:21<7:02:32, 11.70s/it]                                                      {'loss': 0.8616, 'grad_norm': 1.3098905086517334, 'learning_rate': 4.388873951730909e-06, 'epoch': 0.25}
 25%|██▌       | 739/2906 [2:24:21<7:02:32, 11.70s/it] 25%|██▌       | 740/2906 [2:24:32<7:02:36, 11.71s/it]                                                      {'loss': 0.8595, 'grad_norm': 1.37594735622406, 'learning_rate': 4.38703917013091e-06, 'epoch': 0.25}
 25%|██▌       | 740/2906 [2:24:32<7:02:36, 11.71s/it] 25%|██▌       | 741/2906 [2:24:44<6:57:59, 11.58s/it]                                                      {'loss': 0.8326, 'grad_norm': 1.3618217706680298, 'learning_rate': 4.385202023127158e-06, 'epoch': 0.25}
 25%|██▌       | 741/2906 [2:24:44<6:57:59, 11.58s/it] 26%|██▌       | 742/2906 [2:24:55<6:52:25, 11.44s/it]                                                      {'loss': 0.8127, 'grad_norm': 1.2854605913162231, 'learning_rate': 4.383362513022515e-06, 'epoch': 0.26}
 26%|██▌       | 742/2906 [2:24:55<6:52:25, 11.44s/it] 26%|██▌       | 743/2906 [2:25:07<6:57:40, 11.59s/it]                                                      {'loss': 0.7836, 'grad_norm': 1.2426338195800781, 'learning_rate': 4.381520642122808e-06, 'epoch': 0.26}
 26%|██▌       | 743/2906 [2:25:07<6:57:40, 11.59s/it] 26%|██▌       | 744/2906 [2:25:18<6:57:13, 11.58s/it]                                                      {'loss': 0.8052, 'grad_norm': 1.281103491783142, 'learning_rate': 4.379676412736823e-06, 'epoch': 0.26}
 26%|██▌       | 744/2906 [2:25:18<6:57:13, 11.58s/it] 26%|██▌       | 745/2906 [2:25:31<7:03:32, 11.76s/it]                                                      {'loss': 0.836, 'grad_norm': 1.2847038507461548, 'learning_rate': 4.3778298271762995e-06, 'epoch': 0.26}
 26%|██▌       | 745/2906 [2:25:31<7:03:32, 11.76s/it] 26%|██▌       | 746/2906 [2:25:43<7:07:47, 11.88s/it]                                                      {'loss': 0.9262, 'grad_norm': 1.3163888454437256, 'learning_rate': 4.375980887755935e-06, 'epoch': 0.26}
 26%|██▌       | 746/2906 [2:25:43<7:07:47, 11.88s/it] 26%|██▌       | 747/2906 [2:25:54<7:01:21, 11.71s/it]                                                      {'loss': 0.8121, 'grad_norm': 1.2685467004776, 'learning_rate': 4.374129596793375e-06, 'epoch': 0.26}
 26%|██▌       | 747/2906 [2:25:54<7:01:21, 11.71s/it] 26%|██▌       | 748/2906 [2:26:06<6:59:01, 11.65s/it]                                                      {'loss': 0.8253, 'grad_norm': 1.25138258934021, 'learning_rate': 4.372275956609211e-06, 'epoch': 0.26}
 26%|██▌       | 748/2906 [2:26:06<6:59:01, 11.65s/it] 26%|██▌       | 749/2906 [2:26:17<7:01:23, 11.72s/it]                                                      {'loss': 0.8135, 'grad_norm': 1.3246146440505981, 'learning_rate': 4.370419969526982e-06, 'epoch': 0.26}
 26%|██▌       | 749/2906 [2:26:17<7:01:23, 11.72s/it] 26%|██▌       | 750/2906 [2:26:29<6:54:58, 11.55s/it]                                                      {'loss': 0.8314, 'grad_norm': 1.3447785377502441, 'learning_rate': 4.368561637873169e-06, 'epoch': 0.26}
 26%|██▌       | 750/2906 [2:26:29<6:54:58, 11.55s/it] 26%|██▌       | 751/2906 [2:26:41<7:04:41, 11.82s/it]                                                      {'loss': 0.703, 'grad_norm': 1.1874769926071167, 'learning_rate': 4.366700963977188e-06, 'epoch': 0.26}
 26%|██▌       | 751/2906 [2:26:41<7:04:41, 11.82s/it] 26%|██▌       | 752/2906 [2:26:53<7:01:45, 11.75s/it]                                                      {'loss': 0.8091, 'grad_norm': 1.3606905937194824, 'learning_rate': 4.364837950171398e-06, 'epoch': 0.26}
 26%|██▌       | 752/2906 [2:26:53<7:01:45, 11.75s/it] 26%|██▌       | 753/2906 [2:27:04<6:58:11, 11.65s/it]                                                      {'loss': 0.7795, 'grad_norm': 1.2756274938583374, 'learning_rate': 4.362972598791085e-06, 'epoch': 0.26}
 26%|██▌       | 753/2906 [2:27:04<6:58:11, 11.65s/it] 26%|██▌       | 754/2906 [2:27:16<7:05:42, 11.87s/it]                                                      {'loss': 0.8103, 'grad_norm': 1.3446907997131348, 'learning_rate': 4.3611049121744664e-06, 'epoch': 0.26}
 26%|██▌       | 754/2906 [2:27:16<7:05:42, 11.87s/it] 26%|██▌       | 755/2906 [2:27:28<7:01:00, 11.74s/it]                                                      {'loss': 0.7734, 'grad_norm': 1.2613468170166016, 'learning_rate': 4.3592348926626886e-06, 'epoch': 0.26}
 26%|██▌       | 755/2906 [2:27:28<7:01:00, 11.74s/it] 26%|██▌       | 756/2906 [2:27:40<7:07:12, 11.92s/it]                                                      {'loss': 0.8463, 'grad_norm': 1.3320417404174805, 'learning_rate': 4.3573625425998195e-06, 'epoch': 0.26}
 26%|██▌       | 756/2906 [2:27:40<7:07:12, 11.92s/it] 26%|██▌       | 757/2906 [2:27:52<7:05:31, 11.88s/it]                                                      {'loss': 0.8217, 'grad_norm': 1.247549057006836, 'learning_rate': 4.355487864332853e-06, 'epoch': 0.26}
 26%|██▌       | 757/2906 [2:27:52<7:05:31, 11.88s/it] 26%|██▌       | 758/2906 [2:28:04<7:11:12, 12.05s/it]                                                      {'loss': 0.8343, 'grad_norm': 1.3963884115219116, 'learning_rate': 4.353610860211695e-06, 'epoch': 0.26}
 26%|██▌       | 758/2906 [2:28:04<7:11:12, 12.05s/it] 26%|██▌       | 759/2906 [2:28:16<7:06:51, 11.93s/it]                                                      {'loss': 0.7796, 'grad_norm': 1.2141252756118774, 'learning_rate': 4.351731532589173e-06, 'epoch': 0.26}
 26%|██▌       | 759/2906 [2:28:16<7:06:51, 11.93s/it] 26%|██▌       | 760/2906 [2:28:28<7:02:22, 11.81s/it]                                                      {'loss': 0.7762, 'grad_norm': 1.3077648878097534, 'learning_rate': 4.349849883821023e-06, 'epoch': 0.26}
 26%|██▌       | 760/2906 [2:28:28<7:02:22, 11.81s/it] 26%|██▌       | 761/2906 [2:28:39<6:59:50, 11.74s/it]                                                      {'loss': 0.838, 'grad_norm': 1.3194893598556519, 'learning_rate': 4.347965916265893e-06, 'epoch': 0.26}
 26%|██▌       | 761/2906 [2:28:39<6:59:50, 11.74s/it] 26%|██▌       | 762/2906 [2:28:50<6:54:10, 11.59s/it]                                                      {'loss': 0.8758, 'grad_norm': 1.2971060276031494, 'learning_rate': 4.346079632285335e-06, 'epoch': 0.26}
 26%|██▌       | 762/2906 [2:28:50<6:54:10, 11.59s/it] 26%|██▋       | 763/2906 [2:29:02<6:56:51, 11.67s/it]                                                      {'loss': 0.7852, 'grad_norm': 1.2724257707595825, 'learning_rate': 4.3441910342438076e-06, 'epoch': 0.26}
 26%|██▋       | 763/2906 [2:29:02<6:56:51, 11.67s/it] 26%|██▋       | 764/2906 [2:29:14<6:59:20, 11.75s/it]                                                      {'loss': 0.7793, 'grad_norm': 1.4224789142608643, 'learning_rate': 4.342300124508668e-06, 'epoch': 0.26}
 26%|██▋       | 764/2906 [2:29:14<6:59:20, 11.75s/it] 26%|██▋       | 765/2906 [2:29:25<6:51:15, 11.53s/it]                                                      {'loss': 0.8191, 'grad_norm': 1.3046611547470093, 'learning_rate': 4.340406905450171e-06, 'epoch': 0.26}
 26%|██▋       | 765/2906 [2:29:25<6:51:15, 11.53s/it] 26%|██▋       | 766/2906 [2:29:37<6:57:51, 11.72s/it]                                                      {'loss': 0.8874, 'grad_norm': 1.3870776891708374, 'learning_rate': 4.3385113794414676e-06, 'epoch': 0.26}
 26%|██▋       | 766/2906 [2:29:37<6:57:51, 11.72s/it] 26%|██▋       | 767/2906 [2:29:49<6:58:04, 11.73s/it]                                                      {'loss': 0.8139, 'grad_norm': 1.29291832447052, 'learning_rate': 4.3366135488586e-06, 'epoch': 0.26}
 26%|██▋       | 767/2906 [2:29:49<6:58:04, 11.73s/it] 26%|██▋       | 768/2906 [2:30:01<7:03:18, 11.88s/it]                                                      {'loss': 0.797, 'grad_norm': 1.1776148080825806, 'learning_rate': 4.334713416080498e-06, 'epoch': 0.26}
 26%|██▋       | 768/2906 [2:30:01<7:03:18, 11.88s/it] 26%|██▋       | 769/2906 [2:30:12<6:54:03, 11.63s/it]                                                      {'loss': 0.8451, 'grad_norm': 1.3484114408493042, 'learning_rate': 4.332810983488979e-06, 'epoch': 0.26}
 26%|██▋       | 769/2906 [2:30:12<6:54:03, 11.63s/it] 26%|██▋       | 770/2906 [2:30:24<6:58:51, 11.77s/it]                                                      {'loss': 0.796, 'grad_norm': 1.3223367929458618, 'learning_rate': 4.330906253468743e-06, 'epoch': 0.26}
 26%|██▋       | 770/2906 [2:30:24<6:58:51, 11.77s/it] 27%|██▋       | 771/2906 [2:30:36<6:59:13, 11.78s/it]                                                      {'loss': 0.8162, 'grad_norm': 1.2981793880462646, 'learning_rate': 4.3289992284073675e-06, 'epoch': 0.27}
 27%|██▋       | 771/2906 [2:30:36<6:59:13, 11.78s/it] 27%|██▋       | 772/2906 [2:30:48<6:55:58, 11.70s/it]                                                      {'loss': 0.7808, 'grad_norm': 1.3366183042526245, 'learning_rate': 4.32708991069531e-06, 'epoch': 0.27}
 27%|██▋       | 772/2906 [2:30:48<6:55:58, 11.70s/it] 27%|██▋       | 773/2906 [2:30:59<6:51:57, 11.59s/it]                                                      {'loss': 0.8537, 'grad_norm': 1.3253146409988403, 'learning_rate': 4.325178302725901e-06, 'epoch': 0.27}
 27%|██▋       | 773/2906 [2:30:59<6:51:57, 11.59s/it] 27%|██▋       | 774/2906 [2:31:11<6:52:14, 11.60s/it]                                                      {'loss': 0.8142, 'grad_norm': 1.225265383720398, 'learning_rate': 4.323264406895339e-06, 'epoch': 0.27}
 27%|██▋       | 774/2906 [2:31:11<6:52:14, 11.60s/it] 27%|██▋       | 775/2906 [2:31:22<6:50:29, 11.56s/it]                                                      {'loss': 0.7977, 'grad_norm': 1.3731796741485596, 'learning_rate': 4.321348225602694e-06, 'epoch': 0.27}
 27%|██▋       | 775/2906 [2:31:22<6:50:29, 11.56s/it] 27%|██▋       | 776/2906 [2:31:34<6:48:33, 11.51s/it]                                                      {'loss': 0.8465, 'grad_norm': 1.3059227466583252, 'learning_rate': 4.319429761249899e-06, 'epoch': 0.27}
 27%|██▋       | 776/2906 [2:31:34<6:48:33, 11.51s/it] 27%|██▋       | 777/2906 [2:31:46<6:55:19, 11.70s/it]                                                      {'loss': 0.7138, 'grad_norm': 1.2591416835784912, 'learning_rate': 4.31750901624175e-06, 'epoch': 0.27}
 27%|██▋       | 777/2906 [2:31:46<6:55:19, 11.70s/it] 27%|██▋       | 778/2906 [2:31:58<6:57:42, 11.78s/it]                                                      {'loss': 0.8009, 'grad_norm': 1.2778245210647583, 'learning_rate': 4.3155859929859004e-06, 'epoch': 0.27}
 27%|██▋       | 778/2906 [2:31:58<6:57:42, 11.78s/it] 27%|██▋       | 779/2906 [2:32:09<6:52:31, 11.64s/it]                                                      {'loss': 0.8073, 'grad_norm': 1.2666667699813843, 'learning_rate': 4.31366069389286e-06, 'epoch': 0.27}
 27%|██▋       | 779/2906 [2:32:09<6:52:31, 11.64s/it] 27%|██▋       | 780/2906 [2:32:21<6:56:20, 11.75s/it]                                                      {'loss': 0.7983, 'grad_norm': 1.3746808767318726, 'learning_rate': 4.311733121375991e-06, 'epoch': 0.27}
 27%|██▋       | 780/2906 [2:32:21<6:56:20, 11.75s/it] 27%|██▋       | 781/2906 [2:32:32<6:51:10, 11.61s/it]                                                      {'loss': 0.8296, 'grad_norm': 1.3003783226013184, 'learning_rate': 4.309803277851507e-06, 'epoch': 0.27}
 27%|██▋       | 781/2906 [2:32:32<6:51:10, 11.61s/it] 27%|██▋       | 782/2906 [2:32:44<6:47:40, 11.52s/it]                                                      {'loss': 0.7663, 'grad_norm': 1.310378074645996, 'learning_rate': 4.3078711657384655e-06, 'epoch': 0.27}
 27%|██▋       | 782/2906 [2:32:44<6:47:40, 11.52s/it] 27%|██▋       | 783/2906 [2:32:55<6:49:46, 11.58s/it]                                                      {'loss': 0.8375, 'grad_norm': 1.3141367435455322, 'learning_rate': 4.305936787458769e-06, 'epoch': 0.27}
 27%|██▋       | 783/2906 [2:32:55<6:49:46, 11.58s/it] 27%|██▋       | 784/2906 [2:33:07<6:46:44, 11.50s/it]                                                      {'loss': 0.7565, 'grad_norm': 1.2691675424575806, 'learning_rate': 4.304000145437164e-06, 'epoch': 0.27}
 27%|██▋       | 784/2906 [2:33:07<6:46:44, 11.50s/it] 27%|██▋       | 785/2906 [2:33:18<6:48:35, 11.56s/it]                                                      {'loss': 0.7874, 'grad_norm': 1.3502302169799805, 'learning_rate': 4.302061242101226e-06, 'epoch': 0.27}
 27%|██▋       | 785/2906 [2:33:18<6:48:35, 11.56s/it] 27%|██▋       | 786/2906 [2:33:30<6:54:35, 11.73s/it]                                                      {'loss': 0.8036, 'grad_norm': 1.4442981481552124, 'learning_rate': 4.300120079881376e-06, 'epoch': 0.27}
 27%|██▋       | 786/2906 [2:33:31<6:54:35, 11.73s/it] 27%|██▋       | 787/2906 [2:33:42<6:56:51, 11.80s/it]                                                      {'loss': 0.7588, 'grad_norm': 1.3678765296936035, 'learning_rate': 4.2981766612108576e-06, 'epoch': 0.27}
 27%|██▋       | 787/2906 [2:33:42<6:56:51, 11.80s/it] 27%|██▋       | 788/2906 [2:33:54<6:58:36, 11.86s/it]                                                      {'loss': 0.8374, 'grad_norm': 1.416084885597229, 'learning_rate': 4.296230988525748e-06, 'epoch': 0.27}
 27%|██▋       | 788/2906 [2:33:54<6:58:36, 11.86s/it] 27%|██▋       | 789/2906 [2:34:06<6:59:26, 11.89s/it]                                                      {'loss': 0.7584, 'grad_norm': 1.2862119674682617, 'learning_rate': 4.294283064264947e-06, 'epoch': 0.27}
 27%|██▋       | 789/2906 [2:34:06<6:59:26, 11.89s/it] 27%|██▋       | 790/2906 [2:34:18<6:57:05, 11.83s/it]                                                      {'loss': 0.7683, 'grad_norm': 1.2844569683074951, 'learning_rate': 4.292332890870178e-06, 'epoch': 0.27}
 27%|██▋       | 790/2906 [2:34:18<6:57:05, 11.83s/it] 27%|██▋       | 791/2906 [2:34:29<6:50:30, 11.65s/it]                                                      {'loss': 0.7933, 'grad_norm': 1.3020099401474, 'learning_rate': 4.290380470785984e-06, 'epoch': 0.27}
 27%|██▋       | 791/2906 [2:34:29<6:50:30, 11.65s/it] 27%|██▋       | 792/2906 [2:34:41<6:53:26, 11.73s/it]                                                      {'loss': 0.7833, 'grad_norm': 1.3363336324691772, 'learning_rate': 4.288425806459723e-06, 'epoch': 0.27}
 27%|██▋       | 792/2906 [2:34:41<6:53:26, 11.73s/it] 27%|██▋       | 793/2906 [2:34:54<6:59:41, 11.92s/it]                                                      {'loss': 0.7471, 'grad_norm': 1.2667995691299438, 'learning_rate': 4.2864689003415675e-06, 'epoch': 0.27}
 27%|██▋       | 793/2906 [2:34:54<6:59:41, 11.92s/it] 27%|██▋       | 794/2906 [2:35:05<6:58:58, 11.90s/it]                                                      {'loss': 0.8062, 'grad_norm': 1.2632534503936768, 'learning_rate': 4.2845097548845e-06, 'epoch': 0.27}
 27%|██▋       | 794/2906 [2:35:05<6:58:58, 11.90s/it] 27%|██▋       | 795/2906 [2:35:17<6:58:23, 11.89s/it]                                                      {'loss': 0.8453, 'grad_norm': 1.3800690174102783, 'learning_rate': 4.282548372544307e-06, 'epoch': 0.27}
 27%|██▋       | 795/2906 [2:35:17<6:58:23, 11.89s/it] 27%|██▋       | 796/2906 [2:35:29<6:54:00, 11.77s/it]                                                      {'loss': 0.8338, 'grad_norm': 1.4261043071746826, 'learning_rate': 4.2805847557795846e-06, 'epoch': 0.27}
 27%|██▋       | 796/2906 [2:35:29<6:54:00, 11.77s/it] 27%|██▋       | 797/2906 [2:35:40<6:52:41, 11.74s/it]                                                      {'loss': 0.7758, 'grad_norm': 1.3971714973449707, 'learning_rate': 4.278618907051724e-06, 'epoch': 0.27}
 27%|██▋       | 797/2906 [2:35:41<6:52:41, 11.74s/it] 27%|██▋       | 798/2906 [2:35:52<6:50:44, 11.69s/it]                                                      {'loss': 0.7656, 'grad_norm': 1.3863792419433594, 'learning_rate': 4.276650828824919e-06, 'epoch': 0.27}
 27%|██▋       | 798/2906 [2:35:52<6:50:44, 11.69s/it] 27%|██▋       | 799/2906 [2:36:04<6:51:10, 11.71s/it]                                                      {'loss': 0.7817, 'grad_norm': 1.3419262170791626, 'learning_rate': 4.274680523566154e-06, 'epoch': 0.27}
 27%|██▋       | 799/2906 [2:36:04<6:51:10, 11.71s/it] 28%|██▊       | 800/2906 [2:36:15<6:50:17, 11.69s/it]                                                      {'loss': 0.8098, 'grad_norm': 1.2619614601135254, 'learning_rate': 4.272707993745208e-06, 'epoch': 0.28}
 28%|██▊       | 800/2906 [2:36:15<6:50:17, 11.69s/it][INFO|trainer.py:3984] 2025-08-21 14:58:45,007 >> Saving model checkpoint to /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800
[INFO|configuration_utils.py:419] 2025-08-21 14:58:45,013 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/config.json
[INFO|configuration_utils.py:911] 2025-08-21 14:58:45,013 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/generation_config.json
[INFO|modeling_utils.py:3580] 2025-08-21 14:59:13,939 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-08-21 14:59:13,953 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 14:59:13,953 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/special_tokens_map.json
[2025-08-21 14:59:14,595] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step800 is about to be saved!
[2025-08-21 14:59:14,845] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/global_step800/mp_rank_00_model_states.pt
[2025-08-21 14:59:14,845] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/global_step800/mp_rank_00_model_states.pt...
[2025-08-21 14:59:48,864] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/global_step800/mp_rank_00_model_states.pt.
[2025-08-21 14:59:48,943] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/global_step800/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-21 15:00:34,644] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/global_step800/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-21 15:00:34,645] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/global_step800/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-21 15:00:34,645] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step800 is ready now!
[INFO|image_processing_base.py:260] 2025-08-21 15:00:46,801 >> Image processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/preprocessor_config.json
[INFO|tokenization_utils_base.py:2510] 2025-08-21 15:00:46,802 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 15:00:46,802 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/special_tokens_map.json
[INFO|processing_utils.py:648] 2025-08-21 15:00:46,978 >> chat template saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/chat_template.json
[INFO|processing_utils.py:654] 2025-08-21 15:00:47,114 >> processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-800/processor_config.json
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 28%|██▊       | 801/2906 [2:38:37<29:36:14, 50.63s/it]                                                       {'loss': 0.7969, 'grad_norm': 1.2899328470230103, 'learning_rate': 4.270733241834647e-06, 'epoch': 0.28}
 28%|██▊       | 801/2906 [2:38:37<29:36:14, 50.63s/it] 28%|██▊       | 802/2906 [2:38:48<22:43:39, 38.89s/it]                                                       {'loss': 0.8456, 'grad_norm': 1.2973592281341553, 'learning_rate': 4.2687562703098214e-06, 'epoch': 0.28}
 28%|██▊       | 802/2906 [2:38:48<22:43:39, 38.89s/it] 28%|██▊       | 803/2906 [2:39:00<17:54:12, 30.65s/it]                                                       {'loss': 0.8521, 'grad_norm': 1.323277235031128, 'learning_rate': 4.266777081648868e-06, 'epoch': 0.28}
 28%|██▊       | 803/2906 [2:39:00<17:54:12, 30.65s/it] 28%|██▊       | 804/2906 [2:39:12<14:33:57, 24.95s/it]                                                       {'loss': 0.8178, 'grad_norm': 1.3589348793029785, 'learning_rate': 4.264795678332697e-06, 'epoch': 0.28}
 28%|██▊       | 804/2906 [2:39:12<14:33:57, 24.95s/it] 28%|██▊       | 805/2906 [2:39:24<12:24:14, 21.25s/it]                                                       {'loss': 0.8385, 'grad_norm': 1.35676908493042, 'learning_rate': 4.262812062844999e-06, 'epoch': 0.28}
 28%|██▊       | 805/2906 [2:39:24<12:24:14, 21.25s/it] 28%|██▊       | 806/2906 [2:39:36<10:41:16, 18.32s/it]                                                       {'loss': 0.7974, 'grad_norm': 1.2095861434936523, 'learning_rate': 4.260826237672237e-06, 'epoch': 0.28}
 28%|██▊       | 806/2906 [2:39:36<10:41:16, 18.32s/it] 28%|██▊       | 807/2906 [2:39:47<9:32:07, 16.35s/it]                                                       {'loss': 0.772, 'grad_norm': 1.1901428699493408, 'learning_rate': 4.25883820530364e-06, 'epoch': 0.28}
 28%|██▊       | 807/2906 [2:39:47<9:32:07, 16.35s/it] 28%|██▊       | 808/2906 [2:39:59<8:42:16, 14.94s/it]                                                      {'loss': 0.8282, 'grad_norm': 1.2851134538650513, 'learning_rate': 4.25684796823121e-06, 'epoch': 0.28}
 28%|██▊       | 808/2906 [2:39:59<8:42:16, 14.94s/it] 28%|██▊       | 809/2906 [2:40:11<8:12:08, 14.08s/it]                                                      {'loss': 0.7835, 'grad_norm': 1.24265718460083, 'learning_rate': 4.254855528949709e-06, 'epoch': 0.28}
 28%|██▊       | 809/2906 [2:40:11<8:12:08, 14.08s/it] 28%|██▊       | 810/2906 [2:40:23<7:48:15, 13.40s/it]                                                      {'loss': 0.8278, 'grad_norm': 1.3049089908599854, 'learning_rate': 4.252860889956658e-06, 'epoch': 0.28}
 28%|██▊       | 810/2906 [2:40:23<7:48:15, 13.40s/it] 28%|██▊       | 811/2906 [2:40:34<7:25:29, 12.76s/it]                                                      {'loss': 0.8364, 'grad_norm': 1.3488786220550537, 'learning_rate': 4.250864053752337e-06, 'epoch': 0.28}
 28%|██▊       | 811/2906 [2:40:34<7:25:29, 12.76s/it] 28%|██▊       | 812/2906 [2:40:46<7:17:59, 12.55s/it]                                                      {'loss': 0.8199, 'grad_norm': 1.231899619102478, 'learning_rate': 4.248865022839783e-06, 'epoch': 0.28}
 28%|██▊       | 812/2906 [2:40:46<7:17:59, 12.55s/it] 28%|██▊       | 813/2906 [2:40:58<7:09:11, 12.30s/it]                                                      {'loss': 0.7379, 'grad_norm': 1.1924116611480713, 'learning_rate': 4.2468637997247794e-06, 'epoch': 0.28}
 28%|██▊       | 813/2906 [2:40:58<7:09:11, 12.30s/it] 28%|██▊       | 814/2906 [2:41:09<6:57:56, 11.99s/it]                                                      {'loss': 0.8019, 'grad_norm': 1.2594431638717651, 'learning_rate': 4.2448603869158585e-06, 'epoch': 0.28}
 28%|██▊       | 814/2906 [2:41:09<6:57:56, 11.99s/it] 28%|██▊       | 815/2906 [2:41:21<6:52:36, 11.84s/it]                                                      {'loss': 0.835, 'grad_norm': 1.3117356300354004, 'learning_rate': 4.242854786924302e-06, 'epoch': 0.28}
 28%|██▊       | 815/2906 [2:41:21<6:52:36, 11.84s/it] 28%|██▊       | 816/2906 [2:41:32<6:50:38, 11.79s/it]                                                      {'loss': 0.8033, 'grad_norm': 1.2329161167144775, 'learning_rate': 4.240847002264126e-06, 'epoch': 0.28}
 28%|██▊       | 816/2906 [2:41:32<6:50:38, 11.79s/it] 28%|██▊       | 817/2906 [2:41:44<6:52:54, 11.86s/it]                                                      {'loss': 0.8171, 'grad_norm': 1.2190955877304077, 'learning_rate': 4.238837035452092e-06, 'epoch': 0.28}
 28%|██▊       | 817/2906 [2:41:44<6:52:54, 11.86s/it] 28%|██▊       | 818/2906 [2:41:56<6:53:01, 11.87s/it]                                                      {'loss': 0.8072, 'grad_norm': 1.3557724952697754, 'learning_rate': 4.23682488900769e-06, 'epoch': 0.28}
 28%|██▊       | 818/2906 [2:41:56<6:53:01, 11.87s/it] 28%|██▊       | 819/2906 [2:42:09<6:58:39, 12.04s/it]                                                      {'loss': 0.8316, 'grad_norm': 1.2569953203201294, 'learning_rate': 4.234810565453148e-06, 'epoch': 0.28}
 28%|██▊       | 819/2906 [2:42:09<6:58:39, 12.04s/it] 28%|██▊       | 820/2906 [2:42:21<6:56:06, 11.97s/it]                                                      {'loss': 0.8473, 'grad_norm': 1.282663345336914, 'learning_rate': 4.23279406731342e-06, 'epoch': 0.28}
 28%|██▊       | 820/2906 [2:42:21<6:56:06, 11.97s/it] 28%|██▊       | 821/2906 [2:42:33<6:57:33, 12.02s/it]                                                      {'loss': 0.7595, 'grad_norm': 1.2686558961868286, 'learning_rate': 4.230775397116188e-06, 'epoch': 0.28}
 28%|██▊       | 821/2906 [2:42:33<6:57:33, 12.02s/it] 28%|██▊       | 822/2906 [2:42:45<6:57:38, 12.02s/it]                                                      {'loss': 0.7731, 'grad_norm': 1.279204249382019, 'learning_rate': 4.228754557391853e-06, 'epoch': 0.28}
 28%|██▊       | 822/2906 [2:42:45<6:57:38, 12.02s/it] 28%|██▊       | 823/2906 [2:42:57<6:58:16, 12.05s/it]                                                      {'loss': 0.7962, 'grad_norm': 1.2633720636367798, 'learning_rate': 4.2267315506735394e-06, 'epoch': 0.28}
 28%|██▊       | 823/2906 [2:42:57<6:58:16, 12.05s/it] 28%|██▊       | 824/2906 [2:43:09<6:55:11, 11.96s/it]                                                      {'loss': 0.8271, 'grad_norm': 1.303841233253479, 'learning_rate': 4.2247063794970854e-06, 'epoch': 0.28}
 28%|██▊       | 824/2906 [2:43:09<6:55:11, 11.96s/it] 28%|██▊       | 825/2906 [2:43:20<6:52:58, 11.91s/it]                                                      {'loss': 0.7815, 'grad_norm': 1.2670228481292725, 'learning_rate': 4.2226790464010445e-06, 'epoch': 0.28}
 28%|██▊       | 825/2906 [2:43:20<6:52:58, 11.91s/it] 28%|██▊       | 826/2906 [2:43:32<6:50:17, 11.84s/it]                                                      {'loss': 0.7868, 'grad_norm': 1.3127440214157104, 'learning_rate': 4.220649553926677e-06, 'epoch': 0.28}
 28%|██▊       | 826/2906 [2:43:32<6:50:17, 11.84s/it] 28%|██▊       | 827/2906 [2:43:43<6:44:54, 11.69s/it]                                                      {'loss': 0.7608, 'grad_norm': 1.2529574632644653, 'learning_rate': 4.218617904617953e-06, 'epoch': 0.28}
 28%|██▊       | 827/2906 [2:43:43<6:44:54, 11.69s/it] 28%|██▊       | 828/2906 [2:43:55<6:44:51, 11.69s/it]                                                      {'loss': 0.8691, 'grad_norm': 1.2946919202804565, 'learning_rate': 4.216584101021546e-06, 'epoch': 0.28}
 28%|██▊       | 828/2906 [2:43:55<6:44:51, 11.69s/it] 29%|██▊       | 829/2906 [2:44:07<6:48:16, 11.79s/it]                                                      {'loss': 0.848, 'grad_norm': 1.3568788766860962, 'learning_rate': 4.2145481456868265e-06, 'epoch': 0.29}
 29%|██▊       | 829/2906 [2:44:07<6:48:16, 11.79s/it] 29%|██▊       | 830/2906 [2:44:19<6:46:26, 11.75s/it]                                                      {'loss': 0.8349, 'grad_norm': 1.3106145858764648, 'learning_rate': 4.212510041165868e-06, 'epoch': 0.29}
 29%|██▊       | 830/2906 [2:44:19<6:46:26, 11.75s/it] 29%|██▊       | 831/2906 [2:44:30<6:41:12, 11.60s/it]                                                      {'loss': 0.8148, 'grad_norm': 1.368038296699524, 'learning_rate': 4.210469790013431e-06, 'epoch': 0.29}
 29%|██▊       | 831/2906 [2:44:30<6:41:12, 11.60s/it] 29%|██▊       | 832/2906 [2:44:42<6:41:25, 11.61s/it]                                                      {'loss': 0.7825, 'grad_norm': 1.3578945398330688, 'learning_rate': 4.208427394786973e-06, 'epoch': 0.29}
 29%|██▊       | 832/2906 [2:44:42<6:41:25, 11.61s/it] 29%|██▊       | 833/2906 [2:44:54<6:45:59, 11.75s/it]                                                      {'loss': 0.8548, 'grad_norm': 1.3799738883972168, 'learning_rate': 4.206382858046636e-06, 'epoch': 0.29}
 29%|██▊       | 833/2906 [2:44:54<6:45:59, 11.75s/it] 29%|██▊       | 834/2906 [2:45:06<6:47:35, 11.80s/it]                                                      {'loss': 0.7396, 'grad_norm': 1.2944447994232178, 'learning_rate': 4.204336182355246e-06, 'epoch': 0.29}
 29%|██▊       | 834/2906 [2:45:06<6:47:35, 11.80s/it] 29%|██▊       | 835/2906 [2:45:18<6:53:43, 11.99s/it]                                                      {'loss': 0.7395, 'grad_norm': 1.2831629514694214, 'learning_rate': 4.202287370278313e-06, 'epoch': 0.29}
 29%|██▊       | 835/2906 [2:45:18<6:53:43, 11.99s/it] 29%|██▉       | 836/2906 [2:45:30<6:48:17, 11.83s/it]                                                      {'loss': 0.7407, 'grad_norm': 1.2961376905441284, 'learning_rate': 4.200236424384022e-06, 'epoch': 0.29}
 29%|██▉       | 836/2906 [2:45:30<6:48:17, 11.83s/it] 29%|██▉       | 837/2906 [2:45:41<6:47:11, 11.81s/it]                                                      {'loss': 0.7846, 'grad_norm': 1.3519154787063599, 'learning_rate': 4.198183347243233e-06, 'epoch': 0.29}
 29%|██▉       | 837/2906 [2:45:41<6:47:11, 11.81s/it] 29%|██▉       | 838/2906 [2:45:53<6:45:55, 11.78s/it]                                                      {'loss': 0.826, 'grad_norm': 1.3331308364868164, 'learning_rate': 4.19612814142948e-06, 'epoch': 0.29}
 29%|██▉       | 838/2906 [2:45:53<6:45:55, 11.78s/it] 29%|██▉       | 839/2906 [2:46:05<6:43:26, 11.71s/it]                                                      {'loss': 0.7913, 'grad_norm': 1.3260215520858765, 'learning_rate': 4.194070809518963e-06, 'epoch': 0.29}
 29%|██▉       | 839/2906 [2:46:05<6:43:26, 11.71s/it] 29%|██▉       | 840/2906 [2:46:16<6:41:54, 11.67s/it]                                                      {'loss': 0.7025, 'grad_norm': 1.2604711055755615, 'learning_rate': 4.192011354090548e-06, 'epoch': 0.29}
 29%|██▉       | 840/2906 [2:46:16<6:41:54, 11.67s/it] 29%|██▉       | 841/2906 [2:46:28<6:42:09, 11.68s/it]                                                      {'loss': 0.7796, 'grad_norm': 1.300485372543335, 'learning_rate': 4.1899497777257615e-06, 'epoch': 0.29}
 29%|██▉       | 841/2906 [2:46:28<6:42:09, 11.68s/it] 29%|██▉       | 842/2906 [2:46:39<6:41:43, 11.68s/it]                                                      {'loss': 0.828, 'grad_norm': 1.3303813934326172, 'learning_rate': 4.187886083008791e-06, 'epoch': 0.29}
 29%|██▉       | 842/2906 [2:46:40<6:41:43, 11.68s/it] 29%|██▉       | 843/2906 [2:46:51<6:40:54, 11.66s/it]                                                      {'loss': 0.7713, 'grad_norm': 1.2124364376068115, 'learning_rate': 4.185820272526477e-06, 'epoch': 0.29}
 29%|██▉       | 843/2906 [2:46:51<6:40:54, 11.66s/it] 29%|██▉       | 844/2906 [2:47:03<6:44:37, 11.77s/it]                                                      {'loss': 0.8009, 'grad_norm': 1.230875849723816, 'learning_rate': 4.183752348868313e-06, 'epoch': 0.29}
 29%|██▉       | 844/2906 [2:47:03<6:44:37, 11.77s/it] 29%|██▉       | 845/2906 [2:47:15<6:46:19, 11.83s/it]                                                      {'loss': 0.7966, 'grad_norm': 1.4060747623443604, 'learning_rate': 4.181682314626443e-06, 'epoch': 0.29}
 29%|██▉       | 845/2906 [2:47:15<6:46:19, 11.83s/it] 29%|██▉       | 846/2906 [2:47:27<6:47:31, 11.87s/it]                                                      {'loss': 0.8687, 'grad_norm': 1.3459950685501099, 'learning_rate': 4.179610172395653e-06, 'epoch': 0.29}
 29%|██▉       | 846/2906 [2:47:27<6:47:31, 11.87s/it] 29%|██▉       | 847/2906 [2:47:39<6:45:10, 11.81s/it]                                                      {'loss': 0.8778, 'grad_norm': 1.4435315132141113, 'learning_rate': 4.177535924773375e-06, 'epoch': 0.29}
 29%|██▉       | 847/2906 [2:47:39<6:45:10, 11.81s/it] 29%|██▉       | 848/2906 [2:47:50<6:41:35, 11.71s/it]                                                      {'loss': 0.8023, 'grad_norm': 1.214852213859558, 'learning_rate': 4.175459574359678e-06, 'epoch': 0.29}
 29%|██▉       | 848/2906 [2:47:50<6:41:35, 11.71s/it] 29%|██▉       | 849/2906 [2:48:02<6:42:49, 11.75s/it]                                                      {'loss': 0.7773, 'grad_norm': 1.2661129236221313, 'learning_rate': 4.173381123757268e-06, 'epoch': 0.29}
 29%|██▉       | 849/2906 [2:48:02<6:42:49, 11.75s/it] 29%|██▉       | 850/2906 [2:48:13<6:38:22, 11.63s/it]                                                      {'loss': 0.8484, 'grad_norm': 1.343247652053833, 'learning_rate': 4.1713005755714815e-06, 'epoch': 0.29}
 29%|██▉       | 850/2906 [2:48:13<6:38:22, 11.63s/it] 29%|██▉       | 851/2906 [2:48:25<6:41:57, 11.74s/it]                                                      {'loss': 0.8443, 'grad_norm': 1.3099271059036255, 'learning_rate': 4.169217932410288e-06, 'epoch': 0.29}
 29%|██▉       | 851/2906 [2:48:25<6:41:57, 11.74s/it] 29%|██▉       | 852/2906 [2:48:38<6:46:54, 11.89s/it]                                                      {'loss': 0.7927, 'grad_norm': 1.33564031124115, 'learning_rate': 4.167133196884279e-06, 'epoch': 0.29}
 29%|██▉       | 852/2906 [2:48:38<6:46:54, 11.89s/it] 29%|██▉       | 853/2906 [2:48:49<6:44:44, 11.83s/it]                                                      {'loss': 0.7495, 'grad_norm': 1.2439754009246826, 'learning_rate': 4.165046371606671e-06, 'epoch': 0.29}
 29%|██▉       | 853/2906 [2:48:49<6:44:44, 11.83s/it] 29%|██▉       | 854/2906 [2:49:01<6:42:52, 11.78s/it]                                                      {'loss': 0.8648, 'grad_norm': 1.2383062839508057, 'learning_rate': 4.1629574591933e-06, 'epoch': 0.29}
 29%|██▉       | 854/2906 [2:49:01<6:42:52, 11.78s/it] 29%|██▉       | 855/2906 [2:49:12<6:38:36, 11.66s/it]                                                      {'loss': 0.8116, 'grad_norm': 1.2382389307022095, 'learning_rate': 4.160866462262618e-06, 'epoch': 0.29}
 29%|██▉       | 855/2906 [2:49:12<6:38:36, 11.66s/it] 29%|██▉       | 856/2906 [2:49:24<6:40:51, 11.73s/it]                                                      {'loss': 0.7983, 'grad_norm': 1.2767484188079834, 'learning_rate': 4.1587733834356905e-06, 'epoch': 0.29}
 29%|██▉       | 856/2906 [2:49:24<6:40:51, 11.73s/it] 29%|██▉       | 857/2906 [2:49:36<6:38:23, 11.67s/it]                                                      {'loss': 0.7957, 'grad_norm': 1.2490538358688354, 'learning_rate': 4.15667822533619e-06, 'epoch': 0.29}
 29%|██▉       | 857/2906 [2:49:36<6:38:23, 11.67s/it] 30%|██▉       | 858/2906 [2:49:47<6:34:52, 11.57s/it]                                                      {'loss': 0.7422, 'grad_norm': 1.2871544361114502, 'learning_rate': 4.154580990590399e-06, 'epoch': 0.3}
 30%|██▉       | 858/2906 [2:49:47<6:34:52, 11.57s/it] 30%|██▉       | 859/2906 [2:49:59<6:36:51, 11.63s/it]                                                      {'loss': 0.8107, 'grad_norm': 1.2312754392623901, 'learning_rate': 4.152481681827201e-06, 'epoch': 0.3}
 30%|██▉       | 859/2906 [2:49:59<6:36:51, 11.63s/it] 30%|██▉       | 860/2906 [2:50:11<6:40:02, 11.73s/it]                                                      {'loss': 0.8239, 'grad_norm': 1.33573579788208, 'learning_rate': 4.15038030167808e-06, 'epoch': 0.3}
 30%|██▉       | 860/2906 [2:50:11<6:40:02, 11.73s/it] 30%|██▉       | 861/2906 [2:50:23<6:42:20, 11.80s/it]                                                      {'loss': 0.7595, 'grad_norm': 1.2928647994995117, 'learning_rate': 4.1482768527771155e-06, 'epoch': 0.3}
 30%|██▉       | 861/2906 [2:50:23<6:42:20, 11.80s/it] 30%|██▉       | 862/2906 [2:50:35<6:44:57, 11.89s/it]                                                      {'loss': 0.8402, 'grad_norm': 1.3420125246047974, 'learning_rate': 4.146171337760981e-06, 'epoch': 0.3}
 30%|██▉       | 862/2906 [2:50:35<6:44:57, 11.89s/it] 30%|██▉       | 863/2906 [2:50:47<6:41:56, 11.80s/it]                                                      {'loss': 0.8245, 'grad_norm': 1.2255133390426636, 'learning_rate': 4.14406375926894e-06, 'epoch': 0.3}
 30%|██▉       | 863/2906 [2:50:47<6:41:56, 11.80s/it] 30%|██▉       | 864/2906 [2:50:58<6:41:56, 11.81s/it]                                                      {'loss': 0.8075, 'grad_norm': 1.306741714477539, 'learning_rate': 4.141954119942843e-06, 'epoch': 0.3}
 30%|██▉       | 864/2906 [2:50:58<6:41:56, 11.81s/it] 30%|██▉       | 865/2906 [2:51:10<6:39:13, 11.74s/it]                                                      {'loss': 0.8053, 'grad_norm': 1.2838637828826904, 'learning_rate': 4.13984242242712e-06, 'epoch': 0.3}
 30%|██▉       | 865/2906 [2:51:10<6:39:13, 11.74s/it] 30%|██▉       | 866/2906 [2:51:21<6:37:00, 11.68s/it]                                                      {'loss': 0.7713, 'grad_norm': 1.3548331260681152, 'learning_rate': 4.137728669368789e-06, 'epoch': 0.3}
 30%|██▉       | 866/2906 [2:51:21<6:37:00, 11.68s/it] 30%|██▉       | 867/2906 [2:51:34<6:40:45, 11.79s/it]                                                      {'loss': 0.7372, 'grad_norm': 1.2962146997451782, 'learning_rate': 4.135612863417435e-06, 'epoch': 0.3}
 30%|██▉       | 867/2906 [2:51:34<6:40:45, 11.79s/it] 30%|██▉       | 868/2906 [2:51:45<6:32:28, 11.55s/it]                                                      {'loss': 0.8051, 'grad_norm': 1.2962833642959595, 'learning_rate': 4.133495007225224e-06, 'epoch': 0.3}
 30%|██▉       | 868/2906 [2:51:45<6:32:28, 11.55s/it] 30%|██▉       | 869/2906 [2:51:57<6:37:31, 11.71s/it]                                                      {'loss': 0.8306, 'grad_norm': 1.330247402191162, 'learning_rate': 4.131375103446889e-06, 'epoch': 0.3}
 30%|██▉       | 869/2906 [2:51:57<6:37:31, 11.71s/it] 30%|██▉       | 870/2906 [2:52:09<6:42:35, 11.86s/it]                                                      {'loss': 0.892, 'grad_norm': 1.388953447341919, 'learning_rate': 4.129253154739726e-06, 'epoch': 0.3}
 30%|██▉       | 870/2906 [2:52:09<6:42:35, 11.86s/it] 30%|██▉       | 871/2906 [2:52:20<6:37:12, 11.71s/it]                                                      {'loss': 0.8774, 'grad_norm': 1.324244499206543, 'learning_rate': 4.127129163763601e-06, 'epoch': 0.3}
 30%|██▉       | 871/2906 [2:52:20<6:37:12, 11.71s/it] 30%|███       | 872/2906 [2:52:32<6:39:47, 11.79s/it]                                                      {'loss': 0.7992, 'grad_norm': 1.3372825384140015, 'learning_rate': 4.125003133180937e-06, 'epoch': 0.3}
 30%|███       | 872/2906 [2:52:32<6:39:47, 11.79s/it] 30%|███       | 873/2906 [2:52:44<6:37:58, 11.75s/it]                                                      {'loss': 0.8144, 'grad_norm': 1.282662272453308, 'learning_rate': 4.122875065656712e-06, 'epoch': 0.3}
 30%|███       | 873/2906 [2:52:44<6:37:58, 11.75s/it] 30%|███       | 874/2906 [2:52:55<6:32:01, 11.58s/it]                                                      {'loss': 0.7942, 'grad_norm': 1.446570634841919, 'learning_rate': 4.120744963858459e-06, 'epoch': 0.3}
 30%|███       | 874/2906 [2:52:55<6:32:01, 11.58s/it] 30%|███       | 875/2906 [2:53:06<6:28:02, 11.46s/it]                                                      {'loss': 0.7836, 'grad_norm': 1.2678354978561401, 'learning_rate': 4.118612830456262e-06, 'epoch': 0.3}
 30%|███       | 875/2906 [2:53:06<6:28:02, 11.46s/it] 30%|███       | 876/2906 [2:53:18<6:28:30, 11.48s/it]                                                      {'loss': 0.8355, 'grad_norm': 1.3284164667129517, 'learning_rate': 4.11647866812275e-06, 'epoch': 0.3}
 30%|███       | 876/2906 [2:53:18<6:28:30, 11.48s/it] 30%|███       | 877/2906 [2:53:30<6:37:20, 11.75s/it]                                                      {'loss': 0.8722, 'grad_norm': 1.3076499700546265, 'learning_rate': 4.114342479533094e-06, 'epoch': 0.3}
 30%|███       | 877/2906 [2:53:30<6:37:20, 11.75s/it] 30%|███       | 878/2906 [2:53:42<6:43:32, 11.94s/it]                                                      {'loss': 0.8587, 'grad_norm': 1.2999705076217651, 'learning_rate': 4.112204267365008e-06, 'epoch': 0.3}
 30%|███       | 878/2906 [2:53:42<6:43:32, 11.94s/it] 30%|███       | 879/2906 [2:53:55<6:49:58, 12.14s/it]                                                      {'loss': 0.8239, 'grad_norm': 1.248750925064087, 'learning_rate': 4.110064034298741e-06, 'epoch': 0.3}
 30%|███       | 879/2906 [2:53:55<6:49:58, 12.14s/it] 30%|███       | 880/2906 [2:54:07<6:50:24, 12.15s/it]                                                      {'loss': 0.805, 'grad_norm': 1.2147819995880127, 'learning_rate': 4.107921783017076e-06, 'epoch': 0.3}
 30%|███       | 880/2906 [2:54:07<6:50:24, 12.15s/it] 30%|███       | 881/2906 [2:54:19<6:48:37, 12.11s/it]                                                      {'loss': 0.8075, 'grad_norm': 1.3027336597442627, 'learning_rate': 4.105777516205324e-06, 'epoch': 0.3}
 30%|███       | 881/2906 [2:54:19<6:48:37, 12.11s/it] 30%|███       | 882/2906 [2:54:31<6:42:48, 11.94s/it]                                                      {'loss': 0.7661, 'grad_norm': 1.2932363748550415, 'learning_rate': 4.103631236551325e-06, 'epoch': 0.3}
 30%|███       | 882/2906 [2:54:31<6:42:48, 11.94s/it] 30%|███       | 883/2906 [2:54:43<6:44:22, 11.99s/it]                                                      {'loss': 0.7939, 'grad_norm': 1.2192192077636719, 'learning_rate': 4.101482946745438e-06, 'epoch': 0.3}
 30%|███       | 883/2906 [2:54:43<6:44:22, 11.99s/it] 30%|███       | 884/2906 [2:54:55<6:42:37, 11.95s/it]                                                      {'loss': 0.8419, 'grad_norm': 1.3596593141555786, 'learning_rate': 4.099332649480547e-06, 'epoch': 0.3}
 30%|███       | 884/2906 [2:54:55<6:42:37, 11.95s/it] 30%|███       | 885/2906 [2:55:07<6:40:26, 11.89s/it]                                                      {'loss': 0.8772, 'grad_norm': 1.3797836303710938, 'learning_rate': 4.09718034745205e-06, 'epoch': 0.3}
 30%|███       | 885/2906 [2:55:07<6:40:26, 11.89s/it] 30%|███       | 886/2906 [2:55:19<6:41:29, 11.93s/it]                                                      {'loss': 0.8072, 'grad_norm': 1.316931962966919, 'learning_rate': 4.095026043357856e-06, 'epoch': 0.3}
 30%|███       | 886/2906 [2:55:19<6:41:29, 11.93s/it] 31%|███       | 887/2906 [2:55:30<6:39:29, 11.87s/it]                                                      {'loss': 0.8259, 'grad_norm': 1.3430103063583374, 'learning_rate': 4.092869739898386e-06, 'epoch': 0.31}
 31%|███       | 887/2906 [2:55:30<6:39:29, 11.87s/it] 31%|███       | 888/2906 [2:55:42<6:42:51, 11.98s/it]                                                      {'loss': 0.7485, 'grad_norm': 1.2627366781234741, 'learning_rate': 4.090711439776567e-06, 'epoch': 0.31}
 31%|███       | 888/2906 [2:55:43<6:42:51, 11.98s/it] 31%|███       | 889/2906 [2:55:54<6:38:47, 11.86s/it]                                                      {'loss': 0.864, 'grad_norm': 1.3988090753555298, 'learning_rate': 4.0885511456978275e-06, 'epoch': 0.31}
 31%|███       | 889/2906 [2:55:54<6:38:47, 11.86s/it] 31%|███       | 890/2906 [2:56:06<6:42:37, 11.98s/it]                                                      {'loss': 0.8139, 'grad_norm': 1.2847155332565308, 'learning_rate': 4.086388860370098e-06, 'epoch': 0.31}
 31%|███       | 890/2906 [2:56:06<6:42:37, 11.98s/it] 31%|███       | 891/2906 [2:56:18<6:40:47, 11.93s/it]                                                      {'loss': 0.8205, 'grad_norm': 1.4526575803756714, 'learning_rate': 4.084224586503801e-06, 'epoch': 0.31}
 31%|███       | 891/2906 [2:56:18<6:40:47, 11.93s/it] 31%|███       | 892/2906 [2:56:30<6:37:48, 11.85s/it]                                                      {'loss': 0.7932, 'grad_norm': 1.3164477348327637, 'learning_rate': 4.082058326811857e-06, 'epoch': 0.31}
 31%|███       | 892/2906 [2:56:30<6:37:48, 11.85s/it] 31%|███       | 893/2906 [2:56:42<6:38:51, 11.89s/it]                                                      {'loss': 0.8538, 'grad_norm': 1.3406115770339966, 'learning_rate': 4.0798900840096694e-06, 'epoch': 0.31}
 31%|███       | 893/2906 [2:56:42<6:38:51, 11.89s/it] 31%|███       | 894/2906 [2:56:54<6:39:44, 11.92s/it]                                                      {'loss': 0.858, 'grad_norm': 1.426195740699768, 'learning_rate': 4.077719860815132e-06, 'epoch': 0.31}
 31%|███       | 894/2906 [2:56:54<6:39:44, 11.92s/it] 31%|███       | 895/2906 [2:57:05<6:32:51, 11.72s/it]                                                      {'loss': 0.8522, 'grad_norm': 1.3709224462509155, 'learning_rate': 4.075547659948621e-06, 'epoch': 0.31}
 31%|███       | 895/2906 [2:57:05<6:32:51, 11.72s/it] 31%|███       | 896/2906 [2:57:16<6:27:25, 11.57s/it]                                                      {'loss': 0.7971, 'grad_norm': 1.3481965065002441, 'learning_rate': 4.073373484132989e-06, 'epoch': 0.31}
 31%|███       | 896/2906 [2:57:16<6:27:25, 11.57s/it] 31%|███       | 897/2906 [2:57:27<6:23:35, 11.46s/it]                                                      {'loss': 0.7567, 'grad_norm': 1.2535377740859985, 'learning_rate': 4.071197336093566e-06, 'epoch': 0.31}
 31%|███       | 897/2906 [2:57:27<6:23:35, 11.46s/it] 31%|███       | 898/2906 [2:57:39<6:26:48, 11.56s/it]                                                      {'loss': 0.7806, 'grad_norm': 1.324162483215332, 'learning_rate': 4.069019218558154e-06, 'epoch': 0.31}
 31%|███       | 898/2906 [2:57:39<6:26:48, 11.56s/it] 31%|███       | 899/2906 [2:57:51<6:26:12, 11.55s/it]                                                      {'loss': 0.8267, 'grad_norm': 1.3403282165527344, 'learning_rate': 4.0668391342570225e-06, 'epoch': 0.31}
 31%|███       | 899/2906 [2:57:51<6:26:12, 11.55s/it] 31%|███       | 900/2906 [2:58:03<6:28:27, 11.62s/it]                                                      {'loss': 0.7833, 'grad_norm': 1.31051504611969, 'learning_rate': 4.064657085922909e-06, 'epoch': 0.31}
 31%|███       | 900/2906 [2:58:03<6:28:27, 11.62s/it] 31%|███       | 901/2906 [2:58:15<6:32:45, 11.75s/it]                                                      {'loss': 0.7913, 'grad_norm': 1.246871829032898, 'learning_rate': 4.062473076291009e-06, 'epoch': 0.31}
 31%|███       | 901/2906 [2:58:15<6:32:45, 11.75s/it] 31%|███       | 902/2906 [2:58:26<6:30:38, 11.70s/it]                                                      {'loss': 0.8441, 'grad_norm': 1.3395609855651855, 'learning_rate': 4.06028710809898e-06, 'epoch': 0.31}
 31%|███       | 902/2906 [2:58:26<6:30:38, 11.70s/it] 31%|███       | 903/2906 [2:58:38<6:31:44, 11.73s/it]                                                      {'loss': 0.8496, 'grad_norm': 1.4072691202163696, 'learning_rate': 4.058099184086934e-06, 'epoch': 0.31}
 31%|███       | 903/2906 [2:58:38<6:31:44, 11.73s/it] 31%|███       | 904/2906 [2:58:50<6:34:52, 11.83s/it]                                                      {'loss': 0.7596, 'grad_norm': 1.2521024942398071, 'learning_rate': 4.055909306997434e-06, 'epoch': 0.31}
 31%|███       | 904/2906 [2:58:50<6:34:52, 11.83s/it] 31%|███       | 905/2906 [2:59:02<6:36:47, 11.90s/it]                                                      {'loss': 0.7692, 'grad_norm': 1.2922197580337524, 'learning_rate': 4.05371747957549e-06, 'epoch': 0.31}
 31%|███       | 905/2906 [2:59:02<6:36:47, 11.90s/it] 31%|███       | 906/2906 [2:59:14<6:38:15, 11.95s/it]                                                      {'loss': 0.8069, 'grad_norm': 1.2748745679855347, 'learning_rate': 4.051523704568557e-06, 'epoch': 0.31}
 31%|███       | 906/2906 [2:59:14<6:38:15, 11.95s/it] 31%|███       | 907/2906 [2:59:26<6:35:54, 11.88s/it]                                                      {'loss': 0.795, 'grad_norm': 1.25579035282135, 'learning_rate': 4.049327984726535e-06, 'epoch': 0.31}
 31%|███       | 907/2906 [2:59:26<6:35:54, 11.88s/it] 31%|███       | 908/2906 [2:59:37<6:29:54, 11.71s/it]                                                      {'loss': 0.7576, 'grad_norm': 1.3368980884552002, 'learning_rate': 4.047130322801757e-06, 'epoch': 0.31}
 31%|███       | 908/2906 [2:59:37<6:29:54, 11.71s/it] 31%|███▏      | 909/2906 [2:59:49<6:31:13, 11.75s/it]                                                      {'loss': 0.8301, 'grad_norm': 1.3306552171707153, 'learning_rate': 4.044930721548992e-06, 'epoch': 0.31}
 31%|███▏      | 909/2906 [2:59:49<6:31:13, 11.75s/it] 31%|███▏      | 910/2906 [3:00:01<6:29:41, 11.71s/it]                                                      {'loss': 0.7141, 'grad_norm': 1.1883282661437988, 'learning_rate': 4.042729183725441e-06, 'epoch': 0.31}
 31%|███▏      | 910/2906 [3:00:01<6:29:41, 11.71s/it] 31%|███▏      | 911/2906 [3:00:13<6:30:57, 11.76s/it]                                                      {'loss': 0.8298, 'grad_norm': 1.3308837413787842, 'learning_rate': 4.040525712090733e-06, 'epoch': 0.31}
 31%|███▏      | 911/2906 [3:00:13<6:30:57, 11.76s/it] 31%|███▏      | 912/2906 [3:00:25<6:34:16, 11.86s/it]                                                      {'loss': 0.779, 'grad_norm': 1.2297667264938354, 'learning_rate': 4.038320309406919e-06, 'epoch': 0.31}
 31%|███▏      | 912/2906 [3:00:25<6:34:16, 11.86s/it] 31%|███▏      | 913/2906 [3:00:36<6:33:04, 11.83s/it]                                                      {'loss': 0.7747, 'grad_norm': 1.2849328517913818, 'learning_rate': 4.0361129784384705e-06, 'epoch': 0.31}
 31%|███▏      | 913/2906 [3:00:36<6:33:04, 11.83s/it] 31%|███▏      | 914/2906 [3:00:48<6:30:42, 11.77s/it]                                                      {'loss': 0.8523, 'grad_norm': 1.3343837261199951, 'learning_rate': 4.033903721952278e-06, 'epoch': 0.31}
 31%|███▏      | 914/2906 [3:00:48<6:30:42, 11.77s/it] 31%|███▏      | 915/2906 [3:01:00<6:28:22, 11.70s/it]                                                      {'loss': 0.7974, 'grad_norm': 1.321015477180481, 'learning_rate': 4.031692542717645e-06, 'epoch': 0.31}
 31%|███▏      | 915/2906 [3:01:00<6:28:22, 11.70s/it] 32%|███▏      | 916/2906 [3:01:12<6:33:16, 11.86s/it]                                                      {'loss': 0.7298, 'grad_norm': 1.3145334720611572, 'learning_rate': 4.0294794435062845e-06, 'epoch': 0.32}
 32%|███▏      | 916/2906 [3:01:12<6:33:16, 11.86s/it] 32%|███▏      | 917/2906 [3:01:24<6:33:07, 11.86s/it]                                                      {'loss': 0.7188, 'grad_norm': 1.3730425834655762, 'learning_rate': 4.027264427092316e-06, 'epoch': 0.32}
 32%|███▏      | 917/2906 [3:01:24<6:33:07, 11.86s/it] 32%|███▏      | 918/2906 [3:01:35<6:28:02, 11.71s/it]                                                      {'loss': 0.782, 'grad_norm': 1.2493816614151, 'learning_rate': 4.025047496252263e-06, 'epoch': 0.32}
 32%|███▏      | 918/2906 [3:01:35<6:28:02, 11.71s/it] 32%|███▏      | 919/2906 [3:01:47<6:27:28, 11.70s/it]                                                      {'loss': 0.8168, 'grad_norm': 1.309403896331787, 'learning_rate': 4.022828653765049e-06, 'epoch': 0.32}
 32%|███▏      | 919/2906 [3:01:47<6:27:28, 11.70s/it] 32%|███▏      | 920/2906 [3:01:59<6:31:32, 11.83s/it]                                                      {'loss': 0.8363, 'grad_norm': 1.318047285079956, 'learning_rate': 4.020607902411993e-06, 'epoch': 0.32}
 32%|███▏      | 920/2906 [3:01:59<6:31:32, 11.83s/it] 32%|███▏      | 921/2906 [3:02:10<6:26:43, 11.69s/it]                                                      {'loss': 0.8731, 'grad_norm': 1.414161205291748, 'learning_rate': 4.018385244976807e-06, 'epoch': 0.32}
 32%|███▏      | 921/2906 [3:02:10<6:26:43, 11.69s/it] 32%|███▏      | 922/2906 [3:02:22<6:24:04, 11.62s/it]                                                      {'loss': 0.8096, 'grad_norm': 1.2870118618011475, 'learning_rate': 4.016160684245592e-06, 'epoch': 0.32}
 32%|███▏      | 922/2906 [3:02:22<6:24:04, 11.62s/it] 32%|███▏      | 923/2906 [3:02:33<6:20:40, 11.52s/it]                                                      {'loss': 0.7355, 'grad_norm': 1.1900928020477295, 'learning_rate': 4.0139342230068355e-06, 'epoch': 0.32}
 32%|███▏      | 923/2906 [3:02:33<6:20:40, 11.52s/it] 32%|███▏      | 924/2906 [3:02:45<6:23:14, 11.60s/it]                                                      {'loss': 0.7672, 'grad_norm': 1.2919224500656128, 'learning_rate': 4.011705864051406e-06, 'epoch': 0.32}
 32%|███▏      | 924/2906 [3:02:45<6:23:14, 11.60s/it] 32%|███▏      | 925/2906 [3:02:56<6:23:01, 11.60s/it]                                                      {'loss': 0.8411, 'grad_norm': 1.3124866485595703, 'learning_rate': 4.009475610172553e-06, 'epoch': 0.32}
 32%|███▏      | 925/2906 [3:02:56<6:23:01, 11.60s/it] 32%|███▏      | 926/2906 [3:03:08<6:26:46, 11.72s/it]                                                      {'loss': 0.8395, 'grad_norm': 1.342287302017212, 'learning_rate': 4.007243464165899e-06, 'epoch': 0.32}
 32%|███▏      | 926/2906 [3:03:08<6:26:46, 11.72s/it] 32%|███▏      | 927/2906 [3:03:20<6:23:23, 11.62s/it]                                                      {'loss': 0.8046, 'grad_norm': 1.3541048765182495, 'learning_rate': 4.005009428829439e-06, 'epoch': 0.32}
 32%|███▏      | 927/2906 [3:03:20<6:23:23, 11.62s/it] 32%|███▏      | 928/2906 [3:03:32<6:29:35, 11.82s/it]                                                      {'loss': 0.833, 'grad_norm': 1.2963128089904785, 'learning_rate': 4.002773506963537e-06, 'epoch': 0.32}
 32%|███▏      | 928/2906 [3:03:32<6:29:35, 11.82s/it] 32%|███▏      | 929/2906 [3:03:43<6:24:38, 11.67s/it]                                                      {'loss': 0.7656, 'grad_norm': 1.270086407661438, 'learning_rate': 4.0005357013709215e-06, 'epoch': 0.32}
 32%|███▏      | 929/2906 [3:03:43<6:24:38, 11.67s/it] 32%|███▏      | 930/2906 [3:03:55<6:28:21, 11.79s/it]                                                      {'loss': 0.7952, 'grad_norm': 1.3636784553527832, 'learning_rate': 3.998296014856681e-06, 'epoch': 0.32}
 32%|███▏      | 930/2906 [3:03:55<6:28:21, 11.79s/it] 32%|███▏      | 931/2906 [3:04:07<6:28:33, 11.80s/it]                                                      {'loss': 0.8017, 'grad_norm': 1.1850042343139648, 'learning_rate': 3.996054450228263e-06, 'epoch': 0.32}
 32%|███▏      | 931/2906 [3:04:07<6:28:33, 11.80s/it] 32%|███▏      | 932/2906 [3:04:19<6:30:48, 11.88s/it]                                                      {'loss': 0.7591, 'grad_norm': 1.2949379682540894, 'learning_rate': 3.993811010295469e-06, 'epoch': 0.32}
 32%|███▏      | 932/2906 [3:04:19<6:30:48, 11.88s/it] 32%|███▏      | 933/2906 [3:04:32<6:34:12, 11.99s/it]                                                      {'loss': 0.8049, 'grad_norm': 1.3013088703155518, 'learning_rate': 3.991565697870453e-06, 'epoch': 0.32}
 32%|███▏      | 933/2906 [3:04:32<6:34:12, 11.99s/it] 32%|███▏      | 934/2906 [3:04:43<6:32:02, 11.93s/it]                                                      {'loss': 0.8385, 'grad_norm': 1.4046283960342407, 'learning_rate': 3.989318515767711e-06, 'epoch': 0.32}
 32%|███▏      | 934/2906 [3:04:43<6:32:02, 11.93s/it] 32%|███▏      | 935/2906 [3:04:55<6:30:38, 11.89s/it]                                                      {'loss': 0.7678, 'grad_norm': 1.2954226732254028, 'learning_rate': 3.987069466804089e-06, 'epoch': 0.32}
 32%|███▏      | 935/2906 [3:04:55<6:30:38, 11.89s/it] 32%|███▏      | 936/2906 [3:05:07<6:31:48, 11.93s/it]                                                      {'loss': 0.8079, 'grad_norm': 1.2632923126220703, 'learning_rate': 3.984818553798768e-06, 'epoch': 0.32}
 32%|███▏      | 936/2906 [3:05:07<6:31:48, 11.93s/it] 32%|███▏      | 937/2906 [3:05:19<6:31:41, 11.94s/it]                                                      {'loss': 0.7757, 'grad_norm': 1.1593475341796875, 'learning_rate': 3.982565779573269e-06, 'epoch': 0.32}
 32%|███▏      | 937/2906 [3:05:19<6:31:41, 11.94s/it] 32%|███▏      | 938/2906 [3:05:31<6:30:21, 11.90s/it]                                                      {'loss': 0.7508, 'grad_norm': 1.3012826442718506, 'learning_rate': 3.9803111469514435e-06, 'epoch': 0.32}
 32%|███▏      | 938/2906 [3:05:31<6:30:21, 11.90s/it] 32%|███▏      | 939/2906 [3:05:43<6:28:46, 11.86s/it]                                                      {'loss': 0.8221, 'grad_norm': 1.4532489776611328, 'learning_rate': 3.978054658759474e-06, 'epoch': 0.32}
 32%|███▏      | 939/2906 [3:05:43<6:28:46, 11.86s/it] 32%|███▏      | 940/2906 [3:05:54<6:27:58, 11.84s/it]                                                      {'loss': 0.8272, 'grad_norm': 1.3094202280044556, 'learning_rate': 3.975796317825869e-06, 'epoch': 0.32}
 32%|███▏      | 940/2906 [3:05:55<6:27:58, 11.84s/it] 32%|███▏      | 941/2906 [3:06:06<6:28:18, 11.86s/it]                                                      {'loss': 0.8097, 'grad_norm': 1.2717928886413574, 'learning_rate': 3.973536126981459e-06, 'epoch': 0.32}
 32%|███▏      | 941/2906 [3:06:06<6:28:18, 11.86s/it] 32%|███▏      | 942/2906 [3:06:18<6:28:31, 11.87s/it]                                                      {'loss': 0.7534, 'grad_norm': 1.3592900037765503, 'learning_rate': 3.971274089059393e-06, 'epoch': 0.32}
 32%|███▏      | 942/2906 [3:06:18<6:28:31, 11.87s/it] 32%|███▏      | 943/2906 [3:06:30<6:27:45, 11.85s/it]                                                      {'loss': 0.8092, 'grad_norm': 1.3838279247283936, 'learning_rate': 3.969010206895136e-06, 'epoch': 0.32}
 32%|███▏      | 943/2906 [3:06:30<6:27:45, 11.85s/it] 32%|███▏      | 944/2906 [3:06:42<6:29:38, 11.92s/it]                                                      {'loss': 0.7867, 'grad_norm': 1.2598817348480225, 'learning_rate': 3.966744483326465e-06, 'epoch': 0.32}
 32%|███▏      | 944/2906 [3:06:42<6:29:38, 11.92s/it] 33%|███▎      | 945/2906 [3:06:53<6:22:14, 11.70s/it]                                                      {'loss': 0.8524, 'grad_norm': 1.3854645490646362, 'learning_rate': 3.964476921193464e-06, 'epoch': 0.33}
 33%|███▎      | 945/2906 [3:06:53<6:22:14, 11.70s/it] 33%|███▎      | 946/2906 [3:07:05<6:21:56, 11.69s/it]                                                      {'loss': 0.8418, 'grad_norm': 1.386537790298462, 'learning_rate': 3.962207523338523e-06, 'epoch': 0.33}
 33%|███▎      | 946/2906 [3:07:05<6:21:56, 11.69s/it] 33%|███▎      | 947/2906 [3:07:17<6:20:02, 11.64s/it]                                                      {'loss': 0.8491, 'grad_norm': 1.2719749212265015, 'learning_rate': 3.9599362926063315e-06, 'epoch': 0.33}
 33%|███▎      | 947/2906 [3:07:17<6:20:02, 11.64s/it] 33%|███▎      | 948/2906 [3:07:28<6:20:02, 11.65s/it]                                                      {'loss': 0.8261, 'grad_norm': 1.3215125799179077, 'learning_rate': 3.9576632318438764e-06, 'epoch': 0.33}
 33%|███▎      | 948/2906 [3:07:28<6:20:02, 11.65s/it] 33%|███▎      | 949/2906 [3:07:40<6:19:51, 11.65s/it]                                                      {'loss': 0.8201, 'grad_norm': 1.3955130577087402, 'learning_rate': 3.955388343900443e-06, 'epoch': 0.33}
 33%|███▎      | 949/2906 [3:07:40<6:19:51, 11.65s/it] 33%|███▎      | 950/2906 [3:07:51<6:17:26, 11.58s/it]                                                      {'loss': 0.8088, 'grad_norm': 1.2959345579147339, 'learning_rate': 3.9531116316276e-06, 'epoch': 0.33}
 33%|███▎      | 950/2906 [3:07:51<6:17:26, 11.58s/it] 33%|███▎      | 951/2906 [3:08:03<6:14:36, 11.50s/it]                                                      {'loss': 0.7997, 'grad_norm': 1.2441588640213013, 'learning_rate': 3.950833097879208e-06, 'epoch': 0.33}
 33%|███▎      | 951/2906 [3:08:03<6:14:36, 11.50s/it] 33%|███▎      | 952/2906 [3:08:15<6:20:38, 11.69s/it]                                                      {'loss': 0.8251, 'grad_norm': 1.3704344034194946, 'learning_rate': 3.9485527455114095e-06, 'epoch': 0.33}
 33%|███▎      | 952/2906 [3:08:15<6:20:38, 11.69s/it] 33%|███▎      | 953/2906 [3:08:26<6:14:32, 11.51s/it]                                                      {'loss': 0.8634, 'grad_norm': 1.4051026105880737, 'learning_rate': 3.946270577382626e-06, 'epoch': 0.33}
 33%|███▎      | 953/2906 [3:08:26<6:14:32, 11.51s/it] 33%|███▎      | 954/2906 [3:08:38<6:23:30, 11.79s/it]                                                      {'loss': 0.8192, 'grad_norm': 1.3103885650634766, 'learning_rate': 3.943986596353555e-06, 'epoch': 0.33}
 33%|███▎      | 954/2906 [3:08:38<6:23:30, 11.79s/it] 33%|███▎      | 955/2906 [3:08:51<6:28:23, 11.94s/it]                                                      {'loss': 0.8446, 'grad_norm': 1.3414485454559326, 'learning_rate': 3.941700805287169e-06, 'epoch': 0.33}
 33%|███▎      | 955/2906 [3:08:51<6:28:23, 11.94s/it] 33%|███▎      | 956/2906 [3:09:02<6:26:04, 11.88s/it]                                                      {'loss': 0.8194, 'grad_norm': 1.2652041912078857, 'learning_rate': 3.939413207048704e-06, 'epoch': 0.33}
 33%|███▎      | 956/2906 [3:09:02<6:26:04, 11.88s/it] 33%|███▎      | 957/2906 [3:09:14<6:21:27, 11.74s/it]                                                      {'loss': 0.8293, 'grad_norm': 1.2938847541809082, 'learning_rate': 3.937123804505666e-06, 'epoch': 0.33}
 33%|███▎      | 957/2906 [3:09:14<6:21:27, 11.74s/it] 33%|███▎      | 958/2906 [3:09:26<6:25:30, 11.87s/it]                                                      {'loss': 0.8821, 'grad_norm': 1.3951706886291504, 'learning_rate': 3.934832600527822e-06, 'epoch': 0.33}
 33%|███▎      | 958/2906 [3:09:26<6:25:30, 11.87s/it] 33%|███▎      | 959/2906 [3:09:37<6:22:46, 11.80s/it]                                                      {'loss': 0.8058, 'grad_norm': 1.3339200019836426, 'learning_rate': 3.932539597987196e-06, 'epoch': 0.33}
 33%|███▎      | 959/2906 [3:09:38<6:22:46, 11.80s/it] 33%|███▎      | 960/2906 [3:09:49<6:20:53, 11.74s/it]                                                      {'loss': 0.7822, 'grad_norm': 1.4379826784133911, 'learning_rate': 3.930244799758067e-06, 'epoch': 0.33}
 33%|███▎      | 960/2906 [3:09:49<6:20:53, 11.74s/it] 33%|███▎      | 961/2906 [3:10:01<6:20:03, 11.72s/it]                                                      {'loss': 0.7752, 'grad_norm': 1.330264925956726, 'learning_rate': 3.927948208716964e-06, 'epoch': 0.33}
 33%|███▎      | 961/2906 [3:10:01<6:20:03, 11.72s/it] 33%|███▎      | 962/2906 [3:10:13<6:22:48, 11.81s/it]                                                      {'loss': 0.7886, 'grad_norm': 1.3639631271362305, 'learning_rate': 3.925649827742665e-06, 'epoch': 0.33}
 33%|███▎      | 962/2906 [3:10:13<6:22:48, 11.81s/it] 33%|███▎      | 963/2906 [3:10:25<6:21:30, 11.78s/it]                                                      {'loss': 0.8195, 'grad_norm': 1.3184258937835693, 'learning_rate': 3.92334965971619e-06, 'epoch': 0.33}
 33%|███▎      | 963/2906 [3:10:25<6:21:30, 11.78s/it] 33%|███▎      | 964/2906 [3:10:36<6:19:06, 11.71s/it]                                                      {'loss': 0.829, 'grad_norm': 1.3145346641540527, 'learning_rate': 3.9210477075208e-06, 'epoch': 0.33}
 33%|███▎      | 964/2906 [3:10:36<6:19:06, 11.71s/it] 33%|███▎      | 965/2906 [3:10:48<6:19:21, 11.73s/it]                                                      {'loss': 0.8009, 'grad_norm': 1.3098101615905762, 'learning_rate': 3.918743974041992e-06, 'epoch': 0.33}
 33%|███▎      | 965/2906 [3:10:48<6:19:21, 11.73s/it] 33%|███▎      | 966/2906 [3:10:59<6:13:43, 11.56s/it]                                                      {'loss': 0.7997, 'grad_norm': 1.3603132963180542, 'learning_rate': 3.916438462167497e-06, 'epoch': 0.33}
 33%|███▎      | 966/2906 [3:10:59<6:13:43, 11.56s/it] 33%|███▎      | 967/2906 [3:11:12<6:24:45, 11.91s/it]                                                      {'loss': 0.7671, 'grad_norm': 1.3014804124832153, 'learning_rate': 3.914131174787274e-06, 'epoch': 0.33}
 33%|███▎      | 967/2906 [3:11:12<6:24:45, 11.91s/it] 33%|███▎      | 968/2906 [3:11:24<6:25:00, 11.92s/it]                                                      {'loss': 0.811, 'grad_norm': 1.3316658735275269, 'learning_rate': 3.911822114793508e-06, 'epoch': 0.33}
 33%|███▎      | 968/2906 [3:11:24<6:25:00, 11.92s/it] 33%|███▎      | 969/2906 [3:11:35<6:19:19, 11.75s/it]                                                      {'loss': 0.8391, 'grad_norm': 1.3577747344970703, 'learning_rate': 3.909511285080605e-06, 'epoch': 0.33}
 33%|███▎      | 969/2906 [3:11:35<6:19:19, 11.75s/it] 33%|███▎      | 970/2906 [3:11:46<6:15:38, 11.64s/it]                                                      {'loss': 0.7427, 'grad_norm': 1.2629241943359375, 'learning_rate': 3.907198688545191e-06, 'epoch': 0.33}
 33%|███▎      | 970/2906 [3:11:46<6:15:38, 11.64s/it] 33%|███▎      | 971/2906 [3:11:58<6:17:16, 11.70s/it]                                                      {'loss': 0.8172, 'grad_norm': 1.3132998943328857, 'learning_rate': 3.9048843280861055e-06, 'epoch': 0.33}
 33%|███▎      | 971/2906 [3:11:58<6:17:16, 11.70s/it] 33%|███▎      | 972/2906 [3:12:10<6:16:45, 11.69s/it]                                                      {'loss': 0.7685, 'grad_norm': 1.4981565475463867, 'learning_rate': 3.9025682066044e-06, 'epoch': 0.33}
 33%|███▎      | 972/2906 [3:12:10<6:16:45, 11.69s/it] 33%|███▎      | 973/2906 [3:12:22<6:15:50, 11.67s/it]                                                      {'loss': 0.8294, 'grad_norm': 1.3686269521713257, 'learning_rate': 3.900250327003333e-06, 'epoch': 0.33}
 33%|███▎      | 973/2906 [3:12:22<6:15:50, 11.67s/it] 34%|███▎      | 974/2906 [3:12:34<6:20:08, 11.81s/it]                                                      {'loss': 0.8552, 'grad_norm': 1.3888534307479858, 'learning_rate': 3.897930692188366e-06, 'epoch': 0.34}
 34%|███▎      | 974/2906 [3:12:34<6:20:08, 11.81s/it] 34%|███▎      | 975/2906 [3:12:46<6:21:59, 11.87s/it]                                                      {'loss': 0.8261, 'grad_norm': 1.354690670967102, 'learning_rate': 3.895609305067162e-06, 'epoch': 0.34}
 34%|███▎      | 975/2906 [3:12:46<6:21:59, 11.87s/it] 34%|███▎      | 976/2906 [3:12:57<6:17:22, 11.73s/it]                                                      {'loss': 0.7974, 'grad_norm': 1.379786491394043, 'learning_rate': 3.893286168549581e-06, 'epoch': 0.34}
 34%|███▎      | 976/2906 [3:12:57<6:17:22, 11.73s/it] 34%|███▎      | 977/2906 [3:13:09<6:16:16, 11.70s/it]                                                      {'loss': 0.81, 'grad_norm': 1.2755579948425293, 'learning_rate': 3.890961285547672e-06, 'epoch': 0.34}
 34%|███▎      | 977/2906 [3:13:09<6:16:16, 11.70s/it] 34%|███▎      | 978/2906 [3:13:21<6:17:11, 11.74s/it]                                                      {'loss': 0.8792, 'grad_norm': 1.263177514076233, 'learning_rate': 3.88863465897568e-06, 'epoch': 0.34}
 34%|███▎      | 978/2906 [3:13:21<6:17:11, 11.74s/it] 34%|███▎      | 979/2906 [3:13:32<6:18:05, 11.77s/it]                                                      {'loss': 0.7746, 'grad_norm': 1.279819130897522, 'learning_rate': 3.886306291750028e-06, 'epoch': 0.34}
 34%|███▎      | 979/2906 [3:13:32<6:18:05, 11.77s/it] 34%|███▎      | 980/2906 [3:13:44<6:17:28, 11.76s/it]                                                      {'loss': 0.8183, 'grad_norm': 1.4277740716934204, 'learning_rate': 3.883976186789326e-06, 'epoch': 0.34}
 34%|███▎      | 980/2906 [3:13:44<6:17:28, 11.76s/it] 34%|███▍      | 981/2906 [3:13:55<6:08:43, 11.49s/it]                                                      {'loss': 0.8245, 'grad_norm': 1.3066776990890503, 'learning_rate': 3.881644347014361e-06, 'epoch': 0.34}
 34%|███▍      | 981/2906 [3:13:55<6:08:43, 11.49s/it] 34%|███▍      | 982/2906 [3:14:07<6:08:55, 11.51s/it]                                                      {'loss': 0.8681, 'grad_norm': 1.3396509885787964, 'learning_rate': 3.879310775348093e-06, 'epoch': 0.34}
 34%|███▍      | 982/2906 [3:14:07<6:08:55, 11.51s/it] 34%|███▍      | 983/2906 [3:14:18<6:07:50, 11.48s/it]                                                      {'loss': 0.841, 'grad_norm': 1.3103774785995483, 'learning_rate': 3.876975474715656e-06, 'epoch': 0.34}
 34%|███▍      | 983/2906 [3:14:18<6:07:50, 11.48s/it] 34%|███▍      | 984/2906 [3:14:29<6:07:21, 11.47s/it]                                                      {'loss': 0.8713, 'grad_norm': 1.363507866859436, 'learning_rate': 3.874638448044349e-06, 'epoch': 0.34}
 34%|███▍      | 984/2906 [3:14:29<6:07:21, 11.47s/it] 34%|███▍      | 985/2906 [3:14:41<6:08:23, 11.51s/it]                                                      {'loss': 0.7759, 'grad_norm': 1.3377609252929688, 'learning_rate': 3.872299698263634e-06, 'epoch': 0.34}
 34%|███▍      | 985/2906 [3:14:41<6:08:23, 11.51s/it] 34%|███▍      | 986/2906 [3:14:53<6:10:07, 11.57s/it]                                                      {'loss': 0.85, 'grad_norm': 1.3599514961242676, 'learning_rate': 3.869959228305136e-06, 'epoch': 0.34}
 34%|███▍      | 986/2906 [3:14:53<6:10:07, 11.57s/it] 34%|███▍      | 987/2906 [3:15:04<6:10:37, 11.59s/it]                                                      {'loss': 0.8266, 'grad_norm': 1.3036837577819824, 'learning_rate': 3.867617041102633e-06, 'epoch': 0.34}
 34%|███▍      | 987/2906 [3:15:04<6:10:37, 11.59s/it] 34%|███▍      | 988/2906 [3:15:16<6:10:47, 11.60s/it]                                                      {'loss': 0.8211, 'grad_norm': 1.5779545307159424, 'learning_rate': 3.865273139592056e-06, 'epoch': 0.34}
 34%|███▍      | 988/2906 [3:15:16<6:10:47, 11.60s/it] 34%|███▍      | 989/2906 [3:15:28<6:11:44, 11.63s/it]                                                      {'loss': 0.8442, 'grad_norm': 1.3667571544647217, 'learning_rate': 3.862927526711488e-06, 'epoch': 0.34}
 34%|███▍      | 989/2906 [3:15:28<6:11:44, 11.63s/it] 34%|███▍      | 990/2906 [3:15:40<6:17:25, 11.82s/it]                                                      {'loss': 0.7662, 'grad_norm': 1.4254049062728882, 'learning_rate': 3.860580205401154e-06, 'epoch': 0.34}
 34%|███▍      | 990/2906 [3:15:40<6:17:25, 11.82s/it] 34%|███▍      | 991/2906 [3:15:51<6:10:58, 11.62s/it]                                                      {'loss': 0.8078, 'grad_norm': 1.3574360609054565, 'learning_rate': 3.858231178603421e-06, 'epoch': 0.34}
 34%|███▍      | 991/2906 [3:15:51<6:10:58, 11.62s/it] 34%|███▍      | 992/2906 [3:16:03<6:13:19, 11.70s/it]                                                      {'loss': 0.801, 'grad_norm': 1.2928621768951416, 'learning_rate': 3.855880449262794e-06, 'epoch': 0.34}
 34%|███▍      | 992/2906 [3:16:03<6:13:19, 11.70s/it] 34%|███▍      | 993/2906 [3:16:15<6:13:03, 11.70s/it]                                                      {'loss': 0.7995, 'grad_norm': 1.3076804876327515, 'learning_rate': 3.853528020325913e-06, 'epoch': 0.34}
 34%|███▍      | 993/2906 [3:16:15<6:13:03, 11.70s/it] 34%|███▍      | 994/2906 [3:16:26<6:10:46, 11.64s/it]                                                      {'loss': 0.7884, 'grad_norm': 1.2620868682861328, 'learning_rate': 3.851173894741548e-06, 'epoch': 0.34}
 34%|███▍      | 994/2906 [3:16:26<6:10:46, 11.64s/it] 34%|███▍      | 995/2906 [3:16:38<6:10:29, 11.63s/it]                                                      {'loss': 0.8315, 'grad_norm': 1.2884327173233032, 'learning_rate': 3.848818075460595e-06, 'epoch': 0.34}
 34%|███▍      | 995/2906 [3:16:38<6:10:29, 11.63s/it] 34%|███▍      | 996/2906 [3:16:49<6:07:09, 11.53s/it]                                                      {'loss': 0.7458, 'grad_norm': 1.257235050201416, 'learning_rate': 3.846460565436074e-06, 'epoch': 0.34}
 34%|███▍      | 996/2906 [3:16:49<6:07:09, 11.53s/it] 34%|███▍      | 997/2906 [3:17:01<6:14:21, 11.77s/it]                                                      {'loss': 0.7105, 'grad_norm': 1.2891223430633545, 'learning_rate': 3.8441013676231255e-06, 'epoch': 0.34}
 34%|███▍      | 997/2906 [3:17:01<6:14:21, 11.77s/it] 34%|███▍      | 998/2906 [3:17:13<6:13:39, 11.75s/it]                                                      {'loss': 0.8242, 'grad_norm': 1.381847858428955, 'learning_rate': 3.841740484979002e-06, 'epoch': 0.34}
 34%|███▍      | 998/2906 [3:17:13<6:13:39, 11.75s/it] 34%|███▍      | 999/2906 [3:17:25<6:19:12, 11.93s/it]                                                      {'loss': 0.7833, 'grad_norm': 1.359503984451294, 'learning_rate': 3.83937792046307e-06, 'epoch': 0.34}
 34%|███▍      | 999/2906 [3:17:25<6:19:12, 11.93s/it] 34%|███▍      | 1000/2906 [3:17:37<6:17:50, 11.89s/it]                                                       {'loss': 0.7927, 'grad_norm': 1.3680508136749268, 'learning_rate': 3.837013677036806e-06, 'epoch': 0.34}
 34%|███▍      | 1000/2906 [3:17:37<6:17:50, 11.89s/it] 34%|███▍      | 1001/2906 [3:17:48<6:09:01, 11.62s/it]                                                       {'loss': 0.819, 'grad_norm': 1.3855605125427246, 'learning_rate': 3.834647757663788e-06, 'epoch': 0.34}
 34%|███▍      | 1001/2906 [3:17:48<6:09:01, 11.62s/it] 34%|███▍      | 1002/2906 [3:18:01<6:16:26, 11.86s/it]                                                       {'loss': 0.8052, 'grad_norm': 1.313103199005127, 'learning_rate': 3.832280165309697e-06, 'epoch': 0.34}
 34%|███▍      | 1002/2906 [3:18:01<6:16:26, 11.86s/it] 35%|███▍      | 1003/2906 [3:18:12<6:13:36, 11.78s/it]                                                       {'loss': 0.8773, 'grad_norm': 1.4224207401275635, 'learning_rate': 3.829910902942309e-06, 'epoch': 0.35}
 35%|███▍      | 1003/2906 [3:18:12<6:13:36, 11.78s/it] 35%|███▍      | 1004/2906 [3:18:24<6:12:21, 11.75s/it]                                                       {'loss': 0.8184, 'grad_norm': 1.3125033378601074, 'learning_rate': 3.8275399735314965e-06, 'epoch': 0.35}
 35%|███▍      | 1004/2906 [3:18:24<6:12:21, 11.75s/it] 35%|███▍      | 1005/2906 [3:18:36<6:14:09, 11.81s/it]                                                       {'loss': 0.7848, 'grad_norm': 1.2303645610809326, 'learning_rate': 3.825167380049218e-06, 'epoch': 0.35}
 35%|███▍      | 1005/2906 [3:18:36<6:14:09, 11.81s/it] 35%|███▍      | 1006/2906 [3:18:48<6:13:04, 11.78s/it]                                                       {'loss': 0.7967, 'grad_norm': 1.2592542171478271, 'learning_rate': 3.82279312546952e-06, 'epoch': 0.35}
 35%|███▍      | 1006/2906 [3:18:48<6:13:04, 11.78s/it] 35%|███▍      | 1007/2906 [3:18:59<6:13:35, 11.80s/it]                                                       {'loss': 0.8589, 'grad_norm': 1.2766976356506348, 'learning_rate': 3.820417212768531e-06, 'epoch': 0.35}
 35%|███▍      | 1007/2906 [3:18:59<6:13:35, 11.80s/it] 35%|███▍      | 1008/2906 [3:19:11<6:12:32, 11.78s/it]                                                       {'loss': 0.8614, 'grad_norm': 1.4468990564346313, 'learning_rate': 3.818039644924458e-06, 'epoch': 0.35}
 35%|███▍      | 1008/2906 [3:19:11<6:12:32, 11.78s/it] 35%|███▍      | 1009/2906 [3:19:23<6:16:27, 11.91s/it]                                                       {'loss': 0.8618, 'grad_norm': 1.2966551780700684, 'learning_rate': 3.8156604249175825e-06, 'epoch': 0.35}
 35%|███▍      | 1009/2906 [3:19:23<6:16:27, 11.91s/it] 35%|███▍      | 1010/2906 [3:19:35<6:16:45, 11.92s/it]                                                       {'loss': 0.7649, 'grad_norm': 1.198243498802185, 'learning_rate': 3.813279555730256e-06, 'epoch': 0.35}
 35%|███▍      | 1010/2906 [3:19:35<6:16:45, 11.92s/it] 35%|███▍      | 1011/2906 [3:19:47<6:13:28, 11.83s/it]                                                       {'loss': 0.7777, 'grad_norm': 1.2717891931533813, 'learning_rate': 3.810897040346899e-06, 'epoch': 0.35}
 35%|███▍      | 1011/2906 [3:19:47<6:13:28, 11.83s/it] 35%|███▍      | 1012/2906 [3:19:59<6:14:45, 11.87s/it]                                                       {'loss': 0.7447, 'grad_norm': 1.2583729028701782, 'learning_rate': 3.8085128817539958e-06, 'epoch': 0.35}
 35%|███▍      | 1012/2906 [3:19:59<6:14:45, 11.87s/it] 35%|███▍      | 1013/2906 [3:20:11<6:14:22, 11.87s/it]                                                       {'loss': 0.8123, 'grad_norm': 1.291619896888733, 'learning_rate': 3.8061270829400876e-06, 'epoch': 0.35}
 35%|███▍      | 1013/2906 [3:20:11<6:14:22, 11.87s/it] 35%|███▍      | 1014/2906 [3:20:23<6:15:04, 11.89s/it]                                                       {'loss': 0.8623, 'grad_norm': 1.3597081899642944, 'learning_rate': 3.803739646895773e-06, 'epoch': 0.35}
 35%|███▍      | 1014/2906 [3:20:23<6:15:04, 11.89s/it] 35%|███▍      | 1015/2906 [3:20:34<6:06:33, 11.63s/it]                                                       {'loss': 0.8084, 'grad_norm': 1.3856534957885742, 'learning_rate': 3.801350576613706e-06, 'epoch': 0.35}
 35%|███▍      | 1015/2906 [3:20:34<6:06:33, 11.63s/it] 35%|███▍      | 1016/2906 [3:20:45<6:04:02, 11.56s/it]                                                       {'loss': 0.7931, 'grad_norm': 1.3536444902420044, 'learning_rate': 3.798959875088584e-06, 'epoch': 0.35}
 35%|███▍      | 1016/2906 [3:20:45<6:04:02, 11.56s/it] 35%|███▍      | 1017/2906 [3:20:57<6:11:21, 11.80s/it]                                                       {'loss': 0.8365, 'grad_norm': 1.3113197088241577, 'learning_rate': 3.796567545317153e-06, 'epoch': 0.35}
 35%|███▍      | 1017/2906 [3:20:58<6:11:21, 11.80s/it] 35%|███▌      | 1018/2906 [3:21:09<6:09:43, 11.75s/it]                                                       {'loss': 0.7919, 'grad_norm': 1.3241862058639526, 'learning_rate': 3.794173590298197e-06, 'epoch': 0.35}
 35%|███▌      | 1018/2906 [3:21:09<6:09:43, 11.75s/it] 35%|███▌      | 1019/2906 [3:21:21<6:10:43, 11.79s/it]                                                       {'loss': 0.7992, 'grad_norm': 1.3874300718307495, 'learning_rate': 3.79177801303254e-06, 'epoch': 0.35}
 35%|███▌      | 1019/2906 [3:21:21<6:10:43, 11.79s/it] 35%|███▌      | 1020/2906 [3:21:33<6:08:01, 11.71s/it]                                                       {'loss': 0.7948, 'grad_norm': 1.2663551568984985, 'learning_rate': 3.789380816523038e-06, 'epoch': 0.35}
 35%|███▌      | 1020/2906 [3:21:33<6:08:01, 11.71s/it] 35%|███▌      | 1021/2906 [3:21:44<6:04:02, 11.59s/it]                                                       {'loss': 0.8268, 'grad_norm': 1.3389695882797241, 'learning_rate': 3.7869820037745773e-06, 'epoch': 0.35}
 35%|███▌      | 1021/2906 [3:21:44<6:04:02, 11.59s/it] 35%|███▌      | 1022/2906 [3:21:56<6:04:38, 11.61s/it]                                                       {'loss': 0.8553, 'grad_norm': 1.3545351028442383, 'learning_rate': 3.7845815777940694e-06, 'epoch': 0.35}
 35%|███▌      | 1022/2906 [3:21:56<6:04:38, 11.61s/it] 35%|███▌      | 1023/2906 [3:22:07<6:04:17, 11.61s/it]                                                       {'loss': 0.7882, 'grad_norm': 1.2895276546478271, 'learning_rate': 3.7821795415904482e-06, 'epoch': 0.35}
 35%|███▌      | 1023/2906 [3:22:07<6:04:17, 11.61s/it] 35%|███▌      | 1024/2906 [3:22:19<6:03:05, 11.58s/it]                                                       {'loss': 0.8076, 'grad_norm': 1.2698280811309814, 'learning_rate': 3.7797758981746673e-06, 'epoch': 0.35}
 35%|███▌      | 1024/2906 [3:22:19<6:03:05, 11.58s/it] 35%|███▌      | 1025/2906 [3:22:30<6:05:39, 11.66s/it]                                                       {'loss': 0.7443, 'grad_norm': 1.2967180013656616, 'learning_rate': 3.777370650559693e-06, 'epoch': 0.35}
 35%|███▌      | 1025/2906 [3:22:30<6:05:39, 11.66s/it] 35%|███▌      | 1026/2906 [3:22:42<6:04:41, 11.64s/it]                                                       {'loss': 0.7205, 'grad_norm': 1.281981110572815, 'learning_rate': 3.774963801760504e-06, 'epoch': 0.35}
 35%|███▌      | 1026/2906 [3:22:42<6:04:41, 11.64s/it] 35%|███▌      | 1027/2906 [3:22:54<6:08:00, 11.75s/it]                                                       {'loss': 0.8141, 'grad_norm': 1.3023715019226074, 'learning_rate': 3.772555354794085e-06, 'epoch': 0.35}
 35%|███▌      | 1027/2906 [3:22:54<6:08:00, 11.75s/it] 35%|███▌      | 1028/2906 [3:23:05<6:03:34, 11.62s/it]                                                       {'loss': 0.8145, 'grad_norm': 1.427760124206543, 'learning_rate': 3.7701453126794248e-06, 'epoch': 0.35}
 35%|███▌      | 1028/2906 [3:23:05<6:03:34, 11.62s/it] 35%|███▌      | 1029/2906 [3:23:17<6:05:05, 11.67s/it]                                                       {'loss': 0.8032, 'grad_norm': 1.2635568380355835, 'learning_rate': 3.7677336784375107e-06, 'epoch': 0.35}
 35%|███▌      | 1029/2906 [3:23:17<6:05:05, 11.67s/it] 35%|███▌      | 1030/2906 [3:23:29<6:03:42, 11.63s/it]                                                       {'loss': 0.8202, 'grad_norm': 1.320459246635437, 'learning_rate': 3.765320455091327e-06, 'epoch': 0.35}
 35%|███▌      | 1030/2906 [3:23:29<6:03:42, 11.63s/it] 35%|███▌      | 1031/2906 [3:23:41<6:05:49, 11.71s/it]                                                       {'loss': 0.8323, 'grad_norm': 1.2781394720077515, 'learning_rate': 3.76290564566585e-06, 'epoch': 0.35}
 35%|███▌      | 1031/2906 [3:23:41<6:05:49, 11.71s/it] 36%|███▌      | 1032/2906 [3:23:53<6:08:10, 11.79s/it]                                                       {'loss': 0.7028, 'grad_norm': 1.1906338930130005, 'learning_rate': 3.760489253188043e-06, 'epoch': 0.36}
 36%|███▌      | 1032/2906 [3:23:53<6:08:10, 11.79s/it] 36%|███▌      | 1033/2906 [3:24:04<6:06:10, 11.73s/it]                                                       {'loss': 0.8182, 'grad_norm': 1.4219740629196167, 'learning_rate': 3.7580712806868536e-06, 'epoch': 0.36}
 36%|███▌      | 1033/2906 [3:24:04<6:06:10, 11.73s/it] 36%|███▌      | 1034/2906 [3:24:16<6:09:13, 11.83s/it]                                                       {'loss': 0.7841, 'grad_norm': 1.3270220756530762, 'learning_rate': 3.7556517311932106e-06, 'epoch': 0.36}
 36%|███▌      | 1034/2906 [3:24:16<6:09:13, 11.83s/it] 36%|███▌      | 1035/2906 [3:24:28<6:06:53, 11.77s/it]                                                       {'loss': 0.7994, 'grad_norm': 1.2565462589263916, 'learning_rate': 3.7532306077400206e-06, 'epoch': 0.36}
 36%|███▌      | 1035/2906 [3:24:28<6:06:53, 11.77s/it] 36%|███▌      | 1036/2906 [3:24:39<6:03:50, 11.67s/it]                                                       {'loss': 0.7943, 'grad_norm': 1.27315354347229, 'learning_rate': 3.750807913362161e-06, 'epoch': 0.36}
 36%|███▌      | 1036/2906 [3:24:39<6:03:50, 11.67s/it] 36%|███▌      | 1037/2906 [3:24:51<6:04:34, 11.70s/it]                                                       {'loss': 0.8229, 'grad_norm': 1.3249061107635498, 'learning_rate': 3.7483836510964792e-06, 'epoch': 0.36}
 36%|███▌      | 1037/2906 [3:24:51<6:04:34, 11.70s/it] 36%|███▌      | 1038/2906 [3:25:02<6:01:02, 11.60s/it]                                                       {'loss': 0.8354, 'grad_norm': 1.3921120166778564, 'learning_rate': 3.7459578239817885e-06, 'epoch': 0.36}
 36%|███▌      | 1038/2906 [3:25:02<6:01:02, 11.60s/it] 36%|███▌      | 1039/2906 [3:25:14<6:02:03, 11.64s/it]                                                       {'loss': 0.8381, 'grad_norm': 1.334660291671753, 'learning_rate': 3.7435304350588643e-06, 'epoch': 0.36}
 36%|███▌      | 1039/2906 [3:25:14<6:02:03, 11.64s/it] 36%|███▌      | 1040/2906 [3:25:26<6:07:01, 11.80s/it]                                                       {'loss': 0.818, 'grad_norm': 1.2706764936447144, 'learning_rate': 3.7411014873704376e-06, 'epoch': 0.36}
 36%|███▌      | 1040/2906 [3:25:26<6:07:01, 11.80s/it] 36%|███▌      | 1041/2906 [3:25:38<6:04:02, 11.71s/it]                                                       {'loss': 0.7714, 'grad_norm': 1.2672924995422363, 'learning_rate': 3.738670983961195e-06, 'epoch': 0.36}
 36%|███▌      | 1041/2906 [3:25:38<6:04:02, 11.71s/it] 36%|███▌      | 1042/2906 [3:25:50<6:06:54, 11.81s/it]                                                       {'loss': 0.7478, 'grad_norm': 1.2355642318725586, 'learning_rate': 3.736238927877773e-06, 'epoch': 0.36}
 36%|███▌      | 1042/2906 [3:25:50<6:06:54, 11.81s/it] 36%|███▌      | 1043/2906 [3:26:02<6:09:34, 11.90s/it]                                                       {'loss': 0.8553, 'grad_norm': 1.4012948274612427, 'learning_rate': 3.7338053221687533e-06, 'epoch': 0.36}
 36%|███▌      | 1043/2906 [3:26:02<6:09:34, 11.90s/it] 36%|███▌      | 1044/2906 [3:26:14<6:07:14, 11.83s/it]                                                       {'loss': 0.8027, 'grad_norm': 1.2083410024642944, 'learning_rate': 3.7313701698846616e-06, 'epoch': 0.36}
 36%|███▌      | 1044/2906 [3:26:14<6:07:14, 11.83s/it] 36%|███▌      | 1045/2906 [3:26:26<6:11:13, 11.97s/it]                                                       {'loss': 0.8582, 'grad_norm': 1.305060863494873, 'learning_rate': 3.728933474077961e-06, 'epoch': 0.36}
 36%|███▌      | 1045/2906 [3:26:26<6:11:13, 11.97s/it] 36%|███▌      | 1046/2906 [3:26:38<6:10:21, 11.95s/it]                                                       {'loss': 0.8026, 'grad_norm': 1.380345344543457, 'learning_rate': 3.72649523780305e-06, 'epoch': 0.36}
 36%|███▌      | 1046/2906 [3:26:38<6:10:21, 11.95s/it] 36%|███▌      | 1047/2906 [3:26:50<6:11:50, 12.00s/it]                                                       {'loss': 0.8022, 'grad_norm': 1.3593194484710693, 'learning_rate': 3.7240554641162585e-06, 'epoch': 0.36}
 36%|███▌      | 1047/2906 [3:26:50<6:11:50, 12.00s/it] 36%|███▌      | 1048/2906 [3:27:02<6:10:02, 11.95s/it]                                                       {'loss': 0.8363, 'grad_norm': 1.4490668773651123, 'learning_rate': 3.7216141560758422e-06, 'epoch': 0.36}
 36%|███▌      | 1048/2906 [3:27:02<6:10:02, 11.95s/it] 36%|███▌      | 1049/2906 [3:27:14<6:08:16, 11.90s/it]                                                       {'loss': 0.7992, 'grad_norm': 1.3223639726638794, 'learning_rate': 3.7191713167419814e-06, 'epoch': 0.36}
 36%|███▌      | 1049/2906 [3:27:14<6:08:16, 11.90s/it] 36%|███▌      | 1050/2906 [3:27:26<6:11:15, 12.00s/it]                                                       {'loss': 0.8454, 'grad_norm': 1.314701795578003, 'learning_rate': 3.7167269491767755e-06, 'epoch': 0.36}
 36%|███▌      | 1050/2906 [3:27:26<6:11:15, 12.00s/it] 36%|███▌      | 1051/2906 [3:27:37<6:06:42, 11.86s/it]                                                       {'loss': 0.7663, 'grad_norm': 1.264386773109436, 'learning_rate': 3.7142810564442388e-06, 'epoch': 0.36}
 36%|███▌      | 1051/2906 [3:27:37<6:06:42, 11.86s/it] 36%|███▌      | 1052/2906 [3:27:49<6:05:59, 11.84s/it]                                                       {'loss': 0.8168, 'grad_norm': 1.3892850875854492, 'learning_rate': 3.7118336416102997e-06, 'epoch': 0.36}
 36%|███▌      | 1052/2906 [3:27:49<6:05:59, 11.84s/it] 36%|███▌      | 1053/2906 [3:28:01<6:04:25, 11.80s/it]                                                       {'loss': 0.7833, 'grad_norm': 1.3539220094680786, 'learning_rate': 3.7093847077427904e-06, 'epoch': 0.36}
 36%|███▌      | 1053/2906 [3:28:01<6:04:25, 11.80s/it] 36%|███▋      | 1054/2906 [3:28:12<6:02:12, 11.73s/it]                                                       {'loss': 0.7952, 'grad_norm': 1.3384929895401, 'learning_rate': 3.706934257911452e-06, 'epoch': 0.36}
 36%|███▋      | 1054/2906 [3:28:12<6:02:12, 11.73s/it] 36%|███▋      | 1055/2906 [3:28:24<5:58:30, 11.62s/it]                                                       {'loss': 0.8094, 'grad_norm': 1.3057879209518433, 'learning_rate': 3.7044822951879224e-06, 'epoch': 0.36}
 36%|███▋      | 1055/2906 [3:28:24<5:58:30, 11.62s/it] 36%|███▋      | 1056/2906 [3:28:36<5:59:38, 11.66s/it]                                                       {'loss': 0.8145, 'grad_norm': 1.3407704830169678, 'learning_rate': 3.702028822645737e-06, 'epoch': 0.36}
 36%|███▋      | 1056/2906 [3:28:36<5:59:38, 11.66s/it] 36%|███▋      | 1057/2906 [3:28:47<6:00:47, 11.71s/it]                                                       {'loss': 0.8169, 'grad_norm': 1.380557894706726, 'learning_rate': 3.6995738433603234e-06, 'epoch': 0.36}
 36%|███▋      | 1057/2906 [3:28:47<6:00:47, 11.71s/it] 36%|███▋      | 1058/2906 [3:28:58<5:52:45, 11.45s/it]                                                       {'loss': 0.7332, 'grad_norm': 1.3028546571731567, 'learning_rate': 3.697117360408999e-06, 'epoch': 0.36}
 36%|███▋      | 1058/2906 [3:28:58<5:52:45, 11.45s/it] 36%|███▋      | 1059/2906 [3:29:10<5:53:57, 11.50s/it]                                                       {'loss': 0.8231, 'grad_norm': 1.355197548866272, 'learning_rate': 3.6946593768709667e-06, 'epoch': 0.36}
 36%|███▋      | 1059/2906 [3:29:10<5:53:57, 11.50s/it] 36%|███▋      | 1060/2906 [3:29:21<5:51:00, 11.41s/it]                                                       {'loss': 0.855, 'grad_norm': 1.2600919008255005, 'learning_rate': 3.692199895827307e-06, 'epoch': 0.36}
 36%|███▋      | 1060/2906 [3:29:21<5:51:00, 11.41s/it] 37%|███▋      | 1061/2906 [3:29:33<5:53:40, 11.50s/it]                                                       {'loss': 0.789, 'grad_norm': 1.2275017499923706, 'learning_rate': 3.68973892036098e-06, 'epoch': 0.37}
 37%|███▋      | 1061/2906 [3:29:33<5:53:40, 11.50s/it] 37%|███▋      | 1062/2906 [3:29:44<5:54:20, 11.53s/it]                                                       {'loss': 0.7844, 'grad_norm': 1.3176841735839844, 'learning_rate': 3.6872764535568194e-06, 'epoch': 0.37}
 37%|███▋      | 1062/2906 [3:29:44<5:54:20, 11.53s/it] 37%|███▋      | 1063/2906 [3:29:56<5:53:45, 11.52s/it]                                                       {'loss': 0.7778, 'grad_norm': 1.3867923021316528, 'learning_rate': 3.684812498501528e-06, 'epoch': 0.37}
 37%|███▋      | 1063/2906 [3:29:56<5:53:45, 11.52s/it] 37%|███▋      | 1064/2906 [3:30:08<5:57:18, 11.64s/it]                                                       {'loss': 0.7686, 'grad_norm': 1.368643879890442, 'learning_rate': 3.682347058283671e-06, 'epoch': 0.37}
 37%|███▋      | 1064/2906 [3:30:08<5:57:18, 11.64s/it] 37%|███▋      | 1065/2906 [3:30:19<5:57:37, 11.66s/it]                                                       {'loss': 0.7872, 'grad_norm': 1.2875359058380127, 'learning_rate': 3.6798801359936808e-06, 'epoch': 0.37}
 37%|███▋      | 1065/2906 [3:30:19<5:57:37, 11.66s/it] 37%|███▋      | 1066/2906 [3:30:31<5:59:38, 11.73s/it]                                                       {'loss': 0.7456, 'grad_norm': 1.3119134902954102, 'learning_rate': 3.6774117347238436e-06, 'epoch': 0.37}
 37%|███▋      | 1066/2906 [3:30:31<5:59:38, 11.73s/it] 37%|███▋      | 1067/2906 [3:30:44<6:03:51, 11.87s/it]                                                       {'loss': 0.858, 'grad_norm': 1.28944993019104, 'learning_rate': 3.6749418575683005e-06, 'epoch': 0.37}
 37%|███▋      | 1067/2906 [3:30:44<6:03:51, 11.87s/it] 37%|███▋      | 1068/2906 [3:30:55<6:01:10, 11.79s/it]                                                       {'loss': 0.7743, 'grad_norm': 1.3587555885314941, 'learning_rate': 3.6724705076230425e-06, 'epoch': 0.37}
 37%|███▋      | 1068/2906 [3:30:55<6:01:10, 11.79s/it] 37%|███▋      | 1069/2906 [3:31:06<5:54:02, 11.56s/it]                                                       {'loss': 0.7277, 'grad_norm': 1.2773035764694214, 'learning_rate': 3.669997687985908e-06, 'epoch': 0.37}
 37%|███▋      | 1069/2906 [3:31:06<5:54:02, 11.56s/it] 37%|███▋      | 1070/2906 [3:31:18<5:56:13, 11.64s/it]                                                       {'loss': 0.7532, 'grad_norm': 1.2751725912094116, 'learning_rate': 3.6675234017565754e-06, 'epoch': 0.37}
 37%|███▋      | 1070/2906 [3:31:18<5:56:13, 11.64s/it] 37%|███▋      | 1071/2906 [3:31:30<5:58:59, 11.74s/it]                                                       {'loss': 0.8469, 'grad_norm': 1.4131920337677002, 'learning_rate': 3.665047652036563e-06, 'epoch': 0.37}
 37%|███▋      | 1071/2906 [3:31:30<5:58:59, 11.74s/it] 37%|███▋      | 1072/2906 [3:31:42<5:58:58, 11.74s/it]                                                       {'loss': 0.8396, 'grad_norm': 1.383846402168274, 'learning_rate': 3.6625704419292236e-06, 'epoch': 0.37}
 37%|███▋      | 1072/2906 [3:31:42<5:58:58, 11.74s/it] 37%|███▋      | 1073/2906 [3:31:54<6:01:21, 11.83s/it]                                                       {'loss': 0.7462, 'grad_norm': 1.3345922231674194, 'learning_rate': 3.6600917745397403e-06, 'epoch': 0.37}
 37%|███▋      | 1073/2906 [3:31:54<6:01:21, 11.83s/it] 37%|███▋      | 1074/2906 [3:32:05<5:59:04, 11.76s/it]                                                       {'loss': 0.7563, 'grad_norm': 1.4394714832305908, 'learning_rate': 3.6576116529751232e-06, 'epoch': 0.37}
 37%|███▋      | 1074/2906 [3:32:05<5:59:04, 11.76s/it] 37%|███▋      | 1075/2906 [3:32:17<6:00:35, 11.82s/it]                                                       {'loss': 0.8576, 'grad_norm': 1.3555876016616821, 'learning_rate': 3.6551300803442035e-06, 'epoch': 0.37}
 37%|███▋      | 1075/2906 [3:32:17<6:00:35, 11.82s/it] 37%|███▋      | 1076/2906 [3:32:29<6:01:12, 11.84s/it]                                                       {'loss': 0.8237, 'grad_norm': 1.4284512996673584, 'learning_rate': 3.6526470597576342e-06, 'epoch': 0.37}
 37%|███▋      | 1076/2906 [3:32:29<6:01:12, 11.84s/it] 37%|███▋      | 1077/2906 [3:32:41<5:58:13, 11.75s/it]                                                       {'loss': 0.7639, 'grad_norm': 1.2635161876678467, 'learning_rate': 3.650162594327881e-06, 'epoch': 0.37}
 37%|███▋      | 1077/2906 [3:32:41<5:58:13, 11.75s/it] 37%|███▋      | 1078/2906 [3:32:53<5:58:40, 11.77s/it]                                                       {'loss': 0.8139, 'grad_norm': 1.2835031747817993, 'learning_rate': 3.6476766871692216e-06, 'epoch': 0.37}
 37%|███▋      | 1078/2906 [3:32:53<5:58:40, 11.77s/it] 37%|███▋      | 1079/2906 [3:33:04<5:57:54, 11.75s/it]                                                       {'loss': 0.8369, 'grad_norm': 1.3325397968292236, 'learning_rate': 3.6451893413977413e-06, 'epoch': 0.37}
 37%|███▋      | 1079/2906 [3:33:04<5:57:54, 11.75s/it] 37%|███▋      | 1080/2906 [3:33:16<6:01:36, 11.88s/it]                                                       {'loss': 0.8021, 'grad_norm': 1.3207640647888184, 'learning_rate': 3.642700560131327e-06, 'epoch': 0.37}
 37%|███▋      | 1080/2906 [3:33:16<6:01:36, 11.88s/it] 37%|███▋      | 1081/2906 [3:33:28<5:57:46, 11.76s/it]                                                       {'loss': 0.7511, 'grad_norm': 1.3298344612121582, 'learning_rate': 3.6402103464896676e-06, 'epoch': 0.37}
 37%|███▋      | 1081/2906 [3:33:28<5:57:46, 11.76s/it] 37%|███▋      | 1082/2906 [3:33:40<5:56:08, 11.72s/it]                                                       {'loss': 0.8191, 'grad_norm': 1.3379504680633545, 'learning_rate': 3.637718703594246e-06, 'epoch': 0.37}
 37%|███▋      | 1082/2906 [3:33:40<5:56:08, 11.72s/it] 37%|███▋      | 1083/2906 [3:33:52<5:58:56, 11.81s/it]                                                       {'loss': 0.7738, 'grad_norm': 1.200373888015747, 'learning_rate': 3.6352256345683358e-06, 'epoch': 0.37}
 37%|███▋      | 1083/2906 [3:33:52<5:58:56, 11.81s/it] 37%|███▋      | 1084/2906 [3:34:03<5:52:57, 11.62s/it]                                                       {'loss': 0.7965, 'grad_norm': 1.2744406461715698, 'learning_rate': 3.6327311425369995e-06, 'epoch': 0.37}
 37%|███▋      | 1084/2906 [3:34:03<5:52:57, 11.62s/it] 37%|███▋      | 1085/2906 [3:34:15<5:56:53, 11.76s/it]                                                       {'loss': 0.821, 'grad_norm': 1.3455904722213745, 'learning_rate': 3.630235230627085e-06, 'epoch': 0.37}
 37%|███▋      | 1085/2906 [3:34:15<5:56:53, 11.76s/it] 37%|███▋      | 1086/2906 [3:34:27<5:56:35, 11.76s/it]                                                       {'loss': 0.8098, 'grad_norm': 1.3780922889709473, 'learning_rate': 3.627737901967215e-06, 'epoch': 0.37}
 37%|███▋      | 1086/2906 [3:34:27<5:56:35, 11.76s/it] 37%|███▋      | 1087/2906 [3:34:38<5:53:23, 11.66s/it]                                                       {'loss': 0.8876, 'grad_norm': 1.3608664274215698, 'learning_rate': 3.6252391596877923e-06, 'epoch': 0.37}
 37%|███▋      | 1087/2906 [3:34:38<5:53:23, 11.66s/it] 37%|███▋      | 1088/2906 [3:34:50<5:52:59, 11.65s/it]                                                       {'loss': 0.8038, 'grad_norm': 1.2282295227050781, 'learning_rate': 3.6227390069209924e-06, 'epoch': 0.37}
 37%|███▋      | 1088/2906 [3:34:50<5:52:59, 11.65s/it] 37%|███▋      | 1089/2906 [3:35:02<5:57:17, 11.80s/it]                                                       {'loss': 0.8563, 'grad_norm': 1.2894715070724487, 'learning_rate': 3.620237446800754e-06, 'epoch': 0.37}
 37%|███▋      | 1089/2906 [3:35:02<5:57:17, 11.80s/it] 38%|███▊      | 1090/2906 [3:35:13<5:55:22, 11.74s/it]                                                       {'loss': 0.8453, 'grad_norm': 1.4741230010986328, 'learning_rate': 3.6177344824627854e-06, 'epoch': 0.38}
 38%|███▊      | 1090/2906 [3:35:13<5:55:22, 11.74s/it] 38%|███▊      | 1091/2906 [3:35:25<5:56:19, 11.78s/it]                                                       {'loss': 0.8507, 'grad_norm': 1.199626088142395, 'learning_rate': 3.615230117044551e-06, 'epoch': 0.38}
 38%|███▊      | 1091/2906 [3:35:25<5:56:19, 11.78s/it] 38%|███▊      | 1092/2906 [3:35:38<6:03:41, 12.03s/it]                                                       {'loss': 0.7684, 'grad_norm': 1.2096621990203857, 'learning_rate': 3.6127243536852737e-06, 'epoch': 0.38}
 38%|███▊      | 1092/2906 [3:35:38<6:03:41, 12.03s/it] 38%|███▊      | 1093/2906 [3:35:50<6:04:45, 12.07s/it]                                                       {'loss': 0.8341, 'grad_norm': 1.3110936880111694, 'learning_rate': 3.610217195525928e-06, 'epoch': 0.38}
 38%|███▊      | 1093/2906 [3:35:50<6:04:45, 12.07s/it] 38%|███▊      | 1094/2906 [3:36:02<6:04:26, 12.07s/it]                                                       {'loss': 0.7465, 'grad_norm': 1.1885583400726318, 'learning_rate': 3.6077086457092373e-06, 'epoch': 0.38}
 38%|███▊      | 1094/2906 [3:36:02<6:04:26, 12.07s/it] 38%|███▊      | 1095/2906 [3:36:14<6:00:20, 11.94s/it]                                                       {'loss': 0.7835, 'grad_norm': 1.2456514835357666, 'learning_rate': 3.6051987073796684e-06, 'epoch': 0.38}
 38%|███▊      | 1095/2906 [3:36:14<6:00:20, 11.94s/it] 38%|███▊      | 1096/2906 [3:36:26<6:03:25, 12.05s/it]                                                       {'loss': 0.8386, 'grad_norm': 1.2938319444656372, 'learning_rate': 3.6026873836834297e-06, 'epoch': 0.38}
 38%|███▊      | 1096/2906 [3:36:26<6:03:25, 12.05s/it] 38%|███▊      | 1097/2906 [3:36:38<6:01:38, 11.99s/it]                                                       {'loss': 0.7722, 'grad_norm': 1.2621537446975708, 'learning_rate': 3.600174677768465e-06, 'epoch': 0.38}
 38%|███▊      | 1097/2906 [3:36:38<6:01:38, 11.99s/it] 38%|███▊      | 1098/2906 [3:36:50<6:01:49, 12.01s/it]                                                       {'loss': 0.7314, 'grad_norm': 1.2644072771072388, 'learning_rate': 3.5976605927844517e-06, 'epoch': 0.38}
 38%|███▊      | 1098/2906 [3:36:50<6:01:49, 12.01s/it] 38%|███▊      | 1099/2906 [3:37:02<5:59:07, 11.92s/it]                                                       {'loss': 0.7486, 'grad_norm': 1.1941072940826416, 'learning_rate': 3.595145131882795e-06, 'epoch': 0.38}
 38%|███▊      | 1099/2906 [3:37:02<5:59:07, 11.92s/it] 38%|███▊      | 1100/2906 [3:37:14<6:03:24, 12.07s/it]                                                       {'loss': 0.8294, 'grad_norm': 1.236910104751587, 'learning_rate': 3.5926282982166266e-06, 'epoch': 0.38}
 38%|███▊      | 1100/2906 [3:37:14<6:03:24, 12.07s/it] 38%|███▊      | 1101/2906 [3:37:26<6:05:04, 12.14s/it]                                                       {'loss': 0.8176, 'grad_norm': 1.3055144548416138, 'learning_rate': 3.5901100949407967e-06, 'epoch': 0.38}
 38%|███▊      | 1101/2906 [3:37:26<6:05:04, 12.14s/it] 38%|███▊      | 1102/2906 [3:37:38<6:04:10, 12.11s/it]                                                       {'loss': 0.8186, 'grad_norm': 1.3298875093460083, 'learning_rate': 3.587590525211874e-06, 'epoch': 0.38}
 38%|███▊      | 1102/2906 [3:37:38<6:04:10, 12.11s/it] 38%|███▊      | 1103/2906 [3:37:50<6:01:29, 12.03s/it]                                                       {'loss': 0.7655, 'grad_norm': 1.2609363794326782, 'learning_rate': 3.5850695921881383e-06, 'epoch': 0.38}
 38%|███▊      | 1103/2906 [3:37:50<6:01:29, 12.03s/it] 38%|███▊      | 1104/2906 [3:38:02<5:55:13, 11.83s/it]                                                       {'loss': 0.792, 'grad_norm': 1.4180757999420166, 'learning_rate': 3.5825472990295807e-06, 'epoch': 0.38}
 38%|███▊      | 1104/2906 [3:38:02<5:55:13, 11.83s/it] 38%|███▊      | 1105/2906 [3:38:13<5:51:31, 11.71s/it]                                                       {'loss': 0.8285, 'grad_norm': 1.2839303016662598, 'learning_rate': 3.5800236488978946e-06, 'epoch': 0.38}
 38%|███▊      | 1105/2906 [3:38:13<5:51:31, 11.71s/it] 38%|███▊      | 1106/2906 [3:38:25<5:57:18, 11.91s/it]                                                       {'loss': 0.7612, 'grad_norm': 1.350574254989624, 'learning_rate': 3.577498644956477e-06, 'epoch': 0.38}
 38%|███▊      | 1106/2906 [3:38:25<5:57:18, 11.91s/it] 38%|███▊      | 1107/2906 [3:38:37<5:52:09, 11.74s/it]                                                       {'loss': 0.7631, 'grad_norm': 1.2493711709976196, 'learning_rate': 3.574972290370419e-06, 'epoch': 0.38}
 38%|███▊      | 1107/2906 [3:38:37<5:52:09, 11.74s/it] 38%|███▊      | 1108/2906 [3:38:49<5:52:53, 11.78s/it]                                                       {'loss': 0.739, 'grad_norm': 1.2522417306900024, 'learning_rate': 3.572444588306508e-06, 'epoch': 0.38}
 38%|███▊      | 1108/2906 [3:38:49<5:52:53, 11.78s/it] 38%|███▊      | 1109/2906 [3:39:00<5:51:03, 11.72s/it]                                                       {'loss': 0.8814, 'grad_norm': 1.2675095796585083, 'learning_rate': 3.569915541933217e-06, 'epoch': 0.38}
 38%|███▊      | 1109/2906 [3:39:00<5:51:03, 11.72s/it] 38%|███▊      | 1110/2906 [3:39:12<5:53:55, 11.82s/it]                                                       {'loss': 0.8468, 'grad_norm': 1.3513416051864624, 'learning_rate': 3.5673851544207065e-06, 'epoch': 0.38}
 38%|███▊      | 1110/2906 [3:39:12<5:53:55, 11.82s/it] 38%|███▊      | 1111/2906 [3:39:24<5:49:49, 11.69s/it]                                                       {'loss': 0.7922, 'grad_norm': 1.3258209228515625, 'learning_rate': 3.564853428940819e-06, 'epoch': 0.38}
 38%|███▊      | 1111/2906 [3:39:24<5:49:49, 11.69s/it] 38%|███▊      | 1112/2906 [3:39:36<5:52:19, 11.78s/it]                                                       {'loss': 0.8825, 'grad_norm': 1.3362334966659546, 'learning_rate': 3.5623203686670697e-06, 'epoch': 0.38}
 38%|███▊      | 1112/2906 [3:39:36<5:52:19, 11.78s/it] 38%|███▊      | 1113/2906 [3:39:47<5:50:34, 11.73s/it]                                                       {'loss': 0.838, 'grad_norm': 1.3778270483016968, 'learning_rate': 3.5597859767746524e-06, 'epoch': 0.38}
 38%|███▊      | 1113/2906 [3:39:47<5:50:34, 11.73s/it] 38%|███▊      | 1114/2906 [3:39:59<5:54:01, 11.85s/it]                                                       {'loss': 0.7622, 'grad_norm': 1.3085625171661377, 'learning_rate': 3.557250256440426e-06, 'epoch': 0.38}
 38%|███▊      | 1114/2906 [3:39:59<5:54:01, 11.85s/it] 38%|███▊      | 1115/2906 [3:40:11<5:52:59, 11.83s/it]                                                       {'loss': 0.8658, 'grad_norm': 1.2912238836288452, 'learning_rate': 3.5547132108429163e-06, 'epoch': 0.38}
 38%|███▊      | 1115/2906 [3:40:11<5:52:59, 11.83s/it] 38%|███▊      | 1116/2906 [3:40:23<5:54:13, 11.87s/it]                                                       {'loss': 0.7194, 'grad_norm': 1.1379717588424683, 'learning_rate': 3.552174843162311e-06, 'epoch': 0.38}
 38%|███▊      | 1116/2906 [3:40:23<5:54:13, 11.87s/it] 38%|███▊      | 1117/2906 [3:40:35<5:53:31, 11.86s/it]                                                       {'loss': 0.8171, 'grad_norm': 1.2744300365447998, 'learning_rate': 3.5496351565804542e-06, 'epoch': 0.38}
 38%|███▊      | 1117/2906 [3:40:35<5:53:31, 11.86s/it] 38%|███▊      | 1118/2906 [3:40:47<5:51:46, 11.80s/it]                                                       {'loss': 0.8654, 'grad_norm': 1.3929513692855835, 'learning_rate': 3.547094154280842e-06, 'epoch': 0.38}
 38%|███▊      | 1118/2906 [3:40:47<5:51:46, 11.80s/it] 39%|███▊      | 1119/2906 [3:40:58<5:51:21, 11.80s/it]                                                       {'loss': 0.7704, 'grad_norm': 1.2528107166290283, 'learning_rate': 3.5445518394486215e-06, 'epoch': 0.39}
 39%|███▊      | 1119/2906 [3:40:59<5:51:21, 11.80s/it] 39%|███▊      | 1120/2906 [3:41:10<5:48:15, 11.70s/it]                                                       {'loss': 0.7749, 'grad_norm': 1.2771979570388794, 'learning_rate': 3.542008215270586e-06, 'epoch': 0.39}
 39%|███▊      | 1120/2906 [3:41:10<5:48:15, 11.70s/it] 39%|███▊      | 1121/2906 [3:41:22<5:47:04, 11.67s/it]                                                       {'loss': 0.7804, 'grad_norm': 1.2716625928878784, 'learning_rate': 3.5394632849351663e-06, 'epoch': 0.39}
 39%|███▊      | 1121/2906 [3:41:22<5:47:04, 11.67s/it] 39%|███▊      | 1122/2906 [3:41:33<5:48:43, 11.73s/it]                                                       {'loss': 0.8485, 'grad_norm': 1.327353835105896, 'learning_rate': 3.5369170516324343e-06, 'epoch': 0.39}
 39%|███▊      | 1122/2906 [3:41:33<5:48:43, 11.73s/it] 39%|███▊      | 1123/2906 [3:41:46<5:53:51, 11.91s/it]                                                       {'loss': 0.8083, 'grad_norm': 1.323090672492981, 'learning_rate': 3.5343695185540927e-06, 'epoch': 0.39}
 39%|███▊      | 1123/2906 [3:41:46<5:53:51, 11.91s/it] 39%|███▊      | 1124/2906 [3:41:58<5:52:44, 11.88s/it]                                                       {'loss': 0.7838, 'grad_norm': 1.3303442001342773, 'learning_rate': 3.5318206888934756e-06, 'epoch': 0.39}
 39%|███▊      | 1124/2906 [3:41:58<5:52:44, 11.88s/it] 39%|███▊      | 1125/2906 [3:42:09<5:47:50, 11.72s/it]                                                       {'loss': 0.8358, 'grad_norm': 1.3563662767410278, 'learning_rate': 3.5292705658455406e-06, 'epoch': 0.39}
 39%|███▊      | 1125/2906 [3:42:09<5:47:50, 11.72s/it] 39%|███▊      | 1126/2906 [3:42:21<5:50:45, 11.82s/it]                                                       {'loss': 0.8215, 'grad_norm': 1.366641640663147, 'learning_rate': 3.5267191526068666e-06, 'epoch': 0.39}
 39%|███▊      | 1126/2906 [3:42:21<5:50:45, 11.82s/it] 39%|███▉      | 1127/2906 [3:42:33<5:52:00, 11.87s/it]                                                       {'loss': 0.8825, 'grad_norm': 1.3218162059783936, 'learning_rate': 3.524166452375652e-06, 'epoch': 0.39}
 39%|███▉      | 1127/2906 [3:42:33<5:52:00, 11.87s/it] 39%|███▉      | 1128/2906 [3:42:44<5:46:28, 11.69s/it]                                                       {'loss': 0.8314, 'grad_norm': 1.3697751760482788, 'learning_rate': 3.521612468351705e-06, 'epoch': 0.39}
 39%|███▉      | 1128/2906 [3:42:44<5:46:28, 11.69s/it] 39%|███▉      | 1129/2906 [3:42:56<5:42:54, 11.58s/it]                                                       {'loss': 0.8574, 'grad_norm': 1.3463554382324219, 'learning_rate': 3.5190572037364445e-06, 'epoch': 0.39}
 39%|███▉      | 1129/2906 [3:42:56<5:42:54, 11.58s/it] 39%|███▉      | 1130/2906 [3:43:07<5:43:57, 11.62s/it]                                                       {'loss': 0.7469, 'grad_norm': 1.2911443710327148, 'learning_rate': 3.516500661732897e-06, 'epoch': 0.39}
 39%|███▉      | 1130/2906 [3:43:07<5:43:57, 11.62s/it] 39%|███▉      | 1131/2906 [3:43:19<5:45:38, 11.68s/it]                                                       {'loss': 0.7853, 'grad_norm': 1.2938984632492065, 'learning_rate': 3.513942845545686e-06, 'epoch': 0.39}
 39%|███▉      | 1131/2906 [3:43:19<5:45:38, 11.68s/it] 39%|███▉      | 1132/2906 [3:43:31<5:46:54, 11.73s/it]                                                       {'loss': 0.8326, 'grad_norm': 1.2925621271133423, 'learning_rate': 3.511383758381035e-06, 'epoch': 0.39}
 39%|███▉      | 1132/2906 [3:43:31<5:46:54, 11.73s/it] 39%|███▉      | 1133/2906 [3:43:43<5:48:22, 11.79s/it]                                                       {'loss': 0.7834, 'grad_norm': 1.3539766073226929, 'learning_rate': 3.5088234034467604e-06, 'epoch': 0.39}
 39%|███▉      | 1133/2906 [3:43:43<5:48:22, 11.79s/it] 39%|███▉      | 1134/2906 [3:43:55<5:50:12, 11.86s/it]                                                       {'loss': 0.8046, 'grad_norm': 1.405871868133545, 'learning_rate': 3.5062617839522672e-06, 'epoch': 0.39}
 39%|███▉      | 1134/2906 [3:43:55<5:50:12, 11.86s/it] 39%|███▉      | 1135/2906 [3:44:07<5:53:09, 11.96s/it]                                                       {'loss': 0.7244, 'grad_norm': 1.2616980075836182, 'learning_rate': 3.5036989031085455e-06, 'epoch': 0.39}
 39%|███▉      | 1135/2906 [3:44:07<5:53:09, 11.96s/it] 39%|███▉      | 1136/2906 [3:44:19<5:52:25, 11.95s/it]                                                       {'loss': 0.8031, 'grad_norm': 1.192501187324524, 'learning_rate': 3.501134764128167e-06, 'epoch': 0.39}
 39%|███▉      | 1136/2906 [3:44:19<5:52:25, 11.95s/it] 39%|███▉      | 1137/2906 [3:44:31<5:49:40, 11.86s/it]                                                       {'loss': 0.7606, 'grad_norm': 1.2653297185897827, 'learning_rate': 3.498569370225279e-06, 'epoch': 0.39}
 39%|███▉      | 1137/2906 [3:44:31<5:49:40, 11.86s/it] 39%|███▉      | 1138/2906 [3:44:43<5:54:04, 12.02s/it]                                                       {'loss': 0.7856, 'grad_norm': 1.2683265209197998, 'learning_rate': 3.4960027246156043e-06, 'epoch': 0.39}
 39%|███▉      | 1138/2906 [3:44:43<5:54:04, 12.02s/it] 39%|███▉      | 1139/2906 [3:44:55<5:55:05, 12.06s/it]                                                       {'loss': 0.7255, 'grad_norm': 1.234873652458191, 'learning_rate': 3.4934348305164324e-06, 'epoch': 0.39}
 39%|███▉      | 1139/2906 [3:44:55<5:55:05, 12.06s/it] 39%|███▉      | 1140/2906 [3:45:07<5:51:04, 11.93s/it]                                                       {'loss': 0.7446, 'grad_norm': 1.2597920894622803, 'learning_rate': 3.4908656911466198e-06, 'epoch': 0.39}
 39%|███▉      | 1140/2906 [3:45:07<5:51:04, 11.93s/it] 39%|███▉      | 1141/2906 [3:45:18<5:43:43, 11.68s/it]                                                       {'loss': 0.8078, 'grad_norm': 1.3394012451171875, 'learning_rate': 3.4882953097265814e-06, 'epoch': 0.39}
 39%|███▉      | 1141/2906 [3:45:18<5:43:43, 11.68s/it] 39%|███▉      | 1142/2906 [3:45:29<5:40:50, 11.59s/it]                                                       {'loss': 0.8365, 'grad_norm': 1.328031301498413, 'learning_rate': 3.485723689478292e-06, 'epoch': 0.39}
 39%|███▉      | 1142/2906 [3:45:29<5:40:50, 11.59s/it] 39%|███▉      | 1143/2906 [3:45:41<5:39:50, 11.57s/it]                                                       {'loss': 0.8504, 'grad_norm': 1.298244833946228, 'learning_rate': 3.4831508336252766e-06, 'epoch': 0.39}
 39%|███▉      | 1143/2906 [3:45:41<5:39:50, 11.57s/it] 39%|███▉      | 1144/2906 [3:45:52<5:39:26, 11.56s/it]                                                       {'loss': 0.7614, 'grad_norm': 1.3651291131973267, 'learning_rate': 3.4805767453926116e-06, 'epoch': 0.39}
 39%|███▉      | 1144/2906 [3:45:52<5:39:26, 11.56s/it] 39%|███▉      | 1145/2906 [3:46:04<5:38:52, 11.55s/it]                                                       {'loss': 0.8301, 'grad_norm': 1.413438081741333, 'learning_rate': 3.4780014280069153e-06, 'epoch': 0.39}
 39%|███▉      | 1145/2906 [3:46:04<5:38:52, 11.55s/it] 39%|███▉      | 1146/2906 [3:46:15<5:36:43, 11.48s/it]                                                       {'loss': 0.7881, 'grad_norm': 1.2408682107925415, 'learning_rate': 3.4754248846963494e-06, 'epoch': 0.39}
 39%|███▉      | 1146/2906 [3:46:15<5:36:43, 11.48s/it] 39%|███▉      | 1147/2906 [3:46:27<5:41:42, 11.66s/it]                                                       {'loss': 0.7979, 'grad_norm': 1.3676918745040894, 'learning_rate': 3.472847118690611e-06, 'epoch': 0.39}
 39%|███▉      | 1147/2906 [3:46:27<5:41:42, 11.66s/it] 40%|███▉      | 1148/2906 [3:46:39<5:44:47, 11.77s/it]                                                       {'loss': 0.7614, 'grad_norm': 1.274001955986023, 'learning_rate': 3.47026813322093e-06, 'epoch': 0.4}
 40%|███▉      | 1148/2906 [3:46:39<5:44:47, 11.77s/it] 40%|███▉      | 1149/2906 [3:46:52<5:48:50, 11.91s/it]                                                       {'loss': 0.8715, 'grad_norm': 1.2658045291900635, 'learning_rate': 3.467687931520064e-06, 'epoch': 0.4}
 40%|███▉      | 1149/2906 [3:46:52<5:48:50, 11.91s/it] 40%|███▉      | 1150/2906 [3:47:04<5:49:34, 11.94s/it]                                                       {'loss': 0.7847, 'grad_norm': 1.290664792060852, 'learning_rate': 3.465106516822296e-06, 'epoch': 0.4}
 40%|███▉      | 1150/2906 [3:47:04<5:49:34, 11.94s/it] 40%|███▉      | 1151/2906 [3:47:15<5:47:06, 11.87s/it]                                                       {'loss': 0.8288, 'grad_norm': 1.2332366704940796, 'learning_rate': 3.462523892363432e-06, 'epoch': 0.4}
 40%|███▉      | 1151/2906 [3:47:15<5:47:06, 11.87s/it] 40%|███▉      | 1152/2906 [3:47:27<5:43:59, 11.77s/it]                                                       {'loss': 0.8153, 'grad_norm': 1.3294309377670288, 'learning_rate': 3.459940061380789e-06, 'epoch': 0.4}
 40%|███▉      | 1152/2906 [3:47:27<5:43:59, 11.77s/it] 40%|███▉      | 1153/2906 [3:47:39<5:45:00, 11.81s/it]                                                       {'loss': 0.811, 'grad_norm': 1.3110454082489014, 'learning_rate': 3.4573550271132e-06, 'epoch': 0.4}
 40%|███▉      | 1153/2906 [3:47:39<5:45:00, 11.81s/it] 40%|███▉      | 1154/2906 [3:47:50<5:44:09, 11.79s/it]                                                       {'loss': 0.7575, 'grad_norm': 1.2872190475463867, 'learning_rate': 3.454768792801007e-06, 'epoch': 0.4}
 40%|███▉      | 1154/2906 [3:47:50<5:44:09, 11.79s/it] 40%|███▉      | 1155/2906 [3:48:03<5:47:22, 11.90s/it]                                                       {'loss': 0.798, 'grad_norm': 1.3099321126937866, 'learning_rate': 3.4521813616860545e-06, 'epoch': 0.4}
 40%|███▉      | 1155/2906 [3:48:03<5:47:22, 11.90s/it] 40%|███▉      | 1156/2906 [3:48:14<5:44:43, 11.82s/it]                                                       {'loss': 0.7835, 'grad_norm': 1.322115182876587, 'learning_rate': 3.4495927370116867e-06, 'epoch': 0.4}
 40%|███▉      | 1156/2906 [3:48:14<5:44:43, 11.82s/it] 40%|███▉      | 1157/2906 [3:48:26<5:40:10, 11.67s/it]                                                       {'loss': 0.8318, 'grad_norm': 1.4441535472869873, 'learning_rate': 3.4470029220227445e-06, 'epoch': 0.4}
 40%|███▉      | 1157/2906 [3:48:26<5:40:10, 11.67s/it] 40%|███▉      | 1158/2906 [3:48:37<5:41:55, 11.74s/it]                                                       {'loss': 0.7828, 'grad_norm': 1.2229951620101929, 'learning_rate': 3.4444119199655635e-06, 'epoch': 0.4}
 40%|███▉      | 1158/2906 [3:48:37<5:41:55, 11.74s/it] 40%|███▉      | 1159/2906 [3:48:48<5:35:27, 11.52s/it]                                                       {'loss': 0.8175, 'grad_norm': 1.4417140483856201, 'learning_rate': 3.441819734087963e-06, 'epoch': 0.4}
 40%|███▉      | 1159/2906 [3:48:48<5:35:27, 11.52s/it] 40%|███▉      | 1160/2906 [3:49:00<5:34:45, 11.50s/it]                                                       {'loss': 0.8245, 'grad_norm': 1.3287461996078491, 'learning_rate': 3.439226367639249e-06, 'epoch': 0.4}
 40%|███▉      | 1160/2906 [3:49:00<5:34:45, 11.50s/it] 40%|███▉      | 1161/2906 [3:49:11<5:32:24, 11.43s/it]                                                       {'loss': 0.8499, 'grad_norm': 1.2778956890106201, 'learning_rate': 3.4366318238702063e-06, 'epoch': 0.4}
 40%|███▉      | 1161/2906 [3:49:11<5:32:24, 11.43s/it] 40%|███▉      | 1162/2906 [3:49:23<5:34:28, 11.51s/it]                                                       {'loss': 0.8211, 'grad_norm': 1.3354963064193726, 'learning_rate': 3.4340361060330957e-06, 'epoch': 0.4}
 40%|███▉      | 1162/2906 [3:49:23<5:34:28, 11.51s/it] 40%|████      | 1163/2906 [3:49:35<5:41:01, 11.74s/it]                                                       {'loss': 0.8676, 'grad_norm': 1.3664007186889648, 'learning_rate': 3.4314392173816495e-06, 'epoch': 0.4}
 40%|████      | 1163/2906 [3:49:35<5:41:01, 11.74s/it] 40%|████      | 1164/2906 [3:49:47<5:42:44, 11.81s/it]                                                       {'loss': 0.7879, 'grad_norm': 1.3479483127593994, 'learning_rate': 3.4288411611710683e-06, 'epoch': 0.4}
 40%|████      | 1164/2906 [3:49:47<5:42:44, 11.81s/it] 40%|████      | 1165/2906 [3:49:59<5:44:03, 11.86s/it]                                                       {'loss': 0.7731, 'grad_norm': 1.3015472888946533, 'learning_rate': 3.426241940658015e-06, 'epoch': 0.4}
 40%|████      | 1165/2906 [3:49:59<5:44:03, 11.86s/it] 40%|████      | 1166/2906 [3:50:11<5:47:32, 11.98s/it]                                                       {'loss': 0.8019, 'grad_norm': 1.239378809928894, 'learning_rate': 3.4236415591006146e-06, 'epoch': 0.4}
 40%|████      | 1166/2906 [3:50:11<5:47:32, 11.98s/it] 40%|████      | 1167/2906 [3:50:23<5:45:55, 11.94s/it]                                                       {'loss': 0.8222, 'grad_norm': 1.3359133005142212, 'learning_rate': 3.421040019758443e-06, 'epoch': 0.4}
 40%|████      | 1167/2906 [3:50:23<5:45:55, 11.94s/it] 40%|████      | 1168/2906 [3:50:35<5:48:22, 12.03s/it]                                                       {'loss': 0.8064, 'grad_norm': 1.1999188661575317, 'learning_rate': 3.4184373258925317e-06, 'epoch': 0.4}
 40%|████      | 1168/2906 [3:50:35<5:48:22, 12.03s/it] 40%|████      | 1169/2906 [3:50:47<5:43:52, 11.88s/it]                                                       {'loss': 0.7828, 'grad_norm': 1.2732259035110474, 'learning_rate': 3.4158334807653577e-06, 'epoch': 0.4}
 40%|████      | 1169/2906 [3:50:47<5:43:52, 11.88s/it] 40%|████      | 1170/2906 [3:50:59<5:48:23, 12.04s/it]                                                       {'loss': 0.7844, 'grad_norm': 1.2891563177108765, 'learning_rate': 3.4132284876408404e-06, 'epoch': 0.4}
 40%|████      | 1170/2906 [3:50:59<5:48:23, 12.04s/it] 40%|████      | 1171/2906 [3:51:11<5:44:18, 11.91s/it]                                                       {'loss': 0.8223, 'grad_norm': 1.2831993103027344, 'learning_rate': 3.4106223497843395e-06, 'epoch': 0.4}
 40%|████      | 1171/2906 [3:51:11<5:44:18, 11.91s/it] 40%|████      | 1172/2906 [3:51:22<5:38:43, 11.72s/it]                                                       {'loss': 0.7423, 'grad_norm': 1.2010982036590576, 'learning_rate': 3.408015070462648e-06, 'epoch': 0.4}
 40%|████      | 1172/2906 [3:51:22<5:38:43, 11.72s/it] 40%|████      | 1173/2906 [3:51:34<5:34:26, 11.58s/it]                                                       {'loss': 0.7584, 'grad_norm': 1.2638734579086304, 'learning_rate': 3.4054066529439916e-06, 'epoch': 0.4}
 40%|████      | 1173/2906 [3:51:34<5:34:26, 11.58s/it] 40%|████      | 1174/2906 [3:51:46<5:38:21, 11.72s/it]                                                       {'loss': 0.7814, 'grad_norm': 1.2168807983398438, 'learning_rate': 3.402797100498022e-06, 'epoch': 0.4}
 40%|████      | 1174/2906 [3:51:46<5:38:21, 11.72s/it] 40%|████      | 1175/2906 [3:51:58<5:46:01, 11.99s/it]                                                       {'loss': 0.8068, 'grad_norm': 1.3216608762741089, 'learning_rate': 3.4001864163958125e-06, 'epoch': 0.4}
 40%|████      | 1175/2906 [3:51:58<5:46:01, 11.99s/it] 40%|████      | 1176/2906 [3:52:10<5:41:19, 11.84s/it]                                                       {'loss': 0.7621, 'grad_norm': 1.2623543739318848, 'learning_rate': 3.3975746039098567e-06, 'epoch': 0.4}
 40%|████      | 1176/2906 [3:52:10<5:41:19, 11.84s/it] 41%|████      | 1177/2906 [3:52:21<5:40:25, 11.81s/it]                                                       {'loss': 0.81, 'grad_norm': 1.3214452266693115, 'learning_rate': 3.394961666314061e-06, 'epoch': 0.41}
 41%|████      | 1177/2906 [3:52:21<5:40:25, 11.81s/it] 41%|████      | 1178/2906 [3:52:34<5:43:38, 11.93s/it]                                                       {'loss': 0.8025, 'grad_norm': 1.311627984046936, 'learning_rate': 3.392347606883744e-06, 'epoch': 0.41}
 41%|████      | 1178/2906 [3:52:34<5:43:38, 11.93s/it] 41%|████      | 1179/2906 [3:52:46<5:45:37, 12.01s/it]                                                       {'loss': 0.8282, 'grad_norm': 1.3179296255111694, 'learning_rate': 3.389732428895629e-06, 'epoch': 0.41}
 41%|████      | 1179/2906 [3:52:46<5:45:37, 12.01s/it] 41%|████      | 1180/2906 [3:52:57<5:41:51, 11.88s/it]                                                       {'loss': 0.8279, 'grad_norm': 1.2995884418487549, 'learning_rate': 3.387116135627841e-06, 'epoch': 0.41}
 41%|████      | 1180/2906 [3:52:57<5:41:51, 11.88s/it] 41%|████      | 1181/2906 [3:53:09<5:42:10, 11.90s/it]                                                       {'loss': 0.8308, 'grad_norm': 1.2888480424880981, 'learning_rate': 3.384498730359905e-06, 'epoch': 0.41}
 41%|████      | 1181/2906 [3:53:09<5:42:10, 11.90s/it] 41%|████      | 1182/2906 [3:53:21<5:37:18, 11.74s/it]                                                       {'loss': 0.818, 'grad_norm': 1.259956955909729, 'learning_rate': 3.3818802163727377e-06, 'epoch': 0.41}
 41%|████      | 1182/2906 [3:53:21<5:37:18, 11.74s/it] 41%|████      | 1183/2906 [3:53:32<5:36:12, 11.71s/it]                                                       {'loss': 0.7842, 'grad_norm': 1.2251733541488647, 'learning_rate': 3.379260596948646e-06, 'epoch': 0.41}
 41%|████      | 1183/2906 [3:53:32<5:36:12, 11.71s/it] 41%|████      | 1184/2906 [3:53:44<5:34:18, 11.65s/it]                                                       {'loss': 0.8563, 'grad_norm': 1.3472899198532104, 'learning_rate': 3.376639875371326e-06, 'epoch': 0.41}
 41%|████      | 1184/2906 [3:53:44<5:34:18, 11.65s/it] 41%|████      | 1185/2906 [3:53:55<5:32:47, 11.60s/it]                                                       {'loss': 0.8244, 'grad_norm': 1.3887121677398682, 'learning_rate': 3.3740180549258496e-06, 'epoch': 0.41}
 41%|████      | 1185/2906 [3:53:55<5:32:47, 11.60s/it] 41%|████      | 1186/2906 [3:54:07<5:33:57, 11.65s/it]                                                       {'loss': 0.8312, 'grad_norm': 1.3163310289382935, 'learning_rate': 3.3713951388986697e-06, 'epoch': 0.41}
 41%|████      | 1186/2906 [3:54:07<5:33:57, 11.65s/it] 41%|████      | 1187/2906 [3:54:19<5:32:46, 11.62s/it]                                                       {'loss': 0.7834, 'grad_norm': 1.2876043319702148, 'learning_rate': 3.368771130577613e-06, 'epoch': 0.41}
 41%|████      | 1187/2906 [3:54:19<5:32:46, 11.62s/it] 41%|████      | 1188/2906 [3:54:31<5:34:56, 11.70s/it]                                                       {'loss': 0.7808, 'grad_norm': 1.288899302482605, 'learning_rate': 3.3661460332518715e-06, 'epoch': 0.41}
 41%|████      | 1188/2906 [3:54:31<5:34:56, 11.70s/it] 41%|████      | 1189/2906 [3:54:42<5:35:21, 11.72s/it]                                                       {'loss': 0.8154, 'grad_norm': 1.3681564331054688, 'learning_rate': 3.363519850212007e-06, 'epoch': 0.41}
 41%|████      | 1189/2906 [3:54:42<5:35:21, 11.72s/it] 41%|████      | 1190/2906 [3:54:54<5:36:18, 11.76s/it]                                                       {'loss': 0.8143, 'grad_norm': 1.2958459854125977, 'learning_rate': 3.3608925847499398e-06, 'epoch': 0.41}
 41%|████      | 1190/2906 [3:54:54<5:36:18, 11.76s/it] 41%|████      | 1191/2906 [3:55:06<5:33:50, 11.68s/it]                                                       {'loss': 0.7811, 'grad_norm': 1.2961175441741943, 'learning_rate': 3.358264240158947e-06, 'epoch': 0.41}
 41%|████      | 1191/2906 [3:55:06<5:33:50, 11.68s/it] 41%|████      | 1192/2906 [3:55:18<5:38:19, 11.84s/it]                                                       {'loss': 0.8237, 'grad_norm': 1.2993528842926025, 'learning_rate': 3.355634819733659e-06, 'epoch': 0.41}
 41%|████      | 1192/2906 [3:55:18<5:38:19, 11.84s/it] 41%|████      | 1193/2906 [3:55:29<5:35:52, 11.76s/it]                                                       {'loss': 0.772, 'grad_norm': 1.3972467184066772, 'learning_rate': 3.353004326770055e-06, 'epoch': 0.41}
 41%|████      | 1193/2906 [3:55:29<5:35:52, 11.76s/it] 41%|████      | 1194/2906 [3:55:42<5:40:39, 11.94s/it]                                                       {'loss': 0.7875, 'grad_norm': 1.1939327716827393, 'learning_rate': 3.350372764565457e-06, 'epoch': 0.41}
 41%|████      | 1194/2906 [3:55:42<5:40:39, 11.94s/it] 41%|████      | 1195/2906 [3:55:53<5:37:30, 11.84s/it]                                                       {'loss': 0.7496, 'grad_norm': 1.3528157472610474, 'learning_rate': 3.347740136418529e-06, 'epoch': 0.41}
 41%|████      | 1195/2906 [3:55:53<5:37:30, 11.84s/it] 41%|████      | 1196/2906 [3:56:06<5:39:42, 11.92s/it]                                                       {'loss': 0.7875, 'grad_norm': 1.3371312618255615, 'learning_rate': 3.345106445629271e-06, 'epoch': 0.41}
 41%|████      | 1196/2906 [3:56:06<5:39:42, 11.92s/it] 41%|████      | 1197/2906 [3:56:17<5:37:48, 11.86s/it]                                                       {'loss': 0.8702, 'grad_norm': 1.356324315071106, 'learning_rate': 3.342471695499014e-06, 'epoch': 0.41}
 41%|████      | 1197/2906 [3:56:17<5:37:48, 11.86s/it] 41%|████      | 1198/2906 [3:56:29<5:34:42, 11.76s/it]                                                       {'loss': 0.7962, 'grad_norm': 1.3107128143310547, 'learning_rate': 3.3398358893304176e-06, 'epoch': 0.41}
 41%|████      | 1198/2906 [3:56:29<5:34:42, 11.76s/it] 41%|████▏     | 1199/2906 [3:56:40<5:32:24, 11.68s/it]                                                       {'loss': 0.817, 'grad_norm': 1.4357085227966309, 'learning_rate': 3.3371990304274654e-06, 'epoch': 0.41}
 41%|████▏     | 1199/2906 [3:56:40<5:32:24, 11.68s/it] 41%|████▏     | 1200/2906 [3:56:52<5:32:50, 11.71s/it]                                                       {'loss': 0.785, 'grad_norm': 1.304244875907898, 'learning_rate': 3.3345611220954606e-06, 'epoch': 0.41}
 41%|████▏     | 1200/2906 [3:56:52<5:32:50, 11.71s/it] 41%|████▏     | 1201/2906 [3:57:04<5:31:02, 11.65s/it]                                                       {'loss': 0.7952, 'grad_norm': 1.3399860858917236, 'learning_rate': 3.33192216764102e-06, 'epoch': 0.41}
 41%|████▏     | 1201/2906 [3:57:04<5:31:02, 11.65s/it] 41%|████▏     | 1202/2906 [3:57:15<5:29:47, 11.61s/it]                                                       {'loss': 0.8219, 'grad_norm': 1.3742125034332275, 'learning_rate': 3.3292821703720753e-06, 'epoch': 0.41}
 41%|████▏     | 1202/2906 [3:57:15<5:29:47, 11.61s/it] 41%|████▏     | 1203/2906 [3:57:27<5:29:10, 11.60s/it]                                                       {'loss': 0.8004, 'grad_norm': 1.2950108051300049, 'learning_rate': 3.3266411335978618e-06, 'epoch': 0.41}
 41%|████▏     | 1203/2906 [3:57:27<5:29:10, 11.60s/it] 41%|████▏     | 1204/2906 [3:57:38<5:28:46, 11.59s/it]                                                       {'loss': 0.8636, 'grad_norm': 1.3312408924102783, 'learning_rate': 3.3239990606289197e-06, 'epoch': 0.41}
 41%|████▏     | 1204/2906 [3:57:38<5:28:46, 11.59s/it] 41%|████▏     | 1205/2906 [3:57:50<5:31:36, 11.70s/it]                                                       {'loss': 0.8285, 'grad_norm': 1.4159011840820312, 'learning_rate': 3.3213559547770873e-06, 'epoch': 0.41}
 41%|████▏     | 1205/2906 [3:57:50<5:31:36, 11.70s/it] 42%|████▏     | 1206/2906 [3:58:02<5:32:01, 11.72s/it]                                                       {'loss': 0.7492, 'grad_norm': 1.352111577987671, 'learning_rate': 3.318711819355499e-06, 'epoch': 0.42}
 42%|████▏     | 1206/2906 [3:58:02<5:32:01, 11.72s/it] 42%|████▏     | 1207/2906 [3:58:14<5:31:34, 11.71s/it]                                                       {'loss': 0.8434, 'grad_norm': 1.3478788137435913, 'learning_rate': 3.316066657678577e-06, 'epoch': 0.42}
 42%|████▏     | 1207/2906 [3:58:14<5:31:34, 11.71s/it] 42%|████▏     | 1208/2906 [3:58:26<5:33:40, 11.79s/it]                                                       {'loss': 0.7762, 'grad_norm': 1.2851120233535767, 'learning_rate': 3.313420473062034e-06, 'epoch': 0.42}
 42%|████▏     | 1208/2906 [3:58:26<5:33:40, 11.79s/it] 42%|████▏     | 1209/2906 [3:58:37<5:31:50, 11.73s/it]                                                       {'loss': 0.8341, 'grad_norm': 1.465440034866333, 'learning_rate': 3.310773268822861e-06, 'epoch': 0.42}
 42%|████▏     | 1209/2906 [3:58:37<5:31:50, 11.73s/it] 42%|████▏     | 1210/2906 [3:58:48<5:27:56, 11.60s/it]                                                       {'loss': 0.7295, 'grad_norm': 1.3869000673294067, 'learning_rate': 3.3081250482793294e-06, 'epoch': 0.42}
 42%|████▏     | 1210/2906 [3:58:49<5:27:56, 11.60s/it] 42%|████▏     | 1211/2906 [3:59:00<5:30:47, 11.71s/it]                                                       {'loss': 0.7741, 'grad_norm': 1.23148512840271, 'learning_rate': 3.3054758147509837e-06, 'epoch': 0.42}
 42%|████▏     | 1211/2906 [3:59:00<5:30:47, 11.71s/it] 42%|████▏     | 1212/2906 [3:59:12<5:28:55, 11.65s/it]                                                       {'loss': 0.8461, 'grad_norm': 1.3428772687911987, 'learning_rate': 3.302825571558638e-06, 'epoch': 0.42}
 42%|████▏     | 1212/2906 [3:59:12<5:28:55, 11.65s/it] 42%|████▏     | 1213/2906 [3:59:24<5:31:40, 11.75s/it]                                                       {'loss': 0.8133, 'grad_norm': 1.3196179866790771, 'learning_rate': 3.300174322024373e-06, 'epoch': 0.42}
 42%|████▏     | 1213/2906 [3:59:24<5:31:40, 11.75s/it] 42%|████▏     | 1214/2906 [3:59:36<5:36:47, 11.94s/it]                                                       {'loss': 0.8191, 'grad_norm': 1.3202564716339111, 'learning_rate': 3.2975220694715298e-06, 'epoch': 0.42}
 42%|████▏     | 1214/2906 [3:59:36<5:36:47, 11.94s/it] 42%|████▏     | 1215/2906 [3:59:48<5:37:29, 11.98s/it]                                                       {'loss': 0.8124, 'grad_norm': 1.3704296350479126, 'learning_rate': 3.294868817224707e-06, 'epoch': 0.42}
 42%|████▏     | 1215/2906 [3:59:48<5:37:29, 11.98s/it] 42%|████▏     | 1216/2906 [4:00:00<5:34:48, 11.89s/it]                                                       {'loss': 0.7934, 'grad_norm': 1.286761999130249, 'learning_rate': 3.2922145686097573e-06, 'epoch': 0.42}
 42%|████▏     | 1216/2906 [4:00:00<5:34:48, 11.89s/it] 42%|████▏     | 1217/2906 [4:00:11<5:28:36, 11.67s/it]                                                       {'loss': 0.7615, 'grad_norm': 1.3046094179153442, 'learning_rate': 3.2895593269537806e-06, 'epoch': 0.42}
 42%|████▏     | 1217/2906 [4:00:11<5:28:36, 11.67s/it] 42%|████▏     | 1218/2906 [4:00:23<5:28:03, 11.66s/it]                                                       {'loss': 0.7945, 'grad_norm': 1.2931296825408936, 'learning_rate': 3.2869030955851233e-06, 'epoch': 0.42}
 42%|████▏     | 1218/2906 [4:00:23<5:28:03, 11.66s/it] 42%|████▏     | 1219/2906 [4:00:35<5:32:14, 11.82s/it]                                                       {'loss': 0.7842, 'grad_norm': 1.299056887626648, 'learning_rate': 3.284245877833371e-06, 'epoch': 0.42}
 42%|████▏     | 1219/2906 [4:00:35<5:32:14, 11.82s/it] 42%|████▏     | 1220/2906 [4:00:46<5:28:30, 11.69s/it]                                                       {'loss': 0.8307, 'grad_norm': 1.2240134477615356, 'learning_rate': 3.281587677029347e-06, 'epoch': 0.42}
 42%|████▏     | 1220/2906 [4:00:46<5:28:30, 11.69s/it] 42%|████▏     | 1221/2906 [4:00:58<5:24:42, 11.56s/it]                                                       {'loss': 0.7938, 'grad_norm': 1.2879077196121216, 'learning_rate': 3.2789284965051053e-06, 'epoch': 0.42}
 42%|████▏     | 1221/2906 [4:00:58<5:24:42, 11.56s/it] 42%|████▏     | 1222/2906 [4:01:09<5:23:27, 11.52s/it]                                                       {'loss': 0.749, 'grad_norm': 1.2167526483535767, 'learning_rate': 3.2762683395939297e-06, 'epoch': 0.42}
 42%|████▏     | 1222/2906 [4:01:09<5:23:27, 11.52s/it] 42%|████▏     | 1223/2906 [4:01:21<5:23:46, 11.54s/it]                                                       {'loss': 0.8058, 'grad_norm': 1.268835425376892, 'learning_rate': 3.2736072096303277e-06, 'epoch': 0.42}
 42%|████▏     | 1223/2906 [4:01:21<5:23:46, 11.54s/it] 42%|████▏     | 1224/2906 [4:01:32<5:23:26, 11.54s/it]                                                       {'loss': 0.7811, 'grad_norm': 1.307999610900879, 'learning_rate': 3.270945109950025e-06, 'epoch': 0.42}
 42%|████▏     | 1224/2906 [4:01:32<5:23:26, 11.54s/it] 42%|████▏     | 1225/2906 [4:01:44<5:23:44, 11.56s/it]                                                       {'loss': 0.8115, 'grad_norm': 1.2933241128921509, 'learning_rate': 3.268282043889963e-06, 'epoch': 0.42}
 42%|████▏     | 1225/2906 [4:01:44<5:23:44, 11.56s/it] 42%|████▏     | 1226/2906 [4:01:56<5:25:35, 11.63s/it]                                                       {'loss': 0.7836, 'grad_norm': 1.21418297290802, 'learning_rate': 3.2656180147882963e-06, 'epoch': 0.42}
 42%|████▏     | 1226/2906 [4:01:56<5:25:35, 11.63s/it] 42%|████▏     | 1227/2906 [4:02:07<5:26:08, 11.66s/it]                                                       {'loss': 0.7769, 'grad_norm': 1.295137643814087, 'learning_rate': 3.2629530259843862e-06, 'epoch': 0.42}
 42%|████▏     | 1227/2906 [4:02:07<5:26:08, 11.66s/it] 42%|████▏     | 1228/2906 [4:02:19<5:27:37, 11.71s/it]                                                       {'loss': 0.7568, 'grad_norm': 1.2846490144729614, 'learning_rate': 3.2602870808187955e-06, 'epoch': 0.42}
 42%|████▏     | 1228/2906 [4:02:19<5:27:37, 11.71s/it] 42%|████▏     | 1229/2906 [4:02:31<5:23:44, 11.58s/it]                                                       {'loss': 0.8192, 'grad_norm': 1.3121914863586426, 'learning_rate': 3.2576201826332864e-06, 'epoch': 0.42}
 42%|████▏     | 1229/2906 [4:02:31<5:23:44, 11.58s/it] 42%|████▏     | 1230/2906 [4:02:42<5:25:01, 11.64s/it]                                                       {'loss': 0.8602, 'grad_norm': 1.3495954275131226, 'learning_rate': 3.2549523347708155e-06, 'epoch': 0.42}
 42%|████▏     | 1230/2906 [4:02:42<5:25:01, 11.64s/it] 42%|████▏     | 1231/2906 [4:02:54<5:28:01, 11.75s/it]                                                       {'loss': 0.7736, 'grad_norm': 1.2837426662445068, 'learning_rate': 3.252283540575533e-06, 'epoch': 0.42}
 42%|████▏     | 1231/2906 [4:02:54<5:28:01, 11.75s/it] 42%|████▏     | 1232/2906 [4:03:06<5:23:43, 11.60s/it]                                                       {'loss': 0.775, 'grad_norm': 1.3735299110412598, 'learning_rate': 3.24961380339277e-06, 'epoch': 0.42}
 42%|████▏     | 1232/2906 [4:03:06<5:23:43, 11.60s/it] 42%|████▏     | 1233/2906 [4:03:17<5:24:04, 11.62s/it]                                                       {'loss': 0.7342, 'grad_norm': 1.3015358448028564, 'learning_rate': 3.2469431265690432e-06, 'epoch': 0.42}
 42%|████▏     | 1233/2906 [4:03:17<5:24:04, 11.62s/it] 42%|████▏     | 1234/2906 [4:03:28<5:19:57, 11.48s/it]                                                       {'loss': 0.7645, 'grad_norm': 1.3988990783691406, 'learning_rate': 3.2442715134520457e-06, 'epoch': 0.42}
 42%|████▏     | 1234/2906 [4:03:28<5:19:57, 11.48s/it] 42%|████▏     | 1235/2906 [4:03:40<5:24:23, 11.65s/it]                                                       {'loss': 0.7749, 'grad_norm': 1.2813793420791626, 'learning_rate': 3.2415989673906454e-06, 'epoch': 0.42}
 42%|████▏     | 1235/2906 [4:03:40<5:24:23, 11.65s/it] 43%|████▎     | 1236/2906 [4:03:52<5:24:16, 11.65s/it]                                                       {'loss': 0.8085, 'grad_norm': 1.3745710849761963, 'learning_rate': 3.2389254917348793e-06, 'epoch': 0.43}
 43%|████▎     | 1236/2906 [4:03:52<5:24:16, 11.65s/it] 43%|████▎     | 1237/2906 [4:04:03<5:21:49, 11.57s/it]                                                       {'loss': 0.73, 'grad_norm': 1.478514313697815, 'learning_rate': 3.2362510898359484e-06, 'epoch': 0.43}
 43%|████▎     | 1237/2906 [4:04:03<5:21:49, 11.57s/it] 43%|████▎     | 1238/2906 [4:04:16<5:29:22, 11.85s/it]                                                       {'loss': 0.802, 'grad_norm': 1.3378359079360962, 'learning_rate': 3.233575765046216e-06, 'epoch': 0.43}
 43%|████▎     | 1238/2906 [4:04:16<5:29:22, 11.85s/it] 43%|████▎     | 1239/2906 [4:04:28<5:28:06, 11.81s/it]                                                       {'loss': 0.8124, 'grad_norm': 1.320331335067749, 'learning_rate': 3.2308995207192028e-06, 'epoch': 0.43}
 43%|████▎     | 1239/2906 [4:04:28<5:28:06, 11.81s/it] 43%|████▎     | 1240/2906 [4:04:39<5:25:24, 11.72s/it]                                                       {'loss': 0.8126, 'grad_norm': 1.446837306022644, 'learning_rate': 3.22822236020958e-06, 'epoch': 0.43}
 43%|████▎     | 1240/2906 [4:04:39<5:25:24, 11.72s/it] 43%|████▎     | 1241/2906 [4:04:51<5:26:24, 11.76s/it]                                                       {'loss': 0.747, 'grad_norm': 1.3064143657684326, 'learning_rate': 3.225544286873169e-06, 'epoch': 0.43}
 43%|████▎     | 1241/2906 [4:04:51<5:26:24, 11.76s/it] 43%|████▎     | 1242/2906 [4:05:03<5:27:32, 11.81s/it]                                                       {'loss': 0.845, 'grad_norm': 1.3689634799957275, 'learning_rate': 3.2228653040669355e-06, 'epoch': 0.43}
 43%|████▎     | 1242/2906 [4:05:03<5:27:32, 11.81s/it] 43%|████▎     | 1243/2906 [4:05:15<5:26:17, 11.77s/it]                                                       {'loss': 0.8012, 'grad_norm': 1.315545916557312, 'learning_rate': 3.220185415148984e-06, 'epoch': 0.43}
 43%|████▎     | 1243/2906 [4:05:15<5:26:17, 11.77s/it] 43%|████▎     | 1244/2906 [4:05:27<5:27:04, 11.81s/it]                                                       {'loss': 0.7351, 'grad_norm': 1.229548454284668, 'learning_rate': 3.2175046234785567e-06, 'epoch': 0.43}
 43%|████▎     | 1244/2906 [4:05:27<5:27:04, 11.81s/it] 43%|████▎     | 1245/2906 [4:05:38<5:25:24, 11.75s/it]                                                       {'loss': 0.843, 'grad_norm': 1.3436168432235718, 'learning_rate': 3.2148229324160235e-06, 'epoch': 0.43}
 43%|████▎     | 1245/2906 [4:05:38<5:25:24, 11.75s/it] 43%|████▎     | 1246/2906 [4:05:49<5:21:37, 11.62s/it]                                                       {'loss': 0.8703, 'grad_norm': 1.2950809001922607, 'learning_rate': 3.2121403453228867e-06, 'epoch': 0.43}
 43%|████▎     | 1246/2906 [4:05:49<5:21:37, 11.62s/it] 43%|████▎     | 1247/2906 [4:06:01<5:19:35, 11.56s/it]                                                       {'loss': 0.8191, 'grad_norm': 1.3514095544815063, 'learning_rate': 3.2094568655617692e-06, 'epoch': 0.43}
 43%|████▎     | 1247/2906 [4:06:01<5:19:35, 11.56s/it] 43%|████▎     | 1248/2906 [4:06:12<5:18:00, 11.51s/it]                                                       {'loss': 0.8074, 'grad_norm': 1.3794933557510376, 'learning_rate': 3.206772496496412e-06, 'epoch': 0.43}
 43%|████▎     | 1248/2906 [4:06:12<5:18:00, 11.51s/it] 43%|████▎     | 1249/2906 [4:06:24<5:17:05, 11.48s/it]                                                       {'loss': 0.7852, 'grad_norm': 1.2921068668365479, 'learning_rate': 3.204087241491673e-06, 'epoch': 0.43}
 43%|████▎     | 1249/2906 [4:06:24<5:17:05, 11.48s/it] 43%|████▎     | 1250/2906 [4:06:36<5:21:49, 11.66s/it]                                                       {'loss': 0.7912, 'grad_norm': 1.193587303161621, 'learning_rate': 3.201401103913519e-06, 'epoch': 0.43}
 43%|████▎     | 1250/2906 [4:06:36<5:21:49, 11.66s/it] 43%|████▎     | 1251/2906 [4:06:47<5:21:15, 11.65s/it]                                                       {'loss': 0.7957, 'grad_norm': 1.2765929698944092, 'learning_rate': 3.198714087129024e-06, 'epoch': 0.43}
 43%|████▎     | 1251/2906 [4:06:47<5:21:15, 11.65s/it] 43%|████▎     | 1252/2906 [4:06:59<5:20:56, 11.64s/it]                                                       {'loss': 0.803, 'grad_norm': 1.3965898752212524, 'learning_rate': 3.196026194506364e-06, 'epoch': 0.43}
 43%|████▎     | 1252/2906 [4:06:59<5:20:56, 11.64s/it] 43%|████▎     | 1253/2906 [4:07:10<5:19:08, 11.58s/it]                                                       {'loss': 0.8145, 'grad_norm': 1.3190944194793701, 'learning_rate': 3.1933374294148112e-06, 'epoch': 0.43}
 43%|████▎     | 1253/2906 [4:07:10<5:19:08, 11.58s/it] 43%|████▎     | 1254/2906 [4:07:23<5:23:10, 11.74s/it]                                                       {'loss': 0.7758, 'grad_norm': 1.3099733591079712, 'learning_rate': 3.1906477952247346e-06, 'epoch': 0.43}
 43%|████▎     | 1254/2906 [4:07:23<5:23:10, 11.74s/it] 43%|████▎     | 1255/2906 [4:07:34<5:19:09, 11.60s/it]                                                       {'loss': 0.7262, 'grad_norm': 1.2038201093673706, 'learning_rate': 3.187957295307591e-06, 'epoch': 0.43}
 43%|████▎     | 1255/2906 [4:07:34<5:19:09, 11.60s/it] 43%|████▎     | 1256/2906 [4:07:45<5:17:00, 11.53s/it]                                                       {'loss': 0.7391, 'grad_norm': 1.2628949880599976, 'learning_rate': 3.18526593303592e-06, 'epoch': 0.43}
 43%|████▎     | 1256/2906 [4:07:45<5:17:00, 11.53s/it] 43%|████▎     | 1257/2906 [4:07:57<5:22:44, 11.74s/it]                                                       {'loss': 0.8626, 'grad_norm': 1.2922776937484741, 'learning_rate': 3.1825737117833465e-06, 'epoch': 0.43}
 43%|████▎     | 1257/2906 [4:07:57<5:22:44, 11.74s/it] 43%|████▎     | 1258/2906 [4:08:09<5:21:29, 11.70s/it]                                                       {'loss': 0.7319, 'grad_norm': 1.2412000894546509, 'learning_rate': 3.179880634924569e-06, 'epoch': 0.43}
 43%|████▎     | 1258/2906 [4:08:09<5:21:29, 11.70s/it] 43%|████▎     | 1259/2906 [4:08:20<5:17:05, 11.55s/it]                                                       {'loss': 0.7895, 'grad_norm': 1.2387562990188599, 'learning_rate': 3.177186705835361e-06, 'epoch': 0.43}
 43%|████▎     | 1259/2906 [4:08:20<5:17:05, 11.55s/it] 43%|████▎     | 1260/2906 [4:08:32<5:22:05, 11.74s/it]                                                       {'loss': 0.8001, 'grad_norm': 1.3313658237457275, 'learning_rate': 3.174491927892561e-06, 'epoch': 0.43}
 43%|████▎     | 1260/2906 [4:08:32<5:22:05, 11.74s/it] 43%|████▎     | 1261/2906 [4:08:44<5:21:42, 11.73s/it]                                                       {'loss': 0.8321, 'grad_norm': 1.468095302581787, 'learning_rate': 3.171796304474074e-06, 'epoch': 0.43}
 43%|████▎     | 1261/2906 [4:08:44<5:21:42, 11.73s/it] 43%|████▎     | 1262/2906 [4:08:56<5:20:23, 11.69s/it]                                                       {'loss': 0.8666, 'grad_norm': 1.3805896043777466, 'learning_rate': 3.169099838958865e-06, 'epoch': 0.43}
 43%|████▎     | 1262/2906 [4:08:56<5:20:23, 11.69s/it] 43%|████▎     | 1263/2906 [4:09:07<5:19:58, 11.68s/it]                                                       {'loss': 0.7849, 'grad_norm': 1.2975693941116333, 'learning_rate': 3.1664025347269533e-06, 'epoch': 0.43}
 43%|████▎     | 1263/2906 [4:09:07<5:19:58, 11.68s/it] 43%|████▎     | 1264/2906 [4:09:20<5:27:36, 11.97s/it]                                                       {'loss': 0.7458, 'grad_norm': 1.296231985092163, 'learning_rate': 3.1637043951594093e-06, 'epoch': 0.43}
 43%|████▎     | 1264/2906 [4:09:20<5:27:36, 11.97s/it] 44%|████▎     | 1265/2906 [4:09:31<5:22:33, 11.79s/it]                                                       {'loss': 0.8106, 'grad_norm': 1.4277801513671875, 'learning_rate': 3.1610054236383526e-06, 'epoch': 0.44}
 44%|████▎     | 1265/2906 [4:09:31<5:22:33, 11.79s/it] 44%|████▎     | 1266/2906 [4:09:43<5:21:29, 11.76s/it]                                                       {'loss': 0.8516, 'grad_norm': 1.2495683431625366, 'learning_rate': 3.1583056235469424e-06, 'epoch': 0.44}
 44%|████▎     | 1266/2906 [4:09:43<5:21:29, 11.76s/it] 44%|████▎     | 1267/2906 [4:09:54<5:17:31, 11.62s/it]                                                       {'loss': 0.8057, 'grad_norm': 1.2760754823684692, 'learning_rate': 3.1556049982693794e-06, 'epoch': 0.44}
 44%|████▎     | 1267/2906 [4:09:54<5:17:31, 11.62s/it] 44%|████▎     | 1268/2906 [4:10:06<5:19:01, 11.69s/it]                                                       {'loss': 0.8385, 'grad_norm': 1.233165979385376, 'learning_rate': 3.152903551190897e-06, 'epoch': 0.44}
 44%|████▎     | 1268/2906 [4:10:06<5:19:01, 11.69s/it] 44%|████▎     | 1269/2906 [4:10:18<5:22:13, 11.81s/it]                                                       {'loss': 0.7886, 'grad_norm': 1.2767117023468018, 'learning_rate': 3.1502012856977606e-06, 'epoch': 0.44}
 44%|████▎     | 1269/2906 [4:10:18<5:22:13, 11.81s/it] 44%|████▎     | 1270/2906 [4:10:30<5:22:10, 11.82s/it]                                                       {'loss': 0.7043, 'grad_norm': 1.3113306760787964, 'learning_rate': 3.1474982051772583e-06, 'epoch': 0.44}
 44%|████▎     | 1270/2906 [4:10:30<5:22:10, 11.82s/it] 44%|████▎     | 1271/2906 [4:10:42<5:24:23, 11.90s/it]                                                       {'loss': 0.7461, 'grad_norm': 1.3193178176879883, 'learning_rate': 3.144794313017704e-06, 'epoch': 0.44}
 44%|████▎     | 1271/2906 [4:10:42<5:24:23, 11.90s/it] 44%|████▍     | 1272/2906 [4:10:54<5:26:29, 11.99s/it]                                                       {'loss': 0.7765, 'grad_norm': 1.2734615802764893, 'learning_rate': 3.1420896126084246e-06, 'epoch': 0.44}
 44%|████▍     | 1272/2906 [4:10:54<5:26:29, 11.99s/it] 44%|████▍     | 1273/2906 [4:11:06<5:19:52, 11.75s/it]                                                       {'loss': 0.8719, 'grad_norm': 1.2746307849884033, 'learning_rate': 3.1393841073397636e-06, 'epoch': 0.44}
 44%|████▍     | 1273/2906 [4:11:06<5:19:52, 11.75s/it] 44%|████▍     | 1274/2906 [4:11:17<5:18:00, 11.69s/it]                                                       {'loss': 0.764, 'grad_norm': 1.2303768396377563, 'learning_rate': 3.1366778006030717e-06, 'epoch': 0.44}
 44%|████▍     | 1274/2906 [4:11:17<5:18:00, 11.69s/it] 44%|████▍     | 1275/2906 [4:11:30<5:23:04, 11.88s/it]                                                       {'loss': 0.8036, 'grad_norm': 1.2261375188827515, 'learning_rate': 3.1339706957907058e-06, 'epoch': 0.44}
 44%|████▍     | 1275/2906 [4:11:30<5:23:04, 11.88s/it] 44%|████▍     | 1276/2906 [4:11:42<5:23:27, 11.91s/it]                                                       {'loss': 0.7797, 'grad_norm': 1.311237096786499, 'learning_rate': 3.1312627962960195e-06, 'epoch': 0.44}
 44%|████▍     | 1276/2906 [4:11:42<5:23:27, 11.91s/it] 44%|████▍     | 1277/2906 [4:11:54<5:25:14, 11.98s/it]                                                       {'loss': 0.8563, 'grad_norm': 1.4398787021636963, 'learning_rate': 3.128554105513367e-06, 'epoch': 0.44}
 44%|████▍     | 1277/2906 [4:11:54<5:25:14, 11.98s/it] 44%|████▍     | 1278/2906 [4:12:06<5:24:25, 11.96s/it]                                                       {'loss': 0.7917, 'grad_norm': 1.3548752069473267, 'learning_rate': 3.1258446268380913e-06, 'epoch': 0.44}
 44%|████▍     | 1278/2906 [4:12:06<5:24:25, 11.96s/it] 44%|████▍     | 1279/2906 [4:12:17<5:18:38, 11.75s/it]                                                       {'loss': 0.8184, 'grad_norm': 1.393827199935913, 'learning_rate': 3.123134363666525e-06, 'epoch': 0.44}
 44%|████▍     | 1279/2906 [4:12:17<5:18:38, 11.75s/it] 44%|████▍     | 1280/2906 [4:12:28<5:15:51, 11.66s/it]                                                       {'loss': 0.7549, 'grad_norm': 1.270551323890686, 'learning_rate': 3.120423319395983e-06, 'epoch': 0.44}
 44%|████▍     | 1280/2906 [4:12:28<5:15:51, 11.66s/it] 44%|████▍     | 1281/2906 [4:12:40<5:20:10, 11.82s/it]                                                       {'loss': 0.7448, 'grad_norm': 1.2350854873657227, 'learning_rate': 3.117711497424759e-06, 'epoch': 0.44}
 44%|████▍     | 1281/2906 [4:12:41<5:20:10, 11.82s/it] 44%|████▍     | 1282/2906 [4:12:52<5:21:31, 11.88s/it]                                                       {'loss': 0.7363, 'grad_norm': 1.3331044912338257, 'learning_rate': 3.1149989011521233e-06, 'epoch': 0.44}
 44%|████▍     | 1282/2906 [4:12:53<5:21:31, 11.88s/it] 44%|████▍     | 1283/2906 [4:13:04<5:18:45, 11.78s/it]                                                       {'loss': 0.8052, 'grad_norm': 1.4407668113708496, 'learning_rate': 3.1122855339783135e-06, 'epoch': 0.44}
 44%|████▍     | 1283/2906 [4:13:04<5:18:45, 11.78s/it] 44%|████▍     | 1284/2906 [4:13:15<5:15:29, 11.67s/it]                                                       {'loss': 0.8701, 'grad_norm': 1.3265883922576904, 'learning_rate': 3.1095713993045375e-06, 'epoch': 0.44}
 44%|████▍     | 1284/2906 [4:13:15<5:15:29, 11.67s/it] 44%|████▍     | 1285/2906 [4:13:27<5:16:30, 11.72s/it]                                                       {'loss': 0.782, 'grad_norm': 1.2747559547424316, 'learning_rate': 3.106856500532962e-06, 'epoch': 0.44}
 44%|████▍     | 1285/2906 [4:13:27<5:16:30, 11.72s/it] 44%|████▍     | 1286/2906 [4:13:40<5:21:16, 11.90s/it]                                                       {'loss': 0.795, 'grad_norm': 1.206547737121582, 'learning_rate': 3.1041408410667147e-06, 'epoch': 0.44}
 44%|████▍     | 1286/2906 [4:13:40<5:21:16, 11.90s/it] 44%|████▍     | 1287/2906 [4:13:51<5:20:02, 11.86s/it]                                                       {'loss': 0.771, 'grad_norm': 1.3340916633605957, 'learning_rate': 3.1014244243098723e-06, 'epoch': 0.44}
 44%|████▍     | 1287/2906 [4:13:51<5:20:02, 11.86s/it] 44%|████▍     | 1288/2906 [4:14:03<5:14:15, 11.65s/it]                                                       {'loss': 0.788, 'grad_norm': 1.3003302812576294, 'learning_rate': 3.098707253667466e-06, 'epoch': 0.44}
 44%|████▍     | 1288/2906 [4:14:03<5:14:15, 11.65s/it] 44%|████▍     | 1289/2906 [4:14:14<5:15:08, 11.69s/it]                                                       {'loss': 0.7974, 'grad_norm': 1.3571043014526367, 'learning_rate': 3.0959893325454675e-06, 'epoch': 0.44}
 44%|████▍     | 1289/2906 [4:14:14<5:15:08, 11.69s/it] 44%|████▍     | 1290/2906 [4:14:26<5:14:21, 11.67s/it]                                                       {'loss': 0.7975, 'grad_norm': 1.331431269645691, 'learning_rate': 3.093270664350792e-06, 'epoch': 0.44}
 44%|████▍     | 1290/2906 [4:14:26<5:14:21, 11.67s/it] 44%|████▍     | 1291/2906 [4:14:38<5:15:54, 11.74s/it]                                                       {'loss': 0.7401, 'grad_norm': 1.2833809852600098, 'learning_rate': 3.09055125249129e-06, 'epoch': 0.44}
 44%|████▍     | 1291/2906 [4:14:38<5:15:54, 11.74s/it] 44%|████▍     | 1292/2906 [4:14:50<5:18:13, 11.83s/it]                                                       {'loss': 0.8734, 'grad_norm': 1.3475459814071655, 'learning_rate': 3.087831100375745e-06, 'epoch': 0.44}
 44%|████▍     | 1292/2906 [4:14:50<5:18:13, 11.83s/it] 44%|████▍     | 1293/2906 [4:15:02<5:17:03, 11.79s/it]                                                       {'loss': 0.8021, 'grad_norm': 1.2694097757339478, 'learning_rate': 3.0851102114138677e-06, 'epoch': 0.44}
 44%|████▍     | 1293/2906 [4:15:02<5:17:03, 11.79s/it] 45%|████▍     | 1294/2906 [4:15:13<5:16:04, 11.76s/it]                                                       {'loss': 0.8404, 'grad_norm': 1.3552902936935425, 'learning_rate': 3.0823885890162926e-06, 'epoch': 0.45}
 45%|████▍     | 1294/2906 [4:15:13<5:16:04, 11.76s/it] 45%|████▍     | 1295/2906 [4:15:25<5:12:07, 11.62s/it]                                                       {'loss': 0.7693, 'grad_norm': 1.26555597782135, 'learning_rate': 3.079666236594573e-06, 'epoch': 0.45}
 45%|████▍     | 1295/2906 [4:15:25<5:12:07, 11.62s/it] 45%|████▍     | 1296/2906 [4:15:37<5:15:37, 11.76s/it]                                                       {'loss': 0.8181, 'grad_norm': 1.4261661767959595, 'learning_rate': 3.0769431575611787e-06, 'epoch': 0.45}
 45%|████▍     | 1296/2906 [4:15:37<5:15:37, 11.76s/it] 45%|████▍     | 1297/2906 [4:15:48<5:13:07, 11.68s/it]                                                       {'loss': 0.6976, 'grad_norm': 1.2603458166122437, 'learning_rate': 3.0742193553294896e-06, 'epoch': 0.45}
 45%|████▍     | 1297/2906 [4:15:48<5:13:07, 11.68s/it] 45%|████▍     | 1298/2906 [4:16:00<5:13:41, 11.70s/it]                                                       {'loss': 0.8089, 'grad_norm': 1.3723347187042236, 'learning_rate': 3.0714948333137913e-06, 'epoch': 0.45}
 45%|████▍     | 1298/2906 [4:16:00<5:13:41, 11.70s/it] 45%|████▍     | 1299/2906 [4:16:11<5:11:29, 11.63s/it]                                                       {'loss': 0.7957, 'grad_norm': 1.2965312004089355, 'learning_rate': 3.0687695949292724e-06, 'epoch': 0.45}
 45%|████▍     | 1299/2906 [4:16:11<5:11:29, 11.63s/it] 45%|████▍     | 1300/2906 [4:16:23<5:09:45, 11.57s/it]                                                       {'loss': 0.7982, 'grad_norm': 1.4228085279464722, 'learning_rate': 3.0660436435920197e-06, 'epoch': 0.45}
 45%|████▍     | 1300/2906 [4:16:23<5:09:45, 11.57s/it] 45%|████▍     | 1301/2906 [4:16:34<5:09:26, 11.57s/it]                                                       {'loss': 0.7917, 'grad_norm': 1.248152494430542, 'learning_rate': 3.063316982719014e-06, 'epoch': 0.45}
 45%|████▍     | 1301/2906 [4:16:34<5:09:26, 11.57s/it] 45%|████▍     | 1302/2906 [4:16:46<5:13:21, 11.72s/it]                                                       {'loss': 0.7476, 'grad_norm': 1.2319613695144653, 'learning_rate': 3.060589615728124e-06, 'epoch': 0.45}
 45%|████▍     | 1302/2906 [4:16:46<5:13:21, 11.72s/it] 45%|████▍     | 1303/2906 [4:16:58<5:12:50, 11.71s/it]                                                       {'loss': 0.8325, 'grad_norm': 1.3453096151351929, 'learning_rate': 3.0578615460381047e-06, 'epoch': 0.45}
 45%|████▍     | 1303/2906 [4:16:58<5:12:50, 11.71s/it] 45%|████▍     | 1304/2906 [4:17:10<5:10:35, 11.63s/it]                                                       {'loss': 0.7702, 'grad_norm': 1.3007715940475464, 'learning_rate': 3.055132777068592e-06, 'epoch': 0.45}
 45%|████▍     | 1304/2906 [4:17:10<5:10:35, 11.63s/it] 45%|████▍     | 1305/2906 [4:17:21<5:12:12, 11.70s/it]                                                       {'loss': 0.8153, 'grad_norm': 1.2592867612838745, 'learning_rate': 3.0524033122400974e-06, 'epoch': 0.45}
 45%|████▍     | 1305/2906 [4:17:21<5:12:12, 11.70s/it] 45%|████▍     | 1306/2906 [4:17:33<5:09:11, 11.59s/it]                                                       {'loss': 0.8385, 'grad_norm': 1.4397480487823486, 'learning_rate': 3.0496731549740066e-06, 'epoch': 0.45}
 45%|████▍     | 1306/2906 [4:17:33<5:09:11, 11.59s/it] 45%|████▍     | 1307/2906 [4:17:45<5:12:22, 11.72s/it]                                                       {'loss': 0.7958, 'grad_norm': 1.304347276687622, 'learning_rate': 3.04694230869257e-06, 'epoch': 0.45}
 45%|████▍     | 1307/2906 [4:17:45<5:12:22, 11.72s/it] 45%|████▌     | 1308/2906 [4:17:57<5:12:07, 11.72s/it]                                                       {'loss': 0.7943, 'grad_norm': 1.2901126146316528, 'learning_rate': 3.044210776818906e-06, 'epoch': 0.45}
 45%|████▌     | 1308/2906 [4:17:57<5:12:07, 11.72s/it] 45%|████▌     | 1309/2906 [4:18:08<5:11:47, 11.71s/it]                                                       {'loss': 0.8587, 'grad_norm': 1.3150649070739746, 'learning_rate': 3.0414785627769884e-06, 'epoch': 0.45}
 45%|████▌     | 1309/2906 [4:18:08<5:11:47, 11.71s/it] 45%|████▌     | 1310/2906 [4:18:20<5:10:29, 11.67s/it]                                                       {'loss': 0.8047, 'grad_norm': 1.2292912006378174, 'learning_rate': 3.0387456699916475e-06, 'epoch': 0.45}
 45%|████▌     | 1310/2906 [4:18:20<5:10:29, 11.67s/it] 45%|████▌     | 1311/2906 [4:18:32<5:11:12, 11.71s/it]                                                       {'loss': 0.7956, 'grad_norm': 1.2784991264343262, 'learning_rate': 3.036012101888565e-06, 'epoch': 0.45}
 45%|████▌     | 1311/2906 [4:18:32<5:11:12, 11.71s/it] 45%|████▌     | 1312/2906 [4:18:43<5:10:36, 11.69s/it]                                                       {'loss': 0.8025, 'grad_norm': 1.245921015739441, 'learning_rate': 3.0332778618942693e-06, 'epoch': 0.45}
 45%|████▌     | 1312/2906 [4:18:43<5:10:36, 11.69s/it] 45%|████▌     | 1313/2906 [4:18:55<5:13:12, 11.80s/it]                                                       {'loss': 0.814, 'grad_norm': 1.3756624460220337, 'learning_rate': 3.0305429534361304e-06, 'epoch': 0.45}
 45%|████▌     | 1313/2906 [4:18:55<5:13:12, 11.80s/it] 45%|████▌     | 1314/2906 [4:19:07<5:12:24, 11.77s/it]                                                       {'loss': 0.829, 'grad_norm': 1.3559004068374634, 'learning_rate': 3.0278073799423553e-06, 'epoch': 0.45}
 45%|████▌     | 1314/2906 [4:19:07<5:12:24, 11.77s/it] 45%|████▌     | 1315/2906 [4:19:19<5:16:08, 11.92s/it]                                                       {'loss': 0.7768, 'grad_norm': 1.283174753189087, 'learning_rate': 3.0250711448419867e-06, 'epoch': 0.45}
 45%|████▌     | 1315/2906 [4:19:19<5:16:08, 11.92s/it] 45%|████▌     | 1316/2906 [4:19:31<5:13:05, 11.82s/it]                                                       {'loss': 0.7667, 'grad_norm': 1.4164247512817383, 'learning_rate': 3.0223342515648953e-06, 'epoch': 0.45}
 45%|████▌     | 1316/2906 [4:19:31<5:13:05, 11.82s/it] 45%|████▌     | 1317/2906 [4:19:43<5:13:56, 11.85s/it]                                                       {'loss': 0.7688, 'grad_norm': 1.3534214496612549, 'learning_rate': 3.0195967035417765e-06, 'epoch': 0.45}
 45%|████▌     | 1317/2906 [4:19:43<5:13:56, 11.85s/it] 45%|████▌     | 1318/2906 [4:19:54<5:11:23, 11.77s/it]                                                       {'loss': 0.8108, 'grad_norm': 1.3327624797821045, 'learning_rate': 3.0168585042041478e-06, 'epoch': 0.45}
 45%|████▌     | 1318/2906 [4:19:54<5:11:23, 11.77s/it] 45%|████▌     | 1319/2906 [4:20:06<5:12:22, 11.81s/it]                                                       {'loss': 0.7303, 'grad_norm': 1.232786774635315, 'learning_rate': 3.014119656984341e-06, 'epoch': 0.45}
 45%|████▌     | 1319/2906 [4:20:06<5:12:22, 11.81s/it] 45%|████▌     | 1320/2906 [4:20:18<5:10:18, 11.74s/it]                                                       {'loss': 0.8727, 'grad_norm': 1.3975290060043335, 'learning_rate': 3.011380165315503e-06, 'epoch': 0.45}
 45%|████▌     | 1320/2906 [4:20:18<5:10:18, 11.74s/it] 45%|████▌     | 1321/2906 [4:20:29<5:06:20, 11.60s/it]                                                       {'loss': 0.8209, 'grad_norm': 1.2444089651107788, 'learning_rate': 3.0086400326315853e-06, 'epoch': 0.45}
 45%|████▌     | 1321/2906 [4:20:29<5:06:20, 11.60s/it] 45%|████▌     | 1322/2906 [4:20:41<5:08:42, 11.69s/it]                                                       {'loss': 0.7986, 'grad_norm': 1.3888620138168335, 'learning_rate': 3.0058992623673446e-06, 'epoch': 0.45}
 45%|████▌     | 1322/2906 [4:20:41<5:08:42, 11.69s/it] 46%|████▌     | 1323/2906 [4:20:53<5:11:32, 11.81s/it]                                                       {'loss': 0.8093, 'grad_norm': 1.2544565200805664, 'learning_rate': 3.0031578579583375e-06, 'epoch': 0.46}
 46%|████▌     | 1323/2906 [4:20:53<5:11:32, 11.81s/it] 46%|████▌     | 1324/2906 [4:21:05<5:09:17, 11.73s/it]                                                       {'loss': 0.8195, 'grad_norm': 1.3043632507324219, 'learning_rate': 3.0004158228409154e-06, 'epoch': 0.46}
 46%|████▌     | 1324/2906 [4:21:05<5:09:17, 11.73s/it] 46%|████▌     | 1325/2906 [4:21:17<5:13:34, 11.90s/it]                                                       {'loss': 0.843, 'grad_norm': 1.3587716817855835, 'learning_rate': 2.9976731604522175e-06, 'epoch': 0.46}
 46%|████▌     | 1325/2906 [4:21:17<5:13:34, 11.90s/it] 46%|████▌     | 1326/2906 [4:21:29<5:13:29, 11.90s/it]                                                       {'loss': 0.8141, 'grad_norm': 1.3214740753173828, 'learning_rate': 2.9949298742301715e-06, 'epoch': 0.46}
 46%|████▌     | 1326/2906 [4:21:29<5:13:29, 11.90s/it] 46%|████▌     | 1327/2906 [4:21:40<5:09:41, 11.77s/it]                                                       {'loss': 0.8029, 'grad_norm': 1.2061959505081177, 'learning_rate': 2.992185967613489e-06, 'epoch': 0.46}
 46%|████▌     | 1327/2906 [4:21:40<5:09:41, 11.77s/it] 46%|████▌     | 1328/2906 [4:21:52<5:09:30, 11.77s/it]                                                       {'loss': 0.8085, 'grad_norm': 1.3271087408065796, 'learning_rate': 2.989441444041655e-06, 'epoch': 0.46}
 46%|████▌     | 1328/2906 [4:21:52<5:09:30, 11.77s/it] 46%|████▌     | 1329/2906 [4:22:04<5:08:51, 11.75s/it]                                                       {'loss': 0.7643, 'grad_norm': 1.232622742652893, 'learning_rate': 2.9866963069549315e-06, 'epoch': 0.46}
 46%|████▌     | 1329/2906 [4:22:04<5:08:51, 11.75s/it] 46%|████▌     | 1330/2906 [4:22:16<5:08:50, 11.76s/it]                                                       {'loss': 0.8048, 'grad_norm': 1.2770771980285645, 'learning_rate': 2.9839505597943467e-06, 'epoch': 0.46}
 46%|████▌     | 1330/2906 [4:22:16<5:08:50, 11.76s/it] 46%|████▌     | 1331/2906 [4:22:27<5:06:15, 11.67s/it]                                                       {'loss': 0.8283, 'grad_norm': 1.3514597415924072, 'learning_rate': 2.9812042060016968e-06, 'epoch': 0.46}
 46%|████▌     | 1331/2906 [4:22:27<5:06:15, 11.67s/it] 46%|████▌     | 1332/2906 [4:22:39<5:09:08, 11.78s/it]                                                       {'loss': 0.8182, 'grad_norm': 1.2443336248397827, 'learning_rate': 2.978457249019534e-06, 'epoch': 0.46}
 46%|████▌     | 1332/2906 [4:22:39<5:09:08, 11.78s/it] 46%|████▌     | 1333/2906 [4:22:51<5:06:17, 11.68s/it]                                                       {'loss': 0.8627, 'grad_norm': 1.3332116603851318, 'learning_rate': 2.975709692291171e-06, 'epoch': 0.46}
 46%|████▌     | 1333/2906 [4:22:51<5:06:17, 11.68s/it] 46%|████▌     | 1334/2906 [4:23:03<5:11:45, 11.90s/it]                                                       {'loss': 0.7688, 'grad_norm': 1.3640180826187134, 'learning_rate': 2.9729615392606694e-06, 'epoch': 0.46}
 46%|████▌     | 1334/2906 [4:23:03<5:11:45, 11.90s/it] 46%|████▌     | 1335/2906 [4:23:14<5:08:34, 11.78s/it]                                                       {'loss': 0.8938, 'grad_norm': 1.3435806035995483, 'learning_rate': 2.9702127933728403e-06, 'epoch': 0.46}
 46%|████▌     | 1335/2906 [4:23:14<5:08:34, 11.78s/it] 46%|████▌     | 1336/2906 [4:23:26<5:08:29, 11.79s/it]                                                       {'loss': 0.8229, 'grad_norm': 1.233996868133545, 'learning_rate': 2.967463458073236e-06, 'epoch': 0.46}
 46%|████▌     | 1336/2906 [4:23:26<5:08:29, 11.79s/it] 46%|████▌     | 1337/2906 [4:23:39<5:12:31, 11.95s/it]                                                       {'loss': 0.7689, 'grad_norm': 1.3171881437301636, 'learning_rate': 2.9647135368081488e-06, 'epoch': 0.46}
 46%|████▌     | 1337/2906 [4:23:39<5:12:31, 11.95s/it] 46%|████▌     | 1338/2906 [4:23:50<5:11:23, 11.92s/it]                                                       {'loss': 0.7606, 'grad_norm': 1.2769839763641357, 'learning_rate': 2.961963033024605e-06, 'epoch': 0.46}
 46%|████▌     | 1338/2906 [4:23:50<5:11:23, 11.92s/it] 46%|████▌     | 1339/2906 [4:24:02<5:08:55, 11.83s/it]                                                       {'loss': 0.8035, 'grad_norm': 1.2259206771850586, 'learning_rate': 2.9592119501703607e-06, 'epoch': 0.46}
 46%|████▌     | 1339/2906 [4:24:02<5:08:55, 11.83s/it] 46%|████▌     | 1340/2906 [4:24:14<5:11:50, 11.95s/it]                                                       {'loss': 0.8682, 'grad_norm': 1.3381022214889526, 'learning_rate': 2.9564602916939013e-06, 'epoch': 0.46}
 46%|████▌     | 1340/2906 [4:24:14<5:11:50, 11.95s/it] 46%|████▌     | 1341/2906 [4:24:26<5:12:40, 11.99s/it]                                                       {'loss': 0.7908, 'grad_norm': 1.3463937044143677, 'learning_rate': 2.9537080610444274e-06, 'epoch': 0.46}
 46%|████▌     | 1341/2906 [4:24:26<5:12:40, 11.99s/it] 46%|████▌     | 1342/2906 [4:24:38<5:10:01, 11.89s/it]                                                       {'loss': 0.8929, 'grad_norm': 1.3547210693359375, 'learning_rate': 2.9509552616718623e-06, 'epoch': 0.46}
 46%|████▌     | 1342/2906 [4:24:38<5:10:01, 11.89s/it] 46%|████▌     | 1343/2906 [4:24:49<5:06:21, 11.76s/it]                                                       {'loss': 0.8298, 'grad_norm': 1.3986515998840332, 'learning_rate': 2.9482018970268395e-06, 'epoch': 0.46}
 46%|████▌     | 1343/2906 [4:24:49<5:06:21, 11.76s/it] 46%|████▌     | 1344/2906 [4:25:01<5:05:24, 11.73s/it]                                                       {'loss': 0.7206, 'grad_norm': 1.217663049697876, 'learning_rate': 2.9454479705607027e-06, 'epoch': 0.46}
 46%|████▌     | 1344/2906 [4:25:01<5:05:24, 11.73s/it] 46%|████▋     | 1345/2906 [4:25:13<5:02:49, 11.64s/it]                                                       {'loss': 0.8215, 'grad_norm': 1.3510724306106567, 'learning_rate': 2.9426934857254975e-06, 'epoch': 0.46}
 46%|████▋     | 1345/2906 [4:25:13<5:02:49, 11.64s/it] 46%|████▋     | 1346/2906 [4:25:24<5:02:39, 11.64s/it]                                                       {'loss': 0.7701, 'grad_norm': 1.242230772972107, 'learning_rate': 2.9399384459739723e-06, 'epoch': 0.46}
 46%|████▋     | 1346/2906 [4:25:24<5:02:39, 11.64s/it] 46%|████▋     | 1347/2906 [4:25:36<5:01:46, 11.61s/it]                                                       {'loss': 0.8004, 'grad_norm': 1.3170307874679565, 'learning_rate': 2.9371828547595695e-06, 'epoch': 0.46}
 46%|████▋     | 1347/2906 [4:25:36<5:01:46, 11.61s/it] 46%|████▋     | 1348/2906 [4:25:47<4:59:41, 11.54s/it]                                                       {'loss': 0.8369, 'grad_norm': 1.2785508632659912, 'learning_rate': 2.934426715536422e-06, 'epoch': 0.46}
 46%|████▋     | 1348/2906 [4:25:47<4:59:41, 11.54s/it] 46%|████▋     | 1349/2906 [4:25:59<5:04:31, 11.73s/it]                                                       {'loss': 0.6961, 'grad_norm': 1.223206877708435, 'learning_rate': 2.9316700317593507e-06, 'epoch': 0.46}
 46%|████▋     | 1349/2906 [4:25:59<5:04:31, 11.73s/it] 46%|████▋     | 1350/2906 [4:26:11<5:06:39, 11.82s/it]                                                       {'loss': 0.7899, 'grad_norm': 1.274608850479126, 'learning_rate': 2.9289128068838604e-06, 'epoch': 0.46}
 46%|████▋     | 1350/2906 [4:26:11<5:06:39, 11.82s/it] 46%|████▋     | 1351/2906 [4:26:24<5:09:26, 11.94s/it]                                                       {'loss': 0.8755, 'grad_norm': 1.2830785512924194, 'learning_rate': 2.92615504436613e-06, 'epoch': 0.46}
 46%|████▋     | 1351/2906 [4:26:24<5:09:26, 11.94s/it] 47%|████▋     | 1352/2906 [4:26:36<5:16:00, 12.20s/it]                                                       {'loss': 0.8189, 'grad_norm': 1.3309375047683716, 'learning_rate': 2.9233967476630176e-06, 'epoch': 0.47}
 47%|████▋     | 1352/2906 [4:26:36<5:16:00, 12.20s/it] 47%|████▋     | 1353/2906 [4:26:48<5:09:43, 11.97s/it]                                                       {'loss': 0.8036, 'grad_norm': 1.3704123497009277, 'learning_rate': 2.920637920232047e-06, 'epoch': 0.47}
 47%|████▋     | 1353/2906 [4:26:48<5:09:43, 11.97s/it] 47%|████▋     | 1354/2906 [4:26:59<5:04:36, 11.78s/it]                                                       {'loss': 0.8635, 'grad_norm': 1.3741170167922974, 'learning_rate': 2.9178785655314095e-06, 'epoch': 0.47}
 47%|████▋     | 1354/2906 [4:26:59<5:04:36, 11.78s/it] 47%|████▋     | 1355/2906 [4:27:11<5:06:00, 11.84s/it]                                                       {'loss': 0.7333, 'grad_norm': 1.2649028301239014, 'learning_rate': 2.9151186870199556e-06, 'epoch': 0.47}
 47%|████▋     | 1355/2906 [4:27:11<5:06:00, 11.84s/it] 47%|████▋     | 1356/2906 [4:27:23<5:08:58, 11.96s/it]                                                       {'loss': 0.7586, 'grad_norm': 1.2277811765670776, 'learning_rate': 2.912358288157194e-06, 'epoch': 0.47}
 47%|████▋     | 1356/2906 [4:27:23<5:08:58, 11.96s/it] 47%|████▋     | 1357/2906 [4:27:35<5:06:23, 11.87s/it]                                                       {'loss': 0.8812, 'grad_norm': 1.7666497230529785, 'learning_rate': 2.9095973724032832e-06, 'epoch': 0.47}
 47%|████▋     | 1357/2906 [4:27:35<5:06:23, 11.87s/it] 47%|████▋     | 1358/2906 [4:27:46<5:00:53, 11.66s/it]                                                       {'loss': 0.7965, 'grad_norm': 1.3464792966842651, 'learning_rate': 2.9068359432190333e-06, 'epoch': 0.47}
 47%|████▋     | 1358/2906 [4:27:46<5:00:53, 11.66s/it] 47%|████▋     | 1359/2906 [4:27:57<4:57:39, 11.54s/it]                                                       {'loss': 0.7743, 'grad_norm': 1.199860692024231, 'learning_rate': 2.9040740040658954e-06, 'epoch': 0.47}
 47%|████▋     | 1359/2906 [4:27:57<4:57:39, 11.54s/it] 47%|████▋     | 1360/2906 [4:28:09<5:00:06, 11.65s/it]                                                       {'loss': 0.7491, 'grad_norm': 1.239802598953247, 'learning_rate': 2.9013115584059607e-06, 'epoch': 0.47}
 47%|████▋     | 1360/2906 [4:28:09<5:00:06, 11.65s/it] 47%|████▋     | 1361/2906 [4:28:20<4:52:04, 11.34s/it]                                                       {'loss': 0.8353, 'grad_norm': 1.4498286247253418, 'learning_rate': 2.8985486097019543e-06, 'epoch': 0.47}
 47%|████▋     | 1361/2906 [4:28:20<4:52:04, 11.34s/it] 47%|████▋     | 1362/2906 [4:28:32<4:53:40, 11.41s/it]                                                       {'loss': 0.8271, 'grad_norm': 1.3139917850494385, 'learning_rate': 2.8957851614172333e-06, 'epoch': 0.47}
 47%|████▋     | 1362/2906 [4:28:32<4:53:40, 11.41s/it] 47%|████▋     | 1363/2906 [4:28:43<4:53:29, 11.41s/it]                                                       {'loss': 0.802, 'grad_norm': 1.2481689453125, 'learning_rate': 2.89302121701578e-06, 'epoch': 0.47}
 47%|████▋     | 1363/2906 [4:28:43<4:53:29, 11.41s/it] 47%|████▋     | 1364/2906 [4:28:55<5:00:03, 11.68s/it]                                                       {'loss': 0.7551, 'grad_norm': 1.2247669696807861, 'learning_rate': 2.890256779962198e-06, 'epoch': 0.47}
 47%|████▋     | 1364/2906 [4:28:55<5:00:03, 11.68s/it] 47%|████▋     | 1365/2906 [4:29:07<4:58:37, 11.63s/it]                                                       {'loss': 0.8196, 'grad_norm': 1.2858885526657104, 'learning_rate': 2.8874918537217118e-06, 'epoch': 0.47}
 47%|████▋     | 1365/2906 [4:29:07<4:58:37, 11.63s/it] 47%|████▋     | 1366/2906 [4:29:18<4:58:27, 11.63s/it]                                                       {'loss': 0.8555, 'grad_norm': 1.3001807928085327, 'learning_rate': 2.884726441760155e-06, 'epoch': 0.47}
 47%|████▋     | 1366/2906 [4:29:18<4:58:27, 11.63s/it] 47%|████▋     | 1367/2906 [4:29:30<4:58:38, 11.64s/it]                                                       {'loss': 0.8213, 'grad_norm': 1.3888587951660156, 'learning_rate': 2.8819605475439716e-06, 'epoch': 0.47}
 47%|████▋     | 1367/2906 [4:29:30<4:58:38, 11.64s/it] 47%|████▋     | 1368/2906 [4:29:42<4:57:15, 11.60s/it]                                                       {'loss': 0.7777, 'grad_norm': 1.3098300695419312, 'learning_rate': 2.8791941745402102e-06, 'epoch': 0.47}
 47%|████▋     | 1368/2906 [4:29:42<4:57:15, 11.60s/it] 47%|████▋     | 1369/2906 [4:29:53<4:57:14, 11.60s/it]                                                       {'loss': 0.8121, 'grad_norm': 1.3151230812072754, 'learning_rate': 2.876427326216521e-06, 'epoch': 0.47}
 47%|████▋     | 1369/2906 [4:29:53<4:57:14, 11.60s/it] 47%|████▋     | 1370/2906 [4:30:05<5:02:24, 11.81s/it]                                                       {'loss': 0.8002, 'grad_norm': 1.3400958776474, 'learning_rate': 2.873660006041147e-06, 'epoch': 0.47}
 47%|████▋     | 1370/2906 [4:30:05<5:02:24, 11.81s/it] 47%|████▋     | 1371/2906 [4:30:17<5:01:24, 11.78s/it]                                                       {'loss': 0.821, 'grad_norm': 1.4125670194625854, 'learning_rate': 2.870892217482925e-06, 'epoch': 0.47}
 47%|████▋     | 1371/2906 [4:30:17<5:01:24, 11.78s/it] 47%|████▋     | 1372/2906 [4:30:29<5:04:13, 11.90s/it]                                                       {'loss': 0.8264, 'grad_norm': 1.2902477979660034, 'learning_rate': 2.868123964011278e-06, 'epoch': 0.47}
 47%|████▋     | 1372/2906 [4:30:29<5:04:13, 11.90s/it] 47%|████▋     | 1373/2906 [4:30:41<5:00:15, 11.75s/it]                                                       {'loss': 0.6951, 'grad_norm': 1.2455977201461792, 'learning_rate': 2.8653552490962122e-06, 'epoch': 0.47}
 47%|████▋     | 1373/2906 [4:30:41<5:00:15, 11.75s/it] 47%|████▋     | 1374/2906 [4:30:53<5:04:56, 11.94s/it]                                                       {'loss': 0.8126, 'grad_norm': 1.2619380950927734, 'learning_rate': 2.862586076208312e-06, 'epoch': 0.47}
 47%|████▋     | 1374/2906 [4:30:53<5:04:56, 11.94s/it] 47%|████▋     | 1375/2906 [4:31:05<5:01:34, 11.82s/it]                                                       {'loss': 0.8331, 'grad_norm': 1.4006564617156982, 'learning_rate': 2.8598164488187354e-06, 'epoch': 0.47}
 47%|████▋     | 1375/2906 [4:31:05<5:01:34, 11.82s/it] 47%|████▋     | 1376/2906 [4:31:16<5:00:18, 11.78s/it]                                                       {'loss': 0.7661, 'grad_norm': 1.2057952880859375, 'learning_rate': 2.85704637039921e-06, 'epoch': 0.47}
 47%|████▋     | 1376/2906 [4:31:16<5:00:18, 11.78s/it] 47%|████▋     | 1377/2906 [4:31:29<5:03:23, 11.91s/it]                                                       {'loss': 0.7712, 'grad_norm': 1.249009370803833, 'learning_rate': 2.8542758444220303e-06, 'epoch': 0.47}
 47%|████▋     | 1377/2906 [4:31:29<5:03:23, 11.91s/it] 47%|████▋     | 1378/2906 [4:31:40<5:02:51, 11.89s/it]                                                       {'loss': 0.7963, 'grad_norm': 1.3418240547180176, 'learning_rate': 2.8515048743600515e-06, 'epoch': 0.47}
 47%|████▋     | 1378/2906 [4:31:40<5:02:51, 11.89s/it] 47%|████▋     | 1379/2906 [4:31:52<4:59:23, 11.76s/it]                                                       {'loss': 0.8029, 'grad_norm': 1.3452584743499756, 'learning_rate': 2.848733463686683e-06, 'epoch': 0.47}
 47%|████▋     | 1379/2906 [4:31:52<4:59:23, 11.76s/it] 47%|████▋     | 1380/2906 [4:32:04<5:00:28, 11.81s/it]                                                       {'loss': 0.8087, 'grad_norm': 1.2633445262908936, 'learning_rate': 2.8459616158758894e-06, 'epoch': 0.47}
 47%|████▋     | 1380/2906 [4:32:04<5:00:28, 11.81s/it] 48%|████▊     | 1381/2906 [4:32:15<4:59:04, 11.77s/it]                                                       {'loss': 0.8119, 'grad_norm': 1.3412469625473022, 'learning_rate': 2.843189334402183e-06, 'epoch': 0.48}
 48%|████▊     | 1381/2906 [4:32:15<4:59:04, 11.77s/it] 48%|████▊     | 1382/2906 [4:32:27<4:54:36, 11.60s/it]                                                       {'loss': 0.8154, 'grad_norm': 1.3650754690170288, 'learning_rate': 2.840416622740617e-06, 'epoch': 0.48}
 48%|████▊     | 1382/2906 [4:32:27<4:54:36, 11.60s/it] 48%|████▊     | 1383/2906 [4:32:39<4:57:03, 11.70s/it]                                                       {'loss': 0.787, 'grad_norm': 1.2966198921203613, 'learning_rate': 2.837643484366787e-06, 'epoch': 0.48}
 48%|████▊     | 1383/2906 [4:32:39<4:57:03, 11.70s/it] 48%|████▊     | 1384/2906 [4:32:51<5:00:46, 11.86s/it]                                                       {'loss': 0.7766, 'grad_norm': 1.286492109298706, 'learning_rate': 2.834869922756821e-06, 'epoch': 0.48}
 48%|████▊     | 1384/2906 [4:32:51<5:00:46, 11.86s/it] 48%|████▊     | 1385/2906 [4:33:02<4:58:53, 11.79s/it]                                                       {'loss': 0.8477, 'grad_norm': 1.485359787940979, 'learning_rate': 2.83209594138738e-06, 'epoch': 0.48}
 48%|████▊     | 1385/2906 [4:33:03<4:58:53, 11.79s/it] 48%|████▊     | 1386/2906 [4:33:14<4:57:40, 11.75s/it]                                                       {'loss': 0.7633, 'grad_norm': 1.3651264905929565, 'learning_rate': 2.829321543735649e-06, 'epoch': 0.48}
 48%|████▊     | 1386/2906 [4:33:14<4:57:40, 11.75s/it] 48%|████▊     | 1387/2906 [4:33:26<4:56:58, 11.73s/it]                                                       {'loss': 0.7918, 'grad_norm': 1.3429453372955322, 'learning_rate': 2.8265467332793358e-06, 'epoch': 0.48}
 48%|████▊     | 1387/2906 [4:33:26<4:56:58, 11.73s/it] 48%|████▊     | 1388/2906 [4:33:37<4:53:34, 11.60s/it]                                                       {'loss': 0.7595, 'grad_norm': 1.3580890893936157, 'learning_rate': 2.823771513496666e-06, 'epoch': 0.48}
 48%|████▊     | 1388/2906 [4:33:37<4:53:34, 11.60s/it] 48%|████▊     | 1389/2906 [4:33:49<4:53:25, 11.61s/it]                                                       {'loss': 0.7499, 'grad_norm': 1.2304837703704834, 'learning_rate': 2.820995887866378e-06, 'epoch': 0.48}
 48%|████▊     | 1389/2906 [4:33:49<4:53:25, 11.61s/it] 48%|████▊     | 1390/2906 [4:34:01<4:54:58, 11.67s/it]                                                       {'loss': 0.7729, 'grad_norm': 1.4288792610168457, 'learning_rate': 2.8182198598677176e-06, 'epoch': 0.48}
 48%|████▊     | 1390/2906 [4:34:01<4:54:58, 11.67s/it] 48%|████▊     | 1391/2906 [4:34:12<4:54:18, 11.66s/it]                                                       {'loss': 0.8174, 'grad_norm': 1.3030537366867065, 'learning_rate': 2.8154434329804366e-06, 'epoch': 0.48}
 48%|████▊     | 1391/2906 [4:34:12<4:54:18, 11.66s/it] 48%|████▊     | 1392/2906 [4:34:24<4:54:25, 11.67s/it]                                                       {'loss': 0.739, 'grad_norm': 1.3694974184036255, 'learning_rate': 2.812666610684787e-06, 'epoch': 0.48}
 48%|████▊     | 1392/2906 [4:34:24<4:54:25, 11.67s/it] 48%|████▊     | 1393/2906 [4:34:35<4:53:40, 11.65s/it]                                                       {'loss': 0.7723, 'grad_norm': 1.226377010345459, 'learning_rate': 2.8098893964615165e-06, 'epoch': 0.48}
 48%|████▊     | 1393/2906 [4:34:36<4:53:40, 11.65s/it] 48%|████▊     | 1394/2906 [4:34:47<4:52:01, 11.59s/it]                                                       {'loss': 0.8499, 'grad_norm': 1.3530540466308594, 'learning_rate': 2.8071117937918607e-06, 'epoch': 0.48}
 48%|████▊     | 1394/2906 [4:34:47<4:52:01, 11.59s/it] 48%|████▊     | 1395/2906 [4:34:59<4:52:41, 11.62s/it]                                                       {'loss': 0.7723, 'grad_norm': 1.2711063623428345, 'learning_rate': 2.8043338061575464e-06, 'epoch': 0.48}
 48%|████▊     | 1395/2906 [4:34:59<4:52:41, 11.62s/it] 48%|████▊     | 1396/2906 [4:35:11<4:59:22, 11.90s/it]                                                       {'loss': 0.8023, 'grad_norm': 1.545038104057312, 'learning_rate': 2.8015554370407817e-06, 'epoch': 0.48}
 48%|████▊     | 1396/2906 [4:35:11<4:59:22, 11.90s/it] 48%|████▊     | 1397/2906 [4:35:23<4:59:54, 11.92s/it]                                                       {'loss': 0.7733, 'grad_norm': 1.2536592483520508, 'learning_rate': 2.7987766899242513e-06, 'epoch': 0.48}
 48%|████▊     | 1397/2906 [4:35:23<4:59:54, 11.92s/it] 48%|████▊     | 1398/2906 [4:35:34<4:55:01, 11.74s/it]                                                       {'loss': 0.7974, 'grad_norm': 1.3977819681167603, 'learning_rate': 2.795997568291116e-06, 'epoch': 0.48}
 48%|████▊     | 1398/2906 [4:35:34<4:55:01, 11.74s/it] 48%|████▊     | 1399/2906 [4:35:46<4:55:42, 11.77s/it]                                                       {'loss': 0.7932, 'grad_norm': 1.3074942827224731, 'learning_rate': 2.7932180756250042e-06, 'epoch': 0.48}
 48%|████▊     | 1399/2906 [4:35:46<4:55:42, 11.77s/it] 48%|████▊     | 1400/2906 [4:35:58<4:53:38, 11.70s/it]                                                       {'loss': 0.8283, 'grad_norm': 1.3740882873535156, 'learning_rate': 2.7904382154100116e-06, 'epoch': 0.48}
 48%|████▊     | 1400/2906 [4:35:58<4:53:38, 11.70s/it] 48%|████▊     | 1401/2906 [4:36:09<4:52:33, 11.66s/it]                                                       {'loss': 0.7588, 'grad_norm': 1.3310627937316895, 'learning_rate': 2.787657991130692e-06, 'epoch': 0.48}
 48%|████▊     | 1401/2906 [4:36:09<4:52:33, 11.66s/it] 48%|████▊     | 1402/2906 [4:36:21<4:52:27, 11.67s/it]                                                       {'loss': 0.8037, 'grad_norm': 1.294256567955017, 'learning_rate': 2.784877406272056e-06, 'epoch': 0.48}
 48%|████▊     | 1402/2906 [4:36:21<4:52:27, 11.67s/it] 48%|████▊     | 1403/2906 [4:36:33<4:51:42, 11.64s/it]                                                       {'loss': 0.8325, 'grad_norm': 1.354118824005127, 'learning_rate': 2.7820964643195685e-06, 'epoch': 0.48}
 48%|████▊     | 1403/2906 [4:36:33<4:51:42, 11.64s/it] 48%|████▊     | 1404/2906 [4:36:44<4:51:15, 11.63s/it]                                                       {'loss': 0.8225, 'grad_norm': 1.3322277069091797, 'learning_rate': 2.7793151687591408e-06, 'epoch': 0.48}
 48%|████▊     | 1404/2906 [4:36:44<4:51:15, 11.63s/it] 48%|████▊     | 1405/2906 [4:36:56<4:50:42, 11.62s/it]                                                       {'loss': 0.8051, 'grad_norm': 1.349117636680603, 'learning_rate': 2.7765335230771255e-06, 'epoch': 0.48}
 48%|████▊     | 1405/2906 [4:36:56<4:50:42, 11.62s/it] 48%|████▊     | 1406/2906 [4:37:07<4:49:55, 11.60s/it]                                                       {'loss': 0.7969, 'grad_norm': 1.3767540454864502, 'learning_rate': 2.7737515307603156e-06, 'epoch': 0.48}
 48%|████▊     | 1406/2906 [4:37:07<4:49:55, 11.60s/it] 48%|████▊     | 1407/2906 [4:37:20<4:56:04, 11.85s/it]                                                       {'loss': 0.8211, 'grad_norm': 1.3710060119628906, 'learning_rate': 2.7709691952959406e-06, 'epoch': 0.48}
 48%|████▊     | 1407/2906 [4:37:20<4:56:04, 11.85s/it] 48%|████▊     | 1408/2906 [4:37:32<4:55:40, 11.84s/it]                                                       {'loss': 0.8564, 'grad_norm': 1.3573328256607056, 'learning_rate': 2.768186520171657e-06, 'epoch': 0.48}
 48%|████▊     | 1408/2906 [4:37:32<4:55:40, 11.84s/it] 48%|████▊     | 1409/2906 [4:37:43<4:53:32, 11.77s/it]                                                       {'loss': 0.8235, 'grad_norm': 1.321630835533142, 'learning_rate': 2.765403508875548e-06, 'epoch': 0.48}
 48%|████▊     | 1409/2906 [4:37:43<4:53:32, 11.77s/it] 49%|████▊     | 1410/2906 [4:37:56<4:57:16, 11.92s/it]                                                       {'loss': 0.8149, 'grad_norm': 1.3054286241531372, 'learning_rate': 2.762620164896119e-06, 'epoch': 0.49}
 49%|████▊     | 1410/2906 [4:37:56<4:57:16, 11.92s/it] 49%|████▊     | 1411/2906 [4:38:07<4:55:45, 11.87s/it]                                                       {'loss': 0.7683, 'grad_norm': 1.3154706954956055, 'learning_rate': 2.759836491722292e-06, 'epoch': 0.49}
 49%|████▊     | 1411/2906 [4:38:07<4:55:45, 11.87s/it] 49%|████▊     | 1412/2906 [4:38:20<4:58:42, 12.00s/it]                                                       {'loss': 0.8276, 'grad_norm': 1.3687609434127808, 'learning_rate': 2.757052492843401e-06, 'epoch': 0.49}
 49%|████▊     | 1412/2906 [4:38:20<4:58:42, 12.00s/it] 49%|████▊     | 1413/2906 [4:38:32<4:57:53, 11.97s/it]                                                       {'loss': 0.7875, 'grad_norm': 1.281806230545044, 'learning_rate': 2.75426817174919e-06, 'epoch': 0.49}
 49%|████▊     | 1413/2906 [4:38:32<4:57:53, 11.97s/it] 49%|████▊     | 1414/2906 [4:38:43<4:57:30, 11.96s/it]                                                       {'loss': 0.7899, 'grad_norm': 1.2540736198425293, 'learning_rate': 2.7514835319298045e-06, 'epoch': 0.49}
 49%|████▊     | 1414/2906 [4:38:43<4:57:30, 11.96s/it] 49%|████▊     | 1415/2906 [4:38:55<4:55:06, 11.88s/it]                                                       {'loss': 0.7931, 'grad_norm': 1.4301133155822754, 'learning_rate': 2.7486985768757905e-06, 'epoch': 0.49}
 49%|████▊     | 1415/2906 [4:38:55<4:55:06, 11.88s/it] 49%|████▊     | 1416/2906 [4:39:07<4:53:08, 11.80s/it]                                                       {'loss': 0.7719, 'grad_norm': 1.31851327419281, 'learning_rate': 2.745913310078091e-06, 'epoch': 0.49}
 49%|████▊     | 1416/2906 [4:39:07<4:53:08, 11.80s/it] 49%|████▉     | 1417/2906 [4:39:18<4:51:43, 11.76s/it]                                                       {'loss': 0.8199, 'grad_norm': 1.2447383403778076, 'learning_rate': 2.743127735028037e-06, 'epoch': 0.49}
 49%|████▉     | 1417/2906 [4:39:18<4:51:43, 11.76s/it] 49%|████▉     | 1418/2906 [4:39:31<4:54:14, 11.86s/it]                                                       {'loss': 0.7374, 'grad_norm': 1.391196608543396, 'learning_rate': 2.7403418552173467e-06, 'epoch': 0.49}
 49%|████▉     | 1418/2906 [4:39:31<4:54:14, 11.86s/it] 49%|████▉     | 1419/2906 [4:39:42<4:52:16, 11.79s/it]                                                       {'loss': 0.7823, 'grad_norm': 1.32707941532135, 'learning_rate': 2.7375556741381216e-06, 'epoch': 0.49}
 49%|████▉     | 1419/2906 [4:39:42<4:52:16, 11.79s/it] 49%|████▉     | 1420/2906 [4:39:54<4:54:29, 11.89s/it]                                                       {'loss': 0.7782, 'grad_norm': 1.274134635925293, 'learning_rate': 2.7347691952828394e-06, 'epoch': 0.49}
 49%|████▉     | 1420/2906 [4:39:54<4:54:29, 11.89s/it] 49%|████▉     | 1421/2906 [4:40:06<4:56:32, 11.98s/it]                                                       {'loss': 0.8288, 'grad_norm': 1.3513795137405396, 'learning_rate': 2.731982422144352e-06, 'epoch': 0.49}
 49%|████▉     | 1421/2906 [4:40:07<4:56:32, 11.98s/it] 49%|████▉     | 1422/2906 [4:40:18<4:54:23, 11.90s/it]                                                       {'loss': 0.7525, 'grad_norm': 1.3735913038253784, 'learning_rate': 2.7291953582158786e-06, 'epoch': 0.49}
 49%|████▉     | 1422/2906 [4:40:18<4:54:23, 11.90s/it] 49%|████▉     | 1423/2906 [4:40:30<4:51:16, 11.78s/it]                                                       {'loss': 0.8138, 'grad_norm': 1.3032259941101074, 'learning_rate': 2.726408006991006e-06, 'epoch': 0.49}
 49%|████▉     | 1423/2906 [4:40:30<4:51:16, 11.78s/it] 49%|████▉     | 1424/2906 [4:40:42<4:52:40, 11.85s/it]                                                       {'loss': 0.7843, 'grad_norm': 1.3090953826904297, 'learning_rate': 2.723620371963678e-06, 'epoch': 0.49}
 49%|████▉     | 1424/2906 [4:40:42<4:52:40, 11.85s/it] 49%|████▉     | 1425/2906 [4:40:53<4:50:44, 11.78s/it]                                                       {'loss': 0.7336, 'grad_norm': 1.3395463228225708, 'learning_rate': 2.7208324566281946e-06, 'epoch': 0.49}
 49%|████▉     | 1425/2906 [4:40:53<4:50:44, 11.78s/it] 49%|████▉     | 1426/2906 [4:41:05<4:50:38, 11.78s/it]                                                       {'loss': 0.7829, 'grad_norm': 1.318527102470398, 'learning_rate': 2.71804426447921e-06, 'epoch': 0.49}
 49%|████▉     | 1426/2906 [4:41:05<4:50:38, 11.78s/it] 49%|████▉     | 1427/2906 [4:41:17<4:48:51, 11.72s/it]                                                       {'loss': 0.8708, 'grad_norm': 1.3629177808761597, 'learning_rate': 2.715255799011721e-06, 'epoch': 0.49}
 49%|████▉     | 1427/2906 [4:41:17<4:48:51, 11.72s/it] 49%|████▉     | 1428/2906 [4:41:28<4:47:46, 11.68s/it]                                                       {'loss': 0.8005, 'grad_norm': 1.374756932258606, 'learning_rate': 2.712467063721071e-06, 'epoch': 0.49}
 49%|████▉     | 1428/2906 [4:41:28<4:47:46, 11.68s/it] 49%|████▉     | 1429/2906 [4:41:40<4:44:26, 11.56s/it]                                                       {'loss': 0.8558, 'grad_norm': 1.3321466445922852, 'learning_rate': 2.7096780621029386e-06, 'epoch': 0.49}
 49%|████▉     | 1429/2906 [4:41:40<4:44:26, 11.56s/it] 49%|████▉     | 1430/2906 [4:41:51<4:45:37, 11.61s/it]                                                       {'loss': 0.7266, 'grad_norm': 1.231325626373291, 'learning_rate': 2.7068887976533383e-06, 'epoch': 0.49}
 49%|████▉     | 1430/2906 [4:41:51<4:45:37, 11.61s/it] 49%|████▉     | 1431/2906 [4:42:03<4:47:03, 11.68s/it]                                                       {'loss': 0.7626, 'grad_norm': 1.234062910079956, 'learning_rate': 2.7040992738686135e-06, 'epoch': 0.49}
 49%|████▉     | 1431/2906 [4:42:03<4:47:03, 11.68s/it] 49%|████▉     | 1432/2906 [4:42:15<4:49:09, 11.77s/it]                                                       {'loss': 0.8617, 'grad_norm': 1.4695929288864136, 'learning_rate': 2.7013094942454322e-06, 'epoch': 0.49}
 49%|████▉     | 1432/2906 [4:42:15<4:49:09, 11.77s/it] 49%|████▉     | 1433/2906 [4:42:28<4:53:55, 11.97s/it]                                                       {'loss': 0.8526, 'grad_norm': 1.3618333339691162, 'learning_rate': 2.6985194622807835e-06, 'epoch': 0.49}
 49%|████▉     | 1433/2906 [4:42:28<4:53:55, 11.97s/it] 49%|████▉     | 1434/2906 [4:42:39<4:51:58, 11.90s/it]                                                       {'loss': 0.7778, 'grad_norm': 1.3445240259170532, 'learning_rate': 2.695729181471972e-06, 'epoch': 0.49}
 49%|████▉     | 1434/2906 [4:42:39<4:51:58, 11.90s/it] 49%|████▉     | 1435/2906 [4:42:51<4:50:37, 11.85s/it]                                                       {'loss': 0.8068, 'grad_norm': 1.3822873830795288, 'learning_rate': 2.6929386553166165e-06, 'epoch': 0.49}
 49%|████▉     | 1435/2906 [4:42:51<4:50:37, 11.85s/it] 49%|████▉     | 1436/2906 [4:43:03<4:50:58, 11.88s/it]                                                       {'loss': 0.825, 'grad_norm': 1.356543779373169, 'learning_rate': 2.6901478873126403e-06, 'epoch': 0.49}
 49%|████▉     | 1436/2906 [4:43:03<4:50:58, 11.88s/it] 49%|████▉     | 1437/2906 [4:43:15<4:50:19, 11.86s/it]                                                       {'loss': 0.7618, 'grad_norm': 1.3119158744812012, 'learning_rate': 2.687356880958271e-06, 'epoch': 0.49}
 49%|████▉     | 1437/2906 [4:43:15<4:50:19, 11.86s/it] 49%|████▉     | 1438/2906 [4:43:26<4:48:35, 11.80s/it]                                                       {'loss': 0.8079, 'grad_norm': 1.2148994207382202, 'learning_rate': 2.684565639752037e-06, 'epoch': 0.49}
 49%|████▉     | 1438/2906 [4:43:26<4:48:35, 11.80s/it] 50%|████▉     | 1439/2906 [4:43:38<4:46:13, 11.71s/it]                                                       {'loss': 0.8601, 'grad_norm': 1.340164303779602, 'learning_rate': 2.6817741671927587e-06, 'epoch': 0.5}
 50%|████▉     | 1439/2906 [4:43:38<4:46:13, 11.71s/it] 50%|████▉     | 1440/2906 [4:43:50<4:47:02, 11.75s/it]                                                       {'loss': 0.7874, 'grad_norm': 1.3568859100341797, 'learning_rate': 2.6789824667795467e-06, 'epoch': 0.5}
 50%|████▉     | 1440/2906 [4:43:50<4:47:02, 11.75s/it] 50%|████▉     | 1441/2906 [4:44:02<4:48:46, 11.83s/it]                                                       {'loss': 0.7839, 'grad_norm': 1.2184009552001953, 'learning_rate': 2.676190542011797e-06, 'epoch': 0.5}
 50%|████▉     | 1441/2906 [4:44:02<4:48:46, 11.83s/it] 50%|████▉     | 1442/2906 [4:44:14<4:49:45, 11.88s/it]                                                       {'loss': 0.7995, 'grad_norm': 1.2876802682876587, 'learning_rate': 2.67339839638919e-06, 'epoch': 0.5}
 50%|████▉     | 1442/2906 [4:44:14<4:49:45, 11.88s/it] 50%|████▉     | 1443/2906 [4:44:25<4:46:42, 11.76s/it]                                                       {'loss': 0.7568, 'grad_norm': 1.2286603450775146, 'learning_rate': 2.670606033411678e-06, 'epoch': 0.5}
 50%|████▉     | 1443/2906 [4:44:25<4:46:42, 11.76s/it] 50%|████▉     | 1444/2906 [4:44:37<4:46:25, 11.75s/it]                                                       {'loss': 0.7711, 'grad_norm': 1.3121278285980225, 'learning_rate': 2.6678134565794893e-06, 'epoch': 0.5}
 50%|████▉     | 1444/2906 [4:44:37<4:46:25, 11.75s/it] 50%|████▉     | 1445/2906 [4:44:48<4:42:41, 11.61s/it]                                                       {'loss': 0.7682, 'grad_norm': 1.4277186393737793, 'learning_rate': 2.6650206693931184e-06, 'epoch': 0.5}
 50%|████▉     | 1445/2906 [4:44:48<4:42:41, 11.61s/it] 50%|████▉     | 1446/2906 [4:45:00<4:43:18, 11.64s/it]                                                       {'loss': 0.718, 'grad_norm': 1.1819425821304321, 'learning_rate': 2.6622276753533265e-06, 'epoch': 0.5}
 50%|████▉     | 1446/2906 [4:45:00<4:43:18, 11.64s/it] 50%|████▉     | 1447/2906 [4:45:11<4:41:55, 11.59s/it]                                                       {'loss': 0.7761, 'grad_norm': 1.3283058404922485, 'learning_rate': 2.659434477961129e-06, 'epoch': 0.5}
 50%|████▉     | 1447/2906 [4:45:11<4:41:55, 11.59s/it] 50%|████▉     | 1448/2906 [4:45:23<4:40:02, 11.52s/it]                                                       {'loss': 0.7233, 'grad_norm': 1.281214952468872, 'learning_rate': 2.656641080717801e-06, 'epoch': 0.5}
 50%|████▉     | 1448/2906 [4:45:23<4:40:02, 11.52s/it] 50%|████▉     | 1449/2906 [4:45:35<4:41:52, 11.61s/it]                                                       {'loss': 0.8055, 'grad_norm': 1.2855868339538574, 'learning_rate': 2.653847487124865e-06, 'epoch': 0.5}
 50%|████▉     | 1449/2906 [4:45:35<4:41:52, 11.61s/it] 50%|████▉     | 1450/2906 [4:45:46<4:41:12, 11.59s/it]                                                       {'loss': 0.8232, 'grad_norm': 1.347415804862976, 'learning_rate': 2.6510537006840914e-06, 'epoch': 0.5}
 50%|████▉     | 1450/2906 [4:45:46<4:41:12, 11.59s/it] 50%|████▉     | 1451/2906 [4:45:58<4:42:55, 11.67s/it]                                                       {'loss': 0.8391, 'grad_norm': 1.3412522077560425, 'learning_rate': 2.648259724897492e-06, 'epoch': 0.5}
 50%|████▉     | 1451/2906 [4:45:58<4:42:55, 11.67s/it] 50%|████▉     | 1452/2906 [4:46:09<4:38:37, 11.50s/it]                                                       {'loss': 0.8288, 'grad_norm': 1.3413550853729248, 'learning_rate': 2.6454655632673156e-06, 'epoch': 0.5}
 50%|████▉     | 1452/2906 [4:46:09<4:38:37, 11.50s/it] 50%|█████     | 1453/2906 [4:46:21<4:40:23, 11.58s/it]                                                       {'loss': 0.8033, 'grad_norm': 1.309883952140808, 'learning_rate': 2.6426712192960423e-06, 'epoch': 0.5}
 50%|█████     | 1453/2906 [4:46:21<4:40:23, 11.58s/it] 50%|█████     | 1454/2906 [4:46:32<4:39:37, 11.55s/it]                                                       {'loss': 0.7692, 'grad_norm': 1.3130937814712524, 'learning_rate': 2.6398766964863846e-06, 'epoch': 0.5}
 50%|█████     | 1454/2906 [4:46:32<4:39:37, 11.55s/it] 50%|█████     | 1455/2906 [4:46:44<4:43:16, 11.71s/it]                                                       {'loss': 0.8457, 'grad_norm': 1.3181172609329224, 'learning_rate': 2.637081998341277e-06, 'epoch': 0.5}
 50%|█████     | 1455/2906 [4:46:44<4:43:16, 11.71s/it] 50%|█████     | 1456/2906 [4:46:56<4:43:35, 11.73s/it]                                                       {'loss': 0.8449, 'grad_norm': 1.25864577293396, 'learning_rate': 2.6342871283638733e-06, 'epoch': 0.5}
 50%|█████     | 1456/2906 [4:46:56<4:43:35, 11.73s/it] 50%|█████     | 1457/2906 [4:47:07<4:39:24, 11.57s/it]                                                       {'loss': 0.7842, 'grad_norm': 1.2809529304504395, 'learning_rate': 2.631492090057543e-06, 'epoch': 0.5}
 50%|█████     | 1457/2906 [4:47:07<4:39:24, 11.57s/it] 50%|█████     | 1458/2906 [4:47:19<4:38:03, 11.52s/it]                                                       {'loss': 0.749, 'grad_norm': 1.3000315427780151, 'learning_rate': 2.6286968869258666e-06, 'epoch': 0.5}
 50%|█████     | 1458/2906 [4:47:19<4:38:03, 11.52s/it] 50%|█████     | 1459/2906 [4:47:31<4:39:19, 11.58s/it]                                                       {'loss': 0.7543, 'grad_norm': 1.185028314590454, 'learning_rate': 2.6259015224726325e-06, 'epoch': 0.5}
 50%|█████     | 1459/2906 [4:47:31<4:39:19, 11.58s/it] 50%|█████     | 1460/2906 [4:47:42<4:41:14, 11.67s/it]                                                       {'loss': 0.7886, 'grad_norm': 1.2994505167007446, 'learning_rate': 2.623106000201829e-06, 'epoch': 0.5}
 50%|█████     | 1460/2906 [4:47:42<4:41:14, 11.67s/it] 50%|█████     | 1461/2906 [4:47:54<4:36:55, 11.50s/it]                                                       {'loss': 0.7968, 'grad_norm': 1.360280156135559, 'learning_rate': 2.6203103236176446e-06, 'epoch': 0.5}
 50%|█████     | 1461/2906 [4:47:54<4:36:55, 11.50s/it] 50%|█████     | 1462/2906 [4:48:05<4:39:32, 11.62s/it]                                                       {'loss': 0.8472, 'grad_norm': 1.2936129570007324, 'learning_rate': 2.61751449622446e-06, 'epoch': 0.5}
 50%|█████     | 1462/2906 [4:48:05<4:39:32, 11.62s/it] 50%|█████     | 1463/2906 [4:48:18<4:42:36, 11.75s/it]                                                       {'loss': 0.7441, 'grad_norm': 1.2789576053619385, 'learning_rate': 2.6147185215268446e-06, 'epoch': 0.5}
 50%|█████     | 1463/2906 [4:48:18<4:42:36, 11.75s/it] 50%|█████     | 1464/2906 [4:48:29<4:42:05, 11.74s/it]                                                       {'loss': 0.7529, 'grad_norm': 1.35873544216156, 'learning_rate': 2.611922403029552e-06, 'epoch': 0.5}
 50%|█████     | 1464/2906 [4:48:29<4:42:05, 11.74s/it] 50%|█████     | 1465/2906 [4:48:41<4:42:09, 11.75s/it]                                                       {'loss': 0.8055, 'grad_norm': 1.4482923746109009, 'learning_rate': 2.609126144237519e-06, 'epoch': 0.5}
 50%|█████     | 1465/2906 [4:48:41<4:42:09, 11.75s/it] 50%|█████     | 1466/2906 [4:48:53<4:43:30, 11.81s/it]                                                       {'loss': 0.7866, 'grad_norm': 1.2252624034881592, 'learning_rate': 2.6063297486558558e-06, 'epoch': 0.5}
 50%|█████     | 1466/2906 [4:48:53<4:43:30, 11.81s/it] 50%|█████     | 1467/2906 [4:49:05<4:42:33, 11.78s/it]                                                       {'loss': 0.8116, 'grad_norm': 1.3240307569503784, 'learning_rate': 2.603533219789844e-06, 'epoch': 0.5}
 50%|█████     | 1467/2906 [4:49:05<4:42:33, 11.78s/it] 51%|█████     | 1468/2906 [4:49:16<4:40:37, 11.71s/it]                                                       {'loss': 0.806, 'grad_norm': 1.3410474061965942, 'learning_rate': 2.6007365611449315e-06, 'epoch': 0.51}
 51%|█████     | 1468/2906 [4:49:16<4:40:37, 11.71s/it] 51%|█████     | 1469/2906 [4:49:28<4:40:45, 11.72s/it]                                                       {'loss': 0.8001, 'grad_norm': 1.3581082820892334, 'learning_rate': 2.597939776226732e-06, 'epoch': 0.51}
 51%|█████     | 1469/2906 [4:49:28<4:40:45, 11.72s/it] 51%|█████     | 1470/2906 [4:49:39<4:38:08, 11.62s/it]                                                       {'loss': 0.8279, 'grad_norm': 1.2745842933654785, 'learning_rate': 2.595142868541015e-06, 'epoch': 0.51}
 51%|█████     | 1470/2906 [4:49:39<4:38:08, 11.62s/it] 51%|█████     | 1471/2906 [4:49:51<4:37:06, 11.59s/it]                                                       {'loss': 0.8255, 'grad_norm': 1.3139991760253906, 'learning_rate': 2.5923458415937048e-06, 'epoch': 0.51}
 51%|█████     | 1471/2906 [4:49:51<4:37:06, 11.59s/it] 51%|█████     | 1472/2906 [4:50:03<4:37:29, 11.61s/it]                                                       {'loss': 0.795, 'grad_norm': 1.3777363300323486, 'learning_rate': 2.5895486988908743e-06, 'epoch': 0.51}
 51%|█████     | 1472/2906 [4:50:03<4:37:29, 11.61s/it] 51%|█████     | 1473/2906 [4:50:14<4:38:46, 11.67s/it]                                                       {'loss': 0.794, 'grad_norm': 1.3613523244857788, 'learning_rate': 2.586751443938742e-06, 'epoch': 0.51}
 51%|█████     | 1473/2906 [4:50:14<4:38:46, 11.67s/it] 51%|█████     | 1474/2906 [4:50:26<4:40:33, 11.75s/it]                                                       {'loss': 0.8179, 'grad_norm': 1.2879348993301392, 'learning_rate': 2.583954080243668e-06, 'epoch': 0.51}
 51%|█████     | 1474/2906 [4:50:26<4:40:33, 11.75s/it] 51%|█████     | 1475/2906 [4:50:38<4:37:12, 11.62s/it]                                                       {'loss': 0.7557, 'grad_norm': 1.300568699836731, 'learning_rate': 2.581156611312148e-06, 'epoch': 0.51}
 51%|█████     | 1475/2906 [4:50:38<4:37:12, 11.62s/it] 51%|█████     | 1476/2906 [4:50:49<4:38:34, 11.69s/it]                                                       {'loss': 0.7712, 'grad_norm': 1.4080735445022583, 'learning_rate': 2.578359040650808e-06, 'epoch': 0.51}
 51%|█████     | 1476/2906 [4:50:49<4:38:34, 11.69s/it] 51%|█████     | 1477/2906 [4:51:01<4:35:33, 11.57s/it]                                                       {'loss': 0.7949, 'grad_norm': 1.3481206893920898, 'learning_rate': 2.5755613717664053e-06, 'epoch': 0.51}
 51%|█████     | 1477/2906 [4:51:01<4:35:33, 11.57s/it] 51%|█████     | 1478/2906 [4:51:13<4:39:08, 11.73s/it]                                                       {'loss': 0.7806, 'grad_norm': 1.2574987411499023, 'learning_rate': 2.5727636081658167e-06, 'epoch': 0.51}
 51%|█████     | 1478/2906 [4:51:13<4:39:08, 11.73s/it] 51%|█████     | 1479/2906 [4:51:24<4:34:43, 11.55s/it]                                                       {'loss': 0.7656, 'grad_norm': 1.296319603919983, 'learning_rate': 2.5699657533560386e-06, 'epoch': 0.51}
 51%|█████     | 1479/2906 [4:51:24<4:34:43, 11.55s/it] 51%|█████     | 1480/2906 [4:51:36<4:38:42, 11.73s/it]                                                       {'loss': 0.7904, 'grad_norm': 1.3412305116653442, 'learning_rate': 2.567167810844183e-06, 'epoch': 0.51}
 51%|█████     | 1480/2906 [4:51:36<4:38:42, 11.73s/it] 51%|█████     | 1481/2906 [4:51:48<4:38:33, 11.73s/it]                                                       {'loss': 0.8163, 'grad_norm': 1.3324452638626099, 'learning_rate': 2.5643697841374722e-06, 'epoch': 0.51}
 51%|█████     | 1481/2906 [4:51:48<4:38:33, 11.73s/it] 51%|█████     | 1482/2906 [4:52:00<4:40:10, 11.80s/it]                                                       {'loss': 0.8132, 'grad_norm': 1.2631144523620605, 'learning_rate': 2.5615716767432307e-06, 'epoch': 0.51}
 51%|█████     | 1482/2906 [4:52:00<4:40:10, 11.80s/it] 51%|█████     | 1483/2906 [4:52:11<4:38:02, 11.72s/it]                                                       {'loss': 0.7695, 'grad_norm': 1.328584909439087, 'learning_rate': 2.5587734921688873e-06, 'epoch': 0.51}
 51%|█████     | 1483/2906 [4:52:11<4:38:02, 11.72s/it] 51%|█████     | 1484/2906 [4:52:23<4:35:22, 11.62s/it]                                                       {'loss': 0.8069, 'grad_norm': 1.3085331916809082, 'learning_rate': 2.5559752339219666e-06, 'epoch': 0.51}
 51%|█████     | 1484/2906 [4:52:23<4:35:22, 11.62s/it] 51%|█████     | 1485/2906 [4:52:35<4:40:11, 11.83s/it]                                                       {'loss': 0.6988, 'grad_norm': 1.2562131881713867, 'learning_rate': 2.553176905510086e-06, 'epoch': 0.51}
 51%|█████     | 1485/2906 [4:52:35<4:40:11, 11.83s/it] 51%|█████     | 1486/2906 [4:52:47<4:40:57, 11.87s/it]                                                       {'loss': 0.81, 'grad_norm': 1.2981789112091064, 'learning_rate': 2.55037851044095e-06, 'epoch': 0.51}
 51%|█████     | 1486/2906 [4:52:47<4:40:57, 11.87s/it] 51%|█████     | 1487/2906 [4:52:59<4:39:39, 11.82s/it]                                                       {'loss': 0.8503, 'grad_norm': 1.3243510723114014, 'learning_rate': 2.547580052222347e-06, 'epoch': 0.51}
 51%|█████     | 1487/2906 [4:52:59<4:39:39, 11.82s/it] 51%|█████     | 1488/2906 [4:53:11<4:40:25, 11.87s/it]                                                       {'loss': 0.7766, 'grad_norm': 1.3082084655761719, 'learning_rate': 2.544781534362144e-06, 'epoch': 0.51}
 51%|█████     | 1488/2906 [4:53:11<4:40:25, 11.87s/it] 51%|█████     | 1489/2906 [4:53:23<4:39:53, 11.85s/it]                                                       {'loss': 0.8107, 'grad_norm': 1.3999879360198975, 'learning_rate': 2.5419829603682857e-06, 'epoch': 0.51}
 51%|█████     | 1489/2906 [4:53:23<4:39:53, 11.85s/it] 51%|█████▏    | 1490/2906 [4:53:34<4:38:41, 11.81s/it]                                                       {'loss': 0.7917, 'grad_norm': 1.2701085805892944, 'learning_rate': 2.539184333748782e-06, 'epoch': 0.51}
 51%|█████▏    | 1490/2906 [4:53:34<4:38:41, 11.81s/it] 51%|█████▏    | 1491/2906 [4:53:46<4:35:46, 11.69s/it]                                                       {'loss': 0.792, 'grad_norm': 1.3254139423370361, 'learning_rate': 2.5363856580117126e-06, 'epoch': 0.51}
 51%|█████▏    | 1491/2906 [4:53:46<4:35:46, 11.69s/it] 51%|█████▏    | 1492/2906 [4:53:57<4:32:20, 11.56s/it]                                                       {'loss': 0.7611, 'grad_norm': 1.282120704650879, 'learning_rate': 2.5335869366652176e-06, 'epoch': 0.51}
 51%|█████▏    | 1492/2906 [4:53:57<4:32:20, 11.56s/it] 51%|█████▏    | 1493/2906 [4:54:08<4:32:08, 11.56s/it]                                                       {'loss': 0.7515, 'grad_norm': 1.310189127922058, 'learning_rate': 2.5307881732174954e-06, 'epoch': 0.51}
 51%|█████▏    | 1493/2906 [4:54:08<4:32:08, 11.56s/it] 51%|█████▏    | 1494/2906 [4:54:20<4:31:50, 11.55s/it]                                                       {'loss': 0.8323, 'grad_norm': 1.291263222694397, 'learning_rate': 2.5279893711767955e-06, 'epoch': 0.51}
 51%|█████▏    | 1494/2906 [4:54:20<4:31:50, 11.55s/it] 51%|█████▏    | 1495/2906 [4:54:31<4:28:55, 11.44s/it]                                                       {'loss': 0.8184, 'grad_norm': 1.3062305450439453, 'learning_rate': 2.525190534051416e-06, 'epoch': 0.51}
 51%|█████▏    | 1495/2906 [4:54:31<4:28:55, 11.44s/it] 51%|█████▏    | 1496/2906 [4:54:43<4:29:03, 11.45s/it]                                                       {'loss': 0.8431, 'grad_norm': 1.3747453689575195, 'learning_rate': 2.5223916653497004e-06, 'epoch': 0.51}
 51%|█████▏    | 1496/2906 [4:54:43<4:29:03, 11.45s/it] 52%|█████▏    | 1497/2906 [4:54:54<4:29:51, 11.49s/it]                                                       {'loss': 0.8154, 'grad_norm': 1.2562057971954346, 'learning_rate': 2.519592768580031e-06, 'epoch': 0.52}
 52%|█████▏    | 1497/2906 [4:54:54<4:29:51, 11.49s/it] 52%|█████▏    | 1498/2906 [4:55:06<4:33:49, 11.67s/it]                                                       {'loss': 0.7974, 'grad_norm': 1.2838127613067627, 'learning_rate': 2.5167938472508242e-06, 'epoch': 0.52}
 52%|█████▏    | 1498/2906 [4:55:06<4:33:49, 11.67s/it] 52%|█████▏    | 1499/2906 [4:55:18<4:33:26, 11.66s/it]                                                       {'loss': 0.8117, 'grad_norm': 1.3074004650115967, 'learning_rate': 2.513994904870528e-06, 'epoch': 0.52}
 52%|█████▏    | 1499/2906 [4:55:18<4:33:26, 11.66s/it] 52%|█████▏    | 1500/2906 [4:55:30<4:35:02, 11.74s/it]                                                       {'loss': 0.8668, 'grad_norm': 1.3304814100265503, 'learning_rate': 2.511195944947618e-06, 'epoch': 0.52}
 52%|█████▏    | 1500/2906 [4:55:30<4:35:02, 11.74s/it] 52%|█████▏    | 1501/2906 [4:55:41<4:31:50, 11.61s/it]                                                       {'loss': 0.7932, 'grad_norm': 1.272310495376587, 'learning_rate': 2.5083969709905904e-06, 'epoch': 0.52}
 52%|█████▏    | 1501/2906 [4:55:41<4:31:50, 11.61s/it] 52%|█████▏    | 1502/2906 [4:55:53<4:30:52, 11.58s/it]                                                       {'loss': 0.8071, 'grad_norm': 1.3467152118682861, 'learning_rate': 2.505597986507958e-06, 'epoch': 0.52}
 52%|█████▏    | 1502/2906 [4:55:53<4:30:52, 11.58s/it] 52%|█████▏    | 1503/2906 [4:56:04<4:31:23, 11.61s/it]                                                       {'loss': 0.7557, 'grad_norm': 1.3856937885284424, 'learning_rate': 2.502798995008249e-06, 'epoch': 0.52}
 52%|█████▏    | 1503/2906 [4:56:04<4:31:23, 11.61s/it] 52%|█████▏    | 1504/2906 [4:56:16<4:30:32, 11.58s/it]                                                       {'loss': 0.7772, 'grad_norm': 1.3431717157363892, 'learning_rate': 2.5e-06, 'epoch': 0.52}
 52%|█████▏    | 1504/2906 [4:56:16<4:30:32, 11.58s/it] 52%|█████▏    | 1505/2906 [4:56:27<4:29:20, 11.54s/it]                                                       {'loss': 0.7767, 'grad_norm': 1.2777396440505981, 'learning_rate': 2.4972010049917513e-06, 'epoch': 0.52}
 52%|█████▏    | 1505/2906 [4:56:27<4:29:20, 11.54s/it] 52%|█████▏    | 1506/2906 [4:56:39<4:29:22, 11.54s/it]                                                       {'loss': 0.8662, 'grad_norm': 1.2945773601531982, 'learning_rate': 2.494402013492043e-06, 'epoch': 0.52}
 52%|█████▏    | 1506/2906 [4:56:39<4:29:22, 11.54s/it] 52%|█████▏    | 1507/2906 [4:56:51<4:33:01, 11.71s/it]                                                       {'loss': 0.8102, 'grad_norm': 1.3805222511291504, 'learning_rate': 2.491603029009411e-06, 'epoch': 0.52}
 52%|█████▏    | 1507/2906 [4:56:51<4:33:01, 11.71s/it] 52%|█████▏    | 1508/2906 [4:57:02<4:29:21, 11.56s/it]                                                       {'loss': 0.7086, 'grad_norm': 1.2955785989761353, 'learning_rate': 2.4888040550523824e-06, 'epoch': 0.52}
 52%|█████▏    | 1508/2906 [4:57:02<4:29:21, 11.56s/it] 52%|█████▏    | 1509/2906 [4:57:14<4:28:10, 11.52s/it]                                                       {'loss': 0.8041, 'grad_norm': 1.3314393758773804, 'learning_rate': 2.4860050951294723e-06, 'epoch': 0.52}
 52%|█████▏    | 1509/2906 [4:57:14<4:28:10, 11.52s/it] 52%|█████▏    | 1510/2906 [4:57:26<4:33:12, 11.74s/it]                                                       {'loss': 0.784, 'grad_norm': 1.3442318439483643, 'learning_rate': 2.4832061527491766e-06, 'epoch': 0.52}
 52%|█████▏    | 1510/2906 [4:57:26<4:33:12, 11.74s/it] 52%|█████▏    | 1511/2906 [4:57:38<4:37:17, 11.93s/it]                                                       {'loss': 0.7951, 'grad_norm': 1.2508344650268555, 'learning_rate': 2.480407231419969e-06, 'epoch': 0.52}
 52%|█████▏    | 1511/2906 [4:57:38<4:37:17, 11.93s/it] 52%|█████▏    | 1512/2906 [4:57:50<4:37:23, 11.94s/it]                                                       {'loss': 0.7544, 'grad_norm': 1.2083574533462524, 'learning_rate': 2.4776083346502995e-06, 'epoch': 0.52}
 52%|█████▏    | 1512/2906 [4:57:50<4:37:23, 11.94s/it] 52%|█████▏    | 1513/2906 [4:58:02<4:34:29, 11.82s/it]                                                       {'loss': 0.7875, 'grad_norm': 1.3330954313278198, 'learning_rate': 2.474809465948584e-06, 'epoch': 0.52}
 52%|█████▏    | 1513/2906 [4:58:02<4:34:29, 11.82s/it] 52%|█████▏    | 1514/2906 [4:58:13<4:33:16, 11.78s/it]                                                       {'loss': 0.7565, 'grad_norm': 1.3417723178863525, 'learning_rate': 2.4720106288232053e-06, 'epoch': 0.52}
 52%|█████▏    | 1514/2906 [4:58:13<4:33:16, 11.78s/it] 52%|█████▏    | 1515/2906 [4:58:25<4:33:02, 11.78s/it]                                                       {'loss': 0.8018, 'grad_norm': 1.3069368600845337, 'learning_rate': 2.469211826782506e-06, 'epoch': 0.52}
 52%|█████▏    | 1515/2906 [4:58:25<4:33:02, 11.78s/it] 52%|█████▏    | 1516/2906 [4:58:37<4:32:07, 11.75s/it]                                                       {'loss': 0.7783, 'grad_norm': 1.2602930068969727, 'learning_rate': 2.4664130633347833e-06, 'epoch': 0.52}
 52%|█████▏    | 1516/2906 [4:58:37<4:32:07, 11.75s/it] 52%|█████▏    | 1517/2906 [4:58:48<4:26:36, 11.52s/it]                                                       {'loss': 0.7518, 'grad_norm': 1.302913784980774, 'learning_rate': 2.4636143419882887e-06, 'epoch': 0.52}
 52%|█████▏    | 1517/2906 [4:58:48<4:26:36, 11.52s/it] 52%|█████▏    | 1518/2906 [4:58:59<4:24:00, 11.41s/it]                                                       {'loss': 0.8337, 'grad_norm': 1.3087379932403564, 'learning_rate': 2.460815666251219e-06, 'epoch': 0.52}
 52%|█████▏    | 1518/2906 [4:58:59<4:24:00, 11.41s/it] 52%|█████▏    | 1519/2906 [4:59:10<4:22:31, 11.36s/it]                                                       {'loss': 0.7306, 'grad_norm': 1.282963514328003, 'learning_rate': 2.4580170396317156e-06, 'epoch': 0.52}
 52%|█████▏    | 1519/2906 [4:59:10<4:22:31, 11.36s/it] 52%|█████▏    | 1520/2906 [4:59:22<4:28:17, 11.61s/it]                                                       {'loss': 0.7852, 'grad_norm': 1.2661348581314087, 'learning_rate': 2.4552184656378562e-06, 'epoch': 0.52}
 52%|█████▏    | 1520/2906 [4:59:22<4:28:17, 11.61s/it] 52%|█████▏    | 1521/2906 [4:59:34<4:26:02, 11.53s/it]                                                       {'loss': 0.8107, 'grad_norm': 1.2844624519348145, 'learning_rate': 2.452419947777654e-06, 'epoch': 0.52}
 52%|█████▏    | 1521/2906 [4:59:34<4:26:02, 11.53s/it] 52%|█████▏    | 1522/2906 [4:59:45<4:26:08, 11.54s/it]                                                       {'loss': 0.824, 'grad_norm': 1.3339492082595825, 'learning_rate': 2.4496214895590508e-06, 'epoch': 0.52}
 52%|█████▏    | 1522/2906 [4:59:45<4:26:08, 11.54s/it] 52%|█████▏    | 1523/2906 [4:59:57<4:26:51, 11.58s/it]                                                       {'loss': 0.7866, 'grad_norm': 1.465254306793213, 'learning_rate': 2.4468230944899147e-06, 'epoch': 0.52}
 52%|█████▏    | 1523/2906 [4:59:57<4:26:51, 11.58s/it] 52%|█████▏    | 1524/2906 [5:00:09<4:28:37, 11.66s/it]                                                       {'loss': 0.8137, 'grad_norm': 1.3792632818222046, 'learning_rate': 2.444024766078034e-06, 'epoch': 0.52}
 52%|█████▏    | 1524/2906 [5:00:09<4:28:37, 11.66s/it] 52%|█████▏    | 1525/2906 [5:00:20<4:27:17, 11.61s/it]                                                       {'loss': 0.7732, 'grad_norm': 1.4188073873519897, 'learning_rate': 2.4412265078311135e-06, 'epoch': 0.52}
 52%|█████▏    | 1525/2906 [5:00:20<4:27:17, 11.61s/it] 53%|█████▎    | 1526/2906 [5:00:32<4:28:59, 11.70s/it]                                                       {'loss': 0.7433, 'grad_norm': 1.3601315021514893, 'learning_rate': 2.43842832325677e-06, 'epoch': 0.53}
 53%|█████▎    | 1526/2906 [5:00:32<4:28:59, 11.70s/it] 53%|█████▎    | 1527/2906 [5:00:44<4:28:14, 11.67s/it]                                                       {'loss': 0.7645, 'grad_norm': 1.3087129592895508, 'learning_rate': 2.435630215862529e-06, 'epoch': 0.53}
 53%|█████▎    | 1527/2906 [5:00:44<4:28:14, 11.67s/it] 53%|█████▎    | 1528/2906 [5:00:56<4:28:53, 11.71s/it]                                                       {'loss': 0.7885, 'grad_norm': 1.2704823017120361, 'learning_rate': 2.4328321891558172e-06, 'epoch': 0.53}
 53%|█████▎    | 1528/2906 [5:00:56<4:28:53, 11.71s/it] 53%|█████▎    | 1529/2906 [5:01:08<4:30:55, 11.81s/it]                                                       {'loss': 0.7643, 'grad_norm': 1.3186016082763672, 'learning_rate': 2.4300342466439623e-06, 'epoch': 0.53}
 53%|█████▎    | 1529/2906 [5:01:08<4:30:55, 11.81s/it] 53%|█████▎    | 1530/2906 [5:01:19<4:28:12, 11.69s/it]                                                       {'loss': 0.7653, 'grad_norm': 1.2264330387115479, 'learning_rate': 2.427236391834184e-06, 'epoch': 0.53}
 53%|█████▎    | 1530/2906 [5:01:19<4:28:12, 11.69s/it] 53%|█████▎    | 1531/2906 [5:01:31<4:30:14, 11.79s/it]                                                       {'loss': 0.7841, 'grad_norm': 1.4331098794937134, 'learning_rate': 2.424438628233595e-06, 'epoch': 0.53}
 53%|█████▎    | 1531/2906 [5:01:31<4:30:14, 11.79s/it] 53%|█████▎    | 1532/2906 [5:01:42<4:26:17, 11.63s/it]                                                       {'loss': 0.7917, 'grad_norm': 1.3972541093826294, 'learning_rate': 2.421640959349192e-06, 'epoch': 0.53}
 53%|█████▎    | 1532/2906 [5:01:42<4:26:17, 11.63s/it] 53%|█████▎    | 1533/2906 [5:01:55<4:29:57, 11.80s/it]                                                       {'loss': 0.83, 'grad_norm': 1.31451416015625, 'learning_rate': 2.418843388687853e-06, 'epoch': 0.53}
 53%|█████▎    | 1533/2906 [5:01:55<4:29:57, 11.80s/it] 53%|█████▎    | 1534/2906 [5:02:06<4:27:39, 11.71s/it]                                                       {'loss': 0.8332, 'grad_norm': 1.2417540550231934, 'learning_rate': 2.416045919756332e-06, 'epoch': 0.53}
 53%|█████▎    | 1534/2906 [5:02:06<4:27:39, 11.71s/it] 53%|█████▎    | 1535/2906 [5:02:17<4:24:01, 11.55s/it]                                                       {'loss': 0.7793, 'grad_norm': 1.3957760334014893, 'learning_rate': 2.4132485560612583e-06, 'epoch': 0.53}
 53%|█████▎    | 1535/2906 [5:02:17<4:24:01, 11.55s/it] 53%|█████▎    | 1536/2906 [5:02:29<4:23:21, 11.53s/it]                                                       {'loss': 0.8221, 'grad_norm': 1.332159161567688, 'learning_rate': 2.410451301109127e-06, 'epoch': 0.53}
 53%|█████▎    | 1536/2906 [5:02:29<4:23:21, 11.53s/it] 53%|█████▎    | 1537/2906 [5:02:40<4:21:09, 11.45s/it]                                                       {'loss': 0.9273, 'grad_norm': 1.4942340850830078, 'learning_rate': 2.4076541584062965e-06, 'epoch': 0.53}
 53%|█████▎    | 1537/2906 [5:02:40<4:21:09, 11.45s/it] 53%|█████▎    | 1538/2906 [5:02:52<4:22:36, 11.52s/it]                                                       {'loss': 0.8163, 'grad_norm': 1.3570284843444824, 'learning_rate': 2.404857131458986e-06, 'epoch': 0.53}
 53%|█████▎    | 1538/2906 [5:02:52<4:22:36, 11.52s/it] 53%|█████▎    | 1539/2906 [5:03:03<4:22:40, 11.53s/it]                                                       {'loss': 0.8084, 'grad_norm': 1.38996422290802, 'learning_rate': 2.402060223773269e-06, 'epoch': 0.53}
 53%|█████▎    | 1539/2906 [5:03:03<4:22:40, 11.53s/it] 53%|█████▎    | 1540/2906 [5:03:15<4:21:07, 11.47s/it]                                                       {'loss': 0.8023, 'grad_norm': 1.2289265394210815, 'learning_rate': 2.3992634388550694e-06, 'epoch': 0.53}
 53%|█████▎    | 1540/2906 [5:03:15<4:21:07, 11.47s/it] 53%|█████▎    | 1541/2906 [5:03:26<4:22:13, 11.53s/it]                                                       {'loss': 0.8458, 'grad_norm': 1.3530058860778809, 'learning_rate': 2.3964667802101574e-06, 'epoch': 0.53}
 53%|█████▎    | 1541/2906 [5:03:26<4:22:13, 11.53s/it] 53%|█████▎    | 1542/2906 [5:03:38<4:22:52, 11.56s/it]                                                       {'loss': 0.8165, 'grad_norm': 1.3690733909606934, 'learning_rate': 2.393670251344145e-06, 'epoch': 0.53}
 53%|█████▎    | 1542/2906 [5:03:38<4:22:52, 11.56s/it] 53%|█████▎    | 1543/2906 [5:03:50<4:23:21, 11.59s/it]                                                       {'loss': 0.7957, 'grad_norm': 1.3697582483291626, 'learning_rate': 2.3908738557624812e-06, 'epoch': 0.53}
 53%|█████▎    | 1543/2906 [5:03:50<4:23:21, 11.59s/it] 53%|█████▎    | 1544/2906 [5:04:01<4:21:11, 11.51s/it]                                                       {'loss': 0.7554, 'grad_norm': 1.2478593587875366, 'learning_rate': 2.3880775969704483e-06, 'epoch': 0.53}
 53%|█████▎    | 1544/2906 [5:04:01<4:21:11, 11.51s/it] 53%|█████▎    | 1545/2906 [5:04:12<4:20:25, 11.48s/it]                                                       {'loss': 0.7486, 'grad_norm': 1.2694545984268188, 'learning_rate': 2.385281478473156e-06, 'epoch': 0.53}
 53%|█████▎    | 1545/2906 [5:04:12<4:20:25, 11.48s/it] 53%|█████▎    | 1546/2906 [5:04:24<4:22:01, 11.56s/it]                                                       {'loss': 0.7959, 'grad_norm': 1.219914197921753, 'learning_rate': 2.382485503775541e-06, 'epoch': 0.53}
 53%|█████▎    | 1546/2906 [5:04:24<4:22:01, 11.56s/it] 53%|█████▎    | 1547/2906 [5:04:35<4:20:10, 11.49s/it]                                                       {'loss': 0.8491, 'grad_norm': 1.3168567419052124, 'learning_rate': 2.379689676382356e-06, 'epoch': 0.53}
 53%|█████▎    | 1547/2906 [5:04:35<4:20:10, 11.49s/it] 53%|█████▎    | 1548/2906 [5:04:47<4:22:47, 11.61s/it]                                                       {'loss': 0.8632, 'grad_norm': 1.2885117530822754, 'learning_rate': 2.3768939997981714e-06, 'epoch': 0.53}
 53%|█████▎    | 1548/2906 [5:04:47<4:22:47, 11.61s/it] 53%|█████▎    | 1549/2906 [5:04:59<4:22:45, 11.62s/it]                                                       {'loss': 0.7797, 'grad_norm': 1.3059237003326416, 'learning_rate': 2.3740984775273684e-06, 'epoch': 0.53}
 53%|█████▎    | 1549/2906 [5:04:59<4:22:45, 11.62s/it] 53%|█████▎    | 1550/2906 [5:05:10<4:19:12, 11.47s/it]                                                       {'loss': 0.7907, 'grad_norm': 1.260353684425354, 'learning_rate': 2.371303113074134e-06, 'epoch': 0.53}
 53%|█████▎    | 1550/2906 [5:05:10<4:19:12, 11.47s/it] 53%|█████▎    | 1551/2906 [5:05:21<4:17:04, 11.38s/it]                                                       {'loss': 0.8141, 'grad_norm': 1.1852580308914185, 'learning_rate': 2.368507909942458e-06, 'epoch': 0.53}
 53%|█████▎    | 1551/2906 [5:05:21<4:17:04, 11.38s/it] 53%|█████▎    | 1552/2906 [5:05:33<4:18:13, 11.44s/it]                                                       {'loss': 0.8178, 'grad_norm': 1.313787579536438, 'learning_rate': 2.3657128716361275e-06, 'epoch': 0.53}
 53%|█████▎    | 1552/2906 [5:05:33<4:18:13, 11.44s/it] 53%|█████▎    | 1553/2906 [5:05:44<4:19:32, 11.51s/it]                                                       {'loss': 0.7509, 'grad_norm': 1.3226631879806519, 'learning_rate': 2.362918001658723e-06, 'epoch': 0.53}
 53%|█████▎    | 1553/2906 [5:05:44<4:19:32, 11.51s/it] 53%|█████▎    | 1554/2906 [5:05:56<4:18:29, 11.47s/it]                                                       {'loss': 0.787, 'grad_norm': 1.266139268875122, 'learning_rate': 2.360123303513615e-06, 'epoch': 0.53}
 53%|█████▎    | 1554/2906 [5:05:56<4:18:29, 11.47s/it] 54%|█████▎    | 1555/2906 [5:06:08<4:22:17, 11.65s/it]                                                       {'loss': 0.8136, 'grad_norm': 1.304271936416626, 'learning_rate': 2.3573287807039577e-06, 'epoch': 0.54}
 54%|█████▎    | 1555/2906 [5:06:08<4:22:17, 11.65s/it] 54%|█████▎    | 1556/2906 [5:06:19<4:22:01, 11.65s/it]                                                       {'loss': 0.7963, 'grad_norm': 1.3712857961654663, 'learning_rate': 2.3545344367326857e-06, 'epoch': 0.54}
 54%|█████▎    | 1556/2906 [5:06:20<4:22:01, 11.65s/it] 54%|█████▎    | 1557/2906 [5:06:31<4:23:04, 11.70s/it]                                                       {'loss': 0.799, 'grad_norm': 1.2856501340866089, 'learning_rate': 2.3517402751025083e-06, 'epoch': 0.54}
 54%|█████▎    | 1557/2906 [5:06:31<4:23:04, 11.70s/it] 54%|█████▎    | 1558/2906 [5:06:43<4:22:38, 11.69s/it]                                                       {'loss': 0.904, 'grad_norm': 1.4070154428482056, 'learning_rate': 2.3489462993159094e-06, 'epoch': 0.54}
 54%|█████▎    | 1558/2906 [5:06:43<4:22:38, 11.69s/it] 54%|█████▎    | 1559/2906 [5:06:54<4:20:39, 11.61s/it]                                                       {'loss': 0.7483, 'grad_norm': 1.2713744640350342, 'learning_rate': 2.3461525128751364e-06, 'epoch': 0.54}
 54%|█████▎    | 1559/2906 [5:06:54<4:20:39, 11.61s/it] 54%|█████▎    | 1560/2906 [5:07:06<4:21:53, 11.67s/it]                                                       {'loss': 0.8345, 'grad_norm': 1.3718230724334717, 'learning_rate': 2.3433589192822e-06, 'epoch': 0.54}
 54%|█████▎    | 1560/2906 [5:07:06<4:21:53, 11.67s/it] 54%|█████▎    | 1561/2906 [5:07:18<4:19:52, 11.59s/it]                                                       {'loss': 0.7799, 'grad_norm': 1.2584102153778076, 'learning_rate': 2.3405655220388718e-06, 'epoch': 0.54}
 54%|█████▎    | 1561/2906 [5:07:18<4:19:52, 11.59s/it] 54%|█████▍    | 1562/2906 [5:07:30<4:24:16, 11.80s/it]                                                       {'loss': 0.8114, 'grad_norm': 1.323194980621338, 'learning_rate': 2.3377723246466748e-06, 'epoch': 0.54}
 54%|█████▍    | 1562/2906 [5:07:30<4:24:16, 11.80s/it] 54%|█████▍    | 1563/2906 [5:07:41<4:19:50, 11.61s/it]                                                       {'loss': 0.7657, 'grad_norm': 1.3789150714874268, 'learning_rate': 2.334979330606882e-06, 'epoch': 0.54}
 54%|█████▍    | 1563/2906 [5:07:41<4:19:50, 11.61s/it] 54%|█████▍    | 1564/2906 [5:07:52<4:17:36, 11.52s/it]                                                       {'loss': 0.8333, 'grad_norm': 1.3275847434997559, 'learning_rate': 2.3321865434205115e-06, 'epoch': 0.54}
 54%|█████▍    | 1564/2906 [5:07:52<4:17:36, 11.52s/it] 54%|█████▍    | 1565/2906 [5:08:04<4:17:49, 11.54s/it]                                                       {'loss': 0.7638, 'grad_norm': 1.2813851833343506, 'learning_rate': 2.3293939665883233e-06, 'epoch': 0.54}
 54%|█████▍    | 1565/2906 [5:08:04<4:17:49, 11.54s/it] 54%|█████▍    | 1566/2906 [5:08:15<4:15:14, 11.43s/it]                                                       {'loss': 0.7992, 'grad_norm': 1.3585675954818726, 'learning_rate': 2.3266016036108114e-06, 'epoch': 0.54}
 54%|█████▍    | 1566/2906 [5:08:15<4:15:14, 11.43s/it] 54%|█████▍    | 1567/2906 [5:08:27<4:18:28, 11.58s/it]                                                       {'loss': 0.8588, 'grad_norm': 1.271531581878662, 'learning_rate': 2.3238094579882037e-06, 'epoch': 0.54}
 54%|█████▍    | 1567/2906 [5:08:27<4:18:28, 11.58s/it] 54%|█████▍    | 1568/2906 [5:08:39<4:22:20, 11.76s/it]                                                       {'loss': 0.7832, 'grad_norm': 1.2812494039535522, 'learning_rate': 2.321017533220454e-06, 'epoch': 0.54}
 54%|█████▍    | 1568/2906 [5:08:39<4:22:20, 11.76s/it] 54%|█████▍    | 1569/2906 [5:08:51<4:21:02, 11.71s/it]                                                       {'loss': 0.7099, 'grad_norm': 1.2677429914474487, 'learning_rate': 2.318225832807242e-06, 'epoch': 0.54}
 54%|█████▍    | 1569/2906 [5:08:51<4:21:02, 11.71s/it] 54%|█████▍    | 1570/2906 [5:09:02<4:19:47, 11.67s/it]                                                       {'loss': 0.8249, 'grad_norm': 1.3584593534469604, 'learning_rate': 2.3154343602479634e-06, 'epoch': 0.54}
 54%|█████▍    | 1570/2906 [5:09:02<4:19:47, 11.67s/it] 54%|█████▍    | 1571/2906 [5:09:15<4:23:23, 11.84s/it]                                                       {'loss': 0.814, 'grad_norm': 1.2916200160980225, 'learning_rate': 2.3126431190417294e-06, 'epoch': 0.54}
 54%|█████▍    | 1571/2906 [5:09:15<4:23:23, 11.84s/it] 54%|█████▍    | 1572/2906 [5:09:26<4:21:50, 11.78s/it]                                                       {'loss': 0.8158, 'grad_norm': 1.311640739440918, 'learning_rate': 2.3098521126873605e-06, 'epoch': 0.54}
 54%|█████▍    | 1572/2906 [5:09:26<4:21:50, 11.78s/it] 54%|█████▍    | 1573/2906 [5:09:38<4:20:57, 11.75s/it]                                                       {'loss': 0.7252, 'grad_norm': 1.1978870630264282, 'learning_rate': 2.3070613446833843e-06, 'epoch': 0.54}
 54%|█████▍    | 1573/2906 [5:09:38<4:20:57, 11.75s/it] 54%|█████▍    | 1574/2906 [5:09:50<4:19:55, 11.71s/it]                                                       {'loss': 0.7794, 'grad_norm': 1.3704673051834106, 'learning_rate': 2.3042708185280284e-06, 'epoch': 0.54}
 54%|█████▍    | 1574/2906 [5:09:50<4:19:55, 11.71s/it] 54%|█████▍    | 1575/2906 [5:10:01<4:14:37, 11.48s/it]                                                       {'loss': 0.8232, 'grad_norm': 1.3771679401397705, 'learning_rate': 2.3014805377192173e-06, 'epoch': 0.54}
 54%|█████▍    | 1575/2906 [5:10:01<4:14:37, 11.48s/it] 54%|█████▍    | 1576/2906 [5:10:12<4:14:57, 11.50s/it]                                                       {'loss': 0.8514, 'grad_norm': 1.3300105333328247, 'learning_rate': 2.2986905057545677e-06, 'epoch': 0.54}
 54%|█████▍    | 1576/2906 [5:10:12<4:14:57, 11.50s/it] 54%|█████▍    | 1577/2906 [5:10:24<4:16:06, 11.56s/it]                                                       {'loss': 0.8214, 'grad_norm': 1.2675045728683472, 'learning_rate': 2.2959007261313865e-06, 'epoch': 0.54}
 54%|█████▍    | 1577/2906 [5:10:24<4:16:06, 11.56s/it] 54%|█████▍    | 1578/2906 [5:10:35<4:14:53, 11.52s/it]                                                       {'loss': 0.7715, 'grad_norm': 1.3276982307434082, 'learning_rate': 2.2931112023466617e-06, 'epoch': 0.54}
 54%|█████▍    | 1578/2906 [5:10:35<4:14:53, 11.52s/it] 54%|█████▍    | 1579/2906 [5:10:47<4:15:39, 11.56s/it]                                                       {'loss': 0.8111, 'grad_norm': 1.3773304224014282, 'learning_rate': 2.2903219378970623e-06, 'epoch': 0.54}
 54%|█████▍    | 1579/2906 [5:10:47<4:15:39, 11.56s/it] 54%|█████▍    | 1580/2906 [5:10:59<4:16:52, 11.62s/it]                                                       {'loss': 0.824, 'grad_norm': 1.388569951057434, 'learning_rate': 2.2875329362789302e-06, 'epoch': 0.54}
 54%|█████▍    | 1580/2906 [5:10:59<4:16:52, 11.62s/it] 54%|█████▍    | 1581/2906 [5:11:10<4:13:59, 11.50s/it]                                                       {'loss': 0.806, 'grad_norm': 1.293171763420105, 'learning_rate': 2.2847442009882805e-06, 'epoch': 0.54}
 54%|█████▍    | 1581/2906 [5:11:10<4:13:59, 11.50s/it] 54%|█████▍    | 1582/2906 [5:11:22<4:17:22, 11.66s/it]                                                       {'loss': 0.7766, 'grad_norm': 1.3306331634521484, 'learning_rate': 2.281955735520792e-06, 'epoch': 0.54}
 54%|█████▍    | 1582/2906 [5:11:22<4:17:22, 11.66s/it] 54%|█████▍    | 1583/2906 [5:11:34<4:17:14, 11.67s/it]                                                       {'loss': 0.7915, 'grad_norm': 1.2980270385742188, 'learning_rate': 2.2791675433718058e-06, 'epoch': 0.54}
 54%|█████▍    | 1583/2906 [5:11:34<4:17:14, 11.67s/it] 55%|█████▍    | 1584/2906 [5:11:45<4:18:33, 11.73s/it]                                                       {'loss': 0.8094, 'grad_norm': 1.2860546112060547, 'learning_rate': 2.276379628036323e-06, 'epoch': 0.55}
 55%|█████▍    | 1584/2906 [5:11:45<4:18:33, 11.73s/it] 55%|█████▍    | 1585/2906 [5:11:57<4:17:30, 11.70s/it]                                                       {'loss': 0.774, 'grad_norm': 1.2300411462783813, 'learning_rate': 2.273591993008995e-06, 'epoch': 0.55}
 55%|█████▍    | 1585/2906 [5:11:57<4:17:30, 11.70s/it] 55%|█████▍    | 1586/2906 [5:12:09<4:20:22, 11.84s/it]                                                       {'loss': 0.8006, 'grad_norm': 1.3214287757873535, 'learning_rate': 2.270804641784122e-06, 'epoch': 0.55}
 55%|█████▍    | 1586/2906 [5:12:09<4:20:22, 11.84s/it] 55%|█████▍    | 1587/2906 [5:12:22<4:23:54, 12.00s/it]                                                       {'loss': 0.8217, 'grad_norm': 1.3941826820373535, 'learning_rate': 2.268017577855649e-06, 'epoch': 0.55}
 55%|█████▍    | 1587/2906 [5:12:22<4:23:54, 12.00s/it] 55%|█████▍    | 1588/2906 [5:12:33<4:21:52, 11.92s/it]                                                       {'loss': 0.8281, 'grad_norm': 1.3381544351577759, 'learning_rate': 2.265230804717161e-06, 'epoch': 0.55}
 55%|█████▍    | 1588/2906 [5:12:33<4:21:52, 11.92s/it] 55%|█████▍    | 1589/2906 [5:12:45<4:20:08, 11.85s/it]                                                       {'loss': 0.7705, 'grad_norm': 1.2834802865982056, 'learning_rate': 2.262444325861879e-06, 'epoch': 0.55}
 55%|█████▍    | 1589/2906 [5:12:45<4:20:08, 11.85s/it] 55%|█████▍    | 1590/2906 [5:12:57<4:18:38, 11.79s/it]                                                       {'loss': 0.7615, 'grad_norm': 1.310402750968933, 'learning_rate': 2.259658144782654e-06, 'epoch': 0.55}
 55%|█████▍    | 1590/2906 [5:12:57<4:18:38, 11.79s/it] 55%|█████▍    | 1591/2906 [5:13:08<4:14:10, 11.60s/it]                                                       {'loss': 0.7657, 'grad_norm': 1.3145653009414673, 'learning_rate': 2.2568722649719637e-06, 'epoch': 0.55}
 55%|█████▍    | 1591/2906 [5:13:08<4:14:10, 11.60s/it] 55%|█████▍    | 1592/2906 [5:13:20<4:17:04, 11.74s/it]                                                       {'loss': 0.727, 'grad_norm': 1.258461356163025, 'learning_rate': 2.25408668992191e-06, 'epoch': 0.55}
 55%|█████▍    | 1592/2906 [5:13:20<4:17:04, 11.74s/it] 55%|█████▍    | 1593/2906 [5:13:32<4:15:58, 11.70s/it]                                                       {'loss': 0.8085, 'grad_norm': 1.2353851795196533, 'learning_rate': 2.25130142312421e-06, 'epoch': 0.55}
 55%|█████▍    | 1593/2906 [5:13:32<4:15:58, 11.70s/it] 55%|█████▍    | 1594/2906 [5:13:43<4:17:08, 11.76s/it]                                                       {'loss': 0.8007, 'grad_norm': 1.3077630996704102, 'learning_rate': 2.2485164680701963e-06, 'epoch': 0.55}
 55%|█████▍    | 1594/2906 [5:13:43<4:17:08, 11.76s/it] 55%|█████▍    | 1595/2906 [5:13:55<4:18:26, 11.83s/it]                                                       {'loss': 0.8174, 'grad_norm': 1.2428547143936157, 'learning_rate': 2.2457318282508105e-06, 'epoch': 0.55}
 55%|█████▍    | 1595/2906 [5:13:55<4:18:26, 11.83s/it] 55%|█████▍    | 1596/2906 [5:14:07<4:20:01, 11.91s/it]                                                       {'loss': 0.7801, 'grad_norm': 1.2592331171035767, 'learning_rate': 2.242947507156599e-06, 'epoch': 0.55}
 55%|█████▍    | 1596/2906 [5:14:08<4:20:01, 11.91s/it] 55%|█████▍    | 1597/2906 [5:14:19<4:16:58, 11.78s/it]                                                       {'loss': 0.7385, 'grad_norm': 1.2362143993377686, 'learning_rate': 2.2401635082777086e-06, 'epoch': 0.55}
 55%|█████▍    | 1597/2906 [5:14:19<4:16:58, 11.78s/it] 55%|█████▍    | 1598/2906 [5:14:31<4:17:32, 11.81s/it]                                                       {'loss': 0.7551, 'grad_norm': 1.2424588203430176, 'learning_rate': 2.2373798351038816e-06, 'epoch': 0.55}
 55%|█████▍    | 1598/2906 [5:14:31<4:17:32, 11.81s/it] 55%|█████▌    | 1599/2906 [5:14:43<4:18:45, 11.88s/it]                                                       {'loss': 0.7469, 'grad_norm': 1.2216180562973022, 'learning_rate': 2.234596491124452e-06, 'epoch': 0.55}
 55%|█████▌    | 1599/2906 [5:14:43<4:18:45, 11.88s/it] 55%|█████▌    | 1600/2906 [5:14:55<4:19:55, 11.94s/it]                                                       {'loss': 0.7437, 'grad_norm': 1.3581010103225708, 'learning_rate': 2.2318134798283443e-06, 'epoch': 0.55}
 55%|█████▌    | 1600/2906 [5:14:55<4:19:55, 11.94s/it][INFO|trainer.py:3984] 2025-08-21 17:37:24,665 >> Saving model checkpoint to /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600
[INFO|configuration_utils.py:419] 2025-08-21 17:37:24,670 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/config.json
[INFO|configuration_utils.py:911] 2025-08-21 17:37:24,671 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/generation_config.json
[INFO|modeling_utils.py:3580] 2025-08-21 17:37:52,223 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-08-21 17:37:52,223 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 17:37:52,224 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/special_tokens_map.json
[2025-08-21 17:37:52,885] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1600 is about to be saved!
[2025-08-21 17:37:53,152] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/global_step1600/mp_rank_00_model_states.pt
[2025-08-21 17:37:53,152] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/global_step1600/mp_rank_00_model_states.pt...
[2025-08-21 17:38:27,731] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/global_step1600/mp_rank_00_model_states.pt.
[2025-08-21 17:38:27,806] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/global_step1600/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-21 17:39:21,690] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/global_step1600/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-21 17:39:21,691] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/global_step1600/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-21 17:39:21,691] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1600 is ready now!
[INFO|image_processing_base.py:260] 2025-08-21 17:39:30,675 >> Image processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/preprocessor_config.json
[INFO|tokenization_utils_base.py:2510] 2025-08-21 17:39:30,675 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 17:39:30,675 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/special_tokens_map.json
[INFO|processing_utils.py:648] 2025-08-21 17:39:30,822 >> chat template saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/chat_template.json
[INFO|processing_utils.py:654] 2025-08-21 17:39:30,935 >> processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-1600/processor_config.json
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 55%|█████▌    | 1601/2906 [5:17:21<18:55:33, 52.21s/it]                                                        {'loss': 0.8254, 'grad_norm': 1.287476658821106, 'learning_rate': 2.2290308047040607e-06, 'epoch': 0.55}
 55%|█████▌    | 1601/2906 [5:17:21<18:55:33, 52.21s/it] 55%|█████▌    | 1602/2906 [5:17:33<14:31:39, 40.11s/it]                                                        {'loss': 0.8106, 'grad_norm': 1.334302306175232, 'learning_rate': 2.226248469239685e-06, 'epoch': 0.55}
 55%|█████▌    | 1602/2906 [5:17:33<14:31:39, 40.11s/it] 55%|█████▌    | 1603/2906 [5:17:44<11:21:03, 31.36s/it]                                                        {'loss': 0.814, 'grad_norm': 1.4244482517242432, 'learning_rate': 2.2234664769228758e-06, 'epoch': 0.55}
 55%|█████▌    | 1603/2906 [5:17:44<11:21:03, 31.36s/it] 55%|█████▌    | 1604/2906 [5:17:55<9:11:17, 25.41s/it]                                                        {'loss': 0.841, 'grad_norm': 1.4007418155670166, 'learning_rate': 2.2206848312408605e-06, 'epoch': 0.55}
 55%|█████▌    | 1604/2906 [5:17:55<9:11:17, 25.41s/it] 55%|█████▌    | 1605/2906 [5:18:08<7:45:09, 21.45s/it]                                                       {'loss': 0.8318, 'grad_norm': 1.383646845817566, 'learning_rate': 2.217903535680432e-06, 'epoch': 0.55}
 55%|█████▌    | 1605/2906 [5:18:08<7:45:09, 21.45s/it] 55%|█████▌    | 1606/2906 [5:18:19<6:41:44, 18.54s/it]                                                       {'loss': 0.8415, 'grad_norm': 1.3007490634918213, 'learning_rate': 2.2151225937279442e-06, 'epoch': 0.55}
 55%|█████▌    | 1606/2906 [5:18:19<6:41:44, 18.54s/it] 55%|█████▌    | 1607/2906 [5:18:32<5:59:12, 16.59s/it]                                                       {'loss': 0.7735, 'grad_norm': 1.2500081062316895, 'learning_rate': 2.212342008869309e-06, 'epoch': 0.55}
 55%|█████▌    | 1607/2906 [5:18:32<5:59:12, 16.59s/it] 55%|█████▌    | 1608/2906 [5:18:43<5:26:48, 15.11s/it]                                                       {'loss': 0.7806, 'grad_norm': 1.4037643671035767, 'learning_rate': 2.2095617845899892e-06, 'epoch': 0.55}
 55%|█████▌    | 1608/2906 [5:18:43<5:26:48, 15.11s/it] 55%|█████▌    | 1609/2906 [5:18:55<5:02:33, 14.00s/it]                                                       {'loss': 0.7734, 'grad_norm': 1.345643162727356, 'learning_rate': 2.206781924374996e-06, 'epoch': 0.55}
 55%|█████▌    | 1609/2906 [5:18:55<5:02:33, 14.00s/it] 55%|█████▌    | 1610/2906 [5:19:06<4:44:06, 13.15s/it]                                                       {'loss': 0.857, 'grad_norm': 1.3651306629180908, 'learning_rate': 2.2040024317088844e-06, 'epoch': 0.55}
 55%|█████▌    | 1610/2906 [5:19:06<4:44:06, 13.15s/it] 55%|█████▌    | 1611/2906 [5:19:17<4:34:52, 12.74s/it]                                                       {'loss': 0.7953, 'grad_norm': 1.3115155696868896, 'learning_rate': 2.201223310075749e-06, 'epoch': 0.55}
 55%|█████▌    | 1611/2906 [5:19:18<4:34:52, 12.74s/it] 55%|█████▌    | 1612/2906 [5:19:29<4:28:34, 12.45s/it]                                                       {'loss': 0.783, 'grad_norm': 1.313977599143982, 'learning_rate': 2.1984445629592196e-06, 'epoch': 0.55}
 55%|█████▌    | 1612/2906 [5:19:29<4:28:34, 12.45s/it] 56%|█████▌    | 1613/2906 [5:19:41<4:22:37, 12.19s/it]                                                       {'loss': 0.8308, 'grad_norm': 1.3870413303375244, 'learning_rate': 2.1956661938424544e-06, 'epoch': 0.56}
 56%|█████▌    | 1613/2906 [5:19:41<4:22:37, 12.19s/it] 56%|█████▌    | 1614/2906 [5:19:52<4:18:38, 12.01s/it]                                                       {'loss': 0.7868, 'grad_norm': 1.3848906755447388, 'learning_rate': 2.1928882062081397e-06, 'epoch': 0.56}
 56%|█████▌    | 1614/2906 [5:19:52<4:18:38, 12.01s/it] 56%|█████▌    | 1615/2906 [5:20:04<4:17:55, 11.99s/it]                                                       {'loss': 0.7926, 'grad_norm': 1.2980384826660156, 'learning_rate': 2.1901106035384843e-06, 'epoch': 0.56}
 56%|█████▌    | 1615/2906 [5:20:04<4:17:55, 11.99s/it] 56%|█████▌    | 1616/2906 [5:20:16<4:16:08, 11.91s/it]                                                       {'loss': 0.7713, 'grad_norm': 1.347900390625, 'learning_rate': 2.187333389315213e-06, 'epoch': 0.56}
 56%|█████▌    | 1616/2906 [5:20:16<4:16:08, 11.91s/it] 56%|█████▌    | 1617/2906 [5:20:27<4:12:09, 11.74s/it]                                                       {'loss': 0.7408, 'grad_norm': 1.3523200750350952, 'learning_rate': 2.1845565670195634e-06, 'epoch': 0.56}
 56%|█████▌    | 1617/2906 [5:20:27<4:12:09, 11.74s/it] 56%|█████▌    | 1618/2906 [5:20:39<4:11:05, 11.70s/it]                                                       {'loss': 0.8198, 'grad_norm': 1.3657517433166504, 'learning_rate': 2.1817801401322824e-06, 'epoch': 0.56}
 56%|█████▌    | 1618/2906 [5:20:39<4:11:05, 11.70s/it] 56%|█████▌    | 1619/2906 [5:20:51<4:13:30, 11.82s/it]                                                       {'loss': 0.8347, 'grad_norm': 1.4393310546875, 'learning_rate': 2.1790041121336223e-06, 'epoch': 0.56}
 56%|█████▌    | 1619/2906 [5:20:51<4:13:30, 11.82s/it] 56%|█████▌    | 1620/2906 [5:21:02<4:08:52, 11.61s/it]                                                       {'loss': 0.7516, 'grad_norm': 1.2151179313659668, 'learning_rate': 2.1762284865033343e-06, 'epoch': 0.56}
 56%|█████▌    | 1620/2906 [5:21:02<4:08:52, 11.61s/it] 56%|█████▌    | 1621/2906 [5:21:15<4:12:53, 11.81s/it]                                                       {'loss': 0.8189, 'grad_norm': 1.4020003080368042, 'learning_rate': 2.173453266720665e-06, 'epoch': 0.56}
 56%|█████▌    | 1621/2906 [5:21:15<4:12:53, 11.81s/it] 56%|█████▌    | 1622/2906 [5:21:26<4:12:04, 11.78s/it]                                                       {'loss': 0.7827, 'grad_norm': 1.3052592277526855, 'learning_rate': 2.1706784562643522e-06, 'epoch': 0.56}
 56%|█████▌    | 1622/2906 [5:21:26<4:12:04, 11.78s/it] 56%|█████▌    | 1623/2906 [5:21:38<4:11:11, 11.75s/it]                                                       {'loss': 0.755, 'grad_norm': 1.2265454530715942, 'learning_rate': 2.1679040586126214e-06, 'epoch': 0.56}
 56%|█████▌    | 1623/2906 [5:21:38<4:11:11, 11.75s/it] 56%|█████▌    | 1624/2906 [5:21:49<4:07:10, 11.57s/it]                                                       {'loss': 0.7639, 'grad_norm': 1.3073025941848755, 'learning_rate': 2.1651300772431806e-06, 'epoch': 0.56}
 56%|█████▌    | 1624/2906 [5:21:49<4:07:10, 11.57s/it] 56%|█████▌    | 1625/2906 [5:22:00<4:05:37, 11.50s/it]                                                       {'loss': 0.8155, 'grad_norm': 1.3308897018432617, 'learning_rate': 2.1623565156332145e-06, 'epoch': 0.56}
 56%|█████▌    | 1625/2906 [5:22:00<4:05:37, 11.50s/it] 56%|█████▌    | 1626/2906 [5:22:13<4:10:52, 11.76s/it]                                                       {'loss': 0.8096, 'grad_norm': 1.3873279094696045, 'learning_rate': 2.159583377259384e-06, 'epoch': 0.56}
 56%|█████▌    | 1626/2906 [5:22:13<4:10:52, 11.76s/it] 56%|█████▌    | 1627/2906 [5:22:24<4:08:29, 11.66s/it]                                                       {'loss': 0.8118, 'grad_norm': 1.337725281715393, 'learning_rate': 2.1568106655978184e-06, 'epoch': 0.56}
 56%|█████▌    | 1627/2906 [5:22:24<4:08:29, 11.66s/it] 56%|█████▌    | 1628/2906 [5:22:36<4:11:05, 11.79s/it]                                                       {'loss': 0.784, 'grad_norm': 1.247420072555542, 'learning_rate': 2.154038384124111e-06, 'epoch': 0.56}
 56%|█████▌    | 1628/2906 [5:22:36<4:11:05, 11.79s/it] 56%|█████▌    | 1629/2906 [5:22:48<4:10:57, 11.79s/it]                                                       {'loss': 0.7686, 'grad_norm': 1.2347943782806396, 'learning_rate': 2.1512665363133173e-06, 'epoch': 0.56}
 56%|█████▌    | 1629/2906 [5:22:48<4:10:57, 11.79s/it] 56%|█████▌    | 1630/2906 [5:23:00<4:09:20, 11.72s/it]                                                       {'loss': 0.8146, 'grad_norm': 1.419374942779541, 'learning_rate': 2.1484951256399493e-06, 'epoch': 0.56}
 56%|█████▌    | 1630/2906 [5:23:00<4:09:20, 11.72s/it] 56%|█████▌    | 1631/2906 [5:23:12<4:11:34, 11.84s/it]                                                       {'loss': 0.7472, 'grad_norm': 1.2616487741470337, 'learning_rate': 2.14572415557797e-06, 'epoch': 0.56}
 56%|█████▌    | 1631/2906 [5:23:12<4:11:34, 11.84s/it] 56%|█████▌    | 1632/2906 [5:23:23<4:08:42, 11.71s/it]                                                       {'loss': 0.8501, 'grad_norm': 1.2574880123138428, 'learning_rate': 2.1429536296007906e-06, 'epoch': 0.56}
 56%|█████▌    | 1632/2906 [5:23:23<4:08:42, 11.71s/it] 56%|█████▌    | 1633/2906 [5:23:35<4:08:11, 11.70s/it]                                                       {'loss': 0.7385, 'grad_norm': 1.3068419694900513, 'learning_rate': 2.140183551181266e-06, 'epoch': 0.56}
 56%|█████▌    | 1633/2906 [5:23:35<4:08:11, 11.70s/it] 56%|█████▌    | 1634/2906 [5:23:47<4:08:37, 11.73s/it]                                                       {'loss': 0.7891, 'grad_norm': 1.274411678314209, 'learning_rate': 2.137413923791689e-06, 'epoch': 0.56}
 56%|█████▌    | 1634/2906 [5:23:47<4:08:37, 11.73s/it] 56%|█████▋    | 1635/2906 [5:23:58<4:05:01, 11.57s/it]                                                       {'loss': 0.7806, 'grad_norm': 1.4142359495162964, 'learning_rate': 2.1346447509037886e-06, 'epoch': 0.56}
 56%|█████▋    | 1635/2906 [5:23:58<4:05:01, 11.57s/it] 56%|█████▋    | 1636/2906 [5:24:09<4:03:55, 11.52s/it]                                                       {'loss': 0.7669, 'grad_norm': 1.2898844480514526, 'learning_rate': 2.1318760359887224e-06, 'epoch': 0.56}
 56%|█████▋    | 1636/2906 [5:24:09<4:03:55, 11.52s/it] 56%|█████▋    | 1637/2906 [5:24:21<4:02:51, 11.48s/it]                                                       {'loss': 0.798, 'grad_norm': 1.2747535705566406, 'learning_rate': 2.1291077825170756e-06, 'epoch': 0.56}
 56%|█████▋    | 1637/2906 [5:24:21<4:02:51, 11.48s/it] 56%|█████▋    | 1638/2906 [5:24:32<4:02:48, 11.49s/it]                                                       {'loss': 0.8112, 'grad_norm': 1.3331924676895142, 'learning_rate': 2.126339993958853e-06, 'epoch': 0.56}
 56%|█████▋    | 1638/2906 [5:24:32<4:02:48, 11.49s/it] 56%|█████▋    | 1639/2906 [5:24:44<4:03:12, 11.52s/it]                                                       {'loss': 0.7629, 'grad_norm': 1.199912190437317, 'learning_rate': 2.1235726737834794e-06, 'epoch': 0.56}
 56%|█████▋    | 1639/2906 [5:24:44<4:03:12, 11.52s/it] 56%|█████▋    | 1640/2906 [5:24:55<4:03:28, 11.54s/it]                                                       {'loss': 0.7902, 'grad_norm': 1.346832513809204, 'learning_rate': 2.1208058254597898e-06, 'epoch': 0.56}
 56%|█████▋    | 1640/2906 [5:24:55<4:03:28, 11.54s/it] 56%|█████▋    | 1641/2906 [5:25:08<4:07:18, 11.73s/it]                                                       {'loss': 0.8938, 'grad_norm': 1.4613564014434814, 'learning_rate': 2.118039452456029e-06, 'epoch': 0.56}
 56%|█████▋    | 1641/2906 [5:25:08<4:07:18, 11.73s/it] 57%|█████▋    | 1642/2906 [5:25:19<4:08:25, 11.79s/it]                                                       {'loss': 0.7612, 'grad_norm': 1.348373532295227, 'learning_rate': 2.1152735582398453e-06, 'epoch': 0.57}
 57%|█████▋    | 1642/2906 [5:25:19<4:08:25, 11.79s/it] 57%|█████▋    | 1643/2906 [5:25:31<4:07:39, 11.77s/it]                                                       {'loss': 0.7474, 'grad_norm': 1.223719596862793, 'learning_rate': 2.112508146278289e-06, 'epoch': 0.57}
 57%|█████▋    | 1643/2906 [5:25:31<4:07:39, 11.77s/it] 57%|█████▋    | 1644/2906 [5:25:43<4:05:16, 11.66s/it]                                                       {'loss': 0.7642, 'grad_norm': 1.3099186420440674, 'learning_rate': 2.109743220037802e-06, 'epoch': 0.57}
 57%|█████▋    | 1644/2906 [5:25:43<4:05:16, 11.66s/it] 57%|█████▋    | 1645/2906 [5:25:54<4:04:04, 11.61s/it]                                                       {'loss': 0.8163, 'grad_norm': 1.34017813205719, 'learning_rate': 2.106978782984221e-06, 'epoch': 0.57}
 57%|█████▋    | 1645/2906 [5:25:54<4:04:04, 11.61s/it] 57%|█████▋    | 1646/2906 [5:26:06<4:05:17, 11.68s/it]                                                       {'loss': 0.7984, 'grad_norm': 1.3765571117401123, 'learning_rate': 2.104214838582768e-06, 'epoch': 0.57}
 57%|█████▋    | 1646/2906 [5:26:06<4:05:17, 11.68s/it] 57%|█████▋    | 1647/2906 [5:26:17<4:02:39, 11.56s/it]                                                       {'loss': 0.7613, 'grad_norm': 1.2864117622375488, 'learning_rate': 2.101451390298047e-06, 'epoch': 0.57}
 57%|█████▋    | 1647/2906 [5:26:17<4:02:39, 11.56s/it] 57%|█████▋    | 1648/2906 [5:26:29<4:02:28, 11.56s/it]                                                       {'loss': 0.8673, 'grad_norm': 1.4005231857299805, 'learning_rate': 2.09868844159404e-06, 'epoch': 0.57}
 57%|█████▋    | 1648/2906 [5:26:29<4:02:28, 11.56s/it] 57%|█████▋    | 1649/2906 [5:26:40<4:00:17, 11.47s/it]                                                       {'loss': 0.7475, 'grad_norm': 1.2248129844665527, 'learning_rate': 2.095925995934105e-06, 'epoch': 0.57}
 57%|█████▋    | 1649/2906 [5:26:40<4:00:17, 11.47s/it] 57%|█████▋    | 1650/2906 [5:26:52<4:00:23, 11.48s/it]                                                       {'loss': 0.7553, 'grad_norm': 1.315463662147522, 'learning_rate': 2.093164056780967e-06, 'epoch': 0.57}
 57%|█████▋    | 1650/2906 [5:26:52<4:00:23, 11.48s/it] 57%|█████▋    | 1651/2906 [5:27:03<3:59:01, 11.43s/it]                                                       {'loss': 0.8005, 'grad_norm': 1.3018548488616943, 'learning_rate': 2.0904026275967176e-06, 'epoch': 0.57}
 57%|█████▋    | 1651/2906 [5:27:03<3:59:01, 11.43s/it] 57%|█████▋    | 1652/2906 [5:27:15<4:01:42, 11.56s/it]                                                       {'loss': 0.7608, 'grad_norm': 1.3587309122085571, 'learning_rate': 2.087641711842807e-06, 'epoch': 0.57}
 57%|█████▋    | 1652/2906 [5:27:15<4:01:42, 11.56s/it] 57%|█████▋    | 1653/2906 [5:27:27<4:02:52, 11.63s/it]                                                       {'loss': 0.7714, 'grad_norm': 1.2582576274871826, 'learning_rate': 2.084881312980045e-06, 'epoch': 0.57}
 57%|█████▋    | 1653/2906 [5:27:27<4:02:52, 11.63s/it] 57%|█████▋    | 1654/2906 [5:27:38<4:03:49, 11.69s/it]                                                       {'loss': 0.7504, 'grad_norm': 1.2669296264648438, 'learning_rate': 2.0821214344685913e-06, 'epoch': 0.57}
 57%|█████▋    | 1654/2906 [5:27:38<4:03:49, 11.69s/it] 57%|█████▋    | 1655/2906 [5:27:50<4:04:03, 11.71s/it]                                                       {'loss': 0.8318, 'grad_norm': 1.304268479347229, 'learning_rate': 2.0793620797679537e-06, 'epoch': 0.57}
 57%|█████▋    | 1655/2906 [5:27:50<4:04:03, 11.71s/it] 57%|█████▋    | 1656/2906 [5:28:01<4:01:53, 11.61s/it]                                                       {'loss': 0.757, 'grad_norm': 1.235333800315857, 'learning_rate': 2.0766032523369833e-06, 'epoch': 0.57}
 57%|█████▋    | 1656/2906 [5:28:01<4:01:53, 11.61s/it] 57%|█████▋    | 1657/2906 [5:28:13<3:59:58, 11.53s/it]                                                       {'loss': 0.8077, 'grad_norm': 1.2740312814712524, 'learning_rate': 2.0738449556338704e-06, 'epoch': 0.57}
 57%|█████▋    | 1657/2906 [5:28:13<3:59:58, 11.53s/it] 57%|█████▋    | 1658/2906 [5:28:25<4:04:03, 11.73s/it]                                                       {'loss': 0.812, 'grad_norm': 1.3343150615692139, 'learning_rate': 2.071087193116141e-06, 'epoch': 0.57}
 57%|█████▋    | 1658/2906 [5:28:25<4:04:03, 11.73s/it] 57%|█████▋    | 1659/2906 [5:28:36<4:00:07, 11.55s/it]                                                       {'loss': 0.7705, 'grad_norm': 1.5440874099731445, 'learning_rate': 2.0683299682406497e-06, 'epoch': 0.57}
 57%|█████▋    | 1659/2906 [5:28:36<4:00:07, 11.55s/it] 57%|█████▋    | 1660/2906 [5:28:48<4:02:24, 11.67s/it]                                                       {'loss': 0.7788, 'grad_norm': 1.3728212118148804, 'learning_rate': 2.065573284463579e-06, 'epoch': 0.57}
 57%|█████▋    | 1660/2906 [5:28:48<4:02:24, 11.67s/it] 57%|█████▋    | 1661/2906 [5:29:00<4:05:26, 11.83s/it]                                                       {'loss': 0.8352, 'grad_norm': 1.2838784456253052, 'learning_rate': 2.062817145240431e-06, 'epoch': 0.57}
 57%|█████▋    | 1661/2906 [5:29:00<4:05:26, 11.83s/it] 57%|█████▋    | 1662/2906 [5:29:12<4:01:59, 11.67s/it]                                                       {'loss': 0.8374, 'grad_norm': 1.3723883628845215, 'learning_rate': 2.0600615540260277e-06, 'epoch': 0.57}
 57%|█████▋    | 1662/2906 [5:29:12<4:01:59, 11.67s/it] 57%|█████▋    | 1663/2906 [5:29:23<3:59:57, 11.58s/it]                                                       {'loss': 0.828, 'grad_norm': 1.3423049449920654, 'learning_rate': 2.057306514274503e-06, 'epoch': 0.57}
 57%|█████▋    | 1663/2906 [5:29:23<3:59:57, 11.58s/it] 57%|█████▋    | 1664/2906 [5:29:34<3:58:53, 11.54s/it]                                                       {'loss': 0.8389, 'grad_norm': 1.357725977897644, 'learning_rate': 2.0545520294392985e-06, 'epoch': 0.57}
 57%|█████▋    | 1664/2906 [5:29:34<3:58:53, 11.54s/it] 57%|█████▋    | 1665/2906 [5:29:46<3:57:49, 11.50s/it]                                                       {'loss': 0.8511, 'grad_norm': 1.3556119203567505, 'learning_rate': 2.0517981029731613e-06, 'epoch': 0.57}
 57%|█████▋    | 1665/2906 [5:29:46<3:57:49, 11.50s/it] 57%|█████▋    | 1666/2906 [5:29:57<3:57:28, 11.49s/it]                                                       {'loss': 0.7667, 'grad_norm': 1.2905915975570679, 'learning_rate': 2.0490447383281394e-06, 'epoch': 0.57}
 57%|█████▋    | 1666/2906 [5:29:57<3:57:28, 11.49s/it] 57%|█████▋    | 1667/2906 [5:30:09<3:59:45, 11.61s/it]                                                       {'loss': 0.752, 'grad_norm': 1.3107019662857056, 'learning_rate': 2.0462919389555734e-06, 'epoch': 0.57}
 57%|█████▋    | 1667/2906 [5:30:09<3:59:45, 11.61s/it] 57%|█████▋    | 1668/2906 [5:30:21<4:01:47, 11.72s/it]                                                       {'loss': 0.7474, 'grad_norm': 1.3616905212402344, 'learning_rate': 2.0435397083061e-06, 'epoch': 0.57}
 57%|█████▋    | 1668/2906 [5:30:21<4:01:47, 11.72s/it] 57%|█████▋    | 1669/2906 [5:30:33<4:00:33, 11.67s/it]                                                       {'loss': 0.8419, 'grad_norm': 1.4821261167526245, 'learning_rate': 2.0407880498296397e-06, 'epoch': 0.57}
 57%|█████▋    | 1669/2906 [5:30:33<4:00:33, 11.67s/it] 57%|█████▋    | 1670/2906 [5:30:44<3:59:35, 11.63s/it]                                                       {'loss': 0.7573, 'grad_norm': 1.2381597757339478, 'learning_rate': 2.0380369669753964e-06, 'epoch': 0.57}
 57%|█████▋    | 1670/2906 [5:30:44<3:59:35, 11.63s/it] 58%|█████▊    | 1671/2906 [5:30:56<4:00:29, 11.68s/it]                                                       {'loss': 0.789, 'grad_norm': 1.3148034811019897, 'learning_rate': 2.035286463191852e-06, 'epoch': 0.58}
 58%|█████▊    | 1671/2906 [5:30:56<4:00:29, 11.68s/it] 58%|█████▊    | 1672/2906 [5:31:08<4:01:54, 11.76s/it]                                                       {'loss': 0.7858, 'grad_norm': 1.348258376121521, 'learning_rate': 2.032536541926765e-06, 'epoch': 0.58}
 58%|█████▊    | 1672/2906 [5:31:08<4:01:54, 11.76s/it] 58%|█████▊    | 1673/2906 [5:31:20<4:00:29, 11.70s/it]                                                       {'loss': 0.8223, 'grad_norm': 1.3509047031402588, 'learning_rate': 2.0297872066271606e-06, 'epoch': 0.58}
 58%|█████▊    | 1673/2906 [5:31:20<4:00:29, 11.70s/it] 58%|█████▊    | 1674/2906 [5:31:31<3:59:00, 11.64s/it]                                                       {'loss': 0.8043, 'grad_norm': 1.3450872898101807, 'learning_rate': 2.027038460739331e-06, 'epoch': 0.58}
 58%|█████▊    | 1674/2906 [5:31:31<3:59:00, 11.64s/it] 58%|█████▊    | 1675/2906 [5:31:43<3:59:52, 11.69s/it]                                                       {'loss': 0.7765, 'grad_norm': 1.3368654251098633, 'learning_rate': 2.02429030770883e-06, 'epoch': 0.58}
 58%|█████▊    | 1675/2906 [5:31:43<3:59:52, 11.69s/it] 58%|█████▊    | 1676/2906 [5:31:54<3:58:54, 11.65s/it]                                                       {'loss': 0.8397, 'grad_norm': 1.349161982536316, 'learning_rate': 2.0215427509804664e-06, 'epoch': 0.58}
 58%|█████▊    | 1676/2906 [5:31:54<3:58:54, 11.65s/it] 58%|█████▊    | 1677/2906 [5:32:07<4:02:04, 11.82s/it]                                                       {'loss': 0.7628, 'grad_norm': 1.2976750135421753, 'learning_rate': 2.0187957939983045e-06, 'epoch': 0.58}
 58%|█████▊    | 1677/2906 [5:32:07<4:02:04, 11.82s/it] 58%|█████▊    | 1678/2906 [5:32:18<3:58:15, 11.64s/it]                                                       {'loss': 0.7718, 'grad_norm': 1.3125492334365845, 'learning_rate': 2.0160494402056537e-06, 'epoch': 0.58}
 58%|█████▊    | 1678/2906 [5:32:18<3:58:15, 11.64s/it] 58%|█████▊    | 1679/2906 [5:32:30<3:59:07, 11.69s/it]                                                       {'loss': 0.8012, 'grad_norm': 1.217816948890686, 'learning_rate': 2.0133036930450694e-06, 'epoch': 0.58}
 58%|█████▊    | 1679/2906 [5:32:30<3:59:07, 11.69s/it] 58%|█████▊    | 1680/2906 [5:32:41<3:57:55, 11.64s/it]                                                       {'loss': 0.8149, 'grad_norm': 1.3962886333465576, 'learning_rate': 2.0105585559583453e-06, 'epoch': 0.58}
 58%|█████▊    | 1680/2906 [5:32:41<3:57:55, 11.64s/it] 58%|█████▊    | 1681/2906 [5:32:52<3:54:19, 11.48s/it]                                                       {'loss': 0.8249, 'grad_norm': 1.3234456777572632, 'learning_rate': 2.0078140323865114e-06, 'epoch': 0.58}
 58%|█████▊    | 1681/2906 [5:32:52<3:54:19, 11.48s/it] 58%|█████▊    | 1682/2906 [5:33:04<3:53:47, 11.46s/it]                                                       {'loss': 0.7714, 'grad_norm': 1.3009860515594482, 'learning_rate': 2.0050701257698285e-06, 'epoch': 0.58}
 58%|█████▊    | 1682/2906 [5:33:04<3:53:47, 11.46s/it] 58%|█████▊    | 1683/2906 [5:33:15<3:55:18, 11.54s/it]                                                       {'loss': 0.8274, 'grad_norm': 1.2522410154342651, 'learning_rate': 2.0023268395477833e-06, 'epoch': 0.58}
 58%|█████▊    | 1683/2906 [5:33:15<3:55:18, 11.54s/it] 58%|█████▊    | 1684/2906 [5:33:28<3:58:57, 11.73s/it]                                                       {'loss': 0.8296, 'grad_norm': 1.287194013595581, 'learning_rate': 1.999584177159085e-06, 'epoch': 0.58}
 58%|█████▊    | 1684/2906 [5:33:28<3:58:57, 11.73s/it] 58%|█████▊    | 1685/2906 [5:33:40<3:59:49, 11.78s/it]                                                       {'loss': 0.786, 'grad_norm': 1.2346223592758179, 'learning_rate': 1.9968421420416633e-06, 'epoch': 0.58}
 58%|█████▊    | 1685/2906 [5:33:40<3:59:49, 11.78s/it] 58%|█████▊    | 1686/2906 [5:33:51<3:59:03, 11.76s/it]                                                       {'loss': 0.8538, 'grad_norm': 1.2330504655838013, 'learning_rate': 1.994100737632656e-06, 'epoch': 0.58}
 58%|█████▊    | 1686/2906 [5:33:51<3:59:03, 11.76s/it] 58%|█████▊    | 1687/2906 [5:34:03<3:59:12, 11.77s/it]                                                       {'loss': 0.8207, 'grad_norm': 1.3801592588424683, 'learning_rate': 1.991359967368416e-06, 'epoch': 0.58}
 58%|█████▊    | 1687/2906 [5:34:03<3:59:12, 11.77s/it] 58%|█████▊    | 1688/2906 [5:34:15<4:01:32, 11.90s/it]                                                       {'loss': 0.8079, 'grad_norm': 1.3335344791412354, 'learning_rate': 1.988619834684499e-06, 'epoch': 0.58}
 58%|█████▊    | 1688/2906 [5:34:15<4:01:32, 11.90s/it] 58%|█████▊    | 1689/2906 [5:34:27<4:02:33, 11.96s/it]                                                       {'loss': 0.747, 'grad_norm': 1.248673439025879, 'learning_rate': 1.9858803430156602e-06, 'epoch': 0.58}
 58%|█████▊    | 1689/2906 [5:34:27<4:02:33, 11.96s/it] 58%|█████▊    | 1690/2906 [5:34:39<3:59:59, 11.84s/it]                                                       {'loss': 0.7505, 'grad_norm': 1.3146284818649292, 'learning_rate': 1.983141495795854e-06, 'epoch': 0.58}
 58%|█████▊    | 1690/2906 [5:34:39<3:59:59, 11.84s/it] 58%|█████▊    | 1691/2906 [5:34:51<4:00:18, 11.87s/it]                                                       {'loss': 0.772, 'grad_norm': 1.3286057710647583, 'learning_rate': 1.9804032964582243e-06, 'epoch': 0.58}
 58%|█████▊    | 1691/2906 [5:34:51<4:00:18, 11.87s/it] 58%|█████▊    | 1692/2906 [5:35:02<3:54:37, 11.60s/it]                                                       {'loss': 0.8151, 'grad_norm': 1.3804179430007935, 'learning_rate': 1.9776657484351056e-06, 'epoch': 0.58}
 58%|█████▊    | 1692/2906 [5:35:02<3:54:37, 11.60s/it] 58%|█████▊    | 1693/2906 [5:35:13<3:53:29, 11.55s/it]                                                       {'loss': 0.8173, 'grad_norm': 1.3423396348953247, 'learning_rate': 1.974928855158014e-06, 'epoch': 0.58}
 58%|█████▊    | 1693/2906 [5:35:13<3:53:29, 11.55s/it] 58%|█████▊    | 1694/2906 [5:35:25<3:52:04, 11.49s/it]                                                       {'loss': 0.8472, 'grad_norm': 2.9465725421905518, 'learning_rate': 1.9721926200576455e-06, 'epoch': 0.58}
 58%|█████▊    | 1694/2906 [5:35:25<3:52:04, 11.49s/it] 58%|█████▊    | 1695/2906 [5:35:36<3:51:03, 11.45s/it]                                                       {'loss': 0.8354, 'grad_norm': 1.3099238872528076, 'learning_rate': 1.96945704656387e-06, 'epoch': 0.58}
 58%|█████▊    | 1695/2906 [5:35:36<3:51:03, 11.45s/it] 58%|█████▊    | 1696/2906 [5:35:48<3:54:56, 11.65s/it]                                                       {'loss': 0.8326, 'grad_norm': 1.2766588926315308, 'learning_rate': 1.966722138105731e-06, 'epoch': 0.58}
 58%|█████▊    | 1696/2906 [5:35:48<3:54:56, 11.65s/it] 58%|█████▊    | 1697/2906 [5:36:00<3:54:55, 11.66s/it]                                                       {'loss': 0.7964, 'grad_norm': 1.3899520635604858, 'learning_rate': 1.9639878981114358e-06, 'epoch': 0.58}
 58%|█████▊    | 1697/2906 [5:36:00<3:54:55, 11.66s/it] 58%|█████▊    | 1698/2906 [5:36:12<4:00:10, 11.93s/it]                                                       {'loss': 0.7959, 'grad_norm': 1.3039720058441162, 'learning_rate': 1.9612543300083538e-06, 'epoch': 0.58}
 58%|█████▊    | 1698/2906 [5:36:12<4:00:10, 11.93s/it] 58%|█████▊    | 1699/2906 [5:36:24<3:57:59, 11.83s/it]                                                       {'loss': 0.7511, 'grad_norm': 1.3034816980361938, 'learning_rate': 1.958521437223013e-06, 'epoch': 0.58}
 58%|█████▊    | 1699/2906 [5:36:24<3:57:59, 11.83s/it] 58%|█████▊    | 1700/2906 [5:36:36<3:57:12, 11.80s/it]                                                       {'loss': 0.7452, 'grad_norm': 1.5055030584335327, 'learning_rate': 1.9557892231810947e-06, 'epoch': 0.58}
 58%|█████▊    | 1700/2906 [5:36:36<3:57:12, 11.80s/it] 59%|█████▊    | 1701/2906 [5:36:47<3:51:50, 11.54s/it]                                                       {'loss': 0.8185, 'grad_norm': 1.3292582035064697, 'learning_rate': 1.95305769130743e-06, 'epoch': 0.59}
 59%|█████▊    | 1701/2906 [5:36:47<3:51:50, 11.54s/it] 59%|█████▊    | 1702/2906 [5:36:59<3:55:26, 11.73s/it]                                                       {'loss': 0.7866, 'grad_norm': 1.2229773998260498, 'learning_rate': 1.9503268450259942e-06, 'epoch': 0.59}
 59%|█████▊    | 1702/2906 [5:36:59<3:55:26, 11.73s/it] 59%|█████▊    | 1703/2906 [5:37:10<3:49:31, 11.45s/it]                                                       {'loss': 0.7712, 'grad_norm': 1.381644368171692, 'learning_rate': 1.947596687759902e-06, 'epoch': 0.59}
 59%|█████▊    | 1703/2906 [5:37:10<3:49:31, 11.45s/it] 59%|█████▊    | 1704/2906 [5:37:21<3:51:01, 11.53s/it]                                                       {'loss': 0.753, 'grad_norm': 1.2558432817459106, 'learning_rate': 1.944867222931408e-06, 'epoch': 0.59}
 59%|█████▊    | 1704/2906 [5:37:21<3:51:01, 11.53s/it] 59%|█████▊    | 1705/2906 [5:37:33<3:55:07, 11.75s/it]                                                       {'loss': 0.8275, 'grad_norm': 1.4168931245803833, 'learning_rate': 1.9421384539618957e-06, 'epoch': 0.59}
 59%|█████▊    | 1705/2906 [5:37:34<3:55:07, 11.75s/it] 59%|█████▊    | 1706/2906 [5:37:45<3:53:44, 11.69s/it]                                                       {'loss': 0.739, 'grad_norm': 1.2972228527069092, 'learning_rate': 1.9394103842718772e-06, 'epoch': 0.59}
 59%|█████▊    | 1706/2906 [5:37:45<3:53:44, 11.69s/it] 59%|█████▊    | 1707/2906 [5:37:57<3:52:47, 11.65s/it]                                                       {'loss': 0.8185, 'grad_norm': 1.2985059022903442, 'learning_rate': 1.9366830172809877e-06, 'epoch': 0.59}
 59%|█████▊    | 1707/2906 [5:37:57<3:52:47, 11.65s/it] 59%|█████▉    | 1708/2906 [5:38:09<3:57:08, 11.88s/it]                                                       {'loss': 0.789, 'grad_norm': 1.2609336376190186, 'learning_rate': 1.9339563564079816e-06, 'epoch': 0.59}
 59%|█████▉    | 1708/2906 [5:38:09<3:57:08, 11.88s/it] 59%|█████▉    | 1709/2906 [5:38:20<3:54:22, 11.75s/it]                                                       {'loss': 0.7934, 'grad_norm': 1.3440818786621094, 'learning_rate': 1.9312304050707293e-06, 'epoch': 0.59}
 59%|█████▉    | 1709/2906 [5:38:20<3:54:22, 11.75s/it] 59%|█████▉    | 1710/2906 [5:38:32<3:52:58, 11.69s/it]                                                       {'loss': 0.7904, 'grad_norm': 1.2691677808761597, 'learning_rate': 1.92850516668621e-06, 'epoch': 0.59}
 59%|█████▉    | 1710/2906 [5:38:32<3:52:58, 11.69s/it] 59%|█████▉    | 1711/2906 [5:38:43<3:49:56, 11.55s/it]                                                       {'loss': 0.8244, 'grad_norm': 1.2683923244476318, 'learning_rate': 1.9257806446705116e-06, 'epoch': 0.59}
 59%|█████▉    | 1711/2906 [5:38:43<3:49:56, 11.55s/it] 59%|█████▉    | 1712/2906 [5:38:55<3:49:41, 11.54s/it]                                                       {'loss': 0.7931, 'grad_norm': 1.3013697862625122, 'learning_rate': 1.9230568424388226e-06, 'epoch': 0.59}
 59%|█████▉    | 1712/2906 [5:38:55<3:49:41, 11.54s/it] 59%|█████▉    | 1713/2906 [5:39:06<3:47:32, 11.44s/it]                                                       {'loss': 0.8155, 'grad_norm': 1.4693336486816406, 'learning_rate': 1.920333763405428e-06, 'epoch': 0.59}
 59%|█████▉    | 1713/2906 [5:39:06<3:47:32, 11.44s/it] 59%|█████▉    | 1714/2906 [5:39:18<3:49:27, 11.55s/it]                                                       {'loss': 0.7648, 'grad_norm': 1.3099937438964844, 'learning_rate': 1.9176114109837082e-06, 'epoch': 0.59}
 59%|█████▉    | 1714/2906 [5:39:18<3:49:27, 11.55s/it] 59%|█████▉    | 1715/2906 [5:39:30<3:51:26, 11.66s/it]                                                       {'loss': 0.7454, 'grad_norm': 1.2849668264389038, 'learning_rate': 1.914889788586133e-06, 'epoch': 0.59}
 59%|█████▉    | 1715/2906 [5:39:30<3:51:26, 11.66s/it] 59%|█████▉    | 1716/2906 [5:39:42<3:52:42, 11.73s/it]                                                       {'loss': 0.7852, 'grad_norm': 1.4238190650939941, 'learning_rate': 1.9121688996242557e-06, 'epoch': 0.59}
 59%|█████▉    | 1716/2906 [5:39:42<3:52:42, 11.73s/it] 59%|█████▉    | 1717/2906 [5:39:53<3:51:26, 11.68s/it]                                                       {'loss': 0.7501, 'grad_norm': 1.2300349473953247, 'learning_rate': 1.909448747508711e-06, 'epoch': 0.59}
 59%|█████▉    | 1717/2906 [5:39:53<3:51:26, 11.68s/it] 59%|█████▉    | 1718/2906 [5:40:05<3:53:02, 11.77s/it]                                                       {'loss': 0.8033, 'grad_norm': 1.228744626045227, 'learning_rate': 1.9067293356492083e-06, 'epoch': 0.59}
 59%|█████▉    | 1718/2906 [5:40:05<3:53:02, 11.77s/it] 59%|█████▉    | 1719/2906 [5:40:16<3:49:40, 11.61s/it]                                                       {'loss': 0.8714, 'grad_norm': 1.3446577787399292, 'learning_rate': 1.9040106674545333e-06, 'epoch': 0.59}
 59%|█████▉    | 1719/2906 [5:40:16<3:49:40, 11.61s/it] 59%|█████▉    | 1720/2906 [5:40:28<3:48:20, 11.55s/it]                                                       {'loss': 0.7624, 'grad_norm': 1.2793195247650146, 'learning_rate': 1.9012927463325348e-06, 'epoch': 0.59}
 59%|█████▉    | 1720/2906 [5:40:28<3:48:20, 11.55s/it] 59%|█████▉    | 1721/2906 [5:40:39<3:48:25, 11.57s/it]                                                       {'loss': 0.7657, 'grad_norm': 1.25632905960083, 'learning_rate': 1.898575575690128e-06, 'epoch': 0.59}
 59%|█████▉    | 1721/2906 [5:40:39<3:48:25, 11.57s/it] 59%|█████▉    | 1722/2906 [5:40:51<3:50:59, 11.71s/it]                                                       {'loss': 0.7817, 'grad_norm': 1.3103673458099365, 'learning_rate': 1.8958591589332859e-06, 'epoch': 0.59}
 59%|█████▉    | 1722/2906 [5:40:51<3:50:59, 11.71s/it] 59%|█████▉    | 1723/2906 [5:41:03<3:51:42, 11.75s/it]                                                       {'loss': 0.7581, 'grad_norm': 1.2271416187286377, 'learning_rate': 1.8931434994670377e-06, 'epoch': 0.59}
 59%|█████▉    | 1723/2906 [5:41:03<3:51:42, 11.75s/it] 59%|█████▉    | 1724/2906 [5:41:15<3:49:31, 11.65s/it]                                                       {'loss': 0.7318, 'grad_norm': 1.2749930620193481, 'learning_rate': 1.8904286006954629e-06, 'epoch': 0.59}
 59%|█████▉    | 1724/2906 [5:41:15<3:49:31, 11.65s/it] 59%|█████▉    | 1725/2906 [5:41:26<3:48:39, 11.62s/it]                                                       {'loss': 0.7892, 'grad_norm': 1.2884891033172607, 'learning_rate': 1.8877144660216867e-06, 'epoch': 0.59}
 59%|█████▉    | 1725/2906 [5:41:26<3:48:39, 11.62s/it] 59%|█████▉    | 1726/2906 [5:41:38<3:48:32, 11.62s/it]                                                       {'loss': 0.7954, 'grad_norm': 1.2593579292297363, 'learning_rate': 1.8850010988478774e-06, 'epoch': 0.59}
 59%|█████▉    | 1726/2906 [5:41:38<3:48:32, 11.62s/it] 59%|█████▉    | 1727/2906 [5:41:50<3:48:35, 11.63s/it]                                                       {'loss': 0.8051, 'grad_norm': 1.3124463558197021, 'learning_rate': 1.8822885025752408e-06, 'epoch': 0.59}
 59%|█████▉    | 1727/2906 [5:41:50<3:48:35, 11.63s/it] 59%|█████▉    | 1728/2906 [5:42:01<3:50:19, 11.73s/it]                                                       {'loss': 0.768, 'grad_norm': 1.2387973070144653, 'learning_rate': 1.8795766806040184e-06, 'epoch': 0.59}
 59%|█████▉    | 1728/2906 [5:42:01<3:50:19, 11.73s/it] 59%|█████▉    | 1729/2906 [5:42:13<3:48:20, 11.64s/it]                                                       {'loss': 0.773, 'grad_norm': 1.357244610786438, 'learning_rate': 1.8768656363334759e-06, 'epoch': 0.59}
 59%|█████▉    | 1729/2906 [5:42:13<3:48:20, 11.64s/it] 60%|█████▉    | 1730/2906 [5:42:25<3:49:23, 11.70s/it]                                                       {'loss': 0.7514, 'grad_norm': 1.334159255027771, 'learning_rate': 1.8741553731619095e-06, 'epoch': 0.6}
 60%|█████▉    | 1730/2906 [5:42:25<3:49:23, 11.70s/it] 60%|█████▉    | 1731/2906 [5:42:36<3:48:40, 11.68s/it]                                                       {'loss': 0.8475, 'grad_norm': 1.2742291688919067, 'learning_rate': 1.8714458944866342e-06, 'epoch': 0.6}
 60%|█████▉    | 1731/2906 [5:42:36<3:48:40, 11.68s/it] 60%|█████▉    | 1732/2906 [5:42:48<3:48:07, 11.66s/it]                                                       {'loss': 0.8074, 'grad_norm': 1.3391414880752563, 'learning_rate': 1.8687372037039817e-06, 'epoch': 0.6}
 60%|█████▉    | 1732/2906 [5:42:48<3:48:07, 11.66s/it] 60%|█████▉    | 1733/2906 [5:42:59<3:46:18, 11.58s/it]                                                       {'loss': 0.7715, 'grad_norm': 1.2459899187088013, 'learning_rate': 1.8660293042092953e-06, 'epoch': 0.6}
 60%|█████▉    | 1733/2906 [5:42:59<3:46:18, 11.58s/it] 60%|█████▉    | 1734/2906 [5:43:12<3:49:46, 11.76s/it]                                                       {'loss': 0.7878, 'grad_norm': 1.4910566806793213, 'learning_rate': 1.8633221993969285e-06, 'epoch': 0.6}
 60%|█████▉    | 1734/2906 [5:43:12<3:49:46, 11.76s/it] 60%|█████▉    | 1735/2906 [5:43:23<3:49:28, 11.76s/it]                                                       {'loss': 0.8293, 'grad_norm': 1.3554855585098267, 'learning_rate': 1.8606158926602368e-06, 'epoch': 0.6}
 60%|█████▉    | 1735/2906 [5:43:23<3:49:28, 11.76s/it] 60%|█████▉    | 1736/2906 [5:43:35<3:48:55, 11.74s/it]                                                       {'loss': 0.8321, 'grad_norm': 1.263014316558838, 'learning_rate': 1.857910387391576e-06, 'epoch': 0.6}
 60%|█████▉    | 1736/2906 [5:43:35<3:48:55, 11.74s/it] 60%|█████▉    | 1737/2906 [5:43:46<3:46:57, 11.65s/it]                                                       {'loss': 0.8446, 'grad_norm': 1.3696027994155884, 'learning_rate': 1.8552056869822968e-06, 'epoch': 0.6}
 60%|█████▉    | 1737/2906 [5:43:46<3:46:57, 11.65s/it] 60%|█████▉    | 1738/2906 [5:43:57<3:42:30, 11.43s/it]                                                       {'loss': 0.8247, 'grad_norm': 1.2582066059112549, 'learning_rate': 1.852501794822742e-06, 'epoch': 0.6}
 60%|█████▉    | 1738/2906 [5:43:57<3:42:30, 11.43s/it] 60%|█████▉    | 1739/2906 [5:44:09<3:45:25, 11.59s/it]                                                       {'loss': 0.8342, 'grad_norm': 1.3095420598983765, 'learning_rate': 1.8497987143022405e-06, 'epoch': 0.6}
 60%|█████▉    | 1739/2906 [5:44:09<3:45:25, 11.59s/it] 60%|█████▉    | 1740/2906 [5:44:21<3:45:27, 11.60s/it]                                                       {'loss': 0.755, 'grad_norm': 1.2740490436553955, 'learning_rate': 1.8470964488091038e-06, 'epoch': 0.6}
 60%|█████▉    | 1740/2906 [5:44:21<3:45:27, 11.60s/it] 60%|█████▉    | 1741/2906 [5:44:32<3:43:25, 11.51s/it]                                                       {'loss': 0.7846, 'grad_norm': 1.4210076332092285, 'learning_rate': 1.8443950017306214e-06, 'epoch': 0.6}
 60%|█████▉    | 1741/2906 [5:44:32<3:43:25, 11.51s/it] 60%|█████▉    | 1742/2906 [5:44:44<3:43:14, 11.51s/it]                                                       {'loss': 0.8295, 'grad_norm': 1.355358600616455, 'learning_rate': 1.8416943764530585e-06, 'epoch': 0.6}
 60%|█████▉    | 1742/2906 [5:44:44<3:43:14, 11.51s/it] 60%|█████▉    | 1743/2906 [5:44:55<3:41:17, 11.42s/it]                                                       {'loss': 0.769, 'grad_norm': 1.3423632383346558, 'learning_rate': 1.8389945763616485e-06, 'epoch': 0.6}
 60%|█████▉    | 1743/2906 [5:44:55<3:41:17, 11.42s/it] 60%|██████    | 1744/2906 [5:45:06<3:41:31, 11.44s/it]                                                       {'loss': 0.8136, 'grad_norm': 1.2374324798583984, 'learning_rate': 1.836295604840591e-06, 'epoch': 0.6}
 60%|██████    | 1744/2906 [5:45:06<3:41:31, 11.44s/it] 60%|██████    | 1745/2906 [5:45:18<3:43:54, 11.57s/it]                                                       {'loss': 0.8071, 'grad_norm': 1.3185515403747559, 'learning_rate': 1.8335974652730467e-06, 'epoch': 0.6}
 60%|██████    | 1745/2906 [5:45:18<3:43:54, 11.57s/it] 60%|██████    | 1746/2906 [5:45:30<3:45:40, 11.67s/it]                                                       {'loss': 0.8086, 'grad_norm': 1.2941166162490845, 'learning_rate': 1.8309001610411348e-06, 'epoch': 0.6}
 60%|██████    | 1746/2906 [5:45:30<3:45:40, 11.67s/it] 60%|██████    | 1747/2906 [5:45:42<3:43:53, 11.59s/it]                                                       {'loss': 0.7282, 'grad_norm': 1.3446263074874878, 'learning_rate': 1.8282036955259258e-06, 'epoch': 0.6}
 60%|██████    | 1747/2906 [5:45:42<3:43:53, 11.59s/it] 60%|██████    | 1748/2906 [5:45:53<3:43:33, 11.58s/it]                                                       {'loss': 0.7492, 'grad_norm': 1.2670402526855469, 'learning_rate': 1.8255080721074391e-06, 'epoch': 0.6}
 60%|██████    | 1748/2906 [5:45:53<3:43:33, 11.58s/it] 60%|██████    | 1749/2906 [5:46:05<3:42:15, 11.53s/it]                                                       {'loss': 0.8093, 'grad_norm': 1.4663888216018677, 'learning_rate': 1.8228132941646404e-06, 'epoch': 0.6}
 60%|██████    | 1749/2906 [5:46:05<3:42:15, 11.53s/it] 60%|██████    | 1750/2906 [5:46:16<3:41:33, 11.50s/it]                                                       {'loss': 0.7849, 'grad_norm': 1.306579351425171, 'learning_rate': 1.8201193650754317e-06, 'epoch': 0.6}
 60%|██████    | 1750/2906 [5:46:16<3:41:33, 11.50s/it] 60%|██████    | 1751/2906 [5:46:28<3:43:51, 11.63s/it]                                                       {'loss': 0.7932, 'grad_norm': 1.273726463317871, 'learning_rate': 1.817426288216655e-06, 'epoch': 0.6}
 60%|██████    | 1751/2906 [5:46:28<3:43:51, 11.63s/it] 60%|██████    | 1752/2906 [5:46:40<3:44:51, 11.69s/it]                                                       {'loss': 0.7822, 'grad_norm': 1.37555992603302, 'learning_rate': 1.8147340669640807e-06, 'epoch': 0.6}
 60%|██████    | 1752/2906 [5:46:40<3:44:51, 11.69s/it] 60%|██████    | 1753/2906 [5:46:51<3:41:36, 11.53s/it]                                                       {'loss': 0.8218, 'grad_norm': 1.403237223625183, 'learning_rate': 1.8120427046924106e-06, 'epoch': 0.6}
 60%|██████    | 1753/2906 [5:46:51<3:41:36, 11.53s/it] 60%|██████    | 1754/2906 [5:47:03<3:42:50, 11.61s/it]                                                       {'loss': 0.7495, 'grad_norm': 1.2597507238388062, 'learning_rate': 1.809352204775266e-06, 'epoch': 0.6}
 60%|██████    | 1754/2906 [5:47:03<3:42:50, 11.61s/it] 60%|██████    | 1755/2906 [5:47:15<3:44:03, 11.68s/it]                                                       {'loss': 0.8485, 'grad_norm': 1.3199467658996582, 'learning_rate': 1.8066625705851896e-06, 'epoch': 0.6}
 60%|██████    | 1755/2906 [5:47:15<3:44:03, 11.68s/it] 60%|██████    | 1756/2906 [5:47:27<3:47:10, 11.85s/it]                                                       {'loss': 0.8621, 'grad_norm': 1.4505016803741455, 'learning_rate': 1.803973805493637e-06, 'epoch': 0.6}
 60%|██████    | 1756/2906 [5:47:27<3:47:10, 11.85s/it] 60%|██████    | 1757/2906 [5:47:38<3:43:54, 11.69s/it]                                                       {'loss': 0.8039, 'grad_norm': 1.2380354404449463, 'learning_rate': 1.8012859128709766e-06, 'epoch': 0.6}
 60%|██████    | 1757/2906 [5:47:38<3:43:54, 11.69s/it] 60%|██████    | 1758/2906 [5:47:49<3:38:15, 11.41s/it]                                                       {'loss': 0.7452, 'grad_norm': 1.2696211338043213, 'learning_rate': 1.7985988960864817e-06, 'epoch': 0.6}
 60%|██████    | 1758/2906 [5:47:49<3:38:15, 11.41s/it] 61%|██████    | 1759/2906 [5:48:00<3:38:05, 11.41s/it]                                                       {'loss': 0.7354, 'grad_norm': 1.268928050994873, 'learning_rate': 1.7959127585083281e-06, 'epoch': 0.61}
 61%|██████    | 1759/2906 [5:48:00<3:38:05, 11.41s/it] 61%|██████    | 1760/2906 [5:48:12<3:38:17, 11.43s/it]                                                       {'loss': 0.756, 'grad_norm': 1.3282071352005005, 'learning_rate': 1.7932275035035884e-06, 'epoch': 0.61}
 61%|██████    | 1760/2906 [5:48:12<3:38:17, 11.43s/it] 61%|██████    | 1761/2906 [5:48:23<3:38:17, 11.44s/it]                                                       {'loss': 0.7747, 'grad_norm': 1.272098422050476, 'learning_rate': 1.7905431344382318e-06, 'epoch': 0.61}
 61%|██████    | 1761/2906 [5:48:23<3:38:17, 11.44s/it] 61%|██████    | 1762/2906 [5:48:35<3:42:06, 11.65s/it]                                                       {'loss': 0.8068, 'grad_norm': 1.3097790479660034, 'learning_rate': 1.7878596546771137e-06, 'epoch': 0.61}
 61%|██████    | 1762/2906 [5:48:35<3:42:06, 11.65s/it] 61%|██████    | 1763/2906 [5:48:47<3:42:55, 11.70s/it]                                                       {'loss': 0.7851, 'grad_norm': 1.2251611948013306, 'learning_rate': 1.7851770675839771e-06, 'epoch': 0.61}
 61%|██████    | 1763/2906 [5:48:47<3:42:55, 11.70s/it] 61%|██████    | 1764/2906 [5:48:59<3:41:13, 11.62s/it]                                                       {'loss': 0.8047, 'grad_norm': 1.371240496635437, 'learning_rate': 1.7824953765214443e-06, 'epoch': 0.61}
 61%|██████    | 1764/2906 [5:48:59<3:41:13, 11.62s/it] 61%|██████    | 1765/2906 [5:49:10<3:41:11, 11.63s/it]                                                       {'loss': 0.7815, 'grad_norm': 1.3218377828598022, 'learning_rate': 1.7798145848510162e-06, 'epoch': 0.61}
 61%|██████    | 1765/2906 [5:49:10<3:41:11, 11.63s/it] 61%|██████    | 1766/2906 [5:49:22<3:39:04, 11.53s/it]                                                       {'loss': 0.8082, 'grad_norm': 1.3183201551437378, 'learning_rate': 1.7771346959330649e-06, 'epoch': 0.61}
 61%|██████    | 1766/2906 [5:49:22<3:39:04, 11.53s/it] 61%|██████    | 1767/2906 [5:49:34<3:41:22, 11.66s/it]                                                       {'loss': 0.8145, 'grad_norm': 1.2795969247817993, 'learning_rate': 1.7744557131268312e-06, 'epoch': 0.61}
 61%|██████    | 1767/2906 [5:49:34<3:41:22, 11.66s/it] 61%|██████    | 1768/2906 [5:49:45<3:38:12, 11.50s/it]                                                       {'loss': 0.7654, 'grad_norm': 1.3349848985671997, 'learning_rate': 1.7717776397904202e-06, 'epoch': 0.61}
 61%|██████    | 1768/2906 [5:49:45<3:38:12, 11.50s/it] 61%|██████    | 1769/2906 [5:49:56<3:38:14, 11.52s/it]                                                       {'loss': 0.8472, 'grad_norm': 1.2587604522705078, 'learning_rate': 1.7691004792807976e-06, 'epoch': 0.61}
 61%|██████    | 1769/2906 [5:49:56<3:38:14, 11.52s/it] 61%|██████    | 1770/2906 [5:50:08<3:39:02, 11.57s/it]                                                       {'loss': 0.7912, 'grad_norm': 1.5069224834442139, 'learning_rate': 1.766424234953785e-06, 'epoch': 0.61}
 61%|██████    | 1770/2906 [5:50:08<3:39:02, 11.57s/it] 61%|██████    | 1771/2906 [5:50:20<3:40:31, 11.66s/it]                                                       {'loss': 0.7751, 'grad_norm': 1.2055542469024658, 'learning_rate': 1.7637489101640526e-06, 'epoch': 0.61}
 61%|██████    | 1771/2906 [5:50:20<3:40:31, 11.66s/it] 61%|██████    | 1772/2906 [5:50:31<3:37:45, 11.52s/it]                                                       {'loss': 0.8293, 'grad_norm': 1.3300410509109497, 'learning_rate': 1.7610745082651218e-06, 'epoch': 0.61}
 61%|██████    | 1772/2906 [5:50:31<3:37:45, 11.52s/it] 61%|██████    | 1773/2906 [5:50:43<3:39:12, 11.61s/it]                                                       {'loss': 0.7654, 'grad_norm': 1.2818126678466797, 'learning_rate': 1.7584010326093554e-06, 'epoch': 0.61}
 61%|██████    | 1773/2906 [5:50:43<3:39:12, 11.61s/it] 61%|██████    | 1774/2906 [5:50:54<3:39:22, 11.63s/it]                                                       {'loss': 0.7872, 'grad_norm': 1.2883144617080688, 'learning_rate': 1.7557284865479553e-06, 'epoch': 0.61}
 61%|██████    | 1774/2906 [5:50:55<3:39:22, 11.63s/it] 61%|██████    | 1775/2906 [5:51:06<3:39:44, 11.66s/it]                                                       {'loss': 0.7742, 'grad_norm': 1.2850815057754517, 'learning_rate': 1.7530568734309578e-06, 'epoch': 0.61}
 61%|██████    | 1775/2906 [5:51:06<3:39:44, 11.66s/it] 61%|██████    | 1776/2906 [5:51:18<3:40:24, 11.70s/it]                                                       {'loss': 0.8234, 'grad_norm': 1.3557544946670532, 'learning_rate': 1.750386196607231e-06, 'epoch': 0.61}
 61%|██████    | 1776/2906 [5:51:18<3:40:24, 11.70s/it] 61%|██████    | 1777/2906 [5:51:30<3:40:21, 11.71s/it]                                                       {'loss': 0.734, 'grad_norm': 1.3287792205810547, 'learning_rate': 1.747716459424468e-06, 'epoch': 0.61}
 61%|██████    | 1777/2906 [5:51:30<3:40:21, 11.71s/it] 61%|██████    | 1778/2906 [5:51:41<3:37:42, 11.58s/it]                                                       {'loss': 0.7904, 'grad_norm': 1.2774354219436646, 'learning_rate': 1.7450476652291847e-06, 'epoch': 0.61}
 61%|██████    | 1778/2906 [5:51:41<3:37:42, 11.58s/it] 61%|██████    | 1779/2906 [5:51:53<3:38:41, 11.64s/it]                                                       {'loss': 0.7711, 'grad_norm': 1.4000805616378784, 'learning_rate': 1.7423798173667144e-06, 'epoch': 0.61}
 61%|██████    | 1779/2906 [5:51:53<3:38:41, 11.64s/it] 61%|██████▏   | 1780/2906 [5:52:05<3:39:05, 11.67s/it]                                                       {'loss': 0.7824, 'grad_norm': 1.3753527402877808, 'learning_rate': 1.7397129191812058e-06, 'epoch': 0.61}
 61%|██████▏   | 1780/2906 [5:52:05<3:39:05, 11.67s/it] 61%|██████▏   | 1781/2906 [5:52:16<3:39:10, 11.69s/it]                                                       {'loss': 0.8398, 'grad_norm': 1.42148756980896, 'learning_rate': 1.7370469740156146e-06, 'epoch': 0.61}
 61%|██████▏   | 1781/2906 [5:52:16<3:39:10, 11.69s/it] 61%|██████▏   | 1782/2906 [5:52:28<3:38:18, 11.65s/it]                                                       {'loss': 0.7947, 'grad_norm': 1.3181043863296509, 'learning_rate': 1.734381985211704e-06, 'epoch': 0.61}
 61%|██████▏   | 1782/2906 [5:52:28<3:38:18, 11.65s/it] 61%|██████▏   | 1783/2906 [5:52:40<3:39:01, 11.70s/it]                                                       {'loss': 0.8487, 'grad_norm': 1.4021971225738525, 'learning_rate': 1.7317179561100372e-06, 'epoch': 0.61}
 61%|██████▏   | 1783/2906 [5:52:40<3:39:01, 11.70s/it] 61%|██████▏   | 1784/2906 [5:52:51<3:35:31, 11.53s/it]                                                       {'loss': 0.8463, 'grad_norm': 1.3528631925582886, 'learning_rate': 1.729054890049976e-06, 'epoch': 0.61}
 61%|██████▏   | 1784/2906 [5:52:51<3:35:31, 11.53s/it] 61%|██████▏   | 1785/2906 [5:53:02<3:35:52, 11.55s/it]                                                       {'loss': 0.8165, 'grad_norm': 1.3705638647079468, 'learning_rate': 1.726392790369673e-06, 'epoch': 0.61}
 61%|██████▏   | 1785/2906 [5:53:02<3:35:52, 11.55s/it] 61%|██████▏   | 1786/2906 [5:53:14<3:34:26, 11.49s/it]                                                       {'loss': 0.8075, 'grad_norm': 1.3647862672805786, 'learning_rate': 1.7237316604060705e-06, 'epoch': 0.61}
 61%|██████▏   | 1786/2906 [5:53:14<3:34:26, 11.49s/it] 61%|██████▏   | 1787/2906 [5:53:26<3:35:52, 11.58s/it]                                                       {'loss': 0.7774, 'grad_norm': 1.2677083015441895, 'learning_rate': 1.7210715034948949e-06, 'epoch': 0.61}
 61%|██████▏   | 1787/2906 [5:53:26<3:35:52, 11.58s/it] 62%|██████▏   | 1788/2906 [5:53:37<3:36:35, 11.62s/it]                                                       {'loss': 0.7599, 'grad_norm': 1.217180609703064, 'learning_rate': 1.7184123229706533e-06, 'epoch': 0.62}
 62%|██████▏   | 1788/2906 [5:53:37<3:36:35, 11.62s/it] 62%|██████▏   | 1789/2906 [5:53:49<3:36:15, 11.62s/it]                                                       {'loss': 0.8339, 'grad_norm': 1.2954283952713013, 'learning_rate': 1.7157541221666291e-06, 'epoch': 0.62}
 62%|██████▏   | 1789/2906 [5:53:49<3:36:15, 11.62s/it] 62%|██████▏   | 1790/2906 [5:53:59<3:30:16, 11.31s/it]                                                       {'loss': 0.7926, 'grad_norm': 1.33143150806427, 'learning_rate': 1.7130969044148771e-06, 'epoch': 0.62}
 62%|██████▏   | 1790/2906 [5:53:59<3:30:16, 11.31s/it] 62%|██████▏   | 1791/2906 [5:54:11<3:33:31, 11.49s/it]                                                       {'loss': 0.8084, 'grad_norm': 1.3479712009429932, 'learning_rate': 1.7104406730462203e-06, 'epoch': 0.62}
 62%|██████▏   | 1791/2906 [5:54:11<3:33:31, 11.49s/it] 62%|██████▏   | 1792/2906 [5:54:23<3:36:05, 11.64s/it]                                                       {'loss': 0.75, 'grad_norm': 1.3401495218276978, 'learning_rate': 1.7077854313902437e-06, 'epoch': 0.62}
 62%|██████▏   | 1792/2906 [5:54:23<3:36:05, 11.64s/it] 62%|██████▏   | 1793/2906 [5:54:35<3:36:42, 11.68s/it]                                                       {'loss': 0.6916, 'grad_norm': 1.2788116931915283, 'learning_rate': 1.705131182775294e-06, 'epoch': 0.62}
 62%|██████▏   | 1793/2906 [5:54:35<3:36:42, 11.68s/it] 62%|██████▏   | 1794/2906 [5:54:47<3:35:02, 11.60s/it]                                                       {'loss': 0.7194, 'grad_norm': 1.2521666288375854, 'learning_rate': 1.702477930528471e-06, 'epoch': 0.62}
 62%|██████▏   | 1794/2906 [5:54:47<3:35:02, 11.60s/it] 62%|██████▏   | 1795/2906 [5:54:58<3:35:50, 11.66s/it]                                                       {'loss': 0.7909, 'grad_norm': 1.243959665298462, 'learning_rate': 1.6998256779756279e-06, 'epoch': 0.62}
 62%|██████▏   | 1795/2906 [5:54:58<3:35:50, 11.66s/it] 62%|██████▏   | 1796/2906 [5:55:10<3:34:48, 11.61s/it]                                                       {'loss': 0.84, 'grad_norm': 1.3267821073532104, 'learning_rate': 1.6971744284413626e-06, 'epoch': 0.62}
 62%|██████▏   | 1796/2906 [5:55:10<3:34:48, 11.61s/it] 62%|██████▏   | 1797/2906 [5:55:22<3:38:02, 11.80s/it]                                                       {'loss': 0.8395, 'grad_norm': 1.3239566087722778, 'learning_rate': 1.6945241852490173e-06, 'epoch': 0.62}
 62%|██████▏   | 1797/2906 [5:55:22<3:38:02, 11.80s/it] 62%|██████▏   | 1798/2906 [5:55:34<3:38:25, 11.83s/it]                                                       {'loss': 0.7374, 'grad_norm': 1.212873935699463, 'learning_rate': 1.6918749517206712e-06, 'epoch': 0.62}
 62%|██████▏   | 1798/2906 [5:55:34<3:38:25, 11.83s/it] 62%|██████▏   | 1799/2906 [5:55:46<3:37:44, 11.80s/it]                                                       {'loss': 0.7879, 'grad_norm': 1.2882018089294434, 'learning_rate': 1.6892267311771395e-06, 'epoch': 0.62}
 62%|██████▏   | 1799/2906 [5:55:46<3:37:44, 11.80s/it] 62%|██████▏   | 1800/2906 [5:55:57<3:35:48, 11.71s/it]                                                       {'loss': 0.744, 'grad_norm': 1.1935712099075317, 'learning_rate': 1.6865795269379667e-06, 'epoch': 0.62}
 62%|██████▏   | 1800/2906 [5:55:57<3:35:48, 11.71s/it] 62%|██████▏   | 1801/2906 [5:56:09<3:35:23, 11.70s/it]                                                       {'loss': 0.8442, 'grad_norm': 1.4186980724334717, 'learning_rate': 1.6839333423214235e-06, 'epoch': 0.62}
 62%|██████▏   | 1801/2906 [5:56:09<3:35:23, 11.70s/it] 62%|██████▏   | 1802/2906 [5:56:21<3:37:20, 11.81s/it]                                                       {'loss': 0.8025, 'grad_norm': 1.3414793014526367, 'learning_rate': 1.6812881806445019e-06, 'epoch': 0.62}
 62%|██████▏   | 1802/2906 [5:56:21<3:37:20, 11.81s/it] 62%|██████▏   | 1803/2906 [5:56:32<3:35:22, 11.72s/it]                                                       {'loss': 0.806, 'grad_norm': 1.3792537450790405, 'learning_rate': 1.6786440452229134e-06, 'epoch': 0.62}
 62%|██████▏   | 1803/2906 [5:56:32<3:35:22, 11.72s/it] 62%|██████▏   | 1804/2906 [5:56:44<3:35:33, 11.74s/it]                                                       {'loss': 0.7838, 'grad_norm': 1.5227112770080566, 'learning_rate': 1.6760009393710814e-06, 'epoch': 0.62}
 62%|██████▏   | 1804/2906 [5:56:44<3:35:33, 11.74s/it] 62%|██████▏   | 1805/2906 [5:56:56<3:35:48, 11.76s/it]                                                       {'loss': 0.8355, 'grad_norm': 1.3489214181900024, 'learning_rate': 1.673358866402139e-06, 'epoch': 0.62}
 62%|██████▏   | 1805/2906 [5:56:56<3:35:48, 11.76s/it] 62%|██████▏   | 1806/2906 [5:57:07<3:31:47, 11.55s/it]                                                       {'loss': 0.8183, 'grad_norm': 1.4340200424194336, 'learning_rate': 1.6707178296279256e-06, 'epoch': 0.62}
 62%|██████▏   | 1806/2906 [5:57:07<3:31:47, 11.55s/it] 62%|██████▏   | 1807/2906 [5:57:18<3:30:17, 11.48s/it]                                                       {'loss': 0.8348, 'grad_norm': 1.3292925357818604, 'learning_rate': 1.6680778323589798e-06, 'epoch': 0.62}
 62%|██████▏   | 1807/2906 [5:57:18<3:30:17, 11.48s/it] 62%|██████▏   | 1808/2906 [5:57:30<3:28:01, 11.37s/it]                                                       {'loss': 0.8164, 'grad_norm': 1.437014102935791, 'learning_rate': 1.66543887790454e-06, 'epoch': 0.62}
 62%|██████▏   | 1808/2906 [5:57:30<3:28:01, 11.37s/it] 62%|██████▏   | 1809/2906 [5:57:41<3:28:55, 11.43s/it]                                                       {'loss': 0.7752, 'grad_norm': 1.293350100517273, 'learning_rate': 1.6628009695725348e-06, 'epoch': 0.62}
 62%|██████▏   | 1809/2906 [5:57:41<3:28:55, 11.43s/it] 62%|██████▏   | 1810/2906 [5:57:52<3:26:55, 11.33s/it]                                                       {'loss': 0.8313, 'grad_norm': 1.3610738515853882, 'learning_rate': 1.6601641106695826e-06, 'epoch': 0.62}
 62%|██████▏   | 1810/2906 [5:57:52<3:26:55, 11.33s/it] 62%|██████▏   | 1811/2906 [5:58:04<3:27:26, 11.37s/it]                                                       {'loss': 0.7538, 'grad_norm': 1.3056097030639648, 'learning_rate': 1.657528304500986e-06, 'epoch': 0.62}
 62%|██████▏   | 1811/2906 [5:58:04<3:27:26, 11.37s/it] 62%|██████▏   | 1812/2906 [5:58:15<3:27:37, 11.39s/it]                                                       {'loss': 0.8263, 'grad_norm': 1.4234837293624878, 'learning_rate': 1.6548935543707295e-06, 'epoch': 0.62}
 62%|██████▏   | 1812/2906 [5:58:15<3:27:37, 11.39s/it] 62%|██████▏   | 1813/2906 [5:58:27<3:27:43, 11.40s/it]                                                       {'loss': 0.7945, 'grad_norm': 1.3348792791366577, 'learning_rate': 1.6522598635814718e-06, 'epoch': 0.62}
 62%|██████▏   | 1813/2906 [5:58:27<3:27:43, 11.40s/it] 62%|██████▏   | 1814/2906 [5:58:39<3:31:26, 11.62s/it]                                                       {'loss': 0.7703, 'grad_norm': 1.2981266975402832, 'learning_rate': 1.649627235434544e-06, 'epoch': 0.62}
 62%|██████▏   | 1814/2906 [5:58:39<3:31:26, 11.62s/it] 62%|██████▏   | 1815/2906 [5:58:50<3:31:14, 11.62s/it]                                                       {'loss': 0.7543, 'grad_norm': 1.2288258075714111, 'learning_rate': 1.6469956732299463e-06, 'epoch': 0.62}
 62%|██████▏   | 1815/2906 [5:58:50<3:31:14, 11.62s/it] 62%|██████▏   | 1816/2906 [5:59:01<3:27:03, 11.40s/it]                                                       {'loss': 0.8243, 'grad_norm': 1.2784045934677124, 'learning_rate': 1.6443651802663419e-06, 'epoch': 0.62}
 62%|██████▏   | 1816/2906 [5:59:01<3:27:03, 11.40s/it] 63%|██████▎   | 1817/2906 [5:59:13<3:28:53, 11.51s/it]                                                       {'loss': 0.8309, 'grad_norm': 1.3493272066116333, 'learning_rate': 1.6417357598410539e-06, 'epoch': 0.63}
 63%|██████▎   | 1817/2906 [5:59:13<3:28:53, 11.51s/it] 63%|██████▎   | 1818/2906 [5:59:25<3:29:08, 11.53s/it]                                                       {'loss': 0.7552, 'grad_norm': 1.3403940200805664, 'learning_rate': 1.639107415250061e-06, 'epoch': 0.63}
 63%|██████▎   | 1818/2906 [5:59:25<3:29:08, 11.53s/it] 63%|██████▎   | 1819/2906 [5:59:36<3:29:22, 11.56s/it]                                                       {'loss': 0.827, 'grad_norm': 1.3765053749084473, 'learning_rate': 1.636480149787994e-06, 'epoch': 0.63}
 63%|██████▎   | 1819/2906 [5:59:36<3:29:22, 11.56s/it] 63%|██████▎   | 1820/2906 [5:59:49<3:34:17, 11.84s/it]                                                       {'loss': 0.8001, 'grad_norm': 1.2783607244491577, 'learning_rate': 1.6338539667481296e-06, 'epoch': 0.63}
 63%|██████▎   | 1820/2906 [5:59:49<3:34:17, 11.84s/it] 63%|██████▎   | 1821/2906 [6:00:00<3:33:40, 11.82s/it]                                                       {'loss': 0.7962, 'grad_norm': 1.3393646478652954, 'learning_rate': 1.6312288694223882e-06, 'epoch': 0.63}
 63%|██████▎   | 1821/2906 [6:00:00<3:33:40, 11.82s/it] 63%|██████▎   | 1822/2906 [6:00:12<3:33:17, 11.81s/it]                                                       {'loss': 0.7945, 'grad_norm': 1.2179453372955322, 'learning_rate': 1.6286048611013309e-06, 'epoch': 0.63}
 63%|██████▎   | 1822/2906 [6:00:12<3:33:17, 11.81s/it] 63%|██████▎   | 1823/2906 [6:00:24<3:35:00, 11.91s/it]                                                       {'loss': 0.868, 'grad_norm': 1.3393205404281616, 'learning_rate': 1.6259819450741512e-06, 'epoch': 0.63}
 63%|██████▎   | 1823/2906 [6:00:24<3:35:00, 11.91s/it] 63%|██████▎   | 1824/2906 [6:00:36<3:32:57, 11.81s/it]                                                       {'loss': 0.8296, 'grad_norm': 1.3803266286849976, 'learning_rate': 1.623360124628675e-06, 'epoch': 0.63}
 63%|██████▎   | 1824/2906 [6:00:36<3:32:57, 11.81s/it] 63%|██████▎   | 1825/2906 [6:00:47<3:31:01, 11.71s/it]                                                       {'loss': 0.8021, 'grad_norm': 1.3208717107772827, 'learning_rate': 1.620739403051354e-06, 'epoch': 0.63}
 63%|██████▎   | 1825/2906 [6:00:47<3:31:01, 11.71s/it] 63%|██████▎   | 1826/2906 [6:00:59<3:30:34, 11.70s/it]                                                       {'loss': 0.8178, 'grad_norm': 1.3979638814926147, 'learning_rate': 1.618119783627263e-06, 'epoch': 0.63}
 63%|██████▎   | 1826/2906 [6:00:59<3:30:34, 11.70s/it] 63%|██████▎   | 1827/2906 [6:01:11<3:29:24, 11.64s/it]                                                       {'loss': 0.7476, 'grad_norm': 1.3250657320022583, 'learning_rate': 1.6155012696400959e-06, 'epoch': 0.63}
 63%|██████▎   | 1827/2906 [6:01:11<3:29:24, 11.64s/it] 63%|██████▎   | 1828/2906 [6:01:22<3:30:22, 11.71s/it]                                                       {'loss': 0.7838, 'grad_norm': 1.1758800745010376, 'learning_rate': 1.6128838643721596e-06, 'epoch': 0.63}
 63%|██████▎   | 1828/2906 [6:01:22<3:30:22, 11.71s/it] 63%|██████▎   | 1829/2906 [6:01:34<3:29:18, 11.66s/it]                                                       {'loss': 0.8308, 'grad_norm': 1.371041178703308, 'learning_rate': 1.6102675711043719e-06, 'epoch': 0.63}
 63%|██████▎   | 1829/2906 [6:01:34<3:29:18, 11.66s/it] 63%|██████▎   | 1830/2906 [6:01:45<3:26:11, 11.50s/it]                                                       {'loss': 0.8254, 'grad_norm': 1.2904343605041504, 'learning_rate': 1.607652393116256e-06, 'epoch': 0.63}
 63%|██████▎   | 1830/2906 [6:01:45<3:26:11, 11.50s/it] 63%|██████▎   | 1831/2906 [6:01:56<3:24:13, 11.40s/it]                                                       {'loss': 0.8051, 'grad_norm': 1.3883416652679443, 'learning_rate': 1.6050383336859388e-06, 'epoch': 0.63}
 63%|██████▎   | 1831/2906 [6:01:56<3:24:13, 11.40s/it] 63%|██████▎   | 1832/2906 [6:02:08<3:25:31, 11.48s/it]                                                       {'loss': 0.7483, 'grad_norm': 1.365790843963623, 'learning_rate': 1.6024253960901437e-06, 'epoch': 0.63}
 63%|██████▎   | 1832/2906 [6:02:08<3:25:31, 11.48s/it] 63%|██████▎   | 1833/2906 [6:02:20<3:27:49, 11.62s/it]                                                       {'loss': 0.741, 'grad_norm': 1.3379274606704712, 'learning_rate': 1.599813583604188e-06, 'epoch': 0.63}
 63%|██████▎   | 1833/2906 [6:02:20<3:27:49, 11.62s/it] 63%|██████▎   | 1834/2906 [6:02:32<3:28:08, 11.65s/it]                                                       {'loss': 0.8546, 'grad_norm': 1.3717900514602661, 'learning_rate': 1.5972028995019794e-06, 'epoch': 0.63}
 63%|██████▎   | 1834/2906 [6:02:32<3:28:08, 11.65s/it] 63%|██████▎   | 1835/2906 [6:02:43<3:28:52, 11.70s/it]                                                       {'loss': 0.8035, 'grad_norm': 1.3163557052612305, 'learning_rate': 1.5945933470560097e-06, 'epoch': 0.63}
 63%|██████▎   | 1835/2906 [6:02:43<3:28:52, 11.70s/it] 63%|██████▎   | 1836/2906 [6:02:55<3:27:46, 11.65s/it]                                                       {'loss': 0.7887, 'grad_norm': 1.3159260749816895, 'learning_rate': 1.5919849295373529e-06, 'epoch': 0.63}
 63%|██████▎   | 1836/2906 [6:02:55<3:27:46, 11.65s/it] 63%|██████▎   | 1837/2906 [6:03:07<3:29:02, 11.73s/it]                                                       {'loss': 0.8493, 'grad_norm': 1.3061130046844482, 'learning_rate': 1.5893776502156616e-06, 'epoch': 0.63}
 63%|██████▎   | 1837/2906 [6:03:07<3:29:02, 11.73s/it] 63%|██████▎   | 1838/2906 [6:03:18<3:24:50, 11.51s/it]                                                       {'loss': 0.7221, 'grad_norm': 1.4095419645309448, 'learning_rate': 1.5867715123591604e-06, 'epoch': 0.63}
 63%|██████▎   | 1838/2906 [6:03:18<3:24:50, 11.51s/it] 63%|██████▎   | 1839/2906 [6:03:30<3:26:07, 11.59s/it]                                                       {'loss': 0.805, 'grad_norm': 1.2813557386398315, 'learning_rate': 1.5841665192346432e-06, 'epoch': 0.63}
 63%|██████▎   | 1839/2906 [6:03:30<3:26:07, 11.59s/it] 63%|██████▎   | 1840/2906 [6:03:41<3:27:07, 11.66s/it]                                                       {'loss': 0.7458, 'grad_norm': 1.2343056201934814, 'learning_rate': 1.5815626741074692e-06, 'epoch': 0.63}
 63%|██████▎   | 1840/2906 [6:03:41<3:27:07, 11.66s/it] 63%|██████▎   | 1841/2906 [6:03:53<3:27:57, 11.72s/it]                                                       {'loss': 0.8018, 'grad_norm': 1.2910562753677368, 'learning_rate': 1.5789599802415572e-06, 'epoch': 0.63}
 63%|██████▎   | 1841/2906 [6:03:53<3:27:57, 11.72s/it] 63%|██████▎   | 1842/2906 [6:04:05<3:29:12, 11.80s/it]                                                       {'loss': 0.7975, 'grad_norm': 1.2528778314590454, 'learning_rate': 1.5763584408993864e-06, 'epoch': 0.63}
 63%|██████▎   | 1842/2906 [6:04:05<3:29:12, 11.80s/it] 63%|██████▎   | 1843/2906 [6:04:18<3:34:18, 12.10s/it]                                                       {'loss': 0.7647, 'grad_norm': 1.219303846359253, 'learning_rate': 1.5737580593419854e-06, 'epoch': 0.63}
 63%|██████▎   | 1843/2906 [6:04:18<3:34:18, 12.10s/it] 63%|██████▎   | 1844/2906 [6:04:30<3:31:05, 11.93s/it]                                                       {'loss': 0.786, 'grad_norm': 1.31964111328125, 'learning_rate': 1.5711588388289328e-06, 'epoch': 0.63}
 63%|██████▎   | 1844/2906 [6:04:30<3:31:05, 11.93s/it] 63%|██████▎   | 1845/2906 [6:04:42<3:30:56, 11.93s/it]                                                       {'loss': 0.7777, 'grad_norm': 1.2953017950057983, 'learning_rate': 1.5685607826183514e-06, 'epoch': 0.63}
 63%|██████▎   | 1845/2906 [6:04:42<3:30:56, 11.93s/it] 64%|██████▎   | 1846/2906 [6:04:53<3:30:30, 11.92s/it]                                                       {'loss': 0.7476, 'grad_norm': 1.2565159797668457, 'learning_rate': 1.5659638939669054e-06, 'epoch': 0.64}
 64%|██████▎   | 1846/2906 [6:04:53<3:30:30, 11.92s/it] 64%|██████▎   | 1847/2906 [6:05:05<3:28:52, 11.83s/it]                                                       {'loss': 0.8537, 'grad_norm': 1.3557226657867432, 'learning_rate': 1.5633681761297948e-06, 'epoch': 0.64}
 64%|██████▎   | 1847/2906 [6:05:05<3:28:52, 11.83s/it] 64%|██████▎   | 1848/2906 [6:05:17<3:29:59, 11.91s/it]                                                       {'loss': 0.7529, 'grad_norm': 1.3065590858459473, 'learning_rate': 1.560773632360752e-06, 'epoch': 0.64}
 64%|██████▎   | 1848/2906 [6:05:17<3:29:59, 11.91s/it] 64%|██████▎   | 1849/2906 [6:05:29<3:29:01, 11.86s/it]                                                       {'loss': 0.7967, 'grad_norm': 1.313698649406433, 'learning_rate': 1.558180265912037e-06, 'epoch': 0.64}
 64%|██████▎   | 1849/2906 [6:05:29<3:29:01, 11.86s/it] 64%|██████▎   | 1850/2906 [6:05:41<3:30:16, 11.95s/it]                                                       {'loss': 0.8008, 'grad_norm': 1.3990650177001953, 'learning_rate': 1.555588080034437e-06, 'epoch': 0.64}
 64%|██████▎   | 1850/2906 [6:05:41<3:30:16, 11.95s/it] 64%|██████▎   | 1851/2906 [6:05:52<3:27:12, 11.78s/it]                                                       {'loss': 0.7998, 'grad_norm': 1.37907874584198, 'learning_rate': 1.5529970779772552e-06, 'epoch': 0.64}
 64%|██████▎   | 1851/2906 [6:05:52<3:27:12, 11.78s/it] 64%|██████▎   | 1852/2906 [6:06:04<3:25:21, 11.69s/it]                                                       {'loss': 0.8179, 'grad_norm': 1.2600277662277222, 'learning_rate': 1.5504072629883143e-06, 'epoch': 0.64}
 64%|██████▎   | 1852/2906 [6:06:04<3:25:21, 11.69s/it] 64%|██████▍   | 1853/2906 [6:06:16<3:26:23, 11.76s/it]                                                       {'loss': 0.8118, 'grad_norm': 1.406853199005127, 'learning_rate': 1.5478186383139459e-06, 'epoch': 0.64}
 64%|██████▍   | 1853/2906 [6:06:16<3:26:23, 11.76s/it] 64%|██████▍   | 1854/2906 [6:06:28<3:25:44, 11.73s/it]                                                       {'loss': 0.7574, 'grad_norm': 1.3565493822097778, 'learning_rate': 1.545231207198993e-06, 'epoch': 0.64}
 64%|██████▍   | 1854/2906 [6:06:28<3:25:44, 11.73s/it] 64%|██████▍   | 1855/2906 [6:06:39<3:24:16, 11.66s/it]                                                       {'loss': 0.8212, 'grad_norm': 1.3266406059265137, 'learning_rate': 1.5426449728868004e-06, 'epoch': 0.64}
 64%|██████▍   | 1855/2906 [6:06:39<3:24:16, 11.66s/it] 64%|██████▍   | 1856/2906 [6:06:51<3:24:51, 11.71s/it]                                                       {'loss': 0.8015, 'grad_norm': 1.4120571613311768, 'learning_rate': 1.5400599386192122e-06, 'epoch': 0.64}
 64%|██████▍   | 1856/2906 [6:06:51<3:24:51, 11.71s/it] 64%|██████▍   | 1857/2906 [6:07:02<3:23:07, 11.62s/it]                                                       {'loss': 0.8101, 'grad_norm': 1.3397165536880493, 'learning_rate': 1.5374761076365695e-06, 'epoch': 0.64}
 64%|██████▍   | 1857/2906 [6:07:02<3:23:07, 11.62s/it] 64%|██████▍   | 1858/2906 [6:07:14<3:25:17, 11.75s/it]                                                       {'loss': 0.7001, 'grad_norm': 1.287644386291504, 'learning_rate': 1.5348934831777046e-06, 'epoch': 0.64}
 64%|██████▍   | 1858/2906 [6:07:14<3:25:17, 11.75s/it] 64%|██████▍   | 1859/2906 [6:07:26<3:24:16, 11.71s/it]                                                       {'loss': 0.8115, 'grad_norm': 1.361309289932251, 'learning_rate': 1.5323120684799374e-06, 'epoch': 0.64}
 64%|██████▍   | 1859/2906 [6:07:26<3:24:16, 11.71s/it] 64%|██████▍   | 1860/2906 [6:07:37<3:23:01, 11.65s/it]                                                       {'loss': 0.8205, 'grad_norm': 1.3002361059188843, 'learning_rate': 1.5297318667790712e-06, 'epoch': 0.64}
 64%|██████▍   | 1860/2906 [6:07:37<3:23:01, 11.65s/it] 64%|██████▍   | 1861/2906 [6:07:49<3:23:11, 11.67s/it]                                                       {'loss': 0.8199, 'grad_norm': 1.2963021993637085, 'learning_rate': 1.5271528813093896e-06, 'epoch': 0.64}
 64%|██████▍   | 1861/2906 [6:07:49<3:23:11, 11.67s/it] 64%|██████▍   | 1862/2906 [6:08:01<3:21:45, 11.60s/it]                                                       {'loss': 0.8196, 'grad_norm': 1.315003752708435, 'learning_rate': 1.5245751153036512e-06, 'epoch': 0.64}
 64%|██████▍   | 1862/2906 [6:08:01<3:21:45, 11.60s/it] 64%|██████▍   | 1863/2906 [6:08:12<3:22:45, 11.66s/it]                                                       {'loss': 0.7567, 'grad_norm': 1.2543524503707886, 'learning_rate': 1.5219985719930851e-06, 'epoch': 0.64}
 64%|██████▍   | 1863/2906 [6:08:12<3:22:45, 11.66s/it] 64%|██████▍   | 1864/2906 [6:08:25<3:25:38, 11.84s/it]                                                       {'loss': 0.7757, 'grad_norm': 1.323014736175537, 'learning_rate': 1.519423254607389e-06, 'epoch': 0.64}
 64%|██████▍   | 1864/2906 [6:08:25<3:25:38, 11.84s/it] 64%|██████▍   | 1865/2906 [6:08:36<3:22:08, 11.65s/it]                                                       {'loss': 0.7722, 'grad_norm': 1.3685561418533325, 'learning_rate': 1.5168491663747236e-06, 'epoch': 0.64}
 64%|██████▍   | 1865/2906 [6:08:36<3:22:08, 11.65s/it] 64%|██████▍   | 1866/2906 [6:08:47<3:19:40, 11.52s/it]                                                       {'loss': 0.8174, 'grad_norm': 1.294460654258728, 'learning_rate': 1.514276310521709e-06, 'epoch': 0.64}
 64%|██████▍   | 1866/2906 [6:08:47<3:19:40, 11.52s/it] 64%|██████▍   | 1867/2906 [6:08:59<3:19:54, 11.54s/it]                                                       {'loss': 0.8061, 'grad_norm': 1.3054776191711426, 'learning_rate': 1.5117046902734194e-06, 'epoch': 0.64}
 64%|██████▍   | 1867/2906 [6:08:59<3:19:54, 11.54s/it] 64%|██████▍   | 1868/2906 [6:09:11<3:24:12, 11.80s/it]                                                       {'loss': 0.7895, 'grad_norm': 1.3536051511764526, 'learning_rate': 1.509134308853381e-06, 'epoch': 0.64}
 64%|██████▍   | 1868/2906 [6:09:11<3:24:12, 11.80s/it] 64%|██████▍   | 1869/2906 [6:09:23<3:23:03, 11.75s/it]                                                       {'loss': 0.7335, 'grad_norm': 1.20916748046875, 'learning_rate': 1.5065651694835682e-06, 'epoch': 0.64}
 64%|██████▍   | 1869/2906 [6:09:23<3:23:03, 11.75s/it] 64%|██████▍   | 1870/2906 [6:09:34<3:22:23, 11.72s/it]                                                       {'loss': 0.8271, 'grad_norm': 1.2127363681793213, 'learning_rate': 1.5039972753843966e-06, 'epoch': 0.64}
 64%|██████▍   | 1870/2906 [6:09:34<3:22:23, 11.72s/it] 64%|██████▍   | 1871/2906 [6:09:46<3:22:23, 11.73s/it]                                                       {'loss': 0.8027, 'grad_norm': 1.309070348739624, 'learning_rate': 1.5014306297747217e-06, 'epoch': 0.64}
 64%|██████▍   | 1871/2906 [6:09:46<3:22:23, 11.73s/it] 64%|██████▍   | 1872/2906 [6:09:58<3:22:44, 11.76s/it]                                                       {'loss': 0.8528, 'grad_norm': 1.2757492065429688, 'learning_rate': 1.4988652358718336e-06, 'epoch': 0.64}
 64%|██████▍   | 1872/2906 [6:09:58<3:22:44, 11.76s/it] 64%|██████▍   | 1873/2906 [6:10:10<3:22:17, 11.75s/it]                                                       {'loss': 0.8778, 'grad_norm': 1.402664065361023, 'learning_rate': 1.4963010968914549e-06, 'epoch': 0.64}
 64%|██████▍   | 1873/2906 [6:10:10<3:22:17, 11.75s/it] 64%|██████▍   | 1874/2906 [6:10:22<3:22:38, 11.78s/it]                                                       {'loss': 0.7465, 'grad_norm': 1.3593107461929321, 'learning_rate': 1.4937382160477332e-06, 'epoch': 0.64}
 64%|██████▍   | 1874/2906 [6:10:22<3:22:38, 11.78s/it] 65%|██████▍   | 1875/2906 [6:10:33<3:20:53, 11.69s/it]                                                       {'loss': 0.8455, 'grad_norm': 1.426602840423584, 'learning_rate': 1.4911765965532398e-06, 'epoch': 0.65}
 65%|██████▍   | 1875/2906 [6:10:33<3:20:53, 11.69s/it] 65%|██████▍   | 1876/2906 [6:10:44<3:19:04, 11.60s/it]                                                       {'loss': 0.7955, 'grad_norm': 1.219260811805725, 'learning_rate': 1.488616241618965e-06, 'epoch': 0.65}
 65%|██████▍   | 1876/2906 [6:10:44<3:19:04, 11.60s/it] 65%|██████▍   | 1877/2906 [6:10:56<3:17:41, 11.53s/it]                                                       {'loss': 0.7614, 'grad_norm': 1.3326387405395508, 'learning_rate': 1.4860571544543157e-06, 'epoch': 0.65}
 65%|██████▍   | 1877/2906 [6:10:56<3:17:41, 11.53s/it] 65%|██████▍   | 1878/2906 [6:11:07<3:17:45, 11.54s/it]                                                       {'loss': 0.7708, 'grad_norm': 1.2927918434143066, 'learning_rate': 1.4834993382671048e-06, 'epoch': 0.65}
 65%|██████▍   | 1878/2906 [6:11:07<3:17:45, 11.54s/it] 65%|██████▍   | 1879/2906 [6:11:19<3:18:10, 11.58s/it]                                                       {'loss': 0.7742, 'grad_norm': 1.2766739130020142, 'learning_rate': 1.480942796263556e-06, 'epoch': 0.65}
 65%|██████▍   | 1879/2906 [6:11:19<3:18:10, 11.58s/it] 65%|██████▍   | 1880/2906 [6:11:31<3:18:55, 11.63s/it]                                                       {'loss': 0.8052, 'grad_norm': 1.3230090141296387, 'learning_rate': 1.4783875316482964e-06, 'epoch': 0.65}
 65%|██████▍   | 1880/2906 [6:11:31<3:18:55, 11.63s/it] 65%|██████▍   | 1881/2906 [6:11:42<3:15:57, 11.47s/it]                                                       {'loss': 0.8208, 'grad_norm': 1.451229214668274, 'learning_rate': 1.475833547624349e-06, 'epoch': 0.65}
 65%|██████▍   | 1881/2906 [6:11:42<3:15:57, 11.47s/it] 65%|██████▍   | 1882/2906 [6:11:54<3:18:43, 11.64s/it]                                                       {'loss': 0.8767, 'grad_norm': 1.3275692462921143, 'learning_rate': 1.4732808473931336e-06, 'epoch': 0.65}
 65%|██████▍   | 1882/2906 [6:11:54<3:18:43, 11.64s/it] 65%|██████▍   | 1883/2906 [6:12:06<3:19:41, 11.71s/it]                                                       {'loss': 0.7517, 'grad_norm': 1.2674311399459839, 'learning_rate': 1.4707294341544598e-06, 'epoch': 0.65}
 65%|██████▍   | 1883/2906 [6:12:06<3:19:41, 11.71s/it] 65%|██████▍   | 1884/2906 [6:12:18<3:20:59, 11.80s/it]                                                       {'loss': 0.7825, 'grad_norm': 1.339109182357788, 'learning_rate': 1.4681793111065248e-06, 'epoch': 0.65}
 65%|██████▍   | 1884/2906 [6:12:18<3:20:59, 11.80s/it] 65%|██████▍   | 1885/2906 [6:12:30<3:20:32, 11.78s/it]                                                       {'loss': 0.7772, 'grad_norm': 1.278875470161438, 'learning_rate': 1.4656304814459077e-06, 'epoch': 0.65}
 65%|██████▍   | 1885/2906 [6:12:30<3:20:32, 11.78s/it] 65%|██████▍   | 1886/2906 [6:12:41<3:20:45, 11.81s/it]                                                       {'loss': 0.8324, 'grad_norm': 1.3113764524459839, 'learning_rate': 1.4630829483675668e-06, 'epoch': 0.65}
 65%|██████▍   | 1886/2906 [6:12:41<3:20:45, 11.81s/it] 65%|██████▍   | 1887/2906 [6:12:53<3:19:10, 11.73s/it]                                                       {'loss': 0.8028, 'grad_norm': 1.3426603078842163, 'learning_rate': 1.4605367150648341e-06, 'epoch': 0.65}
 65%|██████▍   | 1887/2906 [6:12:53<3:19:10, 11.73s/it] 65%|██████▍   | 1888/2906 [6:13:05<3:18:47, 11.72s/it]                                                       {'loss': 0.8195, 'grad_norm': 1.3871567249298096, 'learning_rate': 1.4579917847294151e-06, 'epoch': 0.65}
 65%|██████▍   | 1888/2906 [6:13:05<3:18:47, 11.72s/it] 65%|██████▌   | 1889/2906 [6:13:17<3:19:49, 11.79s/it]                                                       {'loss': 0.7883, 'grad_norm': 1.2804476022720337, 'learning_rate': 1.455448160551378e-06, 'epoch': 0.65}
 65%|██████▌   | 1889/2906 [6:13:17<3:19:49, 11.79s/it] 65%|██████▌   | 1890/2906 [6:13:28<3:18:16, 11.71s/it]                                                       {'loss': 0.7713, 'grad_norm': 1.2487359046936035, 'learning_rate': 1.452905845719159e-06, 'epoch': 0.65}
 65%|██████▌   | 1890/2906 [6:13:28<3:18:16, 11.71s/it] 65%|██████▌   | 1891/2906 [6:13:40<3:18:27, 11.73s/it]                                                       {'loss': 0.8444, 'grad_norm': 1.3696956634521484, 'learning_rate': 1.4503648434195466e-06, 'epoch': 0.65}
 65%|██████▌   | 1891/2906 [6:13:40<3:18:27, 11.73s/it] 65%|██████▌   | 1892/2906 [6:13:51<3:16:50, 11.65s/it]                                                       {'loss': 0.7867, 'grad_norm': 1.2711842060089111, 'learning_rate': 1.4478251568376897e-06, 'epoch': 0.65}
 65%|██████▌   | 1892/2906 [6:13:51<3:16:50, 11.65s/it] 65%|██████▌   | 1893/2906 [6:14:03<3:17:14, 11.68s/it]                                                       {'loss': 0.7953, 'grad_norm': 1.4328713417053223, 'learning_rate': 1.445286789157084e-06, 'epoch': 0.65}
 65%|██████▌   | 1893/2906 [6:14:03<3:17:14, 11.68s/it] 65%|██████▌   | 1894/2906 [6:14:15<3:17:11, 11.69s/it]                                                       {'loss': 0.7711, 'grad_norm': 1.3483389616012573, 'learning_rate': 1.4427497435595744e-06, 'epoch': 0.65}
 65%|██████▌   | 1894/2906 [6:14:15<3:17:11, 11.69s/it] 65%|██████▌   | 1895/2906 [6:14:26<3:15:29, 11.60s/it]                                                       {'loss': 0.8809, 'grad_norm': 1.3557060956954956, 'learning_rate': 1.4402140232253486e-06, 'epoch': 0.65}
 65%|██████▌   | 1895/2906 [6:14:26<3:15:29, 11.60s/it] 65%|██████▌   | 1896/2906 [6:14:38<3:15:06, 11.59s/it]                                                       {'loss': 0.8111, 'grad_norm': 1.3244236707687378, 'learning_rate': 1.4376796313329305e-06, 'epoch': 0.65}
 65%|██████▌   | 1896/2906 [6:14:38<3:15:06, 11.59s/it] 65%|██████▌   | 1897/2906 [6:14:50<3:16:14, 11.67s/it]                                                       {'loss': 0.7694, 'grad_norm': 1.325000286102295, 'learning_rate': 1.435146571059181e-06, 'epoch': 0.65}
 65%|██████▌   | 1897/2906 [6:14:50<3:16:14, 11.67s/it] 65%|██████▌   | 1898/2906 [6:15:01<3:16:34, 11.70s/it]                                                       {'loss': 0.8354, 'grad_norm': 1.2922213077545166, 'learning_rate': 1.4326148455792943e-06, 'epoch': 0.65}
 65%|██████▌   | 1898/2906 [6:15:01<3:16:34, 11.70s/it] 65%|██████▌   | 1899/2906 [6:15:13<3:15:05, 11.62s/it]                                                       {'loss': 0.8081, 'grad_norm': 1.3883841037750244, 'learning_rate': 1.430084458066784e-06, 'epoch': 0.65}
 65%|██████▌   | 1899/2906 [6:15:13<3:15:05, 11.62s/it] 65%|██████▌   | 1900/2906 [6:15:24<3:14:18, 11.59s/it]                                                       {'loss': 0.8039, 'grad_norm': 1.3912153244018555, 'learning_rate': 1.4275554116934928e-06, 'epoch': 0.65}
 65%|██████▌   | 1900/2906 [6:15:24<3:14:18, 11.59s/it] 65%|██████▌   | 1901/2906 [6:15:36<3:14:21, 11.60s/it]                                                       {'loss': 0.7426, 'grad_norm': 1.2952309846878052, 'learning_rate': 1.4250277096295817e-06, 'epoch': 0.65}
 65%|██████▌   | 1901/2906 [6:15:36<3:14:21, 11.60s/it] 65%|██████▌   | 1902/2906 [6:15:48<3:16:51, 11.76s/it]                                                       {'loss': 0.7938, 'grad_norm': 1.2730765342712402, 'learning_rate': 1.4225013550435238e-06, 'epoch': 0.65}
 65%|██████▌   | 1902/2906 [6:15:48<3:16:51, 11.76s/it] 65%|██████▌   | 1903/2906 [6:16:00<3:17:34, 11.82s/it]                                                       {'loss': 0.8197, 'grad_norm': 1.2452999353408813, 'learning_rate': 1.4199763511021065e-06, 'epoch': 0.65}
 65%|██████▌   | 1903/2906 [6:16:00<3:17:34, 11.82s/it] 66%|██████▌   | 1904/2906 [6:16:12<3:16:55, 11.79s/it]                                                       {'loss': 0.7641, 'grad_norm': 1.2694512605667114, 'learning_rate': 1.4174527009704204e-06, 'epoch': 0.66}
 66%|██████▌   | 1904/2906 [6:16:12<3:16:55, 11.79s/it] 66%|██████▌   | 1905/2906 [6:16:23<3:14:56, 11.68s/it]                                                       {'loss': 0.7364, 'grad_norm': 1.2983040809631348, 'learning_rate': 1.4149304078118619e-06, 'epoch': 0.66}
 66%|██████▌   | 1905/2906 [6:16:23<3:14:56, 11.68s/it] 66%|██████▌   | 1906/2906 [6:16:35<3:13:39, 11.62s/it]                                                       {'loss': 0.7881, 'grad_norm': 1.2890735864639282, 'learning_rate': 1.4124094747881272e-06, 'epoch': 0.66}
 66%|██████▌   | 1906/2906 [6:16:35<3:13:39, 11.62s/it] 66%|██████▌   | 1907/2906 [6:16:47<3:16:26, 11.80s/it]                                                       {'loss': 0.7465, 'grad_norm': 1.2543774843215942, 'learning_rate': 1.4098899050592037e-06, 'epoch': 0.66}
 66%|██████▌   | 1907/2906 [6:16:47<3:16:26, 11.80s/it] 66%|██████▌   | 1908/2906 [6:16:58<3:14:58, 11.72s/it]                                                       {'loss': 0.7852, 'grad_norm': 1.23872971534729, 'learning_rate': 1.4073717017833738e-06, 'epoch': 0.66}
 66%|██████▌   | 1908/2906 [6:16:58<3:14:58, 11.72s/it] 66%|██████▌   | 1909/2906 [6:17:10<3:15:41, 11.78s/it]                                                       {'loss': 0.7779, 'grad_norm': 1.2804166078567505, 'learning_rate': 1.404854868117206e-06, 'epoch': 0.66}
 66%|██████▌   | 1909/2906 [6:17:10<3:15:41, 11.78s/it] 66%|██████▌   | 1910/2906 [6:17:22<3:15:10, 11.76s/it]                                                       {'loss': 0.8081, 'grad_norm': 1.331210970878601, 'learning_rate': 1.4023394072155491e-06, 'epoch': 0.66}
 66%|██████▌   | 1910/2906 [6:17:22<3:15:10, 11.76s/it] 66%|██████▌   | 1911/2906 [6:17:34<3:16:24, 11.84s/it]                                                       {'loss': 0.8612, 'grad_norm': 1.3139456510543823, 'learning_rate': 1.3998253222315363e-06, 'epoch': 0.66}
 66%|██████▌   | 1911/2906 [6:17:34<3:16:24, 11.84s/it] 66%|██████▌   | 1912/2906 [6:17:46<3:18:06, 11.96s/it]                                                       {'loss': 0.7219, 'grad_norm': 1.2644211053848267, 'learning_rate': 1.3973126163165711e-06, 'epoch': 0.66}
 66%|██████▌   | 1912/2906 [6:17:46<3:18:06, 11.96s/it] 66%|██████▌   | 1913/2906 [6:17:58<3:17:30, 11.93s/it]                                                       {'loss': 0.8187, 'grad_norm': 1.337697148323059, 'learning_rate': 1.394801292620332e-06, 'epoch': 0.66}
 66%|██████▌   | 1913/2906 [6:17:58<3:17:30, 11.93s/it] 66%|██████▌   | 1914/2906 [6:18:10<3:14:15, 11.75s/it]                                                       {'loss': 0.8269, 'grad_norm': 1.3259460926055908, 'learning_rate': 1.3922913542907635e-06, 'epoch': 0.66}
 66%|██████▌   | 1914/2906 [6:18:10<3:14:15, 11.75s/it] 66%|██████▌   | 1915/2906 [6:18:22<3:16:32, 11.90s/it]                                                       {'loss': 0.7644, 'grad_norm': 1.3795017004013062, 'learning_rate': 1.389782804474072e-06, 'epoch': 0.66}
 66%|██████▌   | 1915/2906 [6:18:22<3:16:32, 11.90s/it] 66%|██████▌   | 1916/2906 [6:18:34<3:15:39, 11.86s/it]                                                       {'loss': 0.733, 'grad_norm': 1.3417102098464966, 'learning_rate': 1.387275646314726e-06, 'epoch': 0.66}
 66%|██████▌   | 1916/2906 [6:18:34<3:15:39, 11.86s/it] 66%|██████▌   | 1917/2906 [6:18:45<3:15:18, 11.85s/it]                                                       {'loss': 0.8142, 'grad_norm': 1.2602406740188599, 'learning_rate': 1.3847698829554496e-06, 'epoch': 0.66}
 66%|██████▌   | 1917/2906 [6:18:45<3:15:18, 11.85s/it] 66%|██████▌   | 1918/2906 [6:18:58<3:17:13, 11.98s/it]                                                       {'loss': 0.8497, 'grad_norm': 1.3914263248443604, 'learning_rate': 1.3822655175372148e-06, 'epoch': 0.66}
 66%|██████▌   | 1918/2906 [6:18:58<3:17:13, 11.98s/it] 66%|██████▌   | 1919/2906 [6:19:10<3:16:57, 11.97s/it]                                                       {'loss': 0.8139, 'grad_norm': 1.2592288255691528, 'learning_rate': 1.3797625531992464e-06, 'epoch': 0.66}
 66%|██████▌   | 1919/2906 [6:19:10<3:16:57, 11.97s/it] 66%|██████▌   | 1920/2906 [6:19:22<3:17:46, 12.03s/it]                                                       {'loss': 0.8278, 'grad_norm': 1.3516426086425781, 'learning_rate': 1.3772609930790093e-06, 'epoch': 0.66}
 66%|██████▌   | 1920/2906 [6:19:22<3:17:46, 12.03s/it] 66%|██████▌   | 1921/2906 [6:19:34<3:16:44, 11.98s/it]                                                       {'loss': 0.7655, 'grad_norm': 1.311463713645935, 'learning_rate': 1.374760840312208e-06, 'epoch': 0.66}
 66%|██████▌   | 1921/2906 [6:19:34<3:16:44, 11.98s/it] 66%|██████▌   | 1922/2906 [6:19:45<3:14:24, 11.85s/it]                                                       {'loss': 0.8627, 'grad_norm': 1.3258748054504395, 'learning_rate': 1.3722620980327867e-06, 'epoch': 0.66}
 66%|██████▌   | 1922/2906 [6:19:45<3:14:24, 11.85s/it] 66%|██████▌   | 1923/2906 [6:19:57<3:13:58, 11.84s/it]                                                       {'loss': 0.7521, 'grad_norm': 1.2453066110610962, 'learning_rate': 1.3697647693729166e-06, 'epoch': 0.66}
 66%|██████▌   | 1923/2906 [6:19:57<3:13:58, 11.84s/it] 66%|██████▌   | 1924/2906 [6:20:09<3:13:24, 11.82s/it]                                                       {'loss': 0.826, 'grad_norm': 1.3092676401138306, 'learning_rate': 1.3672688574630005e-06, 'epoch': 0.66}
 66%|██████▌   | 1924/2906 [6:20:09<3:13:24, 11.82s/it] 66%|██████▌   | 1925/2906 [6:20:20<3:10:34, 11.66s/it]                                                       {'loss': 0.8554, 'grad_norm': 1.414725422859192, 'learning_rate': 1.3647743654316653e-06, 'epoch': 0.66}
 66%|██████▌   | 1925/2906 [6:20:20<3:10:34, 11.66s/it] 66%|██████▋   | 1926/2906 [6:20:31<3:07:59, 11.51s/it]                                                       {'loss': 0.7828, 'grad_norm': 1.2516446113586426, 'learning_rate': 1.362281296405755e-06, 'epoch': 0.66}
 66%|██████▋   | 1926/2906 [6:20:31<3:07:59, 11.51s/it] 66%|██████▋   | 1927/2906 [6:20:43<3:08:54, 11.58s/it]                                                       {'loss': 0.7872, 'grad_norm': 1.3178433179855347, 'learning_rate': 1.3597896535103328e-06, 'epoch': 0.66}
 66%|██████▋   | 1927/2906 [6:20:43<3:08:54, 11.58s/it] 66%|██████▋   | 1928/2906 [6:20:55<3:08:52, 11.59s/it]                                                       {'loss': 0.7869, 'grad_norm': 1.3030318021774292, 'learning_rate': 1.3572994398686739e-06, 'epoch': 0.66}
 66%|██████▋   | 1928/2906 [6:20:55<3:08:52, 11.59s/it] 66%|██████▋   | 1929/2906 [6:21:06<3:09:50, 11.66s/it]                                                       {'loss': 0.8386, 'grad_norm': 1.379900574684143, 'learning_rate': 1.3548106586022597e-06, 'epoch': 0.66}
 66%|██████▋   | 1929/2906 [6:21:06<3:09:50, 11.66s/it] 66%|██████▋   | 1930/2906 [6:21:18<3:09:24, 11.64s/it]                                                       {'loss': 0.7809, 'grad_norm': 1.2210930585861206, 'learning_rate': 1.3523233128307797e-06, 'epoch': 0.66}
 66%|██████▋   | 1930/2906 [6:21:18<3:09:24, 11.64s/it] 66%|██████▋   | 1931/2906 [6:21:30<3:09:01, 11.63s/it]                                                       {'loss': 0.7471, 'grad_norm': 1.343974232673645, 'learning_rate': 1.3498374056721198e-06, 'epoch': 0.66}
 66%|██████▋   | 1931/2906 [6:21:30<3:09:01, 11.63s/it] 66%|██████▋   | 1932/2906 [6:21:41<3:09:41, 11.69s/it]                                                       {'loss': 0.8513, 'grad_norm': 1.2880679368972778, 'learning_rate': 1.3473529402423664e-06, 'epoch': 0.66}
 66%|██████▋   | 1932/2906 [6:21:41<3:09:41, 11.69s/it] 67%|██████▋   | 1933/2906 [6:21:53<3:09:09, 11.66s/it]                                                       {'loss': 0.7988, 'grad_norm': 1.2909502983093262, 'learning_rate': 1.3448699196557973e-06, 'epoch': 0.67}
 67%|██████▋   | 1933/2906 [6:21:53<3:09:09, 11.66s/it] 67%|██████▋   | 1934/2906 [6:22:05<3:09:22, 11.69s/it]                                                       {'loss': 0.8639, 'grad_norm': 1.3312649726867676, 'learning_rate': 1.3423883470248774e-06, 'epoch': 0.67}
 67%|██████▋   | 1934/2906 [6:22:05<3:09:22, 11.69s/it] 67%|██████▋   | 1935/2906 [6:22:17<3:09:22, 11.70s/it]                                                       {'loss': 0.7923, 'grad_norm': 1.3385590314865112, 'learning_rate': 1.3399082254602594e-06, 'epoch': 0.67}
 67%|██████▋   | 1935/2906 [6:22:17<3:09:22, 11.70s/it] 67%|██████▋   | 1936/2906 [6:22:28<3:09:39, 11.73s/it]                                                       {'loss': 0.756, 'grad_norm': 1.3322306871414185, 'learning_rate': 1.3374295580707766e-06, 'epoch': 0.67}
 67%|██████▋   | 1936/2906 [6:22:28<3:09:39, 11.73s/it] 67%|██████▋   | 1937/2906 [6:22:40<3:10:07, 11.77s/it]                                                       {'loss': 0.7828, 'grad_norm': 1.269039273262024, 'learning_rate': 1.3349523479634368e-06, 'epoch': 0.67}
 67%|██████▋   | 1937/2906 [6:22:40<3:10:07, 11.77s/it] 67%|██████▋   | 1938/2906 [6:22:53<3:12:36, 11.94s/it]                                                       {'loss': 0.8108, 'grad_norm': 1.3338377475738525, 'learning_rate': 1.3324765982434254e-06, 'epoch': 0.67}
 67%|██████▋   | 1938/2906 [6:22:53<3:12:36, 11.94s/it] 67%|██████▋   | 1939/2906 [6:23:05<3:13:13, 11.99s/it]                                                       {'loss': 0.7947, 'grad_norm': 1.279889702796936, 'learning_rate': 1.3300023120140926e-06, 'epoch': 0.67}
 67%|██████▋   | 1939/2906 [6:23:05<3:13:13, 11.99s/it] 67%|██████▋   | 1940/2906 [6:23:16<3:12:07, 11.93s/it]                                                       {'loss': 0.7524, 'grad_norm': 1.4797972440719604, 'learning_rate': 1.3275294923769583e-06, 'epoch': 0.67}
 67%|██████▋   | 1940/2906 [6:23:16<3:12:07, 11.93s/it] 67%|██████▋   | 1941/2906 [6:23:28<3:10:06, 11.82s/it]                                                       {'loss': 0.816, 'grad_norm': 1.2498624324798584, 'learning_rate': 1.3250581424317012e-06, 'epoch': 0.67}
 67%|██████▋   | 1941/2906 [6:23:28<3:10:06, 11.82s/it] 67%|██████▋   | 1942/2906 [6:23:40<3:08:36, 11.74s/it]                                                       {'loss': 0.8982, 'grad_norm': 1.4128179550170898, 'learning_rate': 1.3225882652761575e-06, 'epoch': 0.67}
 67%|██████▋   | 1942/2906 [6:23:40<3:08:36, 11.74s/it] 67%|██████▋   | 1943/2906 [6:23:51<3:08:23, 11.74s/it]                                                       {'loss': 0.7724, 'grad_norm': 1.2297402620315552, 'learning_rate': 1.3201198640063196e-06, 'epoch': 0.67}
 67%|██████▋   | 1943/2906 [6:23:51<3:08:23, 11.74s/it] 67%|██████▋   | 1944/2906 [6:24:03<3:08:33, 11.76s/it]                                                       {'loss': 0.7595, 'grad_norm': 1.2650851011276245, 'learning_rate': 1.3176529417163298e-06, 'epoch': 0.67}
 67%|██████▋   | 1944/2906 [6:24:03<3:08:33, 11.76s/it] 67%|██████▋   | 1945/2906 [6:24:15<3:08:35, 11.77s/it]                                                       {'loss': 0.8483, 'grad_norm': 1.3844581842422485, 'learning_rate': 1.3151875014984734e-06, 'epoch': 0.67}
 67%|██████▋   | 1945/2906 [6:24:15<3:08:35, 11.77s/it] 67%|██████▋   | 1946/2906 [6:24:26<3:03:54, 11.49s/it]                                                       {'loss': 0.7768, 'grad_norm': 1.319704294204712, 'learning_rate': 1.312723546443181e-06, 'epoch': 0.67}
 67%|██████▋   | 1946/2906 [6:24:26<3:03:54, 11.49s/it] 67%|██████▋   | 1947/2906 [6:24:37<3:04:19, 11.53s/it]                                                       {'loss': 0.7812, 'grad_norm': 1.3741012811660767, 'learning_rate': 1.3102610796390209e-06, 'epoch': 0.67}
 67%|██████▋   | 1947/2906 [6:24:37<3:04:19, 11.53s/it] 67%|██████▋   | 1948/2906 [6:24:50<3:08:14, 11.79s/it]                                                       {'loss': 0.8111, 'grad_norm': 1.199786901473999, 'learning_rate': 1.3078001041726937e-06, 'epoch': 0.67}
 67%|██████▋   | 1948/2906 [6:24:50<3:08:14, 11.79s/it] 67%|██████▋   | 1949/2906 [6:25:01<3:06:54, 11.72s/it]                                                       {'loss': 0.8052, 'grad_norm': 1.3644945621490479, 'learning_rate': 1.3053406231290348e-06, 'epoch': 0.67}
 67%|██████▋   | 1949/2906 [6:25:01<3:06:54, 11.72s/it] 67%|██████▋   | 1950/2906 [6:25:14<3:09:07, 11.87s/it]                                                       {'loss': 0.8266, 'grad_norm': 1.3178876638412476, 'learning_rate': 1.3028826395910012e-06, 'epoch': 0.67}
 67%|██████▋   | 1950/2906 [6:25:14<3:09:07, 11.87s/it] 67%|██████▋   | 1951/2906 [6:25:25<3:08:03, 11.82s/it]                                                       {'loss': 0.7658, 'grad_norm': 1.2273352146148682, 'learning_rate': 1.300426156639677e-06, 'epoch': 0.67}
 67%|██████▋   | 1951/2906 [6:25:25<3:08:03, 11.82s/it] 67%|██████▋   | 1952/2906 [6:25:37<3:08:56, 11.88s/it]                                                       {'loss': 0.8348, 'grad_norm': 1.365829586982727, 'learning_rate': 1.2979711773542646e-06, 'epoch': 0.67}
 67%|██████▋   | 1952/2906 [6:25:37<3:08:56, 11.88s/it] 67%|██████▋   | 1953/2906 [6:25:49<3:07:46, 11.82s/it]                                                       {'loss': 0.7524, 'grad_norm': 1.257973074913025, 'learning_rate': 1.2955177048120786e-06, 'epoch': 0.67}
 67%|██████▋   | 1953/2906 [6:25:49<3:07:46, 11.82s/it] 67%|██████▋   | 1954/2906 [6:26:01<3:07:37, 11.83s/it]                                                       {'loss': 0.8087, 'grad_norm': 1.3018368482589722, 'learning_rate': 1.2930657420885494e-06, 'epoch': 0.67}
 67%|██████▋   | 1954/2906 [6:26:01<3:07:37, 11.83s/it] 67%|██████▋   | 1955/2906 [6:26:12<3:04:30, 11.64s/it]                                                       {'loss': 0.8683, 'grad_norm': 1.3963176012039185, 'learning_rate': 1.2906152922572102e-06, 'epoch': 0.67}
 67%|██████▋   | 1955/2906 [6:26:12<3:04:30, 11.64s/it] 67%|██████▋   | 1956/2906 [6:26:24<3:05:57, 11.74s/it]                                                       {'loss': 0.7885, 'grad_norm': 1.3480263948440552, 'learning_rate': 1.2881663583897007e-06, 'epoch': 0.67}
 67%|██████▋   | 1956/2906 [6:26:24<3:05:57, 11.74s/it] 67%|██████▋   | 1957/2906 [6:26:36<3:05:37, 11.74s/it]                                                       {'loss': 0.7885, 'grad_norm': 1.3147982358932495, 'learning_rate': 1.2857189435557616e-06, 'epoch': 0.67}
 67%|██████▋   | 1957/2906 [6:26:36<3:05:37, 11.74s/it] 67%|██████▋   | 1958/2906 [6:26:47<3:03:53, 11.64s/it]                                                       {'loss': 0.8566, 'grad_norm': 1.4074922800064087, 'learning_rate': 1.2832730508232249e-06, 'epoch': 0.67}
 67%|██████▋   | 1958/2906 [6:26:47<3:03:53, 11.64s/it] 67%|██████▋   | 1959/2906 [6:26:59<3:04:44, 11.71s/it]                                                       {'loss': 0.7802, 'grad_norm': 1.3336142301559448, 'learning_rate': 1.2808286832580186e-06, 'epoch': 0.67}
 67%|██████▋   | 1959/2906 [6:26:59<3:04:44, 11.71s/it] 67%|██████▋   | 1960/2906 [6:27:11<3:04:46, 11.72s/it]                                                       {'loss': 0.7739, 'grad_norm': 1.3329373598098755, 'learning_rate': 1.2783858439241582e-06, 'epoch': 0.67}
 67%|██████▋   | 1960/2906 [6:27:11<3:04:46, 11.72s/it] 67%|██████▋   | 1961/2906 [6:27:23<3:05:05, 11.75s/it]                                                       {'loss': 0.7101, 'grad_norm': 1.2242772579193115, 'learning_rate': 1.2759445358837419e-06, 'epoch': 0.67}
 67%|██████▋   | 1961/2906 [6:27:23<3:05:05, 11.75s/it] 68%|██████▊   | 1962/2906 [6:27:35<3:06:05, 11.83s/it]                                                       {'loss': 0.7536, 'grad_norm': 1.36922287940979, 'learning_rate': 1.2735047621969505e-06, 'epoch': 0.68}
 68%|██████▊   | 1962/2906 [6:27:35<3:06:05, 11.83s/it] 68%|██████▊   | 1963/2906 [6:27:47<3:08:07, 11.97s/it]                                                       {'loss': 0.7916, 'grad_norm': 1.4241938591003418, 'learning_rate': 1.2710665259220403e-06, 'epoch': 0.68}
 68%|██████▊   | 1963/2906 [6:27:47<3:08:07, 11.97s/it] 68%|██████▊   | 1964/2906 [6:27:59<3:10:05, 12.11s/it]                                                       {'loss': 0.7839, 'grad_norm': 1.26030433177948, 'learning_rate': 1.2686298301153394e-06, 'epoch': 0.68}
 68%|██████▊   | 1964/2906 [6:27:59<3:10:05, 12.11s/it] 68%|██████▊   | 1965/2906 [6:28:11<3:08:07, 11.99s/it]                                                       {'loss': 0.856, 'grad_norm': 1.3549103736877441, 'learning_rate': 1.2661946778312473e-06, 'epoch': 0.68}
 68%|██████▊   | 1965/2906 [6:28:11<3:08:07, 11.99s/it] 68%|██████▊   | 1966/2906 [6:28:23<3:06:06, 11.88s/it]                                                       {'loss': 0.7828, 'grad_norm': 1.2643494606018066, 'learning_rate': 1.2637610721222282e-06, 'epoch': 0.68}
 68%|██████▊   | 1966/2906 [6:28:23<3:06:06, 11.88s/it] 68%|██████▊   | 1967/2906 [6:28:35<3:07:01, 11.95s/it]                                                       {'loss': 0.7991, 'grad_norm': 1.424651026725769, 'learning_rate': 1.2613290160388052e-06, 'epoch': 0.68}
 68%|██████▊   | 1967/2906 [6:28:35<3:07:01, 11.95s/it] 68%|██████▊   | 1968/2906 [6:28:47<3:06:41, 11.94s/it]                                                       {'loss': 0.7548, 'grad_norm': 1.288800597190857, 'learning_rate': 1.2588985126295634e-06, 'epoch': 0.68}
 68%|██████▊   | 1968/2906 [6:28:47<3:06:41, 11.94s/it] 68%|██████▊   | 1969/2906 [6:28:59<3:07:05, 11.98s/it]                                                       {'loss': 0.8289, 'grad_norm': 1.4035978317260742, 'learning_rate': 1.2564695649411363e-06, 'epoch': 0.68}
 68%|██████▊   | 1969/2906 [6:28:59<3:07:05, 11.98s/it] 68%|██████▊   | 1970/2906 [6:29:10<3:05:27, 11.89s/it]                                                       {'loss': 0.7882, 'grad_norm': 1.251896619796753, 'learning_rate': 1.2540421760182115e-06, 'epoch': 0.68}
 68%|██████▊   | 1970/2906 [6:29:10<3:05:27, 11.89s/it] 68%|██████▊   | 1971/2906 [6:29:22<3:05:01, 11.87s/it]                                                       {'loss': 0.7256, 'grad_norm': 1.3521170616149902, 'learning_rate': 1.2516163489035216e-06, 'epoch': 0.68}
 68%|██████▊   | 1971/2906 [6:29:22<3:05:01, 11.87s/it] 68%|██████▊   | 1972/2906 [6:29:34<3:04:55, 11.88s/it]                                                       {'loss': 0.8142, 'grad_norm': 1.3356339931488037, 'learning_rate': 1.2491920866378399e-06, 'epoch': 0.68}
 68%|██████▊   | 1972/2906 [6:29:34<3:04:55, 11.88s/it] 68%|██████▊   | 1973/2906 [6:29:46<3:06:40, 12.00s/it]                                                       {'loss': 0.7868, 'grad_norm': 1.3716715574264526, 'learning_rate': 1.2467693922599805e-06, 'epoch': 0.68}
 68%|██████▊   | 1973/2906 [6:29:46<3:06:40, 12.00s/it] 68%|██████▊   | 1974/2906 [6:29:58<3:05:22, 11.93s/it]                                                       {'loss': 0.7559, 'grad_norm': 1.2044490575790405, 'learning_rate': 1.2443482688067898e-06, 'epoch': 0.68}
 68%|██████▊   | 1974/2906 [6:29:58<3:05:22, 11.93s/it] 68%|██████▊   | 1975/2906 [6:30:11<3:07:21, 12.08s/it]                                                       {'loss': 0.7584, 'grad_norm': 1.2425870895385742, 'learning_rate': 1.2419287193131468e-06, 'epoch': 0.68}
 68%|██████▊   | 1975/2906 [6:30:11<3:07:21, 12.08s/it] 68%|██████▊   | 1976/2906 [6:30:22<3:03:55, 11.87s/it]                                                       {'loss': 0.7499, 'grad_norm': 1.2965219020843506, 'learning_rate': 1.239510746811958e-06, 'epoch': 0.68}
 68%|██████▊   | 1976/2906 [6:30:22<3:03:55, 11.87s/it] 68%|██████▊   | 1977/2906 [6:30:34<3:02:15, 11.77s/it]                                                       {'loss': 0.7715, 'grad_norm': 1.2006444931030273, 'learning_rate': 1.23709435433415e-06, 'epoch': 0.68}
 68%|██████▊   | 1977/2906 [6:30:34<3:02:15, 11.77s/it] 68%|██████▊   | 1978/2906 [6:30:46<3:03:11, 11.84s/it]                                                       {'loss': 0.8559, 'grad_norm': 1.440300464630127, 'learning_rate': 1.2346795449086723e-06, 'epoch': 0.68}
 68%|██████▊   | 1978/2906 [6:30:46<3:03:11, 11.84s/it] 68%|██████▊   | 1979/2906 [6:30:57<3:03:35, 11.88s/it]                                                       {'loss': 0.8005, 'grad_norm': 1.2839316129684448, 'learning_rate': 1.2322663215624898e-06, 'epoch': 0.68}
 68%|██████▊   | 1979/2906 [6:30:58<3:03:35, 11.88s/it] 68%|██████▊   | 1980/2906 [6:31:09<3:02:33, 11.83s/it]                                                       {'loss': 0.7314, 'grad_norm': 1.2023968696594238, 'learning_rate': 1.2298546873205754e-06, 'epoch': 0.68}
 68%|██████▊   | 1980/2906 [6:31:09<3:02:33, 11.83s/it] 68%|██████▊   | 1981/2906 [6:31:21<3:03:57, 11.93s/it]                                                       {'loss': 0.8363, 'grad_norm': 1.3876091241836548, 'learning_rate': 1.2274446452059158e-06, 'epoch': 0.68}
 68%|██████▊   | 1981/2906 [6:31:21<3:03:57, 11.93s/it] 68%|██████▊   | 1982/2906 [6:31:33<3:03:49, 11.94s/it]                                                       {'loss': 0.8282, 'grad_norm': 1.3083680868148804, 'learning_rate': 1.2250361982394964e-06, 'epoch': 0.68}
 68%|██████▊   | 1982/2906 [6:31:33<3:03:49, 11.94s/it] 68%|██████▊   | 1983/2906 [6:31:45<3:02:18, 11.85s/it]                                                       {'loss': 0.7743, 'grad_norm': 1.4163343906402588, 'learning_rate': 1.222629349440308e-06, 'epoch': 0.68}
 68%|██████▊   | 1983/2906 [6:31:45<3:02:18, 11.85s/it] 68%|██████▊   | 1984/2906 [6:31:57<3:01:47, 11.83s/it]                                                       {'loss': 0.7783, 'grad_norm': 1.3355149030685425, 'learning_rate': 1.2202241018253333e-06, 'epoch': 0.68}
 68%|██████▊   | 1984/2906 [6:31:57<3:01:47, 11.83s/it] 68%|██████▊   | 1985/2906 [6:32:09<3:01:53, 11.85s/it]                                                       {'loss': 0.7886, 'grad_norm': 1.253095269203186, 'learning_rate': 1.2178204584095526e-06, 'epoch': 0.68}
 68%|██████▊   | 1985/2906 [6:32:09<3:01:53, 11.85s/it] 68%|██████▊   | 1986/2906 [6:32:20<3:00:56, 11.80s/it]                                                       {'loss': 0.8093, 'grad_norm': 1.2842646837234497, 'learning_rate': 1.2154184222059315e-06, 'epoch': 0.68}
 68%|██████▊   | 1986/2906 [6:32:20<3:00:56, 11.80s/it] 68%|██████▊   | 1987/2906 [6:32:32<3:00:22, 11.78s/it]                                                       {'loss': 0.8029, 'grad_norm': 1.2758221626281738, 'learning_rate': 1.213017996225424e-06, 'epoch': 0.68}
 68%|██████▊   | 1987/2906 [6:32:32<3:00:22, 11.78s/it] 68%|██████▊   | 1988/2906 [6:32:44<3:01:54, 11.89s/it]                                                       {'loss': 0.7233, 'grad_norm': 1.3636229038238525, 'learning_rate': 1.2106191834769627e-06, 'epoch': 0.68}
 68%|██████▊   | 1988/2906 [6:32:44<3:01:54, 11.89s/it] 68%|██████▊   | 1989/2906 [6:32:56<3:00:11, 11.79s/it]                                                       {'loss': 0.7679, 'grad_norm': 1.2895839214324951, 'learning_rate': 1.2082219869674603e-06, 'epoch': 0.68}
 68%|██████▊   | 1989/2906 [6:32:56<3:00:11, 11.79s/it] 68%|██████▊   | 1990/2906 [6:33:08<3:01:01, 11.86s/it]                                                       {'loss': 0.771, 'grad_norm': 1.3330124616622925, 'learning_rate': 1.2058264097018038e-06, 'epoch': 0.68}
 68%|██████▊   | 1990/2906 [6:33:08<3:01:01, 11.86s/it] 69%|██████▊   | 1991/2906 [6:33:19<2:59:28, 11.77s/it]                                                       {'loss': 0.8103, 'grad_norm': 1.3004136085510254, 'learning_rate': 1.2034324546828477e-06, 'epoch': 0.69}
 69%|██████▊   | 1991/2906 [6:33:19<2:59:28, 11.77s/it] 69%|██████▊   | 1992/2906 [6:33:31<2:59:28, 11.78s/it]                                                       {'loss': 0.765, 'grad_norm': 1.3132225275039673, 'learning_rate': 1.2010401249114166e-06, 'epoch': 0.69}
 69%|██████▊   | 1992/2906 [6:33:31<2:59:28, 11.78s/it] 69%|██████▊   | 1993/2906 [6:33:43<3:00:21, 11.85s/it]                                                       {'loss': 0.7866, 'grad_norm': 1.3530371189117432, 'learning_rate': 1.1986494233862948e-06, 'epoch': 0.69}
 69%|██████▊   | 1993/2906 [6:33:43<3:00:21, 11.85s/it] 69%|██████▊   | 1994/2906 [6:33:55<3:00:31, 11.88s/it]                                                       {'loss': 0.7908, 'grad_norm': 1.2727513313293457, 'learning_rate': 1.1962603531042265e-06, 'epoch': 0.69}
 69%|██████▊   | 1994/2906 [6:33:55<3:00:31, 11.88s/it] 69%|██████▊   | 1995/2906 [6:34:07<3:00:47, 11.91s/it]                                                       {'loss': 0.8425, 'grad_norm': 1.327805519104004, 'learning_rate': 1.1938729170599136e-06, 'epoch': 0.69}
 69%|██████▊   | 1995/2906 [6:34:07<3:00:47, 11.91s/it] 69%|██████▊   | 1996/2906 [6:34:19<2:58:58, 11.80s/it]                                                       {'loss': 0.8489, 'grad_norm': 1.3427636623382568, 'learning_rate': 1.191487118246005e-06, 'epoch': 0.69}
 69%|██████▊   | 1996/2906 [6:34:19<2:58:58, 11.80s/it] 69%|██████▊   | 1997/2906 [6:34:31<2:59:26, 11.84s/it]                                                       {'loss': 0.794, 'grad_norm': 1.2919148206710815, 'learning_rate': 1.1891029596531005e-06, 'epoch': 0.69}
 69%|██████▊   | 1997/2906 [6:34:31<2:59:26, 11.84s/it] 69%|██████▉   | 1998/2906 [6:34:42<2:58:21, 11.79s/it]                                                       {'loss': 0.7635, 'grad_norm': 1.3213610649108887, 'learning_rate': 1.1867204442697447e-06, 'epoch': 0.69}
 69%|██████▉   | 1998/2906 [6:34:42<2:58:21, 11.79s/it] 69%|██████▉   | 1999/2906 [6:34:54<2:57:07, 11.72s/it]                                                       {'loss': 0.7887, 'grad_norm': 1.349847674369812, 'learning_rate': 1.1843395750824183e-06, 'epoch': 0.69}
 69%|██████▉   | 1999/2906 [6:34:54<2:57:07, 11.72s/it] 69%|██████▉   | 2000/2906 [6:35:06<2:57:38, 11.76s/it]                                                       {'loss': 0.8163, 'grad_norm': 1.4174724817276, 'learning_rate': 1.181960355075543e-06, 'epoch': 0.69}
 69%|██████▉   | 2000/2906 [6:35:06<2:57:38, 11.76s/it] 69%|██████▉   | 2001/2906 [6:35:18<2:59:24, 11.89s/it]                                                       {'loss': 0.8013, 'grad_norm': 1.3007501363754272, 'learning_rate': 1.1795827872314694e-06, 'epoch': 0.69}
 69%|██████▉   | 2001/2906 [6:35:18<2:59:24, 11.89s/it] 69%|██████▉   | 2002/2906 [6:35:30<3:00:55, 12.01s/it]                                                       {'loss': 0.8377, 'grad_norm': 1.3460731506347656, 'learning_rate': 1.17720687453048e-06, 'epoch': 0.69}
 69%|██████▉   | 2002/2906 [6:35:30<3:00:55, 12.01s/it] 69%|██████▉   | 2003/2906 [6:35:43<3:03:49, 12.21s/it]                                                       {'loss': 0.7783, 'grad_norm': 1.2577201128005981, 'learning_rate': 1.1748326199507829e-06, 'epoch': 0.69}
 69%|██████▉   | 2003/2906 [6:35:43<3:03:49, 12.21s/it] 69%|██████▉   | 2004/2906 [6:35:55<3:01:55, 12.10s/it]                                                       {'loss': 0.8031, 'grad_norm': 1.309471845626831, 'learning_rate': 1.172460026468505e-06, 'epoch': 0.69}
 69%|██████▉   | 2004/2906 [6:35:55<3:01:55, 12.10s/it] 69%|██████▉   | 2005/2906 [6:36:06<3:00:31, 12.02s/it]                                                       {'loss': 0.8667, 'grad_norm': 1.308683156967163, 'learning_rate': 1.1700890970576914e-06, 'epoch': 0.69}
 69%|██████▉   | 2005/2906 [6:36:07<3:00:31, 12.02s/it] 69%|██████▉   | 2006/2906 [6:36:18<2:59:44, 11.98s/it]                                                       {'loss': 0.7713, 'grad_norm': 1.3941279649734497, 'learning_rate': 1.1677198346903045e-06, 'epoch': 0.69}
 69%|██████▉   | 2006/2906 [6:36:18<2:59:44, 11.98s/it] 69%|██████▉   | 2007/2906 [6:36:30<2:57:46, 11.87s/it]                                                       {'loss': 0.7654, 'grad_norm': 1.271756887435913, 'learning_rate': 1.1653522423362129e-06, 'epoch': 0.69}
 69%|██████▉   | 2007/2906 [6:36:30<2:57:46, 11.87s/it] 69%|██████▉   | 2008/2906 [6:36:41<2:55:48, 11.75s/it]                                                       {'loss': 0.8124, 'grad_norm': 1.319000482559204, 'learning_rate': 1.1629863229631947e-06, 'epoch': 0.69}
 69%|██████▉   | 2008/2906 [6:36:41<2:55:48, 11.75s/it] 69%|██████▉   | 2009/2906 [6:36:53<2:54:23, 11.66s/it]                                                       {'loss': 0.7908, 'grad_norm': 1.3004549741744995, 'learning_rate': 1.1606220795369307e-06, 'epoch': 0.69}
 69%|██████▉   | 2009/2906 [6:36:53<2:54:23, 11.66s/it] 69%|██████▉   | 2010/2906 [6:37:05<2:56:42, 11.83s/it]                                                       {'loss': 0.8169, 'grad_norm': 1.2943495512008667, 'learning_rate': 1.158259515020999e-06, 'epoch': 0.69}
 69%|██████▉   | 2010/2906 [6:37:05<2:56:42, 11.83s/it] 69%|██████▉   | 2011/2906 [6:37:17<2:57:14, 11.88s/it]                                                       {'loss': 0.8026, 'grad_norm': 1.3106045722961426, 'learning_rate': 1.1558986323768758e-06, 'epoch': 0.69}
 69%|██████▉   | 2011/2906 [6:37:17<2:57:14, 11.88s/it] 69%|██████▉   | 2012/2906 [6:37:29<2:58:12, 11.96s/it]                                                       {'loss': 0.787, 'grad_norm': 1.3125050067901611, 'learning_rate': 1.1535394345639261e-06, 'epoch': 0.69}
 69%|██████▉   | 2012/2906 [6:37:29<2:58:12, 11.96s/it] 69%|██████▉   | 2013/2906 [6:37:41<2:56:32, 11.86s/it]                                                       {'loss': 0.8489, 'grad_norm': 1.3219997882843018, 'learning_rate': 1.1511819245394051e-06, 'epoch': 0.69}
 69%|██████▉   | 2013/2906 [6:37:41<2:56:32, 11.86s/it] 69%|██████▉   | 2014/2906 [6:37:53<2:56:28, 11.87s/it]                                                       {'loss': 0.8406, 'grad_norm': 1.4010734558105469, 'learning_rate': 1.1488261052584529e-06, 'epoch': 0.69}
 69%|██████▉   | 2014/2906 [6:37:53<2:56:28, 11.87s/it] 69%|██████▉   | 2015/2906 [6:38:04<2:54:50, 11.77s/it]                                                       {'loss': 0.7999, 'grad_norm': 1.2703458070755005, 'learning_rate': 1.1464719796740875e-06, 'epoch': 0.69}
 69%|██████▉   | 2015/2906 [6:38:04<2:54:50, 11.77s/it] 69%|██████▉   | 2016/2906 [6:38:16<2:53:35, 11.70s/it]                                                       {'loss': 0.7713, 'grad_norm': 1.3359793424606323, 'learning_rate': 1.1441195507372064e-06, 'epoch': 0.69}
 69%|██████▉   | 2016/2906 [6:38:16<2:53:35, 11.70s/it] 69%|██████▉   | 2017/2906 [6:38:28<2:54:08, 11.75s/it]                                                       {'loss': 0.7363, 'grad_norm': 1.2892508506774902, 'learning_rate': 1.1417688213965803e-06, 'epoch': 0.69}
 69%|██████▉   | 2017/2906 [6:38:28<2:54:08, 11.75s/it] 69%|██████▉   | 2018/2906 [6:38:39<2:53:14, 11.71s/it]                                                       {'loss': 0.8094, 'grad_norm': 1.2659918069839478, 'learning_rate': 1.1394197945988466e-06, 'epoch': 0.69}
 69%|██████▉   | 2018/2906 [6:38:39<2:53:14, 11.71s/it] 69%|██████▉   | 2019/2906 [6:38:51<2:53:11, 11.72s/it]                                                       {'loss': 0.8858, 'grad_norm': 1.4102064371109009, 'learning_rate': 1.1370724732885126e-06, 'epoch': 0.69}
 69%|██████▉   | 2019/2906 [6:38:51<2:53:11, 11.72s/it] 70%|██████▉   | 2020/2906 [6:39:03<2:51:57, 11.65s/it]                                                       {'loss': 0.8191, 'grad_norm': 1.283492088317871, 'learning_rate': 1.134726860407944e-06, 'epoch': 0.7}
 70%|██████▉   | 2020/2906 [6:39:03<2:51:57, 11.65s/it] 70%|██████▉   | 2021/2906 [6:39:14<2:52:57, 11.73s/it]                                                       {'loss': 0.8325, 'grad_norm': 1.2860321998596191, 'learning_rate': 1.1323829588973676e-06, 'epoch': 0.7}
 70%|██████▉   | 2021/2906 [6:39:15<2:52:57, 11.73s/it] 70%|██████▉   | 2022/2906 [6:39:27<2:55:18, 11.90s/it]                                                       {'loss': 0.8127, 'grad_norm': 1.4032083749771118, 'learning_rate': 1.130040771694865e-06, 'epoch': 0.7}
 70%|██████▉   | 2022/2906 [6:39:27<2:55:18, 11.90s/it] 70%|██████▉   | 2023/2906 [6:39:39<2:55:10, 11.90s/it]                                                       {'loss': 0.7627, 'grad_norm': 1.299655556678772, 'learning_rate': 1.1277003017363661e-06, 'epoch': 0.7}
 70%|██████▉   | 2023/2906 [6:39:39<2:55:10, 11.90s/it] 70%|██████▉   | 2024/2906 [6:39:50<2:52:28, 11.73s/it]                                                       {'loss': 0.7688, 'grad_norm': 1.2471129894256592, 'learning_rate': 1.1253615519556516e-06, 'epoch': 0.7}
 70%|██████▉   | 2024/2906 [6:39:50<2:52:28, 11.73s/it] 70%|██████▉   | 2025/2906 [6:40:02<2:53:39, 11.83s/it]                                                       {'loss': 0.8418, 'grad_norm': 1.3583015203475952, 'learning_rate': 1.1230245252843456e-06, 'epoch': 0.7}
 70%|██████▉   | 2025/2906 [6:40:02<2:53:39, 11.83s/it] 70%|██████▉   | 2026/2906 [6:40:14<2:53:25, 11.82s/it]                                                       {'loss': 0.7922, 'grad_norm': 1.26078200340271, 'learning_rate': 1.1206892246519083e-06, 'epoch': 0.7}
 70%|██████▉   | 2026/2906 [6:40:14<2:53:25, 11.82s/it] 70%|██████▉   | 2027/2906 [6:40:26<2:55:07, 11.95s/it]                                                       {'loss': 0.7767, 'grad_norm': 1.3936253786087036, 'learning_rate': 1.1183556529856404e-06, 'epoch': 0.7}
 70%|██████▉   | 2027/2906 [6:40:26<2:55:07, 11.95s/it] 70%|██████▉   | 2028/2906 [6:40:38<2:54:21, 11.91s/it]                                                       {'loss': 0.8326, 'grad_norm': 1.4405109882354736, 'learning_rate': 1.1160238132106758e-06, 'epoch': 0.7}
 70%|██████▉   | 2028/2906 [6:40:38<2:54:21, 11.91s/it] 70%|██████▉   | 2029/2906 [6:40:49<2:51:49, 11.76s/it]                                                       {'loss': 0.7336, 'grad_norm': 1.1859968900680542, 'learning_rate': 1.1136937082499733e-06, 'epoch': 0.7}
 70%|██████▉   | 2029/2906 [6:40:49<2:51:49, 11.76s/it] 70%|██████▉   | 2030/2906 [6:41:02<2:53:26, 11.88s/it]                                                       {'loss': 0.7501, 'grad_norm': 1.2584880590438843, 'learning_rate': 1.111365341024322e-06, 'epoch': 0.7}
 70%|██████▉   | 2030/2906 [6:41:02<2:53:26, 11.88s/it] 70%|██████▉   | 2031/2906 [6:41:13<2:53:00, 11.86s/it]                                                       {'loss': 0.8264, 'grad_norm': 1.2935431003570557, 'learning_rate': 1.1090387144523284e-06, 'epoch': 0.7}
 70%|██████▉   | 2031/2906 [6:41:13<2:53:00, 11.86s/it] 70%|██████▉   | 2032/2906 [6:41:25<2:52:10, 11.82s/it]                                                       {'loss': 0.8289, 'grad_norm': 1.2239853143692017, 'learning_rate': 1.10671383145042e-06, 'epoch': 0.7}
 70%|██████▉   | 2032/2906 [6:41:25<2:52:10, 11.82s/it] 70%|██████▉   | 2033/2906 [6:41:36<2:49:46, 11.67s/it]                                                       {'loss': 0.7813, 'grad_norm': 1.3298718929290771, 'learning_rate': 1.1043906949328387e-06, 'epoch': 0.7}
 70%|██████▉   | 2033/2906 [6:41:36<2:49:46, 11.67s/it] 70%|██████▉   | 2034/2906 [6:41:48<2:48:31, 11.60s/it]                                                       {'loss': 0.7429, 'grad_norm': 1.3510231971740723, 'learning_rate': 1.1020693078116347e-06, 'epoch': 0.7}
 70%|██████▉   | 2034/2906 [6:41:48<2:48:31, 11.60s/it] 70%|███████   | 2035/2906 [6:42:00<2:48:43, 11.62s/it]                                                       {'loss': 0.8305, 'grad_norm': 1.2716437578201294, 'learning_rate': 1.0997496729966679e-06, 'epoch': 0.7}
 70%|███████   | 2035/2906 [6:42:00<2:48:43, 11.62s/it] 70%|███████   | 2036/2906 [6:42:11<2:48:50, 11.64s/it]                                                       {'loss': 0.8159, 'grad_norm': 1.2573431730270386, 'learning_rate': 1.0974317933956011e-06, 'epoch': 0.7}
 70%|███████   | 2036/2906 [6:42:11<2:48:50, 11.64s/it] 70%|███████   | 2037/2906 [6:42:23<2:48:13, 11.62s/it]                                                       {'loss': 0.7437, 'grad_norm': 1.2363463640213013, 'learning_rate': 1.0951156719138953e-06, 'epoch': 0.7}
 70%|███████   | 2037/2906 [6:42:23<2:48:13, 11.62s/it] 70%|███████   | 2038/2906 [6:42:34<2:46:49, 11.53s/it]                                                       {'loss': 0.8161, 'grad_norm': 1.3397881984710693, 'learning_rate': 1.0928013114548102e-06, 'epoch': 0.7}
 70%|███████   | 2038/2906 [6:42:34<2:46:49, 11.53s/it] 70%|███████   | 2039/2906 [6:42:46<2:47:16, 11.58s/it]                                                       {'loss': 0.8969, 'grad_norm': 1.4044982194900513, 'learning_rate': 1.090488714919396e-06, 'epoch': 0.7}
 70%|███████   | 2039/2906 [6:42:46<2:47:16, 11.58s/it] 70%|███████   | 2040/2906 [6:42:58<2:48:40, 11.69s/it]                                                       {'loss': 0.7467, 'grad_norm': 1.1879125833511353, 'learning_rate': 1.0881778852064926e-06, 'epoch': 0.7}
 70%|███████   | 2040/2906 [6:42:58<2:48:40, 11.69s/it] 70%|███████   | 2041/2906 [6:43:10<2:50:04, 11.80s/it]                                                       {'loss': 0.8407, 'grad_norm': 1.2773222923278809, 'learning_rate': 1.0858688252127268e-06, 'epoch': 0.7}
 70%|███████   | 2041/2906 [6:43:10<2:50:04, 11.80s/it] 70%|███████   | 2042/2906 [6:43:21<2:48:17, 11.69s/it]                                                       {'loss': 0.7769, 'grad_norm': 1.2632460594177246, 'learning_rate': 1.083561537832503e-06, 'epoch': 0.7}
 70%|███████   | 2042/2906 [6:43:21<2:48:17, 11.69s/it] 70%|███████   | 2043/2906 [6:43:33<2:46:34, 11.58s/it]                                                       {'loss': 0.7877, 'grad_norm': 1.3044198751449585, 'learning_rate': 1.0812560259580076e-06, 'epoch': 0.7}
 70%|███████   | 2043/2906 [6:43:33<2:46:34, 11.58s/it] 70%|███████   | 2044/2906 [6:43:44<2:46:41, 11.60s/it]                                                       {'loss': 0.8458, 'grad_norm': 1.3562517166137695, 'learning_rate': 1.0789522924792005e-06, 'epoch': 0.7}
 70%|███████   | 2044/2906 [6:43:44<2:46:41, 11.60s/it] 70%|███████   | 2045/2906 [6:43:56<2:47:50, 11.70s/it]                                                       {'loss': 0.7889, 'grad_norm': 1.29433012008667, 'learning_rate': 1.0766503402838103e-06, 'epoch': 0.7}
 70%|███████   | 2045/2906 [6:43:56<2:47:50, 11.70s/it] 70%|███████   | 2046/2906 [6:44:08<2:50:16, 11.88s/it]                                                       {'loss': 0.7681, 'grad_norm': 1.2590824365615845, 'learning_rate': 1.074350172257336e-06, 'epoch': 0.7}
 70%|███████   | 2046/2906 [6:44:08<2:50:16, 11.88s/it] 70%|███████   | 2047/2906 [6:44:20<2:50:16, 11.89s/it]                                                       {'loss': 0.7903, 'grad_norm': 1.2251861095428467, 'learning_rate': 1.0720517912830371e-06, 'epoch': 0.7}
 70%|███████   | 2047/2906 [6:44:20<2:50:16, 11.89s/it] 70%|███████   | 2048/2906 [6:44:32<2:49:37, 11.86s/it]                                                       {'loss': 0.8059, 'grad_norm': 1.3946298360824585, 'learning_rate': 1.069755200241934e-06, 'epoch': 0.7}
 70%|███████   | 2048/2906 [6:44:32<2:49:37, 11.86s/it] 71%|███████   | 2049/2906 [6:44:44<2:49:16, 11.85s/it]                                                       {'loss': 0.8136, 'grad_norm': 1.3678227663040161, 'learning_rate': 1.0674604020128051e-06, 'epoch': 0.71}
 71%|███████   | 2049/2906 [6:44:44<2:49:16, 11.85s/it] 71%|███████   | 2050/2906 [6:44:56<2:50:04, 11.92s/it]                                                       {'loss': 0.7735, 'grad_norm': 1.3252460956573486, 'learning_rate': 1.0651673994721787e-06, 'epoch': 0.71}
 71%|███████   | 2050/2906 [6:44:56<2:50:04, 11.92s/it] 71%|███████   | 2051/2906 [6:45:08<2:48:07, 11.80s/it]                                                       {'loss': 0.8134, 'grad_norm': 1.2951552867889404, 'learning_rate': 1.0628761954943343e-06, 'epoch': 0.71}
 71%|███████   | 2051/2906 [6:45:08<2:48:07, 11.80s/it] 71%|███████   | 2052/2906 [6:45:19<2:48:07, 11.81s/it]                                                       {'loss': 0.8748, 'grad_norm': 1.3187255859375, 'learning_rate': 1.0605867929512974e-06, 'epoch': 0.71}
 71%|███████   | 2052/2906 [6:45:19<2:48:07, 11.81s/it] 71%|███████   | 2053/2906 [6:45:31<2:47:51, 11.81s/it]                                                       {'loss': 0.8553, 'grad_norm': 1.3439713716506958, 'learning_rate': 1.0582991947128324e-06, 'epoch': 0.71}
 71%|███████   | 2053/2906 [6:45:31<2:47:51, 11.81s/it] 71%|███████   | 2054/2906 [6:45:43<2:48:25, 11.86s/it]                                                       {'loss': 0.8201, 'grad_norm': 1.317030906677246, 'learning_rate': 1.0560134036464447e-06, 'epoch': 0.71}
 71%|███████   | 2054/2906 [6:45:43<2:48:25, 11.86s/it] 71%|███████   | 2055/2906 [6:45:55<2:49:07, 11.92s/it]                                                       {'loss': 0.7957, 'grad_norm': 1.3394842147827148, 'learning_rate': 1.0537294226173748e-06, 'epoch': 0.71}
 71%|███████   | 2055/2906 [6:45:55<2:49:07, 11.92s/it] 71%|███████   | 2056/2906 [6:46:07<2:48:45, 11.91s/it]                                                       {'loss': 0.8375, 'grad_norm': 1.316980004310608, 'learning_rate': 1.051447254488591e-06, 'epoch': 0.71}
 71%|███████   | 2056/2906 [6:46:07<2:48:45, 11.91s/it] 71%|███████   | 2057/2906 [6:46:19<2:47:22, 11.83s/it]                                                       {'loss': 0.8221, 'grad_norm': 1.3245453834533691, 'learning_rate': 1.0491669021207929e-06, 'epoch': 0.71}
 71%|███████   | 2057/2906 [6:46:19<2:47:22, 11.83s/it] 71%|███████   | 2058/2906 [6:46:30<2:46:11, 11.76s/it]                                                       {'loss': 0.8016, 'grad_norm': 1.2584103345870972, 'learning_rate': 1.046888368372401e-06, 'epoch': 0.71}
 71%|███████   | 2058/2906 [6:46:30<2:46:11, 11.76s/it] 71%|███████   | 2059/2906 [6:46:42<2:45:33, 11.73s/it]                                                       {'loss': 0.7145, 'grad_norm': 1.277011513710022, 'learning_rate': 1.0446116560995582e-06, 'epoch': 0.71}
 71%|███████   | 2059/2906 [6:46:42<2:45:33, 11.73s/it] 71%|███████   | 2060/2906 [6:46:54<2:45:22, 11.73s/it]                                                       {'loss': 0.7289, 'grad_norm': 1.377211570739746, 'learning_rate': 1.0423367681561242e-06, 'epoch': 0.71}
 71%|███████   | 2060/2906 [6:46:54<2:45:22, 11.73s/it] 71%|███████   | 2061/2906 [6:47:06<2:46:44, 11.84s/it]                                                       {'loss': 0.7749, 'grad_norm': 1.301514983177185, 'learning_rate': 1.0400637073936697e-06, 'epoch': 0.71}
 71%|███████   | 2061/2906 [6:47:06<2:46:44, 11.84s/it] 71%|███████   | 2062/2906 [6:47:18<2:46:57, 11.87s/it]                                                       {'loss': 0.827, 'grad_norm': 1.3308756351470947, 'learning_rate': 1.0377924766614775e-06, 'epoch': 0.71}
 71%|███████   | 2062/2906 [6:47:18<2:46:57, 11.87s/it] 71%|███████   | 2063/2906 [6:47:29<2:45:59, 11.81s/it]                                                       {'loss': 0.8093, 'grad_norm': 1.36915922164917, 'learning_rate': 1.0355230788065365e-06, 'epoch': 0.71}
 71%|███████   | 2063/2906 [6:47:29<2:45:59, 11.81s/it] 71%|███████   | 2064/2906 [6:47:41<2:43:08, 11.62s/it]                                                       {'loss': 0.8217, 'grad_norm': 1.3618780374526978, 'learning_rate': 1.033255516673535e-06, 'epoch': 0.71}
 71%|███████   | 2064/2906 [6:47:41<2:43:08, 11.62s/it] 71%|███████   | 2065/2906 [6:47:52<2:42:30, 11.59s/it]                                                       {'loss': 0.834, 'grad_norm': 1.4409843683242798, 'learning_rate': 1.030989793104864e-06, 'epoch': 0.71}
 71%|███████   | 2065/2906 [6:47:52<2:42:30, 11.59s/it] 71%|███████   | 2066/2906 [6:48:04<2:42:42, 11.62s/it]                                                       {'loss': 0.7603, 'grad_norm': 1.390229344367981, 'learning_rate': 1.028725910940607e-06, 'epoch': 0.71}
 71%|███████   | 2066/2906 [6:48:04<2:42:42, 11.62s/it] 71%|███████   | 2067/2906 [6:48:15<2:41:05, 11.52s/it]                                                       {'loss': 0.7661, 'grad_norm': 1.45577871799469, 'learning_rate': 1.0264638730185409e-06, 'epoch': 0.71}
 71%|███████   | 2067/2906 [6:48:15<2:41:05, 11.52s/it] 71%|███████   | 2068/2906 [6:48:27<2:43:26, 11.70s/it]                                                       {'loss': 0.7863, 'grad_norm': 1.359806776046753, 'learning_rate': 1.0242036821741323e-06, 'epoch': 0.71}
 71%|███████   | 2068/2906 [6:48:27<2:43:26, 11.70s/it] 71%|███████   | 2069/2906 [6:48:39<2:41:23, 11.57s/it]                                                       {'loss': 0.8702, 'grad_norm': 1.3685009479522705, 'learning_rate': 1.021945341240527e-06, 'epoch': 0.71}
 71%|███████   | 2069/2906 [6:48:39<2:41:23, 11.57s/it] 71%|███████   | 2070/2906 [6:48:50<2:41:06, 11.56s/it]                                                       {'loss': 0.8612, 'grad_norm': 1.5560907125473022, 'learning_rate': 1.019688853048557e-06, 'epoch': 0.71}
 71%|███████   | 2070/2906 [6:48:50<2:41:06, 11.56s/it] 71%|███████▏  | 2071/2906 [6:49:02<2:40:42, 11.55s/it]                                                       {'loss': 0.7391, 'grad_norm': 1.3320330381393433, 'learning_rate': 1.0174342204267323e-06, 'epoch': 0.71}
 71%|███████▏  | 2071/2906 [6:49:02<2:40:42, 11.55s/it] 71%|███████▏  | 2072/2906 [6:49:13<2:41:49, 11.64s/it]                                                       {'loss': 0.7967, 'grad_norm': 1.3485229015350342, 'learning_rate': 1.0151814462012324e-06, 'epoch': 0.71}
 71%|███████▏  | 2072/2906 [6:49:13<2:41:49, 11.64s/it] 71%|███████▏  | 2073/2906 [6:49:25<2:41:26, 11.63s/it]                                                       {'loss': 0.8368, 'grad_norm': 1.3561935424804688, 'learning_rate': 1.012930533195911e-06, 'epoch': 0.71}
 71%|███████▏  | 2073/2906 [6:49:25<2:41:26, 11.63s/it] 71%|███████▏  | 2074/2906 [6:49:37<2:41:14, 11.63s/it]                                                       {'loss': 0.7908, 'grad_norm': 1.361962914466858, 'learning_rate': 1.0106814842322893e-06, 'epoch': 0.71}
 71%|███████▏  | 2074/2906 [6:49:37<2:41:14, 11.63s/it] 71%|███████▏  | 2075/2906 [6:49:49<2:42:10, 11.71s/it]                                                       {'loss': 0.7878, 'grad_norm': 1.2574599981307983, 'learning_rate': 1.0084343021295476e-06, 'epoch': 0.71}
 71%|███████▏  | 2075/2906 [6:49:49<2:42:10, 11.71s/it] 71%|███████▏  | 2076/2906 [6:50:00<2:40:27, 11.60s/it]                                                       {'loss': 0.7751, 'grad_norm': 1.317480444908142, 'learning_rate': 1.0061889897045313e-06, 'epoch': 0.71}
 71%|███████▏  | 2076/2906 [6:50:00<2:40:27, 11.60s/it] 71%|███████▏  | 2077/2906 [6:50:12<2:41:39, 11.70s/it]                                                       {'loss': 0.7439, 'grad_norm': 1.3450170755386353, 'learning_rate': 1.0039455497717376e-06, 'epoch': 0.71}
 71%|███████▏  | 2077/2906 [6:50:12<2:41:39, 11.70s/it] 72%|███████▏  | 2078/2906 [6:50:23<2:40:53, 11.66s/it]                                                       {'loss': 0.7908, 'grad_norm': 1.3355445861816406, 'learning_rate': 1.0017039851433197e-06, 'epoch': 0.72}
 72%|███████▏  | 2078/2906 [6:50:23<2:40:53, 11.66s/it] 72%|███████▏  | 2079/2906 [6:50:35<2:42:05, 11.76s/it]                                                       {'loss': 0.7851, 'grad_norm': 1.2756712436676025, 'learning_rate': 9.994642986290797e-07, 'epoch': 0.72}
 72%|███████▏  | 2079/2906 [6:50:35<2:42:05, 11.76s/it] 72%|███████▏  | 2080/2906 [6:50:47<2:40:38, 11.67s/it]                                                       {'loss': 0.7832, 'grad_norm': 1.3024390935897827, 'learning_rate': 9.972264930364635e-07, 'epoch': 0.72}
 72%|███████▏  | 2080/2906 [6:50:47<2:40:38, 11.67s/it] 72%|███████▏  | 2081/2906 [6:50:58<2:39:44, 11.62s/it]                                                       {'loss': 0.7556, 'grad_norm': 1.3799691200256348, 'learning_rate': 9.949905711705613e-07, 'epoch': 0.72}
 72%|███████▏  | 2081/2906 [6:50:58<2:39:44, 11.62s/it] 72%|███████▏  | 2082/2906 [6:51:10<2:39:39, 11.63s/it]                                                       {'loss': 0.794, 'grad_norm': 1.2472890615463257, 'learning_rate': 9.927565358341022e-07, 'epoch': 0.72}
 72%|███████▏  | 2082/2906 [6:51:10<2:39:39, 11.63s/it] 72%|███████▏  | 2083/2906 [6:51:22<2:41:57, 11.81s/it]                                                       {'loss': 0.8501, 'grad_norm': 1.3793995380401611, 'learning_rate': 9.905243898274476e-07, 'epoch': 0.72}
 72%|███████▏  | 2083/2906 [6:51:22<2:41:57, 11.81s/it] 72%|███████▏  | 2084/2906 [6:51:34<2:41:51, 11.81s/it]                                                       {'loss': 0.7958, 'grad_norm': 1.222981333732605, 'learning_rate': 9.882941359485945e-07, 'epoch': 0.72}
 72%|███████▏  | 2084/2906 [6:51:34<2:41:51, 11.81s/it] 72%|███████▏  | 2085/2906 [6:51:46<2:41:02, 11.77s/it]                                                       {'loss': 0.8213, 'grad_norm': 1.4421718120574951, 'learning_rate': 9.86065776993165e-07, 'epoch': 0.72}
 72%|███████▏  | 2085/2906 [6:51:46<2:41:02, 11.77s/it] 72%|███████▏  | 2086/2906 [6:51:58<2:41:40, 11.83s/it]                                                       {'loss': 0.7792, 'grad_norm': 1.3834288120269775, 'learning_rate': 9.838393157544082e-07, 'epoch': 0.72}
 72%|███████▏  | 2086/2906 [6:51:58<2:41:40, 11.83s/it] 72%|███████▏  | 2087/2906 [6:52:09<2:40:29, 11.76s/it]                                                       {'loss': 0.775, 'grad_norm': 1.2986767292022705, 'learning_rate': 9.816147550231936e-07, 'epoch': 0.72}
 72%|███████▏  | 2087/2906 [6:52:09<2:40:29, 11.76s/it] 72%|███████▏  | 2088/2906 [6:52:22<2:43:12, 11.97s/it]                                                       {'loss': 0.8082, 'grad_norm': 1.2737609148025513, 'learning_rate': 9.793920975880072e-07, 'epoch': 0.72}
 72%|███████▏  | 2088/2906 [6:52:22<2:43:12, 11.97s/it] 72%|███████▏  | 2089/2906 [6:52:34<2:42:27, 11.93s/it]                                                       {'loss': 0.7655, 'grad_norm': 1.3176846504211426, 'learning_rate': 9.771713462349517e-07, 'epoch': 0.72}
 72%|███████▏  | 2089/2906 [6:52:34<2:42:27, 11.93s/it] 72%|███████▏  | 2090/2906 [6:52:45<2:41:04, 11.84s/it]                                                       {'loss': 0.7579, 'grad_norm': 1.2854739427566528, 'learning_rate': 9.749525037477382e-07, 'epoch': 0.72}
 72%|███████▏  | 2090/2906 [6:52:45<2:41:04, 11.84s/it] 72%|███████▏  | 2091/2906 [6:52:57<2:40:03, 11.78s/it]                                                       {'loss': 0.7936, 'grad_norm': 1.3736685514450073, 'learning_rate': 9.727355729076848e-07, 'epoch': 0.72}
 72%|███████▏  | 2091/2906 [6:52:57<2:40:03, 11.78s/it] 72%|███████▏  | 2092/2906 [6:53:09<2:40:24, 11.82s/it]                                                       {'loss': 0.853, 'grad_norm': 1.5108792781829834, 'learning_rate': 9.705205564937161e-07, 'epoch': 0.72}
 72%|███████▏  | 2092/2906 [6:53:09<2:40:24, 11.82s/it] 72%|███████▏  | 2093/2906 [6:53:20<2:38:15, 11.68s/it]                                                       {'loss': 0.743, 'grad_norm': 1.2845205068588257, 'learning_rate': 9.683074572823558e-07, 'epoch': 0.72}
 72%|███████▏  | 2093/2906 [6:53:20<2:38:15, 11.68s/it] 72%|███████▏  | 2094/2906 [6:53:32<2:38:30, 11.71s/it]                                                       {'loss': 0.7943, 'grad_norm': 1.3511937856674194, 'learning_rate': 9.660962780477223e-07, 'epoch': 0.72}
 72%|███████▏  | 2094/2906 [6:53:32<2:38:30, 11.71s/it] 72%|███████▏  | 2095/2906 [6:53:44<2:40:24, 11.87s/it]                                                       {'loss': 0.816, 'grad_norm': 1.366710901260376, 'learning_rate': 9.638870215615304e-07, 'epoch': 0.72}
 72%|███████▏  | 2095/2906 [6:53:44<2:40:24, 11.87s/it] 72%|███████▏  | 2096/2906 [6:53:56<2:39:47, 11.84s/it]                                                       {'loss': 0.7737, 'grad_norm': 1.3575010299682617, 'learning_rate': 9.61679690593082e-07, 'epoch': 0.72}
 72%|███████▏  | 2096/2906 [6:53:56<2:39:47, 11.84s/it] 72%|███████▏  | 2097/2906 [6:54:08<2:39:34, 11.83s/it]                                                       {'loss': 0.7983, 'grad_norm': 1.3104870319366455, 'learning_rate': 9.594742879092673e-07, 'epoch': 0.72}
 72%|███████▏  | 2097/2906 [6:54:08<2:39:34, 11.83s/it] 72%|███████▏  | 2098/2906 [6:54:19<2:36:41, 11.64s/it]                                                       {'loss': 0.748, 'grad_norm': 1.3015791177749634, 'learning_rate': 9.57270816274559e-07, 'epoch': 0.72}
 72%|███████▏  | 2098/2906 [6:54:19<2:36:41, 11.64s/it] 72%|███████▏  | 2099/2906 [6:54:30<2:35:46, 11.58s/it]                                                       {'loss': 0.8531, 'grad_norm': 1.3241747617721558, 'learning_rate': 9.550692784510085e-07, 'epoch': 0.72}
 72%|███████▏  | 2099/2906 [6:54:30<2:35:46, 11.58s/it] 72%|███████▏  | 2100/2906 [6:54:42<2:36:34, 11.66s/it]                                                       {'loss': 0.8465, 'grad_norm': 1.337928056716919, 'learning_rate': 9.528696771982437e-07, 'epoch': 0.72}
 72%|███████▏  | 2100/2906 [6:54:42<2:36:34, 11.66s/it] 72%|███████▏  | 2101/2906 [6:54:54<2:35:31, 11.59s/it]                                                       {'loss': 0.8225, 'grad_norm': 1.3973777294158936, 'learning_rate': 9.50672015273466e-07, 'epoch': 0.72}
 72%|███████▏  | 2101/2906 [6:54:54<2:35:31, 11.59s/it] 72%|███████▏  | 2102/2906 [6:55:06<2:37:58, 11.79s/it]                                                       {'loss': 0.7899, 'grad_norm': 1.3147451877593994, 'learning_rate': 9.48476295431443e-07, 'epoch': 0.72}
 72%|███████▏  | 2102/2906 [6:55:06<2:37:58, 11.79s/it] 72%|███████▏  | 2103/2906 [6:55:17<2:36:43, 11.71s/it]                                                       {'loss': 0.7809, 'grad_norm': 1.2918490171432495, 'learning_rate': 9.462825204245113e-07, 'epoch': 0.72}
 72%|███████▏  | 2103/2906 [6:55:17<2:36:43, 11.71s/it] 72%|███████▏  | 2104/2906 [6:55:28<2:33:33, 11.49s/it]                                                       {'loss': 0.804, 'grad_norm': 1.4000098705291748, 'learning_rate': 9.440906930025667e-07, 'epoch': 0.72}
 72%|███████▏  | 2104/2906 [6:55:28<2:33:33, 11.49s/it] 72%|███████▏  | 2105/2906 [6:55:41<2:36:40, 11.74s/it]                                                       {'loss': 0.7855, 'grad_norm': 1.2030844688415527, 'learning_rate': 9.419008159130658e-07, 'epoch': 0.72}
 72%|███████▏  | 2105/2906 [6:55:41<2:36:40, 11.74s/it] 72%|███████▏  | 2106/2906 [6:55:52<2:36:15, 11.72s/it]                                                       {'loss': 0.7605, 'grad_norm': 1.2920187711715698, 'learning_rate': 9.397128919010201e-07, 'epoch': 0.72}
 72%|███████▏  | 2106/2906 [6:55:52<2:36:15, 11.72s/it] 73%|███████▎  | 2107/2906 [6:56:04<2:36:15, 11.73s/it]                                                       {'loss': 0.7925, 'grad_norm': 1.359434723854065, 'learning_rate': 9.375269237089915e-07, 'epoch': 0.73}
 73%|███████▎  | 2107/2906 [6:56:04<2:36:15, 11.73s/it] 73%|███████▎  | 2108/2906 [6:56:15<2:33:26, 11.54s/it]                                                       {'loss': 0.8293, 'grad_norm': 1.3477425575256348, 'learning_rate': 9.353429140770926e-07, 'epoch': 0.73}
 73%|███████▎  | 2108/2906 [6:56:15<2:33:26, 11.54s/it] 73%|███████▎  | 2109/2906 [6:56:27<2:35:08, 11.68s/it]                                                       {'loss': 0.7406, 'grad_norm': 1.318707823753357, 'learning_rate': 9.331608657429781e-07, 'epoch': 0.73}
 73%|███████▎  | 2109/2906 [6:56:27<2:35:08, 11.68s/it] 73%|███████▎  | 2110/2906 [6:56:39<2:34:37, 11.66s/it]                                                       {'loss': 0.7736, 'grad_norm': 1.3411942720413208, 'learning_rate': 9.309807814418472e-07, 'epoch': 0.73}
 73%|███████▎  | 2110/2906 [6:56:39<2:34:37, 11.66s/it] 73%|███████▎  | 2111/2906 [6:56:51<2:35:01, 11.70s/it]                                                       {'loss': 0.8192, 'grad_norm': 1.310510516166687, 'learning_rate': 9.288026639064346e-07, 'epoch': 0.73}
 73%|███████▎  | 2111/2906 [6:56:51<2:35:01, 11.70s/it] 73%|███████▎  | 2112/2906 [6:57:02<2:33:46, 11.62s/it]                                                       {'loss': 0.7442, 'grad_norm': 1.2810850143432617, 'learning_rate': 9.266265158670121e-07, 'epoch': 0.73}
 73%|███████▎  | 2112/2906 [6:57:02<2:33:46, 11.62s/it] 73%|███████▎  | 2113/2906 [6:57:14<2:34:59, 11.73s/it]                                                       {'loss': 0.8157, 'grad_norm': 1.3663054704666138, 'learning_rate': 9.244523400513797e-07, 'epoch': 0.73}
 73%|███████▎  | 2113/2906 [6:57:14<2:34:59, 11.73s/it] 73%|███████▎  | 2114/2906 [6:57:26<2:36:02, 11.82s/it]                                                       {'loss': 0.7669, 'grad_norm': 1.23699152469635, 'learning_rate': 9.222801391848688e-07, 'epoch': 0.73}
 73%|███████▎  | 2114/2906 [6:57:26<2:36:02, 11.82s/it] 73%|███████▎  | 2115/2906 [6:57:39<2:39:09, 12.07s/it]                                                       {'loss': 0.8308, 'grad_norm': 1.3624993562698364, 'learning_rate': 9.201099159903318e-07, 'epoch': 0.73}
 73%|███████▎  | 2115/2906 [6:57:39<2:39:09, 12.07s/it] 73%|███████▎  | 2116/2906 [6:57:50<2:36:56, 11.92s/it]                                                       {'loss': 0.7946, 'grad_norm': 1.2941889762878418, 'learning_rate': 9.179416731881441e-07, 'epoch': 0.73}
 73%|███████▎  | 2116/2906 [6:57:50<2:36:56, 11.92s/it] 73%|███████▎  | 2117/2906 [6:58:02<2:36:55, 11.93s/it]                                                       {'loss': 0.7315, 'grad_norm': 1.2229044437408447, 'learning_rate': 9.157754134961997e-07, 'epoch': 0.73}
 73%|███████▎  | 2117/2906 [6:58:02<2:36:55, 11.93s/it] 73%|███████▎  | 2118/2906 [6:58:14<2:35:27, 11.84s/it]                                                       {'loss': 0.8388, 'grad_norm': 1.3896420001983643, 'learning_rate': 9.13611139629903e-07, 'epoch': 0.73}
 73%|███████▎  | 2118/2906 [6:58:14<2:35:27, 11.84s/it] 73%|███████▎  | 2119/2906 [6:58:26<2:37:45, 12.03s/it]                                                       {'loss': 0.8218, 'grad_norm': 1.4432123899459839, 'learning_rate': 9.114488543021724e-07, 'epoch': 0.73}
 73%|███████▎  | 2119/2906 [6:58:26<2:37:45, 12.03s/it] 73%|███████▎  | 2120/2906 [6:58:38<2:36:54, 11.98s/it]                                                       {'loss': 0.8416, 'grad_norm': 1.3373829126358032, 'learning_rate': 9.092885602234339e-07, 'epoch': 0.73}
 73%|███████▎  | 2120/2906 [6:58:38<2:36:54, 11.98s/it] 73%|███████▎  | 2121/2906 [6:58:50<2:35:19, 11.87s/it]                                                       {'loss': 0.8487, 'grad_norm': 1.4542970657348633, 'learning_rate': 9.071302601016147e-07, 'epoch': 0.73}
 73%|███████▎  | 2121/2906 [6:58:50<2:35:19, 11.87s/it] 73%|███████▎  | 2122/2906 [6:59:02<2:34:31, 11.83s/it]                                                       {'loss': 0.8388, 'grad_norm': 1.3952422142028809, 'learning_rate': 9.049739566421453e-07, 'epoch': 0.73}
 73%|███████▎  | 2122/2906 [6:59:02<2:34:31, 11.83s/it] 73%|███████▎  | 2123/2906 [6:59:13<2:34:29, 11.84s/it]                                                       {'loss': 0.8137, 'grad_norm': 1.3468042612075806, 'learning_rate': 9.02819652547951e-07, 'epoch': 0.73}
 73%|███████▎  | 2123/2906 [6:59:13<2:34:29, 11.84s/it] 73%|███████▎  | 2124/2906 [6:59:25<2:33:05, 11.75s/it]                                                       {'loss': 0.7957, 'grad_norm': 1.4124200344085693, 'learning_rate': 9.006673505194527e-07, 'epoch': 0.73}
 73%|███████▎  | 2124/2906 [6:59:25<2:33:05, 11.75s/it] 73%|███████▎  | 2125/2906 [6:59:37<2:33:30, 11.79s/it]                                                       {'loss': 0.805, 'grad_norm': 1.3399252891540527, 'learning_rate': 8.985170532545623e-07, 'epoch': 0.73}
 73%|███████▎  | 2125/2906 [6:59:37<2:33:30, 11.79s/it] 73%|███████▎  | 2126/2906 [6:59:49<2:33:29, 11.81s/it]                                                       {'loss': 0.7471, 'grad_norm': 1.2219470739364624, 'learning_rate': 8.963687634486759e-07, 'epoch': 0.73}
 73%|███████▎  | 2126/2906 [6:59:49<2:33:29, 11.81s/it] 73%|███████▎  | 2127/2906 [7:00:00<2:30:55, 11.62s/it]                                                       {'loss': 0.784, 'grad_norm': 1.2756907939910889, 'learning_rate': 8.942224837946767e-07, 'epoch': 0.73}
 73%|███████▎  | 2127/2906 [7:00:00<2:30:55, 11.62s/it] 73%|███████▎  | 2128/2906 [7:00:12<2:30:48, 11.63s/it]                                                       {'loss': 0.779, 'grad_norm': 1.2729859352111816, 'learning_rate': 8.920782169829242e-07, 'epoch': 0.73}
 73%|███████▎  | 2128/2906 [7:00:12<2:30:48, 11.63s/it] 73%|███████▎  | 2129/2906 [7:00:23<2:30:00, 11.58s/it]                                                       {'loss': 0.7571, 'grad_norm': 1.3269612789154053, 'learning_rate': 8.899359657012585e-07, 'epoch': 0.73}
 73%|███████▎  | 2129/2906 [7:00:23<2:30:00, 11.58s/it] 73%|███████▎  | 2130/2906 [7:00:35<2:31:51, 11.74s/it]                                                       {'loss': 0.8305, 'grad_norm': 1.3719910383224487, 'learning_rate': 8.877957326349923e-07, 'epoch': 0.73}
 73%|███████▎  | 2130/2906 [7:00:35<2:31:51, 11.74s/it] 73%|███████▎  | 2131/2906 [7:00:47<2:31:48, 11.75s/it]                                                       {'loss': 0.7813, 'grad_norm': 1.279268741607666, 'learning_rate': 8.856575204669066e-07, 'epoch': 0.73}
 73%|███████▎  | 2131/2906 [7:00:47<2:31:48, 11.75s/it] 73%|███████▎  | 2132/2906 [7:00:58<2:29:17, 11.57s/it]                                                       {'loss': 0.845, 'grad_norm': 1.4217689037322998, 'learning_rate': 8.835213318772515e-07, 'epoch': 0.73}
 73%|███████▎  | 2132/2906 [7:00:58<2:29:17, 11.57s/it] 73%|███████▎  | 2133/2906 [7:01:09<2:28:05, 11.49s/it]                                                       {'loss': 0.8639, 'grad_norm': 1.3003712892532349, 'learning_rate': 8.813871695437392e-07, 'epoch': 0.73}
 73%|███████▎  | 2133/2906 [7:01:09<2:28:05, 11.49s/it] 73%|███████▎  | 2134/2906 [7:01:21<2:28:36, 11.55s/it]                                                       {'loss': 0.7524, 'grad_norm': 1.2889360189437866, 'learning_rate': 8.792550361415414e-07, 'epoch': 0.73}
 73%|███████▎  | 2134/2906 [7:01:21<2:28:36, 11.55s/it] 73%|███████▎  | 2135/2906 [7:01:33<2:28:35, 11.56s/it]                                                       {'loss': 0.7667, 'grad_norm': 1.2948447465896606, 'learning_rate': 8.771249343432886e-07, 'epoch': 0.73}
 73%|███████▎  | 2135/2906 [7:01:33<2:28:35, 11.56s/it] 74%|███████▎  | 2136/2906 [7:01:45<2:30:16, 11.71s/it]                                                       {'loss': 0.8079, 'grad_norm': 1.28310227394104, 'learning_rate': 8.749968668190642e-07, 'epoch': 0.74}
 74%|███████▎  | 2136/2906 [7:01:45<2:30:16, 11.71s/it] 74%|███████▎  | 2137/2906 [7:01:56<2:29:38, 11.68s/it]                                                       {'loss': 0.8396, 'grad_norm': 1.356491208076477, 'learning_rate': 8.728708362363991e-07, 'epoch': 0.74}
 74%|███████▎  | 2137/2906 [7:01:56<2:29:38, 11.68s/it] 74%|███████▎  | 2138/2906 [7:02:08<2:28:21, 11.59s/it]                                                       {'loss': 0.8275, 'grad_norm': 1.3456857204437256, 'learning_rate': 8.70746845260274e-07, 'epoch': 0.74}
 74%|███████▎  | 2138/2906 [7:02:08<2:28:21, 11.59s/it] 74%|███████▎  | 2139/2906 [7:02:20<2:30:03, 11.74s/it]                                                       {'loss': 0.8292, 'grad_norm': 1.3086967468261719, 'learning_rate': 8.686248965531124e-07, 'epoch': 0.74}
 74%|███████▎  | 2139/2906 [7:02:20<2:30:03, 11.74s/it] 74%|███████▎  | 2140/2906 [7:02:31<2:28:40, 11.65s/it]                                                       {'loss': 0.7651, 'grad_norm': 1.3400143384933472, 'learning_rate': 8.665049927747759e-07, 'epoch': 0.74}
 74%|███████▎  | 2140/2906 [7:02:31<2:28:40, 11.65s/it] 74%|███████▎  | 2141/2906 [7:02:43<2:28:20, 11.64s/it]                                                       {'loss': 0.8183, 'grad_norm': 1.288221001625061, 'learning_rate': 8.643871365825651e-07, 'epoch': 0.74}
 74%|███████▎  | 2141/2906 [7:02:43<2:28:20, 11.64s/it] 74%|███████▎  | 2142/2906 [7:02:55<2:28:44, 11.68s/it]                                                       {'loss': 0.8129, 'grad_norm': 1.340882658958435, 'learning_rate': 8.62271330631212e-07, 'epoch': 0.74}
 74%|███████▎  | 2142/2906 [7:02:55<2:28:44, 11.68s/it] 74%|███████▎  | 2143/2906 [7:03:06<2:28:59, 11.72s/it]                                                       {'loss': 0.8254, 'grad_norm': 1.2938565015792847, 'learning_rate': 8.601575775728793e-07, 'epoch': 0.74}
 74%|███████▎  | 2143/2906 [7:03:06<2:28:59, 11.72s/it] 74%|███████▍  | 2144/2906 [7:03:18<2:30:00, 11.81s/it]                                                       {'loss': 0.8229, 'grad_norm': 1.2297552824020386, 'learning_rate': 8.580458800571587e-07, 'epoch': 0.74}
 74%|███████▍  | 2144/2906 [7:03:18<2:30:00, 11.81s/it] 74%|███████▍  | 2145/2906 [7:03:30<2:30:16, 11.85s/it]                                                       {'loss': 0.755, 'grad_norm': 1.2897722721099854, 'learning_rate': 8.559362407310607e-07, 'epoch': 0.74}
 74%|███████▍  | 2145/2906 [7:03:30<2:30:16, 11.85s/it] 74%|███████▍  | 2146/2906 [7:03:42<2:29:55, 11.84s/it]                                                       {'loss': 0.7693, 'grad_norm': 1.2499101161956787, 'learning_rate': 8.538286622390202e-07, 'epoch': 0.74}
 74%|███████▍  | 2146/2906 [7:03:42<2:29:55, 11.84s/it] 74%|███████▍  | 2147/2906 [7:03:54<2:28:09, 11.71s/it]                                                       {'loss': 0.7563, 'grad_norm': 1.3111780881881714, 'learning_rate': 8.517231472228854e-07, 'epoch': 0.74}
 74%|███████▍  | 2147/2906 [7:03:54<2:28:09, 11.71s/it] 74%|███████▍  | 2148/2906 [7:04:06<2:29:00, 11.80s/it]                                                       {'loss': 0.8009, 'grad_norm': 1.3479504585266113, 'learning_rate': 8.496196983219205e-07, 'epoch': 0.74}
 74%|███████▍  | 2148/2906 [7:04:06<2:29:00, 11.80s/it] 74%|███████▍  | 2149/2906 [7:04:18<2:29:13, 11.83s/it]                                                       {'loss': 0.7896, 'grad_norm': 1.3328243494033813, 'learning_rate': 8.475183181727995e-07, 'epoch': 0.74}
 74%|███████▍  | 2149/2906 [7:04:18<2:29:13, 11.83s/it] 74%|███████▍  | 2150/2906 [7:04:29<2:28:51, 11.81s/it]                                                       {'loss': 0.7788, 'grad_norm': 1.227645754814148, 'learning_rate': 8.45419009409601e-07, 'epoch': 0.74}
 74%|███████▍  | 2150/2906 [7:04:29<2:28:51, 11.81s/it] 74%|███████▍  | 2151/2906 [7:04:41<2:28:49, 11.83s/it]                                                       {'loss': 0.8178, 'grad_norm': 1.3459150791168213, 'learning_rate': 8.433217746638098e-07, 'epoch': 0.74}
 74%|███████▍  | 2151/2906 [7:04:41<2:28:49, 11.83s/it] 74%|███████▍  | 2152/2906 [7:04:52<2:26:48, 11.68s/it]                                                       {'loss': 0.7669, 'grad_norm': 1.3523977994918823, 'learning_rate': 8.412266165643102e-07, 'epoch': 0.74}
 74%|███████▍  | 2152/2906 [7:04:53<2:26:48, 11.68s/it] 74%|███████▍  | 2153/2906 [7:05:04<2:26:01, 11.64s/it]                                                       {'loss': 0.8565, 'grad_norm': 1.4592704772949219, 'learning_rate': 8.391335377373825e-07, 'epoch': 0.74}
 74%|███████▍  | 2153/2906 [7:05:04<2:26:01, 11.64s/it] 74%|███████▍  | 2154/2906 [7:05:16<2:25:45, 11.63s/it]                                                       {'loss': 0.7606, 'grad_norm': 1.3625354766845703, 'learning_rate': 8.370425408067003e-07, 'epoch': 0.74}
 74%|███████▍  | 2154/2906 [7:05:16<2:25:45, 11.63s/it] 74%|███████▍  | 2155/2906 [7:05:27<2:26:24, 11.70s/it]                                                       {'loss': 0.7828, 'grad_norm': 1.283066749572754, 'learning_rate': 8.349536283933302e-07, 'epoch': 0.74}
 74%|███████▍  | 2155/2906 [7:05:28<2:26:24, 11.70s/it] 74%|███████▍  | 2156/2906 [7:05:39<2:25:52, 11.67s/it]                                                       {'loss': 0.7288, 'grad_norm': 1.2303133010864258, 'learning_rate': 8.328668031157219e-07, 'epoch': 0.74}
 74%|███████▍  | 2156/2906 [7:05:39<2:25:52, 11.67s/it] 74%|███████▍  | 2157/2906 [7:05:50<2:24:25, 11.57s/it]                                                       {'loss': 0.8717, 'grad_norm': 1.2527220249176025, 'learning_rate': 8.307820675897127e-07, 'epoch': 0.74}
 74%|███████▍  | 2157/2906 [7:05:50<2:24:25, 11.57s/it] 74%|███████▍  | 2158/2906 [7:06:02<2:26:00, 11.71s/it]                                                       {'loss': 0.7921, 'grad_norm': 1.3664346933364868, 'learning_rate': 8.286994244285191e-07, 'epoch': 0.74}
 74%|███████▍  | 2158/2906 [7:06:03<2:26:00, 11.71s/it] 74%|███████▍  | 2159/2906 [7:06:14<2:25:36, 11.70s/it]                                                       {'loss': 0.7997, 'grad_norm': 1.3021481037139893, 'learning_rate': 8.266188762427327e-07, 'epoch': 0.74}
 74%|███████▍  | 2159/2906 [7:06:14<2:25:36, 11.70s/it] 74%|███████▍  | 2160/2906 [7:06:26<2:26:09, 11.76s/it]                                                       {'loss': 0.8076, 'grad_norm': 1.3705238103866577, 'learning_rate': 8.245404256403228e-07, 'epoch': 0.74}
 74%|███████▍  | 2160/2906 [7:06:26<2:26:09, 11.76s/it] 74%|███████▍  | 2161/2906 [7:06:37<2:23:56, 11.59s/it]                                                       {'loss': 0.7936, 'grad_norm': 1.469866394996643, 'learning_rate': 8.224640752266256e-07, 'epoch': 0.74}
 74%|███████▍  | 2161/2906 [7:06:37<2:23:56, 11.59s/it] 74%|███████▍  | 2162/2906 [7:06:48<2:21:57, 11.45s/it]                                                       {'loss': 0.7317, 'grad_norm': 1.2997181415557861, 'learning_rate': 8.203898276043471e-07, 'epoch': 0.74}
 74%|███████▍  | 2162/2906 [7:06:48<2:21:57, 11.45s/it] 74%|███████▍  | 2163/2906 [7:07:00<2:22:26, 11.50s/it]                                                       {'loss': 0.7591, 'grad_norm': 1.2787445783615112, 'learning_rate': 8.18317685373558e-07, 'epoch': 0.74}
 74%|███████▍  | 2163/2906 [7:07:00<2:22:26, 11.50s/it] 74%|███████▍  | 2164/2906 [7:07:11<2:22:16, 11.50s/it]                                                       {'loss': 0.8155, 'grad_norm': 1.4115749597549438, 'learning_rate': 8.162476511316872e-07, 'epoch': 0.74}
 74%|███████▍  | 2164/2906 [7:07:12<2:22:16, 11.50s/it] 75%|███████▍  | 2165/2906 [7:07:23<2:22:43, 11.56s/it]                                                       {'loss': 0.7897, 'grad_norm': 1.2911491394042969, 'learning_rate': 8.141797274735242e-07, 'epoch': 0.75}
 75%|███████▍  | 2165/2906 [7:07:23<2:22:43, 11.56s/it] 75%|███████▍  | 2166/2906 [7:07:35<2:22:15, 11.53s/it]                                                       {'loss': 0.7578, 'grad_norm': 1.4317430257797241, 'learning_rate': 8.121139169912098e-07, 'epoch': 0.75}
 75%|███████▍  | 2166/2906 [7:07:35<2:22:15, 11.53s/it] 75%|███████▍  | 2167/2906 [7:07:46<2:23:00, 11.61s/it]                                                       {'loss': 0.7274, 'grad_norm': 1.3349529504776, 'learning_rate': 8.100502222742387e-07, 'epoch': 0.75}
 75%|███████▍  | 2167/2906 [7:07:46<2:23:00, 11.61s/it] 75%|███████▍  | 2168/2906 [7:07:59<2:24:40, 11.76s/it]                                                       {'loss': 0.8157, 'grad_norm': 1.2715932130813599, 'learning_rate': 8.07988645909453e-07, 'epoch': 0.75}
 75%|███████▍  | 2168/2906 [7:07:59<2:24:40, 11.76s/it] 75%|███████▍  | 2169/2906 [7:08:11<2:25:49, 11.87s/it]                                                       {'loss': 0.7772, 'grad_norm': 1.4040460586547852, 'learning_rate': 8.059291904810373e-07, 'epoch': 0.75}
 75%|███████▍  | 2169/2906 [7:08:11<2:25:49, 11.87s/it] 75%|███████▍  | 2170/2906 [7:08:22<2:24:52, 11.81s/it]                                                       {'loss': 0.8024, 'grad_norm': 1.3214327096939087, 'learning_rate': 8.038718585705199e-07, 'epoch': 0.75}
 75%|███████▍  | 2170/2906 [7:08:22<2:24:52, 11.81s/it] 75%|███████▍  | 2171/2906 [7:08:34<2:23:11, 11.69s/it]                                                       {'loss': 0.751, 'grad_norm': 1.2705936431884766, 'learning_rate': 8.018166527567672e-07, 'epoch': 0.75}
 75%|███████▍  | 2171/2906 [7:08:34<2:23:11, 11.69s/it] 75%|███████▍  | 2172/2906 [7:08:45<2:21:38, 11.58s/it]                                                       {'loss': 0.7512, 'grad_norm': 1.285077452659607, 'learning_rate': 7.997635756159785e-07, 'epoch': 0.75}
 75%|███████▍  | 2172/2906 [7:08:45<2:21:38, 11.58s/it] 75%|███████▍  | 2173/2906 [7:08:57<2:21:09, 11.55s/it]                                                       {'loss': 0.7758, 'grad_norm': 1.2667704820632935, 'learning_rate': 7.977126297216878e-07, 'epoch': 0.75}
 75%|███████▍  | 2173/2906 [7:08:57<2:21:09, 11.55s/it] 75%|███████▍  | 2174/2906 [7:09:08<2:21:58, 11.64s/it]                                                       {'loss': 0.7826, 'grad_norm': 1.2252734899520874, 'learning_rate': 7.956638176447548e-07, 'epoch': 0.75}
 75%|███████▍  | 2174/2906 [7:09:08<2:21:58, 11.64s/it] 75%|███████▍  | 2175/2906 [7:09:20<2:21:03, 11.58s/it]                                                       {'loss': 0.7911, 'grad_norm': 1.2909563779830933, 'learning_rate': 7.936171419533653e-07, 'epoch': 0.75}
 75%|███████▍  | 2175/2906 [7:09:20<2:21:03, 11.58s/it] 75%|███████▍  | 2176/2906 [7:09:31<2:19:53, 11.50s/it]                                                       {'loss': 0.7831, 'grad_norm': 1.283960223197937, 'learning_rate': 7.915726052130285e-07, 'epoch': 0.75}
 75%|███████▍  | 2176/2906 [7:09:31<2:19:53, 11.50s/it] 75%|███████▍  | 2177/2906 [7:09:43<2:22:22, 11.72s/it]                                                       {'loss': 0.86, 'grad_norm': 1.286858320236206, 'learning_rate': 7.895302099865701e-07, 'epoch': 0.75}
 75%|███████▍  | 2177/2906 [7:09:43<2:22:22, 11.72s/it] 75%|███████▍  | 2178/2906 [7:09:56<2:24:39, 11.92s/it]                                                       {'loss': 0.7781, 'grad_norm': 1.2884622812271118, 'learning_rate': 7.874899588341333e-07, 'epoch': 0.75}
 75%|███████▍  | 2178/2906 [7:09:56<2:24:39, 11.92s/it] 75%|███████▍  | 2179/2906 [7:10:07<2:21:53, 11.71s/it]                                                       {'loss': 0.7614, 'grad_norm': 1.3019499778747559, 'learning_rate': 7.854518543131742e-07, 'epoch': 0.75}
 75%|███████▍  | 2179/2906 [7:10:07<2:21:53, 11.71s/it] 75%|███████▌  | 2180/2906 [7:10:19<2:21:44, 11.71s/it]                                                       {'loss': 0.7948, 'grad_norm': 1.2020362615585327, 'learning_rate': 7.834158989784549e-07, 'epoch': 0.75}
 75%|███████▌  | 2180/2906 [7:10:19<2:21:44, 11.71s/it] 75%|███████▌  | 2181/2906 [7:10:31<2:22:58, 11.83s/it]                                                       {'loss': 0.825, 'grad_norm': 1.448870062828064, 'learning_rate': 7.813820953820469e-07, 'epoch': 0.75}
 75%|███████▌  | 2181/2906 [7:10:31<2:22:58, 11.83s/it] 75%|███████▌  | 2182/2906 [7:10:43<2:25:12, 12.03s/it]                                                       {'loss': 0.7732, 'grad_norm': 1.2942895889282227, 'learning_rate': 7.793504460733236e-07, 'epoch': 0.75}
 75%|███████▌  | 2182/2906 [7:10:43<2:25:12, 12.03s/it] 75%|███████▌  | 2183/2906 [7:10:55<2:23:12, 11.88s/it]                                                       {'loss': 0.8229, 'grad_norm': 1.2732915878295898, 'learning_rate': 7.773209535989562e-07, 'epoch': 0.75}
 75%|███████▌  | 2183/2906 [7:10:55<2:23:12, 11.88s/it] 75%|███████▌  | 2184/2906 [7:11:06<2:21:14, 11.74s/it]                                                       {'loss': 0.7945, 'grad_norm': 1.3377200365066528, 'learning_rate': 7.752936205029152e-07, 'epoch': 0.75}
 75%|███████▌  | 2184/2906 [7:11:06<2:21:14, 11.74s/it] 75%|███████▌  | 2185/2906 [7:11:18<2:21:22, 11.77s/it]                                                       {'loss': 0.7774, 'grad_norm': 1.3376306295394897, 'learning_rate': 7.732684493264611e-07, 'epoch': 0.75}
 75%|███████▌  | 2185/2906 [7:11:18<2:21:22, 11.77s/it] 75%|███████▌  | 2186/2906 [7:11:30<2:20:23, 11.70s/it]                                                       {'loss': 0.8341, 'grad_norm': 1.4664123058319092, 'learning_rate': 7.71245442608147e-07, 'epoch': 0.75}
 75%|███████▌  | 2186/2906 [7:11:30<2:20:23, 11.70s/it] 75%|███████▌  | 2187/2906 [7:11:42<2:21:21, 11.80s/it]                                                       {'loss': 0.7921, 'grad_norm': 1.2591382265090942, 'learning_rate': 7.69224602883813e-07, 'epoch': 0.75}
 75%|███████▌  | 2187/2906 [7:11:42<2:21:21, 11.80s/it] 75%|███████▌  | 2188/2906 [7:11:54<2:21:44, 11.84s/it]                                                       {'loss': 0.7499, 'grad_norm': 1.3227310180664062, 'learning_rate': 7.6720593268658e-07, 'epoch': 0.75}
 75%|███████▌  | 2188/2906 [7:11:54<2:21:44, 11.84s/it] 75%|███████▌  | 2189/2906 [7:12:05<2:20:16, 11.74s/it]                                                       {'loss': 0.8012, 'grad_norm': 1.352664589881897, 'learning_rate': 7.651894345468522e-07, 'epoch': 0.75}
 75%|███████▌  | 2189/2906 [7:12:05<2:20:16, 11.74s/it] 75%|███████▌  | 2190/2906 [7:12:17<2:19:21, 11.68s/it]                                                       {'loss': 0.8394, 'grad_norm': 1.344809651374817, 'learning_rate': 7.631751109923108e-07, 'epoch': 0.75}
 75%|███████▌  | 2190/2906 [7:12:17<2:19:21, 11.68s/it] 75%|███████▌  | 2191/2906 [7:12:28<2:19:24, 11.70s/it]                                                       {'loss': 0.831, 'grad_norm': 1.3603068590164185, 'learning_rate': 7.61162964547909e-07, 'epoch': 0.75}
 75%|███████▌  | 2191/2906 [7:12:28<2:19:24, 11.70s/it] 75%|███████▌  | 2192/2906 [7:12:40<2:19:09, 11.69s/it]                                                       {'loss': 0.7884, 'grad_norm': 1.301777720451355, 'learning_rate': 7.591529977358744e-07, 'epoch': 0.75}
 75%|███████▌  | 2192/2906 [7:12:40<2:19:09, 11.69s/it] 75%|███████▌  | 2193/2906 [7:12:52<2:18:24, 11.65s/it]                                                       {'loss': 0.8086, 'grad_norm': 1.444087028503418, 'learning_rate': 7.571452130756984e-07, 'epoch': 0.75}
 75%|███████▌  | 2193/2906 [7:12:52<2:18:24, 11.65s/it] 75%|███████▌  | 2194/2906 [7:13:04<2:19:47, 11.78s/it]                                                       {'loss': 0.7999, 'grad_norm': 1.2914865016937256, 'learning_rate': 7.551396130841406e-07, 'epoch': 0.75}
 75%|███████▌  | 2194/2906 [7:13:04<2:19:47, 11.78s/it] 76%|███████▌  | 2195/2906 [7:13:16<2:20:12, 11.83s/it]                                                       {'loss': 0.8427, 'grad_norm': 1.3770735263824463, 'learning_rate': 7.531362002752224e-07, 'epoch': 0.76}
 76%|███████▌  | 2195/2906 [7:13:16<2:20:12, 11.83s/it] 76%|███████▌  | 2196/2906 [7:13:28<2:20:35, 11.88s/it]                                                       {'loss': 0.7762, 'grad_norm': 1.312498927116394, 'learning_rate': 7.51134977160218e-07, 'epoch': 0.76}
 76%|███████▌  | 2196/2906 [7:13:28<2:20:35, 11.88s/it] 76%|███████▌  | 2197/2906 [7:13:40<2:22:16, 12.04s/it]                                                       {'loss': 0.8375, 'grad_norm': 1.3061630725860596, 'learning_rate': 7.491359462476632e-07, 'epoch': 0.76}
 76%|███████▌  | 2197/2906 [7:13:40<2:22:16, 12.04s/it] 76%|███████▌  | 2198/2906 [7:13:52<2:22:13, 12.05s/it]                                                       {'loss': 0.8106, 'grad_norm': 1.5006455183029175, 'learning_rate': 7.471391100433436e-07, 'epoch': 0.76}
 76%|███████▌  | 2198/2906 [7:13:52<2:22:13, 12.05s/it] 76%|███████▌  | 2199/2906 [7:14:04<2:20:39, 11.94s/it]                                                       {'loss': 0.7638, 'grad_norm': 1.3715935945510864, 'learning_rate': 7.451444710502923e-07, 'epoch': 0.76}
 76%|███████▌  | 2199/2906 [7:14:04<2:20:39, 11.94s/it] 76%|███████▌  | 2200/2906 [7:14:16<2:19:32, 11.86s/it]                                                       {'loss': 0.8162, 'grad_norm': 1.3847179412841797, 'learning_rate': 7.431520317687899e-07, 'epoch': 0.76}
 76%|███████▌  | 2200/2906 [7:14:16<2:19:32, 11.86s/it] 76%|███████▌  | 2201/2906 [7:14:28<2:19:53, 11.91s/it]                                                       {'loss': 0.7871, 'grad_norm': 1.3386106491088867, 'learning_rate': 7.411617946963604e-07, 'epoch': 0.76}
 76%|███████▌  | 2201/2906 [7:14:28<2:19:53, 11.91s/it] 76%|███████▌  | 2202/2906 [7:14:39<2:19:38, 11.90s/it]                                                       {'loss': 0.7566, 'grad_norm': 1.2787024974822998, 'learning_rate': 7.391737623277642e-07, 'epoch': 0.76}
 76%|███████▌  | 2202/2906 [7:14:39<2:19:38, 11.90s/it] 76%|███████▌  | 2203/2906 [7:14:51<2:18:08, 11.79s/it]                                                       {'loss': 0.7807, 'grad_norm': 1.3022541999816895, 'learning_rate': 7.371879371550017e-07, 'epoch': 0.76}
 76%|███████▌  | 2203/2906 [7:14:51<2:18:08, 11.79s/it] 76%|███████▌  | 2204/2906 [7:15:03<2:18:29, 11.84s/it]                                                       {'loss': 0.7439, 'grad_norm': 1.268558144569397, 'learning_rate': 7.352043216673035e-07, 'epoch': 0.76}
 76%|███████▌  | 2204/2906 [7:15:03<2:18:29, 11.84s/it] 76%|███████▌  | 2205/2906 [7:15:15<2:17:56, 11.81s/it]                                                       {'loss': 0.7664, 'grad_norm': 1.3295390605926514, 'learning_rate': 7.332229183511325e-07, 'epoch': 0.76}
 76%|███████▌  | 2205/2906 [7:15:15<2:17:56, 11.81s/it] 76%|███████▌  | 2206/2906 [7:15:26<2:17:07, 11.75s/it]                                                       {'loss': 0.8115, 'grad_norm': 1.3620914220809937, 'learning_rate': 7.312437296901786e-07, 'epoch': 0.76}
 76%|███████▌  | 2206/2906 [7:15:26<2:17:07, 11.75s/it] 76%|███████▌  | 2207/2906 [7:15:37<2:14:26, 11.54s/it]                                                       {'loss': 0.8079, 'grad_norm': 1.436789870262146, 'learning_rate': 7.292667581653537e-07, 'epoch': 0.76}
 76%|███████▌  | 2207/2906 [7:15:37<2:14:26, 11.54s/it] 76%|███████▌  | 2208/2906 [7:15:49<2:15:13, 11.62s/it]                                                       {'loss': 0.7802, 'grad_norm': 1.3569962978363037, 'learning_rate': 7.27292006254792e-07, 'epoch': 0.76}
 76%|███████▌  | 2208/2906 [7:15:49<2:15:13, 11.62s/it] 76%|███████▌  | 2209/2906 [7:16:01<2:15:46, 11.69s/it]                                                       {'loss': 0.8485, 'grad_norm': 1.277616262435913, 'learning_rate': 7.253194764338465e-07, 'epoch': 0.76}
 76%|███████▌  | 2209/2906 [7:16:01<2:15:46, 11.69s/it] 76%|███████▌  | 2210/2906 [7:16:12<2:14:25, 11.59s/it]                                                       {'loss': 0.6981, 'grad_norm': 1.5573015213012695, 'learning_rate': 7.233491711750815e-07, 'epoch': 0.76}
 76%|███████▌  | 2210/2906 [7:16:12<2:14:25, 11.59s/it] 76%|███████▌  | 2211/2906 [7:16:24<2:14:35, 11.62s/it]                                                       {'loss': 0.7402, 'grad_norm': 1.3399468660354614, 'learning_rate': 7.213810929482765e-07, 'epoch': 0.76}
 76%|███████▌  | 2211/2906 [7:16:24<2:14:35, 11.62s/it] 76%|███████▌  | 2212/2906 [7:16:36<2:14:46, 11.65s/it]                                                       {'loss': 0.7568, 'grad_norm': 1.1937278509140015, 'learning_rate': 7.194152442204164e-07, 'epoch': 0.76}
 76%|███████▌  | 2212/2906 [7:16:36<2:14:46, 11.65s/it] 76%|███████▌  | 2213/2906 [7:16:47<2:14:19, 11.63s/it]                                                       {'loss': 0.7838, 'grad_norm': 1.3358806371688843, 'learning_rate': 7.174516274556931e-07, 'epoch': 0.76}
 76%|███████▌  | 2213/2906 [7:16:47<2:14:19, 11.63s/it] 76%|███████▌  | 2214/2906 [7:16:59<2:14:58, 11.70s/it]                                                       {'loss': 0.7911, 'grad_norm': 1.2629258632659912, 'learning_rate': 7.154902451155016e-07, 'epoch': 0.76}
 76%|███████▌  | 2214/2906 [7:16:59<2:14:58, 11.70s/it] 76%|███████▌  | 2215/2906 [7:17:11<2:16:16, 11.83s/it]                                                       {'loss': 0.7403, 'grad_norm': 1.3145755529403687, 'learning_rate': 7.13531099658433e-07, 'epoch': 0.76}
 76%|███████▌  | 2215/2906 [7:17:11<2:16:16, 11.83s/it] 76%|███████▋  | 2216/2906 [7:17:23<2:14:21, 11.68s/it]                                                       {'loss': 0.7553, 'grad_norm': 1.307399034500122, 'learning_rate': 7.11574193540277e-07, 'epoch': 0.76}
 76%|███████▋  | 2216/2906 [7:17:23<2:14:21, 11.68s/it] 76%|███████▋  | 2217/2906 [7:17:34<2:13:54, 11.66s/it]                                                       {'loss': 0.7345, 'grad_norm': 1.2027714252471924, 'learning_rate': 7.096195292140173e-07, 'epoch': 0.76}
 76%|███████▋  | 2217/2906 [7:17:34<2:13:54, 11.66s/it] 76%|███████▋  | 2218/2906 [7:17:46<2:14:44, 11.75s/it]                                                       {'loss': 0.7507, 'grad_norm': 1.3142951726913452, 'learning_rate': 7.076671091298229e-07, 'epoch': 0.76}
 76%|███████▋  | 2218/2906 [7:17:46<2:14:44, 11.75s/it] 76%|███████▋  | 2219/2906 [7:17:58<2:13:18, 11.64s/it]                                                       {'loss': 0.8346, 'grad_norm': 1.2807326316833496, 'learning_rate': 7.057169357350535e-07, 'epoch': 0.76}
 76%|███████▋  | 2219/2906 [7:17:58<2:13:18, 11.64s/it] 76%|███████▋  | 2220/2906 [7:18:09<2:13:05, 11.64s/it]                                                       {'loss': 0.8233, 'grad_norm': 1.3041208982467651, 'learning_rate': 7.037690114742529e-07, 'epoch': 0.76}
 76%|███████▋  | 2220/2906 [7:18:09<2:13:05, 11.64s/it] 76%|███████▋  | 2221/2906 [7:18:20<2:11:15, 11.50s/it]                                                       {'loss': 0.7988, 'grad_norm': 1.3700200319290161, 'learning_rate': 7.018233387891426e-07, 'epoch': 0.76}
 76%|███████▋  | 2221/2906 [7:18:20<2:11:15, 11.50s/it] 76%|███████▋  | 2222/2906 [7:18:33<2:13:07, 11.68s/it]                                                       {'loss': 0.8006, 'grad_norm': 1.310867428779602, 'learning_rate': 6.998799201186251e-07, 'epoch': 0.76}
 76%|███████▋  | 2222/2906 [7:18:33<2:13:07, 11.68s/it] 76%|███████▋  | 2223/2906 [7:18:44<2:11:38, 11.56s/it]                                                       {'loss': 0.7757, 'grad_norm': 1.2606897354125977, 'learning_rate': 6.97938757898774e-07, 'epoch': 0.76}
 76%|███████▋  | 2223/2906 [7:18:44<2:11:38, 11.56s/it] 77%|███████▋  | 2224/2906 [7:18:56<2:11:55, 11.61s/it]                                                       {'loss': 0.7679, 'grad_norm': 1.341734766960144, 'learning_rate': 6.959998545628374e-07, 'epoch': 0.77}
 77%|███████▋  | 2224/2906 [7:18:56<2:11:55, 11.61s/it] 77%|███████▋  | 2225/2906 [7:19:07<2:12:06, 11.64s/it]                                                       {'loss': 0.7532, 'grad_norm': 1.3532366752624512, 'learning_rate': 6.940632125412314e-07, 'epoch': 0.77}
 77%|███████▋  | 2225/2906 [7:19:07<2:12:06, 11.64s/it] 77%|███████▋  | 2226/2906 [7:19:19<2:11:55, 11.64s/it]                                                       {'loss': 0.8083, 'grad_norm': 1.262845516204834, 'learning_rate': 6.921288342615356e-07, 'epoch': 0.77}
 77%|███████▋  | 2226/2906 [7:19:19<2:11:55, 11.64s/it] 77%|███████▋  | 2227/2906 [7:19:30<2:10:44, 11.55s/it]                                                       {'loss': 0.7539, 'grad_norm': 1.2989076375961304, 'learning_rate': 6.901967221484937e-07, 'epoch': 0.77}
 77%|███████▋  | 2227/2906 [7:19:30<2:10:44, 11.55s/it] 77%|███████▋  | 2228/2906 [7:19:42<2:10:46, 11.57s/it]                                                       {'loss': 0.739, 'grad_norm': 1.3095179796218872, 'learning_rate': 6.882668786240096e-07, 'epoch': 0.77}
 77%|███████▋  | 2228/2906 [7:19:42<2:10:46, 11.57s/it] 77%|███████▋  | 2229/2906 [7:19:53<2:10:44, 11.59s/it]                                                       {'loss': 0.764, 'grad_norm': 1.3017592430114746, 'learning_rate': 6.863393061071407e-07, 'epoch': 0.77}
 77%|███████▋  | 2229/2906 [7:19:53<2:10:44, 11.59s/it] 77%|███████▋  | 2230/2906 [7:20:05<2:09:31, 11.50s/it]                                                       {'loss': 0.8739, 'grad_norm': 1.2716516256332397, 'learning_rate': 6.844140070141006e-07, 'epoch': 0.77}
 77%|███████▋  | 2230/2906 [7:20:05<2:09:31, 11.50s/it] 77%|███████▋  | 2231/2906 [7:20:16<2:09:46, 11.53s/it]                                                       {'loss': 0.7565, 'grad_norm': 1.393255591392517, 'learning_rate': 6.824909837582505e-07, 'epoch': 0.77}
 77%|███████▋  | 2231/2906 [7:20:16<2:09:46, 11.53s/it] 77%|███████▋  | 2232/2906 [7:20:28<2:09:16, 11.51s/it]                                                       {'loss': 0.8039, 'grad_norm': 1.3541589975357056, 'learning_rate': 6.80570238750101e-07, 'epoch': 0.77}
 77%|███████▋  | 2232/2906 [7:20:28<2:09:16, 11.51s/it] 77%|███████▋  | 2233/2906 [7:20:40<2:10:04, 11.60s/it]                                                       {'loss': 0.8217, 'grad_norm': 1.4124294519424438, 'learning_rate': 6.786517743973065e-07, 'epoch': 0.77}
 77%|███████▋  | 2233/2906 [7:20:40<2:10:04, 11.60s/it] 77%|███████▋  | 2234/2906 [7:20:51<2:08:40, 11.49s/it]                                                       {'loss': 0.7612, 'grad_norm': 1.214643120765686, 'learning_rate': 6.767355931046613e-07, 'epoch': 0.77}
 77%|███████▋  | 2234/2906 [7:20:51<2:08:40, 11.49s/it] 77%|███████▋  | 2235/2906 [7:21:02<2:09:00, 11.54s/it]                                                       {'loss': 0.77, 'grad_norm': 1.304176926612854, 'learning_rate': 6.748216972740992e-07, 'epoch': 0.77}
 77%|███████▋  | 2235/2906 [7:21:03<2:09:00, 11.54s/it] 77%|███████▋  | 2236/2906 [7:21:14<2:09:25, 11.59s/it]                                                       {'loss': 0.7838, 'grad_norm': 1.2782474756240845, 'learning_rate': 6.729100893046897e-07, 'epoch': 0.77}
 77%|███████▋  | 2236/2906 [7:21:14<2:09:25, 11.59s/it] 77%|███████▋  | 2237/2906 [7:21:26<2:10:13, 11.68s/it]                                                       {'loss': 0.781, 'grad_norm': 1.3893558979034424, 'learning_rate': 6.71000771592632e-07, 'epoch': 0.77}
 77%|███████▋  | 2237/2906 [7:21:26<2:10:13, 11.68s/it] 77%|███████▋  | 2238/2906 [7:21:38<2:10:15, 11.70s/it]                                                       {'loss': 0.8655, 'grad_norm': 1.3427791595458984, 'learning_rate': 6.690937465312574e-07, 'epoch': 0.77}
 77%|███████▋  | 2238/2906 [7:21:38<2:10:15, 11.70s/it] 77%|███████▋  | 2239/2906 [7:21:49<2:09:39, 11.66s/it]                                                       {'loss': 0.7663, 'grad_norm': 1.3534377813339233, 'learning_rate': 6.671890165110214e-07, 'epoch': 0.77}
 77%|███████▋  | 2239/2906 [7:21:49<2:09:39, 11.66s/it] 77%|███████▋  | 2240/2906 [7:22:01<2:10:09, 11.73s/it]                                                       {'loss': 0.7773, 'grad_norm': 1.2396526336669922, 'learning_rate': 6.652865839195025e-07, 'epoch': 0.77}
 77%|███████▋  | 2240/2906 [7:22:01<2:10:09, 11.73s/it] 77%|███████▋  | 2241/2906 [7:22:13<2:08:53, 11.63s/it]                                                       {'loss': 0.7931, 'grad_norm': 1.3538304567337036, 'learning_rate': 6.633864511414015e-07, 'epoch': 0.77}
 77%|███████▋  | 2241/2906 [7:22:13<2:08:53, 11.63s/it] 77%|███████▋  | 2242/2906 [7:22:25<2:09:31, 11.70s/it]                                                       {'loss': 0.7506, 'grad_norm': 1.3674079179763794, 'learning_rate': 6.614886205585333e-07, 'epoch': 0.77}
 77%|███████▋  | 2242/2906 [7:22:25<2:09:31, 11.70s/it] 77%|███████▋  | 2243/2906 [7:22:37<2:10:33, 11.82s/it]                                                       {'loss': 0.8159, 'grad_norm': 1.3483705520629883, 'learning_rate': 6.595930945498297e-07, 'epoch': 0.77}
 77%|███████▋  | 2243/2906 [7:22:37<2:10:33, 11.82s/it] 77%|███████▋  | 2244/2906 [7:22:48<2:09:40, 11.75s/it]                                                       {'loss': 0.754, 'grad_norm': 1.2821526527404785, 'learning_rate': 6.576998754913333e-07, 'epoch': 0.77}
 77%|███████▋  | 2244/2906 [7:22:48<2:09:40, 11.75s/it] 77%|███████▋  | 2245/2906 [7:23:00<2:10:00, 11.80s/it]                                                       {'loss': 0.8065, 'grad_norm': 1.3299155235290527, 'learning_rate': 6.558089657561931e-07, 'epoch': 0.77}
 77%|███████▋  | 2245/2906 [7:23:00<2:10:00, 11.80s/it] 77%|███████▋  | 2246/2906 [7:23:12<2:08:56, 11.72s/it]                                                       {'loss': 0.7253, 'grad_norm': 1.2851731777191162, 'learning_rate': 6.53920367714665e-07, 'epoch': 0.77}
 77%|███████▋  | 2246/2906 [7:23:12<2:08:56, 11.72s/it] 77%|███████▋  | 2247/2906 [7:23:23<2:08:29, 11.70s/it]                                                       {'loss': 0.8228, 'grad_norm': 1.427966594696045, 'learning_rate': 6.520340837341079e-07, 'epoch': 0.77}
 77%|███████▋  | 2247/2906 [7:23:23<2:08:29, 11.70s/it] 77%|███████▋  | 2248/2906 [7:23:35<2:08:38, 11.73s/it]                                                       {'loss': 0.8389, 'grad_norm': 1.320691704750061, 'learning_rate': 6.501501161789772e-07, 'epoch': 0.77}
 77%|███████▋  | 2248/2906 [7:23:35<2:08:38, 11.73s/it] 77%|███████▋  | 2249/2906 [7:23:47<2:09:30, 11.83s/it]                                                       {'loss': 0.7731, 'grad_norm': 1.3835119009017944, 'learning_rate': 6.482684674108281e-07, 'epoch': 0.77}
 77%|███████▋  | 2249/2906 [7:23:47<2:09:30, 11.83s/it] 77%|███████▋  | 2250/2906 [7:23:59<2:08:30, 11.75s/it]                                                       {'loss': 0.8054, 'grad_norm': 1.2533577680587769, 'learning_rate': 6.463891397883057e-07, 'epoch': 0.77}
 77%|███████▋  | 2250/2906 [7:23:59<2:08:30, 11.75s/it] 77%|███████▋  | 2251/2906 [7:24:10<2:07:18, 11.66s/it]                                                       {'loss': 0.8519, 'grad_norm': 1.3358453512191772, 'learning_rate': 6.445121356671483e-07, 'epoch': 0.77}
 77%|███████▋  | 2251/2906 [7:24:10<2:07:18, 11.66s/it] 77%|███████▋  | 2252/2906 [7:24:23<2:09:43, 11.90s/it]                                                       {'loss': 0.8463, 'grad_norm': 1.378990650177002, 'learning_rate': 6.426374574001812e-07, 'epoch': 0.77}
 77%|███████▋  | 2252/2906 [7:24:23<2:09:43, 11.90s/it] 78%|███████▊  | 2253/2906 [7:24:34<2:08:21, 11.79s/it]                                                       {'loss': 0.7527, 'grad_norm': 1.3428202867507935, 'learning_rate': 6.407651073373125e-07, 'epoch': 0.78}
 78%|███████▊  | 2253/2906 [7:24:34<2:08:21, 11.79s/it] 78%|███████▊  | 2254/2906 [7:24:46<2:07:53, 11.77s/it]                                                       {'loss': 0.7819, 'grad_norm': 1.2762404680252075, 'learning_rate': 6.388950878255348e-07, 'epoch': 0.78}
 78%|███████▊  | 2254/2906 [7:24:46<2:07:53, 11.77s/it] 78%|███████▊  | 2255/2906 [7:24:58<2:08:33, 11.85s/it]                                                       {'loss': 0.7836, 'grad_norm': 1.2336676120758057, 'learning_rate': 6.370274012089159e-07, 'epoch': 0.78}
 78%|███████▊  | 2255/2906 [7:24:58<2:08:33, 11.85s/it] 78%|███████▊  | 2256/2906 [7:25:10<2:09:32, 11.96s/it]                                                       {'loss': 0.7668, 'grad_norm': 1.2280744314193726, 'learning_rate': 6.351620498286021e-07, 'epoch': 0.78}
 78%|███████▊  | 2256/2906 [7:25:10<2:09:32, 11.96s/it] 78%|███████▊  | 2257/2906 [7:25:22<2:09:11, 11.94s/it]                                                       {'loss': 0.7814, 'grad_norm': 1.3728983402252197, 'learning_rate': 6.332990360228119e-07, 'epoch': 0.78}
 78%|███████▊  | 2257/2906 [7:25:22<2:09:11, 11.94s/it] 78%|███████▊  | 2258/2906 [7:25:34<2:07:59, 11.85s/it]                                                       {'loss': 0.7761, 'grad_norm': 1.3816410303115845, 'learning_rate': 6.314383621268322e-07, 'epoch': 0.78}
 78%|███████▊  | 2258/2906 [7:25:34<2:07:59, 11.85s/it] 78%|███████▊  | 2259/2906 [7:25:46<2:08:03, 11.87s/it]                                                       {'loss': 0.7572, 'grad_norm': 1.3559633493423462, 'learning_rate': 6.29580030473019e-07, 'epoch': 0.78}
 78%|███████▊  | 2259/2906 [7:25:46<2:08:03, 11.87s/it] 78%|███████▊  | 2260/2906 [7:25:57<2:07:12, 11.81s/it]                                                       {'loss': 0.7445, 'grad_norm': 1.3322004079818726, 'learning_rate': 6.277240433907908e-07, 'epoch': 0.78}
 78%|███████▊  | 2260/2906 [7:25:57<2:07:12, 11.81s/it] 78%|███████▊  | 2261/2906 [7:26:09<2:05:18, 11.66s/it]                                                       {'loss': 0.7904, 'grad_norm': 1.360892415046692, 'learning_rate': 6.258704032066265e-07, 'epoch': 0.78}
 78%|███████▊  | 2261/2906 [7:26:09<2:05:18, 11.66s/it] 78%|███████▊  | 2262/2906 [7:26:20<2:05:37, 11.70s/it]                                                       {'loss': 0.8421, 'grad_norm': 1.391427993774414, 'learning_rate': 6.240191122440653e-07, 'epoch': 0.78}
 78%|███████▊  | 2262/2906 [7:26:20<2:05:37, 11.70s/it] 78%|███████▊  | 2263/2906 [7:26:32<2:05:28, 11.71s/it]                                                       {'loss': 0.7586, 'grad_norm': 1.2761579751968384, 'learning_rate': 6.221701728237008e-07, 'epoch': 0.78}
 78%|███████▊  | 2263/2906 [7:26:32<2:05:28, 11.71s/it] 78%|███████▊  | 2264/2906 [7:26:44<2:05:02, 11.69s/it]                                                       {'loss': 0.8517, 'grad_norm': 1.3984259366989136, 'learning_rate': 6.203235872631777e-07, 'epoch': 0.78}
 78%|███████▊  | 2264/2906 [7:26:44<2:05:02, 11.69s/it] 78%|███████▊  | 2265/2906 [7:26:56<2:07:23, 11.92s/it]                                                       {'loss': 0.7689, 'grad_norm': 1.2633730173110962, 'learning_rate': 6.184793578771919e-07, 'epoch': 0.78}
 78%|███████▊  | 2265/2906 [7:26:56<2:07:23, 11.92s/it] 78%|███████▊  | 2266/2906 [7:27:08<2:06:00, 11.81s/it]                                                       {'loss': 0.8103, 'grad_norm': 1.243717074394226, 'learning_rate': 6.166374869774855e-07, 'epoch': 0.78}
 78%|███████▊  | 2266/2906 [7:27:08<2:06:00, 11.81s/it] 78%|███████▊  | 2267/2906 [7:27:19<2:05:16, 11.76s/it]                                                       {'loss': 0.7863, 'grad_norm': 1.2449887990951538, 'learning_rate': 6.147979768728427e-07, 'epoch': 0.78}
 78%|███████▊  | 2267/2906 [7:27:20<2:05:16, 11.76s/it] 78%|███████▊  | 2268/2906 [7:27:31<2:05:22, 11.79s/it]                                                       {'loss': 0.8348, 'grad_norm': 1.2778552770614624, 'learning_rate': 6.129608298690906e-07, 'epoch': 0.78}
 78%|███████▊  | 2268/2906 [7:27:31<2:05:22, 11.79s/it] 78%|███████▊  | 2269/2906 [7:27:43<2:04:13, 11.70s/it]                                                       {'loss': 0.8753, 'grad_norm': 1.347377896308899, 'learning_rate': 6.11126048269092e-07, 'epoch': 0.78}
 78%|███████▊  | 2269/2906 [7:27:43<2:04:13, 11.70s/it] 78%|███████▊  | 2270/2906 [7:27:54<2:02:23, 11.55s/it]                                                       {'loss': 0.768, 'grad_norm': 1.2871907949447632, 'learning_rate': 6.092936343727463e-07, 'epoch': 0.78}
 78%|███████▊  | 2270/2906 [7:27:54<2:02:23, 11.55s/it] 78%|███████▊  | 2271/2906 [7:28:06<2:02:17, 11.56s/it]                                                       {'loss': 0.7797, 'grad_norm': 1.3098969459533691, 'learning_rate': 6.074635904769855e-07, 'epoch': 0.78}
 78%|███████▊  | 2271/2906 [7:28:06<2:02:17, 11.56s/it] 78%|███████▊  | 2272/2906 [7:28:18<2:03:29, 11.69s/it]                                                       {'loss': 0.7728, 'grad_norm': 1.333521842956543, 'learning_rate': 6.056359188757679e-07, 'epoch': 0.78}
 78%|███████▊  | 2272/2906 [7:28:18<2:03:29, 11.69s/it] 78%|███████▊  | 2273/2906 [7:28:29<2:03:24, 11.70s/it]                                                       {'loss': 0.8161, 'grad_norm': 1.356644630432129, 'learning_rate': 6.03810621860082e-07, 'epoch': 0.78}
 78%|███████▊  | 2273/2906 [7:28:29<2:03:24, 11.70s/it] 78%|███████▊  | 2274/2906 [7:28:41<2:02:12, 11.60s/it]                                                       {'loss': 0.7439, 'grad_norm': 1.265322208404541, 'learning_rate': 6.019877017179357e-07, 'epoch': 0.78}
 78%|███████▊  | 2274/2906 [7:28:41<2:02:12, 11.60s/it] 78%|███████▊  | 2275/2906 [7:28:53<2:04:09, 11.81s/it]                                                       {'loss': 0.864, 'grad_norm': 1.3223817348480225, 'learning_rate': 6.001671607343609e-07, 'epoch': 0.78}
 78%|███████▊  | 2275/2906 [7:28:53<2:04:09, 11.81s/it] 78%|███████▊  | 2276/2906 [7:29:05<2:03:33, 11.77s/it]                                                       {'loss': 0.8366, 'grad_norm': 1.387319803237915, 'learning_rate': 5.983490011914059e-07, 'epoch': 0.78}
 78%|███████▊  | 2276/2906 [7:29:05<2:03:33, 11.77s/it] 78%|███████▊  | 2277/2906 [7:29:17<2:04:41, 11.89s/it]                                                       {'loss': 0.8462, 'grad_norm': 1.3996659517288208, 'learning_rate': 5.96533225368133e-07, 'epoch': 0.78}
 78%|███████▊  | 2277/2906 [7:29:17<2:04:41, 11.89s/it] 78%|███████▊  | 2278/2906 [7:29:28<2:02:39, 11.72s/it]                                                       {'loss': 0.7625, 'grad_norm': 1.314314842224121, 'learning_rate': 5.947198355406178e-07, 'epoch': 0.78}
 78%|███████▊  | 2278/2906 [7:29:28<2:02:39, 11.72s/it] 78%|███████▊  | 2279/2906 [7:29:40<2:01:41, 11.65s/it]                                                       {'loss': 0.7943, 'grad_norm': 1.3631868362426758, 'learning_rate': 5.929088339819452e-07, 'epoch': 0.78}
 78%|███████▊  | 2279/2906 [7:29:40<2:01:41, 11.65s/it] 78%|███████▊  | 2280/2906 [7:29:52<2:02:37, 11.75s/it]                                                       {'loss': 0.8287, 'grad_norm': 1.356217622756958, 'learning_rate': 5.911002229622054e-07, 'epoch': 0.78}
 78%|███████▊  | 2280/2906 [7:29:52<2:02:37, 11.75s/it] 78%|███████▊  | 2281/2906 [7:30:03<2:02:21, 11.75s/it]                                                       {'loss': 0.8273, 'grad_norm': 1.3238857984542847, 'learning_rate': 5.892940047484915e-07, 'epoch': 0.78}
 78%|███████▊  | 2281/2906 [7:30:03<2:02:21, 11.75s/it] 79%|███████▊  | 2282/2906 [7:30:15<2:01:44, 11.71s/it]                                                       {'loss': 0.8355, 'grad_norm': 1.3087072372436523, 'learning_rate': 5.874901816048997e-07, 'epoch': 0.79}
 79%|███████▊  | 2282/2906 [7:30:15<2:01:44, 11.71s/it] 79%|███████▊  | 2283/2906 [7:30:27<2:01:42, 11.72s/it]                                                       {'loss': 0.8074, 'grad_norm': 1.377817988395691, 'learning_rate': 5.856887557925209e-07, 'epoch': 0.79}
 79%|███████▊  | 2283/2906 [7:30:27<2:01:42, 11.72s/it] 79%|███████▊  | 2284/2906 [7:30:39<2:01:43, 11.74s/it]                                                       {'loss': 0.8246, 'grad_norm': 1.3479743003845215, 'learning_rate': 5.838897295694435e-07, 'epoch': 0.79}
 79%|███████▊  | 2284/2906 [7:30:39<2:01:43, 11.74s/it] 79%|███████▊  | 2285/2906 [7:30:50<2:02:00, 11.79s/it]                                                       {'loss': 0.7793, 'grad_norm': 1.3940589427947998, 'learning_rate': 5.820931051907471e-07, 'epoch': 0.79}
 79%|███████▊  | 2285/2906 [7:30:50<2:02:00, 11.79s/it] 79%|███████▊  | 2286/2906 [7:31:02<2:00:54, 11.70s/it]                                                       {'loss': 0.7665, 'grad_norm': 1.3106441497802734, 'learning_rate': 5.802988849085001e-07, 'epoch': 0.79}
 79%|███████▊  | 2286/2906 [7:31:02<2:00:54, 11.70s/it] 79%|███████▊  | 2287/2906 [7:31:14<2:00:25, 11.67s/it]                                                       {'loss': 0.8025, 'grad_norm': 1.357610821723938, 'learning_rate': 5.785070709717583e-07, 'epoch': 0.79}
 79%|███████▊  | 2287/2906 [7:31:14<2:00:25, 11.67s/it] 79%|███████▊  | 2288/2906 [7:31:25<2:00:18, 11.68s/it]                                                       {'loss': 0.7752, 'grad_norm': 1.3207066059112549, 'learning_rate': 5.767176656265596e-07, 'epoch': 0.79}
 79%|███████▊  | 2288/2906 [7:31:25<2:00:18, 11.68s/it] 79%|███████▉  | 2289/2906 [7:31:36<1:58:51, 11.56s/it]                                                       {'loss': 0.7349, 'grad_norm': 1.3710931539535522, 'learning_rate': 5.749306711159245e-07, 'epoch': 0.79}
 79%|███████▉  | 2289/2906 [7:31:37<1:58:51, 11.56s/it] 79%|███████▉  | 2290/2906 [7:31:48<1:58:18, 11.52s/it]                                                       {'loss': 0.7411, 'grad_norm': 1.2606405019760132, 'learning_rate': 5.731460896798511e-07, 'epoch': 0.79}
 79%|███████▉  | 2290/2906 [7:31:48<1:58:18, 11.52s/it] 79%|███████▉  | 2291/2906 [7:32:00<1:59:02, 11.61s/it]                                                       {'loss': 0.8294, 'grad_norm': 1.3322921991348267, 'learning_rate': 5.713639235553115e-07, 'epoch': 0.79}
 79%|███████▉  | 2291/2906 [7:32:00<1:59:02, 11.61s/it] 79%|███████▉  | 2292/2906 [7:32:12<2:00:51, 11.81s/it]                                                       {'loss': 0.7738, 'grad_norm': 1.205917239189148, 'learning_rate': 5.695841749762518e-07, 'epoch': 0.79}
 79%|███████▉  | 2292/2906 [7:32:12<2:00:51, 11.81s/it] 79%|███████▉  | 2293/2906 [7:32:24<2:01:17, 11.87s/it]                                                       {'loss': 0.7707, 'grad_norm': 1.3770320415496826, 'learning_rate': 5.678068461735864e-07, 'epoch': 0.79}
 79%|███████▉  | 2293/2906 [7:32:24<2:01:17, 11.87s/it] 79%|███████▉  | 2294/2906 [7:32:36<2:01:01, 11.86s/it]                                                       {'loss': 0.7764, 'grad_norm': 1.2501672506332397, 'learning_rate': 5.660319393751973e-07, 'epoch': 0.79}
 79%|███████▉  | 2294/2906 [7:32:36<2:01:01, 11.86s/it] 79%|███████▉  | 2295/2906 [7:32:47<1:59:28, 11.73s/it]                                                       {'loss': 0.7853, 'grad_norm': 1.254427194595337, 'learning_rate': 5.642594568059309e-07, 'epoch': 0.79}
 79%|███████▉  | 2295/2906 [7:32:47<1:59:28, 11.73s/it] 79%|███████▉  | 2296/2906 [7:32:59<1:58:02, 11.61s/it]                                                       {'loss': 0.7819, 'grad_norm': 1.3073675632476807, 'learning_rate': 5.624894006875931e-07, 'epoch': 0.79}
 79%|███████▉  | 2296/2906 [7:32:59<1:58:02, 11.61s/it] 79%|███████▉  | 2297/2906 [7:33:10<1:57:44, 11.60s/it]                                                       {'loss': 0.7868, 'grad_norm': 1.2584092617034912, 'learning_rate': 5.607217732389503e-07, 'epoch': 0.79}
 79%|███████▉  | 2297/2906 [7:33:10<1:57:44, 11.60s/it] 79%|███████▉  | 2298/2906 [7:33:22<1:57:19, 11.58s/it]                                                       {'loss': 0.8101, 'grad_norm': 1.2954779863357544, 'learning_rate': 5.589565766757238e-07, 'epoch': 0.79}
 79%|███████▉  | 2298/2906 [7:33:22<1:57:19, 11.58s/it] 79%|███████▉  | 2299/2906 [7:33:34<1:57:51, 11.65s/it]                                                       {'loss': 0.7589, 'grad_norm': 1.2919970750808716, 'learning_rate': 5.571938132105867e-07, 'epoch': 0.79}
 79%|███████▉  | 2299/2906 [7:33:34<1:57:51, 11.65s/it] 79%|███████▉  | 2300/2906 [7:33:45<1:57:59, 11.68s/it]                                                       {'loss': 0.8159, 'grad_norm': 1.34317946434021, 'learning_rate': 5.554334850531643e-07, 'epoch': 0.79}
 79%|███████▉  | 2300/2906 [7:33:45<1:57:59, 11.68s/it] 79%|███████▉  | 2301/2906 [7:33:57<1:56:40, 11.57s/it]                                                       {'loss': 0.8825, 'grad_norm': 1.3481967449188232, 'learning_rate': 5.536755944100269e-07, 'epoch': 0.79}
 79%|███████▉  | 2301/2906 [7:33:57<1:56:40, 11.57s/it] 79%|███████▉  | 2302/2906 [7:34:08<1:56:06, 11.53s/it]                                                       {'loss': 0.8418, 'grad_norm': 1.3565844297409058, 'learning_rate': 5.519201434846916e-07, 'epoch': 0.79}
 79%|███████▉  | 2302/2906 [7:34:08<1:56:06, 11.53s/it] 79%|███████▉  | 2303/2906 [7:34:20<1:56:43, 11.61s/it]                                                       {'loss': 0.8425, 'grad_norm': 1.3585994243621826, 'learning_rate': 5.501671344776152e-07, 'epoch': 0.79}
 79%|███████▉  | 2303/2906 [7:34:20<1:56:43, 11.61s/it] 79%|███████▉  | 2304/2906 [7:34:32<1:57:02, 11.67s/it]                                                       {'loss': 0.8245, 'grad_norm': 1.376541256904602, 'learning_rate': 5.484165695861959e-07, 'epoch': 0.79}
 79%|███████▉  | 2304/2906 [7:34:32<1:57:02, 11.67s/it] 79%|███████▉  | 2305/2906 [7:34:44<1:57:22, 11.72s/it]                                                       {'loss': 0.765, 'grad_norm': 1.2278367280960083, 'learning_rate': 5.466684510047659e-07, 'epoch': 0.79}
 79%|███████▉  | 2305/2906 [7:34:44<1:57:22, 11.72s/it] 79%|███████▉  | 2306/2906 [7:34:56<1:58:59, 11.90s/it]                                                       {'loss': 0.7599, 'grad_norm': 1.3607593774795532, 'learning_rate': 5.449227809245927e-07, 'epoch': 0.79}
 79%|███████▉  | 2306/2906 [7:34:56<1:58:59, 11.90s/it] 79%|███████▉  | 2307/2906 [7:35:08<1:58:59, 11.92s/it]                                                       {'loss': 0.7047, 'grad_norm': 1.3350197076797485, 'learning_rate': 5.43179561533873e-07, 'epoch': 0.79}
 79%|███████▉  | 2307/2906 [7:35:08<1:58:59, 11.92s/it] 79%|███████▉  | 2308/2906 [7:35:20<1:58:54, 11.93s/it]                                                       {'loss': 0.7928, 'grad_norm': 1.3040623664855957, 'learning_rate': 5.41438795017733e-07, 'epoch': 0.79}
 79%|███████▉  | 2308/2906 [7:35:20<1:58:54, 11.93s/it] 79%|███████▉  | 2309/2906 [7:35:31<1:57:11, 11.78s/it]                                                       {'loss': 0.8048, 'grad_norm': 1.31330144405365, 'learning_rate': 5.397004835582242e-07, 'epoch': 0.79}
 79%|███████▉  | 2309/2906 [7:35:31<1:57:11, 11.78s/it] 79%|███████▉  | 2310/2906 [7:35:44<1:59:48, 12.06s/it]                                                       {'loss': 0.7675, 'grad_norm': 1.3116315603256226, 'learning_rate': 5.379646293343193e-07, 'epoch': 0.79}
 79%|███████▉  | 2310/2906 [7:35:44<1:59:48, 12.06s/it] 80%|███████▉  | 2311/2906 [7:35:56<1:58:37, 11.96s/it]                                                       {'loss': 0.7774, 'grad_norm': 1.1902809143066406, 'learning_rate': 5.362312345219125e-07, 'epoch': 0.8}
 80%|███████▉  | 2311/2906 [7:35:56<1:58:37, 11.96s/it] 80%|███████▉  | 2312/2906 [7:36:09<2:01:12, 12.24s/it]                                                       {'loss': 0.8183, 'grad_norm': 1.4687920808792114, 'learning_rate': 5.345003012938132e-07, 'epoch': 0.8}
 80%|███████▉  | 2312/2906 [7:36:09<2:01:12, 12.24s/it] 80%|███████▉  | 2313/2906 [7:36:20<1:59:32, 12.10s/it]                                                       {'loss': 0.8307, 'grad_norm': 1.4063639640808105, 'learning_rate': 5.327718318197469e-07, 'epoch': 0.8}
 80%|███████▉  | 2313/2906 [7:36:20<1:59:32, 12.10s/it] 80%|███████▉  | 2314/2906 [7:36:32<1:58:17, 11.99s/it]                                                       {'loss': 0.8162, 'grad_norm': 1.2446727752685547, 'learning_rate': 5.310458282663514e-07, 'epoch': 0.8}
 80%|███████▉  | 2314/2906 [7:36:32<1:58:17, 11.99s/it] 80%|███████▉  | 2315/2906 [7:36:44<1:58:02, 11.98s/it]                                                       {'loss': 0.8541, 'grad_norm': 1.4518053531646729, 'learning_rate': 5.293222927971703e-07, 'epoch': 0.8}
 80%|███████▉  | 2315/2906 [7:36:44<1:58:02, 11.98s/it] 80%|███████▉  | 2316/2906 [7:36:56<1:56:48, 11.88s/it]                                                       {'loss': 0.765, 'grad_norm': 1.4605135917663574, 'learning_rate': 5.276012275726564e-07, 'epoch': 0.8}
 80%|███████▉  | 2316/2906 [7:36:56<1:56:48, 11.88s/it] 80%|███████▉  | 2317/2906 [7:37:07<1:55:15, 11.74s/it]                                                       {'loss': 0.8466, 'grad_norm': 1.4601646661758423, 'learning_rate': 5.258826347501655e-07, 'epoch': 0.8}
 80%|███████▉  | 2317/2906 [7:37:07<1:55:15, 11.74s/it] 80%|███████▉  | 2318/2906 [7:37:19<1:54:49, 11.72s/it]                                                       {'loss': 0.7578, 'grad_norm': 1.322607398033142, 'learning_rate': 5.241665164839532e-07, 'epoch': 0.8}
 80%|███████▉  | 2318/2906 [7:37:19<1:54:49, 11.72s/it] 80%|███████▉  | 2319/2906 [7:37:30<1:54:21, 11.69s/it]                                                       {'loss': 0.7529, 'grad_norm': 1.2138227224349976, 'learning_rate': 5.224528749251747e-07, 'epoch': 0.8}
 80%|███████▉  | 2319/2906 [7:37:30<1:54:21, 11.69s/it] 80%|███████▉  | 2320/2906 [7:37:42<1:52:46, 11.55s/it]                                                       {'loss': 0.7384, 'grad_norm': 1.3286030292510986, 'learning_rate': 5.207417122218785e-07, 'epoch': 0.8}
 80%|███████▉  | 2320/2906 [7:37:42<1:52:46, 11.55s/it] 80%|███████▉  | 2321/2906 [7:37:53<1:53:33, 11.65s/it]                                                       {'loss': 0.7611, 'grad_norm': 1.348026990890503, 'learning_rate': 5.190330305190081e-07, 'epoch': 0.8}
 80%|███████▉  | 2321/2906 [7:37:53<1:53:33, 11.65s/it] 80%|███████▉  | 2322/2906 [7:38:05<1:52:59, 11.61s/it]                                                       {'loss': 0.8003, 'grad_norm': 1.3054401874542236, 'learning_rate': 5.173268319583965e-07, 'epoch': 0.8}
 80%|███████▉  | 2322/2906 [7:38:05<1:52:59, 11.61s/it] 80%|███████▉  | 2323/2906 [7:38:17<1:53:53, 11.72s/it]                                                       {'loss': 0.8272, 'grad_norm': 1.3986915349960327, 'learning_rate': 5.156231186787633e-07, 'epoch': 0.8}
 80%|███████▉  | 2323/2906 [7:38:17<1:53:53, 11.72s/it] 80%|███████▉  | 2324/2906 [7:38:28<1:52:02, 11.55s/it]                                                       {'loss': 0.7836, 'grad_norm': 1.3794887065887451, 'learning_rate': 5.139218928157125e-07, 'epoch': 0.8}
 80%|███████▉  | 2324/2906 [7:38:28<1:52:02, 11.55s/it] 80%|████████  | 2325/2906 [7:38:40<1:51:48, 11.55s/it]                                                       {'loss': 0.7834, 'grad_norm': 1.4469012022018433, 'learning_rate': 5.122231565017321e-07, 'epoch': 0.8}
 80%|████████  | 2325/2906 [7:38:40<1:51:48, 11.55s/it] 80%|████████  | 2326/2906 [7:38:51<1:52:27, 11.63s/it]                                                       {'loss': 0.7567, 'grad_norm': 1.3177781105041504, 'learning_rate': 5.10526911866187e-07, 'epoch': 0.8}
 80%|████████  | 2326/2906 [7:38:51<1:52:27, 11.63s/it] 80%|████████  | 2327/2906 [7:39:03<1:53:22, 11.75s/it]                                                       {'loss': 0.8309, 'grad_norm': 1.333823800086975, 'learning_rate': 5.088331610353209e-07, 'epoch': 0.8}
 80%|████████  | 2327/2906 [7:39:03<1:53:22, 11.75s/it] 80%|████████  | 2328/2906 [7:39:15<1:51:48, 11.61s/it]                                                       {'loss': 0.8825, 'grad_norm': 1.4328211545944214, 'learning_rate': 5.071419061322508e-07, 'epoch': 0.8}
 80%|████████  | 2328/2906 [7:39:15<1:51:48, 11.61s/it] 80%|████████  | 2329/2906 [7:39:27<1:52:08, 11.66s/it]                                                       {'loss': 0.7941, 'grad_norm': 1.2526342868804932, 'learning_rate': 5.054531492769637e-07, 'epoch': 0.8}
 80%|████████  | 2329/2906 [7:39:27<1:52:08, 11.66s/it] 80%|████████  | 2330/2906 [7:39:38<1:51:47, 11.65s/it]                                                       {'loss': 0.7914, 'grad_norm': 1.2653133869171143, 'learning_rate': 5.037668925863179e-07, 'epoch': 0.8}
 80%|████████  | 2330/2906 [7:39:38<1:51:47, 11.65s/it] 80%|████████  | 2331/2906 [7:39:50<1:52:10, 11.71s/it]                                                       {'loss': 0.8344, 'grad_norm': 1.2496213912963867, 'learning_rate': 5.020831381740348e-07, 'epoch': 0.8}
 80%|████████  | 2331/2906 [7:39:50<1:52:10, 11.71s/it] 80%|████████  | 2332/2906 [7:40:02<1:52:21, 11.75s/it]                                                       {'loss': 0.8383, 'grad_norm': 1.2547892332077026, 'learning_rate': 5.004018881507016e-07, 'epoch': 0.8}
 80%|████████  | 2332/2906 [7:40:02<1:52:21, 11.75s/it] 80%|████████  | 2333/2906 [7:40:13<1:51:49, 11.71s/it]                                                       {'loss': 0.84, 'grad_norm': 1.2444548606872559, 'learning_rate': 4.987231446237656e-07, 'epoch': 0.8}
 80%|████████  | 2333/2906 [7:40:13<1:51:49, 11.71s/it] 80%|████████  | 2334/2906 [7:40:25<1:50:12, 11.56s/it]                                                       {'loss': 0.8331, 'grad_norm': 1.3536767959594727, 'learning_rate': 4.970469096975311e-07, 'epoch': 0.8}
 80%|████████  | 2334/2906 [7:40:25<1:50:12, 11.56s/it] 80%|████████  | 2335/2906 [7:40:37<1:52:10, 11.79s/it]                                                       {'loss': 0.7796, 'grad_norm': 1.257598876953125, 'learning_rate': 4.953731854731591e-07, 'epoch': 0.8}
 80%|████████  | 2335/2906 [7:40:37<1:52:10, 11.79s/it] 80%|████████  | 2336/2906 [7:40:49<1:51:18, 11.72s/it]                                                       {'loss': 0.79, 'grad_norm': 1.3837134838104248, 'learning_rate': 4.937019740486637e-07, 'epoch': 0.8}
 80%|████████  | 2336/2906 [7:40:49<1:51:18, 11.72s/it] 80%|████████  | 2337/2906 [7:41:00<1:50:10, 11.62s/it]                                                       {'loss': 0.8264, 'grad_norm': 1.2511487007141113, 'learning_rate': 4.920332775189074e-07, 'epoch': 0.8}
 80%|████████  | 2337/2906 [7:41:00<1:50:10, 11.62s/it] 80%|████████  | 2338/2906 [7:41:12<1:50:06, 11.63s/it]                                                       {'loss': 0.7294, 'grad_norm': 1.3451008796691895, 'learning_rate': 4.903670979756026e-07, 'epoch': 0.8}
 80%|████████  | 2338/2906 [7:41:12<1:50:06, 11.63s/it] 80%|████████  | 2339/2906 [7:41:23<1:49:50, 11.62s/it]                                                       {'loss': 0.781, 'grad_norm': 1.3083699941635132, 'learning_rate': 4.887034375073041e-07, 'epoch': 0.8}
 80%|████████  | 2339/2906 [7:41:23<1:49:50, 11.62s/it] 81%|████████  | 2340/2906 [7:41:35<1:49:25, 11.60s/it]                                                       {'loss': 0.8069, 'grad_norm': 1.3866140842437744, 'learning_rate': 4.870422981994113e-07, 'epoch': 0.81}
 81%|████████  | 2340/2906 [7:41:35<1:49:25, 11.60s/it] 81%|████████  | 2341/2906 [7:41:47<1:50:03, 11.69s/it]                                                       {'loss': 0.8175, 'grad_norm': 1.343627691268921, 'learning_rate': 4.853836821341632e-07, 'epoch': 0.81}
 81%|████████  | 2341/2906 [7:41:47<1:50:03, 11.69s/it] 81%|████████  | 2342/2906 [7:41:58<1:49:19, 11.63s/it]                                                       {'loss': 0.8638, 'grad_norm': 1.3038902282714844, 'learning_rate': 4.837275913906336e-07, 'epoch': 0.81}
 81%|████████  | 2342/2906 [7:41:58<1:49:19, 11.63s/it] 81%|████████  | 2343/2906 [7:42:10<1:50:08, 11.74s/it]                                                       {'loss': 0.7925, 'grad_norm': 1.3247642517089844, 'learning_rate': 4.820740280447331e-07, 'epoch': 0.81}
 81%|████████  | 2343/2906 [7:42:10<1:50:08, 11.74s/it] 81%|████████  | 2344/2906 [7:42:22<1:50:01, 11.75s/it]                                                       {'loss': 0.8611, 'grad_norm': 1.3968193531036377, 'learning_rate': 4.804229941692049e-07, 'epoch': 0.81}
 81%|████████  | 2344/2906 [7:42:22<1:50:01, 11.75s/it] 81%|████████  | 2345/2906 [7:42:34<1:50:08, 11.78s/it]                                                       {'loss': 0.7759, 'grad_norm': 1.373037338256836, 'learning_rate': 4.787744918336173e-07, 'epoch': 0.81}
 81%|████████  | 2345/2906 [7:42:34<1:50:08, 11.78s/it] 81%|████████  | 2346/2906 [7:42:46<1:50:23, 11.83s/it]                                                       {'loss': 0.7793, 'grad_norm': 1.2319772243499756, 'learning_rate': 4.771285231043696e-07, 'epoch': 0.81}
 81%|████████  | 2346/2906 [7:42:46<1:50:23, 11.83s/it] 81%|████████  | 2347/2906 [7:42:57<1:48:49, 11.68s/it]                                                       {'loss': 0.854, 'grad_norm': 1.292364478111267, 'learning_rate': 4.7548509004468444e-07, 'epoch': 0.81}
 81%|████████  | 2347/2906 [7:42:57<1:48:49, 11.68s/it] 81%|████████  | 2348/2906 [7:43:09<1:48:52, 11.71s/it]                                                       {'loss': 0.7596, 'grad_norm': 1.2651362419128418, 'learning_rate': 4.738441947146039e-07, 'epoch': 0.81}
 81%|████████  | 2348/2906 [7:43:09<1:48:52, 11.71s/it] 81%|████████  | 2349/2906 [7:43:20<1:48:07, 11.65s/it]                                                       {'loss': 0.8154, 'grad_norm': 1.3658545017242432, 'learning_rate': 4.7220583917099135e-07, 'epoch': 0.81}
 81%|████████  | 2349/2906 [7:43:20<1:48:07, 11.65s/it] 81%|████████  | 2350/2906 [7:43:32<1:47:45, 11.63s/it]                                                       {'loss': 0.728, 'grad_norm': 1.3149949312210083, 'learning_rate': 4.7057002546752497e-07, 'epoch': 0.81}
 81%|████████  | 2350/2906 [7:43:32<1:47:45, 11.63s/it] 81%|████████  | 2351/2906 [7:43:43<1:47:31, 11.62s/it]                                                       {'loss': 0.8233, 'grad_norm': 1.3120917081832886, 'learning_rate': 4.6893675565469754e-07, 'epoch': 0.81}
 81%|████████  | 2351/2906 [7:43:44<1:47:31, 11.62s/it] 81%|████████  | 2352/2906 [7:43:55<1:47:30, 11.64s/it]                                                       {'loss': 0.7213, 'grad_norm': 1.2286344766616821, 'learning_rate': 4.673060317798139e-07, 'epoch': 0.81}
 81%|████████  | 2352/2906 [7:43:55<1:47:30, 11.64s/it] 81%|████████  | 2353/2906 [7:44:07<1:47:53, 11.71s/it]                                                       {'loss': 0.8402, 'grad_norm': 1.3067638874053955, 'learning_rate': 4.656778558869848e-07, 'epoch': 0.81}
 81%|████████  | 2353/2906 [7:44:07<1:47:53, 11.71s/it] 81%|████████  | 2354/2906 [7:44:19<1:47:23, 11.67s/it]                                                       {'loss': 0.7936, 'grad_norm': 1.2432814836502075, 'learning_rate': 4.640522300171299e-07, 'epoch': 0.81}
 81%|████████  | 2354/2906 [7:44:19<1:47:23, 11.67s/it] 81%|████████  | 2355/2906 [7:44:30<1:47:05, 11.66s/it]                                                       {'loss': 0.7853, 'grad_norm': 1.2916615009307861, 'learning_rate': 4.624291562079719e-07, 'epoch': 0.81}
 81%|████████  | 2355/2906 [7:44:30<1:47:05, 11.66s/it] 81%|████████  | 2356/2906 [7:44:42<1:47:35, 11.74s/it]                                                       {'loss': 0.7295, 'grad_norm': 1.3140432834625244, 'learning_rate': 4.608086364940326e-07, 'epoch': 0.81}
 81%|████████  | 2356/2906 [7:44:42<1:47:35, 11.74s/it] 81%|████████  | 2357/2906 [7:44:54<1:47:12, 11.72s/it]                                                       {'loss': 0.7832, 'grad_norm': 1.261980414390564, 'learning_rate': 4.5919067290663503e-07, 'epoch': 0.81}
 81%|████████  | 2357/2906 [7:44:54<1:47:12, 11.72s/it] 81%|████████  | 2358/2906 [7:45:06<1:47:07, 11.73s/it]                                                       {'loss': 0.809, 'grad_norm': 1.3693736791610718, 'learning_rate': 4.5757526747389506e-07, 'epoch': 0.81}
 81%|████████  | 2358/2906 [7:45:06<1:47:07, 11.73s/it] 81%|████████  | 2359/2906 [7:45:17<1:47:03, 11.74s/it]                                                       {'loss': 0.7544, 'grad_norm': 1.333553433418274, 'learning_rate': 4.5596242222072457e-07, 'epoch': 0.81}
 81%|████████  | 2359/2906 [7:45:17<1:47:03, 11.74s/it] 81%|████████  | 2360/2906 [7:45:29<1:45:44, 11.62s/it]                                                       {'loss': 0.7527, 'grad_norm': 1.2811897993087769, 'learning_rate': 4.543521391688255e-07, 'epoch': 0.81}
 81%|████████  | 2360/2906 [7:45:29<1:45:44, 11.62s/it] 81%|████████  | 2361/2906 [7:45:41<1:46:23, 11.71s/it]                                                       {'loss': 0.8005, 'grad_norm': 1.3244057893753052, 'learning_rate': 4.527444203366868e-07, 'epoch': 0.81}
 81%|████████  | 2361/2906 [7:45:41<1:46:23, 11.71s/it] 81%|████████▏ | 2362/2906 [7:45:53<1:46:41, 11.77s/it]                                                       {'loss': 0.7589, 'grad_norm': 1.3061612844467163, 'learning_rate': 4.5113926773958485e-07, 'epoch': 0.81}
 81%|████████▏ | 2362/2906 [7:45:53<1:46:41, 11.77s/it] 81%|████████▏ | 2363/2906 [7:46:04<1:45:48, 11.69s/it]                                                       {'loss': 0.7716, 'grad_norm': 1.2583307027816772, 'learning_rate': 4.4953668338957896e-07, 'epoch': 0.81}
 81%|████████▏ | 2363/2906 [7:46:04<1:45:48, 11.69s/it] 81%|████████▏ | 2364/2906 [7:46:16<1:46:09, 11.75s/it]                                                       {'loss': 0.8043, 'grad_norm': 1.3639540672302246, 'learning_rate': 4.479366692955076e-07, 'epoch': 0.81}
 81%|████████▏ | 2364/2906 [7:46:16<1:46:09, 11.75s/it] 81%|████████▏ | 2365/2906 [7:46:28<1:45:55, 11.75s/it]                                                       {'loss': 0.767, 'grad_norm': 1.305328607559204, 'learning_rate': 4.4633922746298965e-07, 'epoch': 0.81}
 81%|████████▏ | 2365/2906 [7:46:28<1:45:55, 11.75s/it] 81%|████████▏ | 2366/2906 [7:46:39<1:44:30, 11.61s/it]                                                       {'loss': 0.7418, 'grad_norm': 1.3292096853256226, 'learning_rate': 4.447443598944179e-07, 'epoch': 0.81}
 81%|████████▏ | 2366/2906 [7:46:39<1:44:30, 11.61s/it] 81%|████████▏ | 2367/2906 [7:46:51<1:44:14, 11.60s/it]                                                       {'loss': 0.8153, 'grad_norm': 1.3448712825775146, 'learning_rate': 4.431520685889587e-07, 'epoch': 0.81}
 81%|████████▏ | 2367/2906 [7:46:51<1:44:14, 11.60s/it] 81%|████████▏ | 2368/2906 [7:47:03<1:46:44, 11.90s/it]                                                       {'loss': 0.766, 'grad_norm': 1.2552478313446045, 'learning_rate': 4.415623555425505e-07, 'epoch': 0.81}
 81%|████████▏ | 2368/2906 [7:47:03<1:46:44, 11.90s/it] 82%|████████▏ | 2369/2906 [7:47:15<1:45:17, 11.76s/it]                                                       {'loss': 0.7797, 'grad_norm': 1.266106367111206, 'learning_rate': 4.3997522274789735e-07, 'epoch': 0.82}
 82%|████████▏ | 2369/2906 [7:47:15<1:45:17, 11.76s/it] 82%|████████▏ | 2370/2906 [7:47:26<1:44:47, 11.73s/it]                                                       {'loss': 0.7704, 'grad_norm': 1.351051926612854, 'learning_rate': 4.3839067219447114e-07, 'epoch': 0.82}
 82%|████████▏ | 2370/2906 [7:47:26<1:44:47, 11.73s/it] 82%|████████▏ | 2371/2906 [7:47:38<1:44:48, 11.75s/it]                                                       {'loss': 0.7925, 'grad_norm': 1.3761898279190063, 'learning_rate': 4.3680870586850636e-07, 'epoch': 0.82}
 82%|████████▏ | 2371/2906 [7:47:38<1:44:48, 11.75s/it] 82%|████████▏ | 2372/2906 [7:47:50<1:44:21, 11.73s/it]                                                       {'loss': 0.8513, 'grad_norm': 1.3666690587997437, 'learning_rate': 4.3522932575299715e-07, 'epoch': 0.82}
 82%|████████▏ | 2372/2906 [7:47:50<1:44:21, 11.73s/it] 82%|████████▏ | 2373/2906 [7:48:01<1:44:01, 11.71s/it]                                                       {'loss': 0.7265, 'grad_norm': 1.3645042181015015, 'learning_rate': 4.33652533827697e-07, 'epoch': 0.82}
 82%|████████▏ | 2373/2906 [7:48:01<1:44:01, 11.71s/it] 82%|████████▏ | 2374/2906 [7:48:13<1:44:20, 11.77s/it]                                                       {'loss': 0.7671, 'grad_norm': 1.3182398080825806, 'learning_rate': 4.320783320691152e-07, 'epoch': 0.82}
 82%|████████▏ | 2374/2906 [7:48:13<1:44:20, 11.77s/it] 82%|████████▏ | 2375/2906 [7:48:25<1:43:53, 11.74s/it]                                                       {'loss': 0.8338, 'grad_norm': 1.3768059015274048, 'learning_rate': 4.30506722450513e-07, 'epoch': 0.82}
 82%|████████▏ | 2375/2906 [7:48:25<1:43:53, 11.74s/it] 82%|████████▏ | 2376/2906 [7:48:37<1:43:33, 11.72s/it]                                                       {'loss': 0.7837, 'grad_norm': 1.4070053100585938, 'learning_rate': 4.289377069419037e-07, 'epoch': 0.82}
 82%|████████▏ | 2376/2906 [7:48:37<1:43:33, 11.72s/it] 82%|████████▏ | 2377/2906 [7:48:48<1:42:43, 11.65s/it]                                                       {'loss': 0.8122, 'grad_norm': 1.3977662324905396, 'learning_rate': 4.2737128751004804e-07, 'epoch': 0.82}
 82%|████████▏ | 2377/2906 [7:48:48<1:42:43, 11.65s/it] 82%|████████▏ | 2378/2906 [7:49:00<1:43:00, 11.71s/it]                                                       {'loss': 0.7937, 'grad_norm': 1.263159990310669, 'learning_rate': 4.2580746611845273e-07, 'epoch': 0.82}
 82%|████████▏ | 2378/2906 [7:49:00<1:43:00, 11.71s/it] 82%|████████▏ | 2379/2906 [7:49:12<1:43:33, 11.79s/it]                                                       {'loss': 0.8371, 'grad_norm': 1.399747610092163, 'learning_rate': 4.2424624472736904e-07, 'epoch': 0.82}
 82%|████████▏ | 2379/2906 [7:49:12<1:43:33, 11.79s/it] 82%|████████▏ | 2380/2906 [7:49:24<1:42:42, 11.72s/it]                                                       {'loss': 0.8325, 'grad_norm': 1.2783070802688599, 'learning_rate': 4.226876252937867e-07, 'epoch': 0.82}
 82%|████████▏ | 2380/2906 [7:49:24<1:42:42, 11.72s/it] 82%|████████▏ | 2381/2906 [7:49:36<1:43:35, 11.84s/it]                                                       {'loss': 0.8376, 'grad_norm': 1.301356554031372, 'learning_rate': 4.21131609771436e-07, 'epoch': 0.82}
 82%|████████▏ | 2381/2906 [7:49:36<1:43:35, 11.84s/it] 82%|████████▏ | 2382/2906 [7:49:48<1:43:48, 11.89s/it]                                                       {'loss': 0.7711, 'grad_norm': 1.5986661911010742, 'learning_rate': 4.1957820011078316e-07, 'epoch': 0.82}
 82%|████████▏ | 2382/2906 [7:49:48<1:43:48, 11.89s/it] 82%|████████▏ | 2383/2906 [7:49:59<1:43:18, 11.85s/it]                                                       {'loss': 0.8593, 'grad_norm': 1.3197766542434692, 'learning_rate': 4.1802739825902604e-07, 'epoch': 0.82}
 82%|████████▏ | 2383/2906 [7:49:59<1:43:18, 11.85s/it] 82%|████████▏ | 2384/2906 [7:50:11<1:42:27, 11.78s/it]                                                       {'loss': 0.7932, 'grad_norm': 1.377413272857666, 'learning_rate': 4.164792061600964e-07, 'epoch': 0.82}
 82%|████████▏ | 2384/2906 [7:50:11<1:42:27, 11.78s/it] 82%|████████▏ | 2385/2906 [7:50:22<1:41:25, 11.68s/it]                                                       {'loss': 0.7296, 'grad_norm': 1.2660958766937256, 'learning_rate': 4.149336257546513e-07, 'epoch': 0.82}
 82%|████████▏ | 2385/2906 [7:50:22<1:41:25, 11.68s/it] 82%|████████▏ | 2386/2906 [7:50:34<1:40:17, 11.57s/it]                                                       {'loss': 0.794, 'grad_norm': 1.3603984117507935, 'learning_rate': 4.133906589800771e-07, 'epoch': 0.82}
 82%|████████▏ | 2386/2906 [7:50:34<1:40:17, 11.57s/it] 82%|████████▏ | 2387/2906 [7:50:46<1:40:44, 11.65s/it]                                                       {'loss': 0.8119, 'grad_norm': 1.277937412261963, 'learning_rate': 4.1185030777048385e-07, 'epoch': 0.82}
 82%|████████▏ | 2387/2906 [7:50:46<1:40:44, 11.65s/it] 82%|████████▏ | 2388/2906 [7:50:57<1:38:59, 11.47s/it]                                                       {'loss': 0.8429, 'grad_norm': 1.298084020614624, 'learning_rate': 4.103125740566993e-07, 'epoch': 0.82}
 82%|████████▏ | 2388/2906 [7:50:57<1:38:59, 11.47s/it] 82%|████████▏ | 2389/2906 [7:51:08<1:37:32, 11.32s/it]                                                       {'loss': 0.774, 'grad_norm': 1.275890588760376, 'learning_rate': 4.0877745976627416e-07, 'epoch': 0.82}
 82%|████████▏ | 2389/2906 [7:51:08<1:37:32, 11.32s/it] 82%|████████▏ | 2390/2906 [7:51:19<1:38:34, 11.46s/it]                                                       {'loss': 0.767, 'grad_norm': 1.2532895803451538, 'learning_rate': 4.0724496682347484e-07, 'epoch': 0.82}
 82%|████████▏ | 2390/2906 [7:51:19<1:38:34, 11.46s/it] 82%|████████▏ | 2391/2906 [7:51:31<1:39:24, 11.58s/it]                                                       {'loss': 0.7969, 'grad_norm': 1.366442084312439, 'learning_rate': 4.0571509714928015e-07, 'epoch': 0.82}
 82%|████████▏ | 2391/2906 [7:51:31<1:39:24, 11.58s/it] 82%|████████▏ | 2392/2906 [7:51:43<1:39:27, 11.61s/it]                                                       {'loss': 0.7958, 'grad_norm': 1.3060532808303833, 'learning_rate': 4.0418785266138266e-07, 'epoch': 0.82}
 82%|████████▏ | 2392/2906 [7:51:43<1:39:27, 11.61s/it] 82%|████████▏ | 2393/2906 [7:51:54<1:38:59, 11.58s/it]                                                       {'loss': 0.7916, 'grad_norm': 1.3400310277938843, 'learning_rate': 4.0266323527418384e-07, 'epoch': 0.82}
 82%|████████▏ | 2393/2906 [7:51:54<1:38:59, 11.58s/it] 82%|████████▏ | 2394/2906 [7:52:06<1:38:54, 11.59s/it]                                                       {'loss': 0.8216, 'grad_norm': 1.3883821964263916, 'learning_rate': 4.011412468987905e-07, 'epoch': 0.82}
 82%|████████▏ | 2394/2906 [7:52:06<1:38:54, 11.59s/it] 82%|████████▏ | 2395/2906 [7:52:18<1:38:57, 11.62s/it]                                                       {'loss': 0.8073, 'grad_norm': 1.3444489240646362, 'learning_rate': 3.996218894430165e-07, 'epoch': 0.82}
 82%|████████▏ | 2395/2906 [7:52:18<1:38:57, 11.62s/it] 82%|████████▏ | 2396/2906 [7:52:29<1:38:23, 11.58s/it]                                                       {'loss': 0.7197, 'grad_norm': 1.4063218832015991, 'learning_rate': 3.981051648113754e-07, 'epoch': 0.82}
 82%|████████▏ | 2396/2906 [7:52:29<1:38:23, 11.58s/it] 82%|████████▏ | 2397/2906 [7:52:40<1:37:23, 11.48s/it]                                                       {'loss': 0.7784, 'grad_norm': 1.2625483274459839, 'learning_rate': 3.965910749050822e-07, 'epoch': 0.82}
 82%|████████▏ | 2397/2906 [7:52:41<1:37:23, 11.48s/it] 83%|████████▎ | 2398/2906 [7:52:52<1:36:59, 11.46s/it]                                                       {'loss': 0.6927, 'grad_norm': 1.4031662940979004, 'learning_rate': 3.9507962162204926e-07, 'epoch': 0.83}
 83%|████████▎ | 2398/2906 [7:52:52<1:36:59, 11.46s/it] 83%|████████▎ | 2399/2906 [7:53:03<1:35:45, 11.33s/it]                                                       {'loss': 0.7897, 'grad_norm': 1.289746642112732, 'learning_rate': 3.935708068568822e-07, 'epoch': 0.83}
 83%|████████▎ | 2399/2906 [7:53:03<1:35:45, 11.33s/it] 83%|████████▎ | 2400/2906 [7:53:15<1:37:04, 11.51s/it]                                                       {'loss': 0.7316, 'grad_norm': 1.2732678651809692, 'learning_rate': 3.920646325008809e-07, 'epoch': 0.83}
 83%|████████▎ | 2400/2906 [7:53:15<1:37:04, 11.51s/it][INFO|trainer.py:3984] 2025-08-21 20:15:43,579 >> Saving model checkpoint to /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400
[INFO|configuration_utils.py:419] 2025-08-21 20:15:43,584 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/config.json
[INFO|configuration_utils.py:911] 2025-08-21 20:15:43,584 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/generation_config.json
[INFO|modeling_utils.py:3580] 2025-08-21 20:16:10,506 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-08-21 20:16:10,508 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 20:16:10,508 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/special_tokens_map.json
[2025-08-21 20:16:11,353] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step2400 is about to be saved!
[2025-08-21 20:16:11,591] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/global_step2400/mp_rank_00_model_states.pt
[2025-08-21 20:16:11,591] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/global_step2400/mp_rank_00_model_states.pt...
[2025-08-21 20:16:43,120] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/global_step2400/mp_rank_00_model_states.pt.
[2025-08-21 20:16:43,195] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/global_step2400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-21 20:17:38,843] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/global_step2400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-21 20:17:38,843] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/global_step2400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-21 20:17:38,844] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2400 is ready now!
[INFO|image_processing_base.py:260] 2025-08-21 20:17:39,552 >> Image processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/preprocessor_config.json
[INFO|tokenization_utils_base.py:2510] 2025-08-21 20:17:39,553 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 20:17:39,553 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/special_tokens_map.json
[INFO|processing_utils.py:648] 2025-08-21 20:17:39,696 >> chat template saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/chat_template.json
[INFO|processing_utils.py:654] 2025-08-21 20:17:39,800 >> processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2400/processor_config.json
/opt/conda/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 83%|████████▎ | 2401/2906 [7:55:31<6:50:25, 48.76s/it]                                                       {'loss': 0.8527, 'grad_norm': 1.3538095951080322, 'learning_rate': 3.9056110044203594e-07, 'epoch': 0.83}
 83%|████████▎ | 2401/2906 [7:55:31<6:50:25, 48.76s/it] 83%|████████▎ | 2402/2906 [7:55:42<5:15:52, 37.60s/it]                                                       {'loss': 0.8164, 'grad_norm': 1.3578962087631226, 'learning_rate': 3.8906021256502364e-07, 'epoch': 0.83}
 83%|████████▎ | 2402/2906 [7:55:42<5:15:52, 37.60s/it] 83%|████████▎ | 2403/2906 [7:55:54<4:09:59, 29.82s/it]                                                       {'loss': 0.8224, 'grad_norm': 1.335453987121582, 'learning_rate': 3.875619707512082e-07, 'epoch': 0.83}
 83%|████████▎ | 2403/2906 [7:55:54<4:09:59, 29.82s/it] 83%|████████▎ | 2404/2906 [7:56:05<3:23:39, 24.34s/it]                                                       {'loss': 0.7384, 'grad_norm': 1.2051844596862793, 'learning_rate': 3.8606637687863437e-07, 'epoch': 0.83}
 83%|████████▎ | 2404/2906 [7:56:05<3:23:39, 24.34s/it] 83%|████████▎ | 2405/2906 [7:56:17<2:51:47, 20.57s/it]                                                       {'loss': 0.8264, 'grad_norm': 1.338531732559204, 'learning_rate': 3.845734328220302e-07, 'epoch': 0.83}
 83%|████████▎ | 2405/2906 [7:56:17<2:51:47, 20.57s/it] 83%|████████▎ | 2406/2906 [7:56:29<2:30:00, 18.00s/it]                                                       {'loss': 0.8386, 'grad_norm': 1.2650055885314941, 'learning_rate': 3.830831404528018e-07, 'epoch': 0.83}
 83%|████████▎ | 2406/2906 [7:56:29<2:30:00, 18.00s/it] 83%|████████▎ | 2407/2906 [7:56:41<2:14:07, 16.13s/it]                                                       {'loss': 0.7514, 'grad_norm': 1.2943822145462036, 'learning_rate': 3.8159550163902936e-07, 'epoch': 0.83}
 83%|████████▎ | 2407/2906 [7:56:41<2:14:07, 16.13s/it] 83%|████████▎ | 2408/2906 [7:56:53<2:03:18, 14.86s/it]                                                       {'loss': 0.7837, 'grad_norm': 1.2786011695861816, 'learning_rate': 3.8011051824546925e-07, 'epoch': 0.83}
 83%|████████▎ | 2408/2906 [7:56:53<2:03:18, 14.86s/it] 83%|████████▎ | 2409/2906 [7:57:04<1:55:03, 13.89s/it]                                                       {'loss': 0.8235, 'grad_norm': 1.3416976928710938, 'learning_rate': 3.786281921335483e-07, 'epoch': 0.83}
 83%|████████▎ | 2409/2906 [7:57:04<1:55:03, 13.89s/it] 83%|████████▎ | 2410/2906 [7:57:16<1:49:38, 13.26s/it]                                                       {'loss': 0.8053, 'grad_norm': 1.2841386795043945, 'learning_rate': 3.771485251613613e-07, 'epoch': 0.83}
 83%|████████▎ | 2410/2906 [7:57:16<1:49:38, 13.26s/it] 83%|████████▎ | 2411/2906 [7:57:28<1:45:22, 12.77s/it]                                                       {'loss': 0.8383, 'grad_norm': 1.3643112182617188, 'learning_rate': 3.7567151918367156e-07, 'epoch': 0.83}
 83%|████████▎ | 2411/2906 [7:57:28<1:45:22, 12.77s/it] 83%|████████▎ | 2412/2906 [7:57:39<1:41:45, 12.36s/it]                                                       {'loss': 0.8696, 'grad_norm': 1.3374104499816895, 'learning_rate': 3.7419717605190695e-07, 'epoch': 0.83}
 83%|████████▎ | 2412/2906 [7:57:39<1:41:45, 12.36s/it] 83%|████████▎ | 2413/2906 [7:57:51<1:39:46, 12.14s/it]                                                       {'loss': 0.7292, 'grad_norm': 1.3143352270126343, 'learning_rate': 3.727254976141556e-07, 'epoch': 0.83}
 83%|████████▎ | 2413/2906 [7:57:51<1:39:46, 12.14s/it] 83%|████████▎ | 2414/2906 [7:58:03<1:38:38, 12.03s/it]                                                       {'loss': 0.7465, 'grad_norm': 1.3661774396896362, 'learning_rate': 3.7125648571516766e-07, 'epoch': 0.83}
 83%|████████▎ | 2414/2906 [7:58:03<1:38:38, 12.03s/it] 83%|████████▎ | 2415/2906 [7:58:14<1:37:07, 11.87s/it]                                                       {'loss': 0.7402, 'grad_norm': 1.2656667232513428, 'learning_rate': 3.697901421963482e-07, 'epoch': 0.83}
 83%|████████▎ | 2415/2906 [7:58:14<1:37:07, 11.87s/it] 83%|████████▎ | 2416/2906 [7:58:26<1:36:55, 11.87s/it]                                                       {'loss': 0.744, 'grad_norm': 1.2233695983886719, 'learning_rate': 3.6832646889575996e-07, 'epoch': 0.83}
 83%|████████▎ | 2416/2906 [7:58:26<1:36:55, 11.87s/it] 83%|████████▎ | 2417/2906 [7:58:37<1:34:31, 11.60s/it]                                                       {'loss': 0.8017, 'grad_norm': 1.280946135520935, 'learning_rate': 3.6686546764811787e-07, 'epoch': 0.83}
 83%|████████▎ | 2417/2906 [7:58:37<1:34:31, 11.60s/it] 83%|████████▎ | 2418/2906 [7:58:49<1:34:31, 11.62s/it]                                                       {'loss': 0.8132, 'grad_norm': 1.3941036462783813, 'learning_rate': 3.654071402847861e-07, 'epoch': 0.83}
 83%|████████▎ | 2418/2906 [7:58:49<1:34:31, 11.62s/it] 83%|████████▎ | 2419/2906 [7:59:00<1:34:24, 11.63s/it]                                                       {'loss': 0.805, 'grad_norm': 1.2912770509719849, 'learning_rate': 3.639514886337786e-07, 'epoch': 0.83}
 83%|████████▎ | 2419/2906 [7:59:00<1:34:24, 11.63s/it] 83%|████████▎ | 2420/2906 [7:59:12<1:34:26, 11.66s/it]                                                       {'loss': 0.8101, 'grad_norm': 1.3991295099258423, 'learning_rate': 3.6249851451975517e-07, 'epoch': 0.83}
 83%|████████▎ | 2420/2906 [7:59:12<1:34:26, 11.66s/it] 83%|████████▎ | 2421/2906 [7:59:23<1:33:47, 11.60s/it]                                                       {'loss': 0.7722, 'grad_norm': 1.3531088829040527, 'learning_rate': 3.6104821976401834e-07, 'epoch': 0.83}
 83%|████████▎ | 2421/2906 [7:59:23<1:33:47, 11.60s/it] 83%|████████▎ | 2422/2906 [7:59:35<1:34:22, 11.70s/it]                                                       {'loss': 0.7857, 'grad_norm': 1.2834110260009766, 'learning_rate': 3.5960060618451336e-07, 'epoch': 0.83}
 83%|████████▎ | 2422/2906 [7:59:35<1:34:22, 11.70s/it] 83%|████████▎ | 2423/2906 [7:59:47<1:34:41, 11.76s/it]                                                       {'loss': 0.7817, 'grad_norm': 1.2819045782089233, 'learning_rate': 3.581556755958232e-07, 'epoch': 0.83}
 83%|████████▎ | 2423/2906 [7:59:47<1:34:41, 11.76s/it] 83%|████████▎ | 2424/2906 [7:59:59<1:33:32, 11.64s/it]                                                       {'loss': 0.7528, 'grad_norm': 1.280246615409851, 'learning_rate': 3.56713429809169e-07, 'epoch': 0.83}
 83%|████████▎ | 2424/2906 [7:59:59<1:33:32, 11.64s/it] 83%|████████▎ | 2425/2906 [8:00:11<1:34:11, 11.75s/it]                                                       {'loss': 0.7841, 'grad_norm': 1.2514967918395996, 'learning_rate': 3.552738706324063e-07, 'epoch': 0.83}
 83%|████████▎ | 2425/2906 [8:00:11<1:34:11, 11.75s/it] 83%|████████▎ | 2426/2906 [8:00:23<1:34:28, 11.81s/it]                                                       {'loss': 0.7841, 'grad_norm': 1.232959508895874, 'learning_rate': 3.538369998700217e-07, 'epoch': 0.83}
 83%|████████▎ | 2426/2906 [8:00:23<1:34:28, 11.81s/it] 84%|████████▎ | 2427/2906 [8:00:35<1:34:30, 11.84s/it]                                                       {'loss': 0.7982, 'grad_norm': 1.328678011894226, 'learning_rate': 3.524028193231338e-07, 'epoch': 0.84}
 84%|████████▎ | 2427/2906 [8:00:35<1:34:30, 11.84s/it] 84%|████████▎ | 2428/2906 [8:00:46<1:33:15, 11.71s/it]                                                       {'loss': 0.7989, 'grad_norm': 1.3280702829360962, 'learning_rate': 3.5097133078948715e-07, 'epoch': 0.84}
 84%|████████▎ | 2428/2906 [8:00:46<1:33:15, 11.71s/it] 84%|████████▎ | 2429/2906 [8:00:57<1:32:43, 11.66s/it]                                                       {'loss': 0.7969, 'grad_norm': 1.3410968780517578, 'learning_rate': 3.4954253606345386e-07, 'epoch': 0.84}
 84%|████████▎ | 2429/2906 [8:00:58<1:32:43, 11.66s/it] 84%|████████▎ | 2430/2906 [8:01:09<1:32:24, 11.65s/it]                                                       {'loss': 0.8125, 'grad_norm': 1.2767019271850586, 'learning_rate': 3.481164369360268e-07, 'epoch': 0.84}
 84%|████████▎ | 2430/2906 [8:01:09<1:32:24, 11.65s/it] 84%|████████▎ | 2431/2906 [8:01:21<1:32:06, 11.63s/it]                                                       {'loss': 0.7449, 'grad_norm': 1.3102847337722778, 'learning_rate': 3.466930351948225e-07, 'epoch': 0.84}
 84%|████████▎ | 2431/2906 [8:01:21<1:32:06, 11.63s/it] 84%|████████▎ | 2432/2906 [8:01:32<1:32:08, 11.66s/it]                                                       {'loss': 0.7069, 'grad_norm': 1.373872995376587, 'learning_rate': 3.4527233262407424e-07, 'epoch': 0.84}
 84%|████████▎ | 2432/2906 [8:01:32<1:32:08, 11.66s/it] 84%|████████▎ | 2433/2906 [8:01:44<1:32:04, 11.68s/it]                                                       {'loss': 0.773, 'grad_norm': 1.301164984703064, 'learning_rate': 3.438543310046341e-07, 'epoch': 0.84}
 84%|████████▎ | 2433/2906 [8:01:44<1:32:04, 11.68s/it] 84%|████████▍ | 2434/2906 [8:01:56<1:31:58, 11.69s/it]                                                       {'loss': 0.77, 'grad_norm': 1.2466522455215454, 'learning_rate': 3.424390321139656e-07, 'epoch': 0.84}
 84%|████████▍ | 2434/2906 [8:01:56<1:31:58, 11.69s/it] 84%|████████▍ | 2435/2906 [8:02:08<1:31:52, 11.70s/it]                                                       {'loss': 0.7866, 'grad_norm': 1.2522637844085693, 'learning_rate': 3.4102643772614713e-07, 'epoch': 0.84}
 84%|████████▍ | 2435/2906 [8:02:08<1:31:52, 11.70s/it] 84%|████████▍ | 2436/2906 [8:02:20<1:32:34, 11.82s/it]                                                       {'loss': 0.8096, 'grad_norm': 1.2224957942962646, 'learning_rate': 3.3961654961186584e-07, 'epoch': 0.84}
 84%|████████▍ | 2436/2906 [8:02:20<1:32:34, 11.82s/it] 84%|████████▍ | 2437/2906 [8:02:31<1:31:59, 11.77s/it]                                                       {'loss': 0.8228, 'grad_norm': 1.282362937927246, 'learning_rate': 3.3820936953841585e-07, 'epoch': 0.84}
 84%|████████▍ | 2437/2906 [8:02:31<1:31:59, 11.77s/it] 84%|████████▍ | 2438/2906 [8:02:43<1:32:04, 11.80s/it]                                                       {'loss': 0.8541, 'grad_norm': 1.4218506813049316, 'learning_rate': 3.368048992696982e-07, 'epoch': 0.84}
 84%|████████▍ | 2438/2906 [8:02:43<1:32:04, 11.80s/it] 84%|████████▍ | 2439/2906 [8:02:54<1:30:18, 11.60s/it]                                                       {'loss': 0.7102, 'grad_norm': 1.2430473566055298, 'learning_rate': 3.354031405662167e-07, 'epoch': 0.84}
 84%|████████▍ | 2439/2906 [8:02:54<1:30:18, 11.60s/it] 84%|████████▍ | 2440/2906 [8:03:06<1:29:19, 11.50s/it]                                                       {'loss': 0.7265, 'grad_norm': 1.3113837242126465, 'learning_rate': 3.340040951850751e-07, 'epoch': 0.84}
 84%|████████▍ | 2440/2906 [8:03:06<1:29:19, 11.50s/it] 84%|████████▍ | 2441/2906 [8:03:18<1:30:06, 11.63s/it]                                                       {'loss': 0.7434, 'grad_norm': 1.2841787338256836, 'learning_rate': 3.3260776487997803e-07, 'epoch': 0.84}
 84%|████████▍ | 2441/2906 [8:03:18<1:30:06, 11.63s/it] 84%|████████▍ | 2442/2906 [8:03:29<1:30:03, 11.64s/it]                                                       {'loss': 0.7873, 'grad_norm': 1.301063060760498, 'learning_rate': 3.312141514012243e-07, 'epoch': 0.84}
 84%|████████▍ | 2442/2906 [8:03:29<1:30:03, 11.64s/it] 84%|████████▍ | 2443/2906 [8:03:41<1:30:25, 11.72s/it]                                                       {'loss': 0.8016, 'grad_norm': 1.295282006263733, 'learning_rate': 3.2982325649570907e-07, 'epoch': 0.84}
 84%|████████▍ | 2443/2906 [8:03:41<1:30:25, 11.72s/it] 84%|████████▍ | 2444/2906 [8:03:53<1:31:07, 11.83s/it]                                                       {'loss': 0.829, 'grad_norm': 1.3757246732711792, 'learning_rate': 3.2843508190692013e-07, 'epoch': 0.84}
 84%|████████▍ | 2444/2906 [8:03:53<1:31:07, 11.83s/it] 84%|████████▍ | 2445/2906 [8:04:06<1:32:11, 12.00s/it]                                                       {'loss': 0.729, 'grad_norm': 1.2211995124816895, 'learning_rate': 3.2704962937493314e-07, 'epoch': 0.84}
 84%|████████▍ | 2445/2906 [8:04:06<1:32:11, 12.00s/it] 84%|████████▍ | 2446/2906 [8:04:17<1:30:59, 11.87s/it]                                                       {'loss': 0.7997, 'grad_norm': 1.2487744092941284, 'learning_rate': 3.256669006364138e-07, 'epoch': 0.84}
 84%|████████▍ | 2446/2906 [8:04:17<1:30:59, 11.87s/it] 84%|████████▍ | 2447/2906 [8:04:29<1:30:42, 11.86s/it]                                                       {'loss': 0.7369, 'grad_norm': 1.1957875490188599, 'learning_rate': 3.2428689742461187e-07, 'epoch': 0.84}
 84%|████████▍ | 2447/2906 [8:04:29<1:30:42, 11.86s/it] 84%|████████▍ | 2448/2906 [8:04:40<1:29:28, 11.72s/it]                                                       {'loss': 0.7717, 'grad_norm': 1.2724597454071045, 'learning_rate': 3.229096214693622e-07, 'epoch': 0.84}
 84%|████████▍ | 2448/2906 [8:04:40<1:29:28, 11.72s/it] 84%|████████▍ | 2449/2906 [8:04:52<1:28:32, 11.63s/it]                                                       {'loss': 0.8552, 'grad_norm': 1.5007617473602295, 'learning_rate': 3.215350744970808e-07, 'epoch': 0.84}
 84%|████████▍ | 2449/2906 [8:04:52<1:28:32, 11.63s/it] 84%|████████▍ | 2450/2906 [8:05:03<1:28:09, 11.60s/it]                                                       {'loss': 0.6898, 'grad_norm': 1.2620978355407715, 'learning_rate': 3.201632582307615e-07, 'epoch': 0.84}
 84%|████████▍ | 2450/2906 [8:05:03<1:28:09, 11.60s/it] 84%|████████▍ | 2451/2906 [8:05:15<1:27:41, 11.56s/it]                                                       {'loss': 0.8198, 'grad_norm': 1.3717752695083618, 'learning_rate': 3.1879417438997583e-07, 'epoch': 0.84}
 84%|████████▍ | 2451/2906 [8:05:15<1:27:41, 11.56s/it] 84%|████████▍ | 2452/2906 [8:05:26<1:27:31, 11.57s/it]                                                       {'loss': 0.7663, 'grad_norm': 1.3095030784606934, 'learning_rate': 3.174278246908713e-07, 'epoch': 0.84}
 84%|████████▍ | 2452/2906 [8:05:26<1:27:31, 11.57s/it] 84%|████████▍ | 2453/2906 [8:05:38<1:27:17, 11.56s/it]                                                       {'loss': 0.77, 'grad_norm': 1.2972071170806885, 'learning_rate': 3.16064210846167e-07, 'epoch': 0.84}
 84%|████████▍ | 2453/2906 [8:05:38<1:27:17, 11.56s/it] 84%|████████▍ | 2454/2906 [8:05:50<1:28:01, 11.68s/it]                                                       {'loss': 0.7728, 'grad_norm': 1.5304752588272095, 'learning_rate': 3.147033345651526e-07, 'epoch': 0.84}
 84%|████████▍ | 2454/2906 [8:05:50<1:28:01, 11.68s/it] 84%|████████▍ | 2455/2906 [8:06:01<1:27:33, 11.65s/it]                                                       {'loss': 0.7069, 'grad_norm': 1.2195075750350952, 'learning_rate': 3.1334519755368805e-07, 'epoch': 0.84}
 84%|████████▍ | 2455/2906 [8:06:02<1:27:33, 11.65s/it] 85%|████████▍ | 2456/2906 [8:06:13<1:27:40, 11.69s/it]                                                       {'loss': 0.7616, 'grad_norm': 1.3591660261154175, 'learning_rate': 3.1198980151419643e-07, 'epoch': 0.85}
 85%|████████▍ | 2456/2906 [8:06:13<1:27:40, 11.69s/it] 85%|████████▍ | 2457/2906 [8:06:25<1:27:18, 11.67s/it]                                                       {'loss': 0.8211, 'grad_norm': 1.3945008516311646, 'learning_rate': 3.106371481456677e-07, 'epoch': 0.85}
 85%|████████▍ | 2457/2906 [8:06:25<1:27:18, 11.67s/it] 85%|████████▍ | 2458/2906 [8:06:37<1:27:08, 11.67s/it]                                                       {'loss': 0.8009, 'grad_norm': 1.4213060140609741, 'learning_rate': 3.0928723914365353e-07, 'epoch': 0.85}
 85%|████████▍ | 2458/2906 [8:06:37<1:27:08, 11.67s/it] 85%|████████▍ | 2459/2906 [8:06:48<1:25:59, 11.54s/it]                                                       {'loss': 0.8631, 'grad_norm': 1.3866835832595825, 'learning_rate': 3.079400762002635e-07, 'epoch': 0.85}
 85%|████████▍ | 2459/2906 [8:06:48<1:25:59, 11.54s/it] 85%|████████▍ | 2460/2906 [8:06:59<1:26:02, 11.57s/it]                                                       {'loss': 0.8211, 'grad_norm': 1.4031085968017578, 'learning_rate': 3.0659566100416813e-07, 'epoch': 0.85}
 85%|████████▍ | 2460/2906 [8:06:59<1:26:02, 11.57s/it] 85%|████████▍ | 2461/2906 [8:07:11<1:25:34, 11.54s/it]                                                       {'loss': 0.8123, 'grad_norm': 1.352189540863037, 'learning_rate': 3.0525399524059055e-07, 'epoch': 0.85}
 85%|████████▍ | 2461/2906 [8:07:11<1:25:34, 11.54s/it] 85%|████████▍ | 2462/2906 [8:07:23<1:25:59, 11.62s/it]                                                       {'loss': 0.7028, 'grad_norm': 1.2433725595474243, 'learning_rate': 3.039150805913094e-07, 'epoch': 0.85}
 85%|████████▍ | 2462/2906 [8:07:23<1:25:59, 11.62s/it] 85%|████████▍ | 2463/2906 [8:07:34<1:25:56, 11.64s/it]                                                       {'loss': 0.8031, 'grad_norm': 1.254488229751587, 'learning_rate': 3.025789187346548e-07, 'epoch': 0.85}
 85%|████████▍ | 2463/2906 [8:07:34<1:25:56, 11.64s/it] 85%|████████▍ | 2464/2906 [8:07:46<1:26:05, 11.69s/it]                                                       {'loss': 0.7975, 'grad_norm': 1.3990447521209717, 'learning_rate': 3.0124551134550484e-07, 'epoch': 0.85}
 85%|████████▍ | 2464/2906 [8:07:46<1:26:05, 11.69s/it] 85%|████████▍ | 2465/2906 [8:07:58<1:25:27, 11.63s/it]                                                       {'loss': 0.7933, 'grad_norm': 1.2737832069396973, 'learning_rate': 2.9991486009528696e-07, 'epoch': 0.85}
 85%|████████▍ | 2465/2906 [8:07:58<1:25:27, 11.63s/it] 85%|████████▍ | 2466/2906 [8:08:09<1:24:28, 11.52s/it]                                                       {'loss': 0.7529, 'grad_norm': 1.2581194639205933, 'learning_rate': 2.985869666519714e-07, 'epoch': 0.85}
 85%|████████▍ | 2466/2906 [8:08:09<1:24:28, 11.52s/it] 85%|████████▍ | 2467/2906 [8:08:21<1:25:00, 11.62s/it]                                                       {'loss': 0.8292, 'grad_norm': 1.278666377067566, 'learning_rate': 2.9726183268007304e-07, 'epoch': 0.85}
 85%|████████▍ | 2467/2906 [8:08:21<1:25:00, 11.62s/it] 85%|████████▍ | 2468/2906 [8:08:33<1:25:28, 11.71s/it]                                                       {'loss': 0.7749, 'grad_norm': 1.3467904329299927, 'learning_rate': 2.959394598406484e-07, 'epoch': 0.85}
 85%|████████▍ | 2468/2906 [8:08:33<1:25:28, 11.71s/it] 85%|████████▍ | 2469/2906 [8:08:44<1:24:09, 11.55s/it]                                                       {'loss': 0.7974, 'grad_norm': 1.338388204574585, 'learning_rate': 2.9461984979129056e-07, 'epoch': 0.85}
 85%|████████▍ | 2469/2906 [8:08:44<1:24:09, 11.55s/it] 85%|████████▍ | 2470/2906 [8:08:56<1:25:32, 11.77s/it]                                                       {'loss': 0.7966, 'grad_norm': 1.225915789604187, 'learning_rate': 2.933030041861312e-07, 'epoch': 0.85}
 85%|████████▍ | 2470/2906 [8:08:56<1:25:32, 11.77s/it] 85%|████████▌ | 2471/2906 [8:09:08<1:25:12, 11.75s/it]                                                       {'loss': 0.8309, 'grad_norm': 1.3381743431091309, 'learning_rate': 2.919889246758373e-07, 'epoch': 0.85}
 85%|████████▌ | 2471/2906 [8:09:08<1:25:12, 11.75s/it] 85%|████████▌ | 2472/2906 [8:09:19<1:24:18, 11.66s/it]                                                       {'loss': 0.792, 'grad_norm': 1.3047425746917725, 'learning_rate': 2.9067761290760695e-07, 'epoch': 0.85}
 85%|████████▌ | 2472/2906 [8:09:19<1:24:18, 11.66s/it] 85%|████████▌ | 2473/2906 [8:09:32<1:26:06, 11.93s/it]                                                       {'loss': 0.7676, 'grad_norm': 1.3185304403305054, 'learning_rate': 2.8936907052516923e-07, 'epoch': 0.85}
 85%|████████▌ | 2473/2906 [8:09:32<1:26:06, 11.93s/it] 85%|████████▌ | 2474/2906 [8:09:44<1:25:59, 11.94s/it]                                                       {'loss': 0.7976, 'grad_norm': 1.246144413948059, 'learning_rate': 2.880632991687826e-07, 'epoch': 0.85}
 85%|████████▌ | 2474/2906 [8:09:44<1:25:59, 11.94s/it] 85%|████████▌ | 2475/2906 [8:09:55<1:24:19, 11.74s/it]                                                       {'loss': 0.8483, 'grad_norm': 1.322935938835144, 'learning_rate': 2.8676030047523115e-07, 'epoch': 0.85}
 85%|████████▌ | 2475/2906 [8:09:55<1:24:19, 11.74s/it] 85%|████████▌ | 2476/2906 [8:10:07<1:23:40, 11.68s/it]                                                       {'loss': 0.7491, 'grad_norm': 1.31247079372406, 'learning_rate': 2.854600760778245e-07, 'epoch': 0.85}
 85%|████████▌ | 2476/2906 [8:10:07<1:23:40, 11.68s/it] 85%|████████▌ | 2477/2906 [8:10:19<1:24:48, 11.86s/it]                                                       {'loss': 0.7917, 'grad_norm': 1.3661541938781738, 'learning_rate': 2.841626276063933e-07, 'epoch': 0.85}
 85%|████████▌ | 2477/2906 [8:10:19<1:24:48, 11.86s/it] 85%|████████▌ | 2478/2906 [8:10:30<1:22:44, 11.60s/it]                                                       {'loss': 0.8558, 'grad_norm': 1.3424443006515503, 'learning_rate': 2.8286795668728967e-07, 'epoch': 0.85}
 85%|████████▌ | 2478/2906 [8:10:30<1:22:44, 11.60s/it] 85%|████████▌ | 2479/2906 [8:10:41<1:22:05, 11.53s/it]                                                       {'loss': 0.7782, 'grad_norm': 1.464162826538086, 'learning_rate': 2.815760649433841e-07, 'epoch': 0.85}
 85%|████████▌ | 2479/2906 [8:10:41<1:22:05, 11.53s/it] 85%|████████▌ | 2480/2906 [8:10:52<1:20:14, 11.30s/it]                                                       {'loss': 0.8672, 'grad_norm': 1.3154611587524414, 'learning_rate': 2.80286953994062e-07, 'epoch': 0.85}
 85%|████████▌ | 2480/2906 [8:10:52<1:20:14, 11.30s/it] 85%|████████▌ | 2481/2906 [8:11:03<1:20:13, 11.33s/it]                                                       {'loss': 0.79, 'grad_norm': 1.3061907291412354, 'learning_rate': 2.7900062545522493e-07, 'epoch': 0.85}
 85%|████████▌ | 2481/2906 [8:11:04<1:20:13, 11.33s/it] 85%|████████▌ | 2482/2906 [8:11:15<1:21:09, 11.48s/it]                                                       {'loss': 0.7901, 'grad_norm': 1.3202545642852783, 'learning_rate': 2.77717080939286e-07, 'epoch': 0.85}
 85%|████████▌ | 2482/2906 [8:11:15<1:21:09, 11.48s/it] 85%|████████▌ | 2483/2906 [8:11:27<1:22:07, 11.65s/it]                                                       {'loss': 0.7971, 'grad_norm': 1.314153790473938, 'learning_rate': 2.764363220551672e-07, 'epoch': 0.85}
 85%|████████▌ | 2483/2906 [8:11:27<1:22:07, 11.65s/it] 85%|████████▌ | 2484/2906 [8:11:39<1:21:27, 11.58s/it]                                                       {'loss': 0.7615, 'grad_norm': 1.4765528440475464, 'learning_rate': 2.7515835040830136e-07, 'epoch': 0.85}
 85%|████████▌ | 2484/2906 [8:11:39<1:21:27, 11.58s/it] 86%|████████▌ | 2485/2906 [8:11:50<1:21:20, 11.59s/it]                                                       {'loss': 0.8463, 'grad_norm': 1.356862187385559, 'learning_rate': 2.7388316760062457e-07, 'epoch': 0.86}
 86%|████████▌ | 2485/2906 [8:11:50<1:21:20, 11.59s/it] 86%|████████▌ | 2486/2906 [8:12:02<1:20:37, 11.52s/it]                                                       {'loss': 0.7894, 'grad_norm': 1.3349066972732544, 'learning_rate': 2.7261077523057927e-07, 'epoch': 0.86}
 86%|████████▌ | 2486/2906 [8:12:02<1:20:37, 11.52s/it] 86%|████████▌ | 2487/2906 [8:12:14<1:21:05, 11.61s/it]                                                       {'loss': 0.7919, 'grad_norm': 1.35750412940979, 'learning_rate': 2.7134117489311023e-07, 'epoch': 0.86}
 86%|████████▌ | 2487/2906 [8:12:14<1:21:05, 11.61s/it] 86%|████████▌ | 2488/2906 [8:12:25<1:20:21, 11.53s/it]                                                       {'loss': 0.7634, 'grad_norm': 1.370363712310791, 'learning_rate': 2.7007436817966e-07, 'epoch': 0.86}
 86%|████████▌ | 2488/2906 [8:12:25<1:20:21, 11.53s/it] 86%|████████▌ | 2489/2906 [8:12:36<1:19:18, 11.41s/it]                                                       {'loss': 0.8115, 'grad_norm': 1.2955690622329712, 'learning_rate': 2.688103566781719e-07, 'epoch': 0.86}
 86%|████████▌ | 2489/2906 [8:12:36<1:19:18, 11.41s/it] 86%|████████▌ | 2490/2906 [8:12:47<1:18:44, 11.36s/it]                                                       {'loss': 0.8482, 'grad_norm': 1.4071236848831177, 'learning_rate': 2.675491419730847e-07, 'epoch': 0.86}
 86%|████████▌ | 2490/2906 [8:12:47<1:18:44, 11.36s/it] 86%|████████▌ | 2491/2906 [8:12:59<1:19:23, 11.48s/it]                                                       {'loss': 0.8563, 'grad_norm': 1.3265937566757202, 'learning_rate': 2.6629072564533007e-07, 'epoch': 0.86}
 86%|████████▌ | 2491/2906 [8:12:59<1:19:23, 11.48s/it] 86%|████████▌ | 2492/2906 [8:13:11<1:19:20, 11.50s/it]                                                       {'loss': 0.7329, 'grad_norm': 1.310890555381775, 'learning_rate': 2.650351092723341e-07, 'epoch': 0.86}
 86%|████████▌ | 2492/2906 [8:13:11<1:19:20, 11.50s/it] 86%|████████▌ | 2493/2906 [8:13:22<1:18:55, 11.47s/it]                                                       {'loss': 0.8158, 'grad_norm': 1.367763638496399, 'learning_rate': 2.6378229442801163e-07, 'epoch': 0.86}
 86%|████████▌ | 2493/2906 [8:13:22<1:18:55, 11.47s/it] 86%|████████▌ | 2494/2906 [8:13:33<1:18:17, 11.40s/it]                                                       {'loss': 0.7625, 'grad_norm': 1.29862380027771, 'learning_rate': 2.6253228268276533e-07, 'epoch': 0.86}
 86%|████████▌ | 2494/2906 [8:13:33<1:18:17, 11.40s/it] 86%|████████▌ | 2495/2906 [8:13:45<1:17:59, 11.39s/it]                                                       {'loss': 0.7918, 'grad_norm': 1.269731044769287, 'learning_rate': 2.6128507560348626e-07, 'epoch': 0.86}
 86%|████████▌ | 2495/2906 [8:13:45<1:17:59, 11.39s/it] 86%|████████▌ | 2496/2906 [8:13:56<1:17:32, 11.35s/it]                                                       {'loss': 0.8138, 'grad_norm': 1.4118343591690063, 'learning_rate': 2.600406747535478e-07, 'epoch': 0.86}
 86%|████████▌ | 2496/2906 [8:13:56<1:17:32, 11.35s/it] 86%|████████▌ | 2497/2906 [8:14:08<1:19:41, 11.69s/it]                                                       {'loss': 0.8058, 'grad_norm': 1.3280322551727295, 'learning_rate': 2.5879908169280653e-07, 'epoch': 0.86}
 86%|████████▌ | 2497/2906 [8:14:08<1:19:41, 11.69s/it] 86%|████████▌ | 2498/2906 [8:14:20<1:19:29, 11.69s/it]                                                       {'loss': 0.7579, 'grad_norm': 1.28616464138031, 'learning_rate': 2.575602979776001e-07, 'epoch': 0.86}
 86%|████████▌ | 2498/2906 [8:14:20<1:19:29, 11.69s/it] 86%|████████▌ | 2499/2906 [8:14:32<1:19:22, 11.70s/it]                                                       {'loss': 0.8133, 'grad_norm': 1.440464735031128, 'learning_rate': 2.563243251607433e-07, 'epoch': 0.86}
 86%|████████▌ | 2499/2906 [8:14:32<1:19:22, 11.70s/it] 86%|████████▌ | 2500/2906 [8:14:43<1:19:01, 11.68s/it]                                                       {'loss': 0.807, 'grad_norm': 1.288794755935669, 'learning_rate': 2.5509116479152855e-07, 'epoch': 0.86}
 86%|████████▌ | 2500/2906 [8:14:43<1:19:01, 11.68s/it] 86%|████████▌ | 2501/2906 [8:14:55<1:19:40, 11.80s/it]                                                       {'loss': 0.8253, 'grad_norm': 1.323678731918335, 'learning_rate': 2.538608184157229e-07, 'epoch': 0.86}
 86%|████████▌ | 2501/2906 [8:14:55<1:19:40, 11.80s/it] 86%|████████▌ | 2502/2906 [8:15:07<1:19:06, 11.75s/it]                                                       {'loss': 0.8189, 'grad_norm': 1.3637138605117798, 'learning_rate': 2.5263328757556436e-07, 'epoch': 0.86}
 86%|████████▌ | 2502/2906 [8:15:07<1:19:06, 11.75s/it] 86%|████████▌ | 2503/2906 [8:15:19<1:19:51, 11.89s/it]                                                       {'loss': 0.8247, 'grad_norm': 1.3061429262161255, 'learning_rate': 2.5140857380976436e-07, 'epoch': 0.86}
 86%|████████▌ | 2503/2906 [8:15:19<1:19:51, 11.89s/it] 86%|████████▌ | 2504/2906 [8:15:31<1:19:15, 11.83s/it]                                                       {'loss': 0.7523, 'grad_norm': 1.2919723987579346, 'learning_rate': 2.5018667865350065e-07, 'epoch': 0.86}
 86%|████████▌ | 2504/2906 [8:15:31<1:19:15, 11.83s/it] 86%|████████▌ | 2505/2906 [8:15:43<1:19:08, 11.84s/it]                                                       {'loss': 0.7294, 'grad_norm': 1.267279028892517, 'learning_rate': 2.489676036384192e-07, 'epoch': 0.86}
 86%|████████▌ | 2505/2906 [8:15:43<1:19:08, 11.84s/it] 86%|████████▌ | 2506/2906 [8:15:54<1:18:12, 11.73s/it]                                                       {'loss': 0.8208, 'grad_norm': 1.3543049097061157, 'learning_rate': 2.47751350292631e-07, 'epoch': 0.86}
 86%|████████▌ | 2506/2906 [8:15:54<1:18:12, 11.73s/it] 86%|████████▋ | 2507/2906 [8:16:06<1:18:17, 11.77s/it]                                                       {'loss': 0.8141, 'grad_norm': 1.2482314109802246, 'learning_rate': 2.4653792014070923e-07, 'epoch': 0.86}
 86%|████████▋ | 2507/2906 [8:16:06<1:18:17, 11.77s/it] 86%|████████▋ | 2508/2906 [8:16:18<1:17:26, 11.68s/it]                                                       {'loss': 0.7966, 'grad_norm': 1.392385482788086, 'learning_rate': 2.4532731470368886e-07, 'epoch': 0.86}
 86%|████████▋ | 2508/2906 [8:16:18<1:17:26, 11.68s/it] 86%|████████▋ | 2509/2906 [8:16:30<1:18:04, 11.80s/it]                                                       {'loss': 0.7927, 'grad_norm': 1.250133752822876, 'learning_rate': 2.441195354990644e-07, 'epoch': 0.86}
 86%|████████▋ | 2509/2906 [8:16:30<1:18:04, 11.80s/it] 86%|████████▋ | 2510/2906 [8:16:42<1:17:55, 11.81s/it]                                                       {'loss': 0.8292, 'grad_norm': 1.3508892059326172, 'learning_rate': 2.429145840407865e-07, 'epoch': 0.86}
 86%|████████▋ | 2510/2906 [8:16:42<1:17:55, 11.81s/it] 86%|████████▋ | 2511/2906 [8:16:53<1:17:55, 11.84s/it]                                                       {'loss': 0.8006, 'grad_norm': 1.3385207653045654, 'learning_rate': 2.4171246183926247e-07, 'epoch': 0.86}
 86%|████████▋ | 2511/2906 [8:16:54<1:17:55, 11.84s/it] 86%|████████▋ | 2512/2906 [8:17:06<1:18:09, 11.90s/it]                                                       {'loss': 0.8873, 'grad_norm': 1.3691020011901855, 'learning_rate': 2.405131704013516e-07, 'epoch': 0.86}
 86%|████████▋ | 2512/2906 [8:17:06<1:18:09, 11.90s/it] 86%|████████▋ | 2513/2906 [8:17:17<1:16:56, 11.75s/it]                                                       {'loss': 0.8152, 'grad_norm': 1.3488852977752686, 'learning_rate': 2.393167112303668e-07, 'epoch': 0.86}
 86%|████████▋ | 2513/2906 [8:17:17<1:16:56, 11.75s/it] 87%|████████▋ | 2514/2906 [8:17:29<1:16:30, 11.71s/it]                                                       {'loss': 0.8426, 'grad_norm': 1.3746252059936523, 'learning_rate': 2.3812308582607024e-07, 'epoch': 0.87}
 87%|████████▋ | 2514/2906 [8:17:29<1:16:30, 11.71s/it] 87%|████████▋ | 2515/2906 [8:17:40<1:16:04, 11.67s/it]                                                       {'loss': 0.7923, 'grad_norm': 1.3776507377624512, 'learning_rate': 2.3693229568466952e-07, 'epoch': 0.87}
 87%|████████▋ | 2515/2906 [8:17:40<1:16:04, 11.67s/it] 87%|████████▋ | 2516/2906 [8:17:52<1:15:48, 11.66s/it]                                                       {'loss': 0.8474, 'grad_norm': 1.3663653135299683, 'learning_rate': 2.357443422988215e-07, 'epoch': 0.87}
 87%|████████▋ | 2516/2906 [8:17:52<1:15:48, 11.66s/it] 87%|████████▋ | 2517/2906 [8:18:04<1:16:30, 11.80s/it]                                                       {'loss': 0.7807, 'grad_norm': 1.2318012714385986, 'learning_rate': 2.345592271576261e-07, 'epoch': 0.87}
 87%|████████▋ | 2517/2906 [8:18:04<1:16:30, 11.80s/it] 87%|████████▋ | 2518/2906 [8:18:16<1:16:54, 11.89s/it]                                                       {'loss': 0.7764, 'grad_norm': 1.2442348003387451, 'learning_rate': 2.3337695174662417e-07, 'epoch': 0.87}
 87%|████████▋ | 2518/2906 [8:18:16<1:16:54, 11.89s/it] 87%|████████▋ | 2519/2906 [8:18:28<1:16:06, 11.80s/it]                                                       {'loss': 0.7716, 'grad_norm': 1.319360375404358, 'learning_rate': 2.3219751754779862e-07, 'epoch': 0.87}
 87%|████████▋ | 2519/2906 [8:18:28<1:16:06, 11.80s/it] 87%|████████▋ | 2520/2906 [8:18:39<1:15:57, 11.81s/it]                                                       {'loss': 0.8404, 'grad_norm': 1.33284330368042, 'learning_rate': 2.3102092603957098e-07, 'epoch': 0.87}
 87%|████████▋ | 2520/2906 [8:18:39<1:15:57, 11.81s/it] 87%|████████▋ | 2521/2906 [8:18:51<1:15:57, 11.84s/it]                                                       {'loss': 0.7552, 'grad_norm': 1.2953200340270996, 'learning_rate': 2.2984717869679762e-07, 'epoch': 0.87}
 87%|████████▋ | 2521/2906 [8:18:51<1:15:57, 11.84s/it] 87%|████████▋ | 2522/2906 [8:19:03<1:15:22, 11.78s/it]                                                       {'loss': 0.8155, 'grad_norm': 1.3264575004577637, 'learning_rate': 2.2867627699077216e-07, 'epoch': 0.87}
 87%|████████▋ | 2522/2906 [8:19:03<1:15:22, 11.78s/it] 87%|████████▋ | 2523/2906 [8:19:15<1:15:41, 11.86s/it]                                                       {'loss': 0.8148, 'grad_norm': 1.3569045066833496, 'learning_rate': 2.2750822238921861e-07, 'epoch': 0.87}
 87%|████████▋ | 2523/2906 [8:19:15<1:15:41, 11.86s/it] 87%|████████▋ | 2524/2906 [8:19:27<1:15:56, 11.93s/it]                                                       {'loss': 0.783, 'grad_norm': 1.2897975444793701, 'learning_rate': 2.2634301635629436e-07, 'epoch': 0.87}
 87%|████████▋ | 2524/2906 [8:19:27<1:15:56, 11.93s/it] 87%|████████▋ | 2525/2906 [8:19:39<1:16:11, 12.00s/it]                                                       {'loss': 0.7688, 'grad_norm': 1.3298747539520264, 'learning_rate': 2.251806603525855e-07, 'epoch': 0.87}
 87%|████████▋ | 2525/2906 [8:19:39<1:16:11, 12.00s/it] 87%|████████▋ | 2526/2906 [8:19:50<1:14:27, 11.76s/it]                                                       {'loss': 0.8061, 'grad_norm': 1.3739988803863525, 'learning_rate': 2.2402115583510437e-07, 'epoch': 0.87}
 87%|████████▋ | 2526/2906 [8:19:50<1:14:27, 11.76s/it] 87%|████████▋ | 2527/2906 [8:20:02<1:13:23, 11.62s/it]                                                       {'loss': 0.8402, 'grad_norm': 1.3681665658950806, 'learning_rate': 2.228645042572908e-07, 'epoch': 0.87}
 87%|████████▋ | 2527/2906 [8:20:02<1:13:23, 11.62s/it] 87%|████████▋ | 2528/2906 [8:20:14<1:13:42, 11.70s/it]                                                       {'loss': 0.7996, 'grad_norm': 1.270203948020935, 'learning_rate': 2.2171070706900776e-07, 'epoch': 0.87}
 87%|████████▋ | 2528/2906 [8:20:14<1:13:42, 11.70s/it] 87%|████████▋ | 2529/2906 [8:20:26<1:14:27, 11.85s/it]                                                       {'loss': 0.8425, 'grad_norm': 1.4778838157653809, 'learning_rate': 2.2055976571653953e-07, 'epoch': 0.87}
 87%|████████▋ | 2529/2906 [8:20:26<1:14:27, 11.85s/it] 87%|████████▋ | 2530/2906 [8:20:37<1:13:51, 11.79s/it]                                                       {'loss': 0.8228, 'grad_norm': 1.247273325920105, 'learning_rate': 2.1941168164259174e-07, 'epoch': 0.87}
 87%|████████▋ | 2530/2906 [8:20:38<1:13:51, 11.79s/it] 87%|████████▋ | 2531/2906 [8:20:49<1:13:15, 11.72s/it]                                                       {'loss': 0.8148, 'grad_norm': 1.4190174341201782, 'learning_rate': 2.1826645628628712e-07, 'epoch': 0.87}
 87%|████████▋ | 2531/2906 [8:20:49<1:13:15, 11.72s/it] 87%|████████▋ | 2532/2906 [8:21:01<1:12:55, 11.70s/it]                                                       {'loss': 0.7626, 'grad_norm': 1.295251727104187, 'learning_rate': 2.1712409108316624e-07, 'epoch': 0.87}
 87%|████████▋ | 2532/2906 [8:21:01<1:12:55, 11.70s/it] 87%|████████▋ | 2533/2906 [8:21:13<1:14:03, 11.91s/it]                                                       {'loss': 0.8075, 'grad_norm': 1.2537132501602173, 'learning_rate': 2.1598458746518448e-07, 'epoch': 0.87}
 87%|████████▋ | 2533/2906 [8:21:13<1:14:03, 11.91s/it] 87%|████████▋ | 2534/2906 [8:21:25<1:13:26, 11.84s/it]                                                       {'loss': 0.7762, 'grad_norm': 1.269911766052246, 'learning_rate': 2.148479468607087e-07, 'epoch': 0.87}
 87%|████████▋ | 2534/2906 [8:21:25<1:13:26, 11.84s/it] 87%|████████▋ | 2535/2906 [8:21:37<1:13:17, 11.85s/it]                                                       {'loss': 0.7622, 'grad_norm': 1.363318681716919, 'learning_rate': 2.1371417069451867e-07, 'epoch': 0.87}
 87%|████████▋ | 2535/2906 [8:21:37<1:13:17, 11.85s/it] 87%|████████▋ | 2536/2906 [8:21:48<1:12:41, 11.79s/it]                                                       {'loss': 0.8076, 'grad_norm': 1.278769612312317, 'learning_rate': 2.1258326038780308e-07, 'epoch': 0.87}
 87%|████████▋ | 2536/2906 [8:21:48<1:12:41, 11.79s/it] 87%|████████▋ | 2537/2906 [8:22:01<1:13:39, 11.98s/it]                                                       {'loss': 0.7458, 'grad_norm': 1.264525055885315, 'learning_rate': 2.1145521735815716e-07, 'epoch': 0.87}
 87%|████████▋ | 2537/2906 [8:22:01<1:13:39, 11.98s/it] 87%|████████▋ | 2538/2906 [8:22:13<1:13:13, 11.94s/it]                                                       {'loss': 0.7608, 'grad_norm': 1.2975436449050903, 'learning_rate': 2.1033004301958343e-07, 'epoch': 0.87}
 87%|████████▋ | 2538/2906 [8:22:13<1:13:13, 11.94s/it] 87%|████████▋ | 2539/2906 [8:22:24<1:12:04, 11.78s/it]                                                       {'loss': 0.8369, 'grad_norm': 1.317700982093811, 'learning_rate': 2.092077387824884e-07, 'epoch': 0.87}
 87%|████████▋ | 2539/2906 [8:22:24<1:12:04, 11.78s/it] 87%|████████▋ | 2540/2906 [8:22:36<1:11:30, 11.72s/it]                                                       {'loss': 0.8251, 'grad_norm': 1.4944339990615845, 'learning_rate': 2.0808830605368008e-07, 'epoch': 0.87}
 87%|████████▋ | 2540/2906 [8:22:36<1:11:30, 11.72s/it] 87%|████████▋ | 2541/2906 [8:22:47<1:11:35, 11.77s/it]                                                       {'loss': 0.7498, 'grad_norm': 1.2718069553375244, 'learning_rate': 2.0697174623636795e-07, 'epoch': 0.87}
 87%|████████▋ | 2541/2906 [8:22:47<1:11:35, 11.77s/it] 87%|████████▋ | 2542/2906 [8:23:00<1:12:10, 11.90s/it]                                                       {'loss': 0.8018, 'grad_norm': 1.3252924680709839, 'learning_rate': 2.0585806073015886e-07, 'epoch': 0.87}
 87%|████████▋ | 2542/2906 [8:23:00<1:12:10, 11.90s/it] 88%|████████▊ | 2543/2906 [8:23:12<1:12:13, 11.94s/it]                                                       {'loss': 0.7715, 'grad_norm': 1.2917524576187134, 'learning_rate': 2.0474725093105857e-07, 'epoch': 0.88}
 88%|████████▊ | 2543/2906 [8:23:12<1:12:13, 11.94s/it] 88%|████████▊ | 2544/2906 [8:23:24<1:12:24, 12.00s/it]                                                       {'loss': 0.7886, 'grad_norm': 1.3358863592147827, 'learning_rate': 2.0363931823146721e-07, 'epoch': 0.88}
 88%|████████▊ | 2544/2906 [8:23:24<1:12:24, 12.00s/it] 88%|████████▊ | 2545/2906 [8:23:35<1:11:33, 11.89s/it]                                                       {'loss': 0.7849, 'grad_norm': 1.2608965635299683, 'learning_rate': 2.025342640201783e-07, 'epoch': 0.88}
 88%|████████▊ | 2545/2906 [8:23:36<1:11:33, 11.89s/it] 88%|████████▊ | 2546/2906 [8:23:48<1:11:39, 11.94s/it]                                                       {'loss': 0.7649, 'grad_norm': 1.2920101881027222, 'learning_rate': 2.014320896823771e-07, 'epoch': 0.88}
 88%|████████▊ | 2546/2906 [8:23:48<1:11:39, 11.94s/it] 88%|████████▊ | 2547/2906 [8:24:00<1:11:33, 11.96s/it]                                                       {'loss': 0.8199, 'grad_norm': 1.2553132772445679, 'learning_rate': 2.003327965996399e-07, 'epoch': 0.88}
 88%|████████▊ | 2547/2906 [8:24:00<1:11:33, 11.96s/it] 88%|████████▊ | 2548/2906 [8:24:11<1:11:15, 11.94s/it]                                                       {'loss': 0.6958, 'grad_norm': 1.2974746227264404, 'learning_rate': 1.9923638614992996e-07, 'epoch': 0.88}
 88%|████████▊ | 2548/2906 [8:24:11<1:11:15, 11.94s/it] 88%|████████▊ | 2549/2906 [8:24:23<1:10:02, 11.77s/it]                                                       {'loss': 0.7915, 'grad_norm': 1.2618330717086792, 'learning_rate': 1.981428597075985e-07, 'epoch': 0.88}
 88%|████████▊ | 2549/2906 [8:24:23<1:10:02, 11.77s/it] 88%|████████▊ | 2550/2906 [8:24:34<1:09:39, 11.74s/it]                                                       {'loss': 0.7829, 'grad_norm': 1.4017945528030396, 'learning_rate': 1.9705221864338043e-07, 'epoch': 0.88}
 88%|████████▊ | 2550/2906 [8:24:35<1:09:39, 11.74s/it] 88%|████████▊ | 2551/2906 [8:24:46<1:08:53, 11.64s/it]                                                       {'loss': 0.7499, 'grad_norm': 1.3513658046722412, 'learning_rate': 1.9596446432439465e-07, 'epoch': 0.88}
 88%|████████▊ | 2551/2906 [8:24:46<1:08:53, 11.64s/it] 88%|████████▊ | 2552/2906 [8:24:58<1:09:41, 11.81s/it]                                                       {'loss': 0.8047, 'grad_norm': 1.3539072275161743, 'learning_rate': 1.9487959811414188e-07, 'epoch': 0.88}
 88%|████████▊ | 2552/2906 [8:24:58<1:09:41, 11.81s/it] 88%|████████▊ | 2553/2906 [8:25:10<1:09:55, 11.89s/it]                                                       {'loss': 0.7829, 'grad_norm': 1.271773099899292, 'learning_rate': 1.9379762137250069e-07, 'epoch': 0.88}
 88%|████████▊ | 2553/2906 [8:25:10<1:09:55, 11.89s/it] 88%|████████▊ | 2554/2906 [8:25:22<1:09:42, 11.88s/it]                                                       {'loss': 0.8104, 'grad_norm': 1.3644752502441406, 'learning_rate': 1.9271853545573038e-07, 'epoch': 0.88}
 88%|████████▊ | 2554/2906 [8:25:22<1:09:42, 11.88s/it] 88%|████████▊ | 2555/2906 [8:25:34<1:08:48, 11.76s/it]                                                       {'loss': 0.7709, 'grad_norm': 1.4350136518478394, 'learning_rate': 1.9164234171646423e-07, 'epoch': 0.88}
 88%|████████▊ | 2555/2906 [8:25:34<1:08:48, 11.76s/it] 88%|████████▊ | 2556/2906 [8:25:46<1:09:31, 11.92s/it]                                                       {'loss': 0.8512, 'grad_norm': 1.3358244895935059, 'learning_rate': 1.9056904150371176e-07, 'epoch': 0.88}
 88%|████████▊ | 2556/2906 [8:25:46<1:09:31, 11.92s/it] 88%|████████▊ | 2557/2906 [8:25:58<1:09:27, 11.94s/it]                                                       {'loss': 0.7372, 'grad_norm': 1.2392171621322632, 'learning_rate': 1.894986361628548e-07, 'epoch': 0.88}
 88%|████████▊ | 2557/2906 [8:25:58<1:09:27, 11.94s/it] 88%|████████▊ | 2558/2906 [8:26:10<1:09:50, 12.04s/it]                                                       {'loss': 0.839, 'grad_norm': 1.3148425817489624, 'learning_rate': 1.8843112703564676e-07, 'epoch': 0.88}
 88%|████████▊ | 2558/2906 [8:26:10<1:09:50, 12.04s/it] 88%|████████▊ | 2559/2906 [8:26:22<1:09:50, 12.07s/it]                                                       {'loss': 0.8141, 'grad_norm': 1.2636975049972534, 'learning_rate': 1.8736651546020946e-07, 'epoch': 0.88}
 88%|████████▊ | 2559/2906 [8:26:22<1:09:50, 12.07s/it] 88%|████████▊ | 2560/2906 [8:26:34<1:08:38, 11.90s/it]                                                       {'loss': 0.8406, 'grad_norm': 1.280871868133545, 'learning_rate': 1.8630480277103458e-07, 'epoch': 0.88}
 88%|████████▊ | 2560/2906 [8:26:34<1:08:38, 11.90s/it] 88%|████████▊ | 2561/2906 [8:26:46<1:08:12, 11.86s/it]                                                       {'loss': 0.7645, 'grad_norm': 1.265377402305603, 'learning_rate': 1.852459902989784e-07, 'epoch': 0.88}
 88%|████████▊ | 2561/2906 [8:26:46<1:08:12, 11.86s/it] 88%|████████▊ | 2562/2906 [8:26:57<1:07:47, 11.82s/it]                                                       {'loss': 0.718, 'grad_norm': 1.225532054901123, 'learning_rate': 1.8419007937126254e-07, 'epoch': 0.88}
 88%|████████▊ | 2562/2906 [8:26:57<1:07:47, 11.82s/it] 88%|████████▊ | 2563/2906 [8:27:09<1:07:04, 11.73s/it]                                                       {'loss': 0.7797, 'grad_norm': 1.2899593114852905, 'learning_rate': 1.8313707131147217e-07, 'epoch': 0.88}
 88%|████████▊ | 2563/2906 [8:27:09<1:07:04, 11.73s/it] 88%|████████▊ | 2564/2906 [8:27:21<1:07:00, 11.75s/it]                                                       {'loss': 0.7859, 'grad_norm': 1.3572068214416504, 'learning_rate': 1.8208696743955228e-07, 'epoch': 0.88}
 88%|████████▊ | 2564/2906 [8:27:21<1:07:00, 11.75s/it] 88%|████████▊ | 2565/2906 [8:27:33<1:08:09, 11.99s/it]                                                       {'loss': 0.8027, 'grad_norm': 1.3782024383544922, 'learning_rate': 1.8103976907180798e-07, 'epoch': 0.88}
 88%|████████▊ | 2565/2906 [8:27:33<1:08:09, 11.99s/it] 88%|████████▊ | 2566/2906 [8:27:45<1:07:45, 11.96s/it]                                                       {'loss': 0.8015, 'grad_norm': 1.342079758644104, 'learning_rate': 1.799954775209034e-07, 'epoch': 0.88}
 88%|████████▊ | 2566/2906 [8:27:45<1:07:45, 11.96s/it] 88%|████████▊ | 2567/2906 [8:27:57<1:07:07, 11.88s/it]                                                       {'loss': 0.8018, 'grad_norm': 1.3526915311813354, 'learning_rate': 1.789540940958573e-07, 'epoch': 0.88}
 88%|████████▊ | 2567/2906 [8:27:57<1:07:07, 11.88s/it] 88%|████████▊ | 2568/2906 [8:28:09<1:06:50, 11.86s/it]                                                       {'loss': 0.8116, 'grad_norm': 1.295949101448059, 'learning_rate': 1.7791562010204432e-07, 'epoch': 0.88}
 88%|████████▊ | 2568/2906 [8:28:09<1:06:50, 11.86s/it] 88%|████████▊ | 2569/2906 [8:28:20<1:06:20, 11.81s/it]                                                       {'loss': 0.8148, 'grad_norm': 1.2755043506622314, 'learning_rate': 1.768800568411913e-07, 'epoch': 0.88}
 88%|████████▊ | 2569/2906 [8:28:20<1:06:20, 11.81s/it] 88%|████████▊ | 2570/2906 [8:28:32<1:06:54, 11.95s/it]                                                       {'loss': 0.7751, 'grad_norm': 1.33543062210083, 'learning_rate': 1.758474056113768e-07, 'epoch': 0.88}
 88%|████████▊ | 2570/2906 [8:28:32<1:06:54, 11.95s/it] 88%|████████▊ | 2571/2906 [8:28:45<1:07:04, 12.01s/it]                                                       {'loss': 0.7977, 'grad_norm': 1.3830159902572632, 'learning_rate': 1.7481766770703013e-07, 'epoch': 0.88}
 88%|████████▊ | 2571/2906 [8:28:45<1:07:04, 12.01s/it] 89%|████████▊ | 2572/2906 [8:28:56<1:06:32, 11.95s/it]                                                       {'loss': 0.7457, 'grad_norm': 1.3805673122406006, 'learning_rate': 1.7379084441892679e-07, 'epoch': 0.89}
 89%|████████▊ | 2572/2906 [8:28:56<1:06:32, 11.95s/it] 89%|████████▊ | 2573/2906 [8:29:09<1:06:45, 12.03s/it]                                                       {'loss': 0.8966, 'grad_norm': 1.3630385398864746, 'learning_rate': 1.7276693703419058e-07, 'epoch': 0.89}
 89%|████████▊ | 2573/2906 [8:29:09<1:06:45, 12.03s/it] 89%|████████▊ | 2574/2906 [8:29:21<1:06:32, 12.02s/it]                                                       {'loss': 0.7658, 'grad_norm': 1.2682855129241943, 'learning_rate': 1.7174594683628891e-07, 'epoch': 0.89}
 89%|████████▊ | 2574/2906 [8:29:21<1:06:32, 12.02s/it] 89%|████████▊ | 2575/2906 [8:29:33<1:06:36, 12.07s/it]                                                       {'loss': 0.7974, 'grad_norm': 1.275097370147705, 'learning_rate': 1.7072787510503313e-07, 'epoch': 0.89}
 89%|████████▊ | 2575/2906 [8:29:33<1:06:36, 12.07s/it] 89%|████████▊ | 2576/2906 [8:29:44<1:05:23, 11.89s/it]                                                       {'loss': 0.6989, 'grad_norm': 1.2473881244659424, 'learning_rate': 1.697127231165771e-07, 'epoch': 0.89}
 89%|████████▊ | 2576/2906 [8:29:44<1:05:23, 11.89s/it] 89%|████████▊ | 2577/2906 [8:29:56<1:04:40, 11.79s/it]                                                       {'loss': 0.7604, 'grad_norm': 1.347176432609558, 'learning_rate': 1.6870049214341266e-07, 'epoch': 0.89}
 89%|████████▊ | 2577/2906 [8:29:56<1:04:40, 11.79s/it] 89%|████████▊ | 2578/2906 [8:30:08<1:04:22, 11.77s/it]                                                       {'loss': 0.8172, 'grad_norm': 1.3841516971588135, 'learning_rate': 1.6769118345437263e-07, 'epoch': 0.89}
 89%|████████▊ | 2578/2906 [8:30:08<1:04:22, 11.77s/it] 89%|████████▊ | 2579/2906 [8:30:20<1:04:26, 11.82s/it]                                                       {'loss': 0.7915, 'grad_norm': 1.2898448705673218, 'learning_rate': 1.6668479831462498e-07, 'epoch': 0.89}
 89%|████████▊ | 2579/2906 [8:30:20<1:04:26, 11.82s/it] 89%|████████▉ | 2580/2906 [8:30:31<1:03:52, 11.76s/it]                                                       {'loss': 0.7487, 'grad_norm': 1.3099874258041382, 'learning_rate': 1.6568133798567283e-07, 'epoch': 0.89}
 89%|████████▉ | 2580/2906 [8:30:31<1:03:52, 11.76s/it] 89%|████████▉ | 2581/2906 [8:30:43<1:03:35, 11.74s/it]                                                       {'loss': 0.7737, 'grad_norm': 1.3198578357696533, 'learning_rate': 1.6468080372535472e-07, 'epoch': 0.89}
 89%|████████▉ | 2581/2906 [8:30:43<1:03:35, 11.74s/it] 89%|████████▉ | 2582/2906 [8:30:55<1:03:30, 11.76s/it]                                                       {'loss': 0.7736, 'grad_norm': 1.3332524299621582, 'learning_rate': 1.636831967878405e-07, 'epoch': 0.89}
 89%|████████▉ | 2582/2906 [8:30:55<1:03:30, 11.76s/it] 89%|████████▉ | 2583/2906 [8:31:06<1:03:25, 11.78s/it]                                                       {'loss': 0.8648, 'grad_norm': 1.3199769258499146, 'learning_rate': 1.6268851842362988e-07, 'epoch': 0.89}
 89%|████████▉ | 2583/2906 [8:31:07<1:03:25, 11.78s/it] 89%|████████▉ | 2584/2906 [8:31:18<1:02:56, 11.73s/it]                                                       {'loss': 0.711, 'grad_norm': 1.2516494989395142, 'learning_rate': 1.616967698795527e-07, 'epoch': 0.89}
 89%|████████▉ | 2584/2906 [8:31:18<1:02:56, 11.73s/it] 89%|████████▉ | 2585/2906 [8:31:30<1:02:43, 11.72s/it]                                                       {'loss': 0.7433, 'grad_norm': 1.2642301321029663, 'learning_rate': 1.607079523987662e-07, 'epoch': 0.89}
 89%|████████▉ | 2585/2906 [8:31:30<1:02:43, 11.72s/it] 89%|████████▉ | 2586/2906 [8:31:41<1:02:02, 11.63s/it]                                                       {'loss': 0.7912, 'grad_norm': 1.3696025609970093, 'learning_rate': 1.5972206722075223e-07, 'epoch': 0.89}
 89%|████████▉ | 2586/2906 [8:31:41<1:02:02, 11.63s/it] 89%|████████▉ | 2587/2906 [8:31:53<1:01:50, 11.63s/it]                                                       {'loss': 0.7969, 'grad_norm': 1.280178189277649, 'learning_rate': 1.5873911558131866e-07, 'epoch': 0.89}
 89%|████████▉ | 2587/2906 [8:31:53<1:01:50, 11.63s/it] 89%|████████▉ | 2588/2906 [8:32:04<1:01:01, 11.51s/it]                                                       {'loss': 0.7601, 'grad_norm': 1.5474694967269897, 'learning_rate': 1.5775909871259515e-07, 'epoch': 0.89}
 89%|████████▉ | 2588/2906 [8:32:04<1:01:01, 11.51s/it] 89%|████████▉ | 2589/2906 [8:32:15<1:00:25, 11.44s/it]                                                       {'loss': 0.8382, 'grad_norm': 1.3774056434631348, 'learning_rate': 1.5678201784303293e-07, 'epoch': 0.89}
 89%|████████▉ | 2589/2906 [8:32:15<1:00:25, 11.44s/it] 89%|████████▉ | 2590/2906 [8:32:27<1:00:39, 11.52s/it]                                                       {'loss': 0.8139, 'grad_norm': 1.3436119556427002, 'learning_rate': 1.558078741974034e-07, 'epoch': 0.89}
 89%|████████▉ | 2590/2906 [8:32:27<1:00:39, 11.52s/it] 89%|████████▉ | 2591/2906 [8:32:39<1:01:43, 11.76s/it]                                                       {'loss': 0.8411, 'grad_norm': 1.5870742797851562, 'learning_rate': 1.548366689967948e-07, 'epoch': 0.89}
 89%|████████▉ | 2591/2906 [8:32:39<1:01:43, 11.76s/it] 89%|████████▉ | 2592/2906 [8:32:51<1:01:17, 11.71s/it]                                                       {'loss': 0.7262, 'grad_norm': 1.216286540031433, 'learning_rate': 1.538684034586141e-07, 'epoch': 0.89}
 89%|████████▉ | 2592/2906 [8:32:51<1:01:17, 11.71s/it] 89%|████████▉ | 2593/2906 [8:33:02<1:00:24, 11.58s/it]                                                       {'loss': 0.8134, 'grad_norm': 1.3748739957809448, 'learning_rate': 1.52903078796581e-07, 'epoch': 0.89}
 89%|████████▉ | 2593/2906 [8:33:02<1:00:24, 11.58s/it] 89%|████████▉ | 2594/2906 [8:33:14<1:00:32, 11.64s/it]                                                       {'loss': 0.7912, 'grad_norm': 1.3074220418930054, 'learning_rate': 1.5194069622073094e-07, 'epoch': 0.89}
 89%|████████▉ | 2594/2906 [8:33:14<1:00:32, 11.64s/it] 89%|████████▉ | 2595/2906 [8:33:25<59:39, 11.51s/it]                                                       {'loss': 0.8493, 'grad_norm': 1.4104171991348267, 'learning_rate': 1.5098125693741027e-07, 'epoch': 0.89}
 89%|████████▉ | 2595/2906 [8:33:25<59:39, 11.51s/it] 89%|████████▉ | 2596/2906 [8:33:37<59:08, 11.45s/it]                                                     {'loss': 0.7546, 'grad_norm': 1.2489513158798218, 'learning_rate': 1.500247621492762e-07, 'epoch': 0.89}
 89%|████████▉ | 2596/2906 [8:33:37<59:08, 11.45s/it] 89%|████████▉ | 2597/2906 [8:33:49<59:52, 11.63s/it]                                                     {'loss': 0.8716, 'grad_norm': 1.3583494424819946, 'learning_rate': 1.490712130552946e-07, 'epoch': 0.89}
 89%|████████▉ | 2597/2906 [8:33:49<59:52, 11.63s/it] 89%|████████▉ | 2598/2906 [8:34:00<59:50, 11.66s/it]                                                     {'loss': 0.7959, 'grad_norm': 1.269896149635315, 'learning_rate': 1.4812061085074048e-07, 'epoch': 0.89}
 89%|████████▉ | 2598/2906 [8:34:00<59:50, 11.66s/it] 89%|████████▉ | 2599/2906 [8:34:12<59:31, 11.63s/it]                                                     {'loss': 0.7625, 'grad_norm': 1.2671267986297607, 'learning_rate': 1.471729567271929e-07, 'epoch': 0.89}
 89%|████████▉ | 2599/2906 [8:34:12<59:31, 11.63s/it] 89%|████████▉ | 2600/2906 [8:34:25<1:00:53, 11.94s/it]                                                       {'loss': 0.8259, 'grad_norm': 1.3179123401641846, 'learning_rate': 1.462282518725361e-07, 'epoch': 0.89}
 89%|████████▉ | 2600/2906 [8:34:25<1:00:53, 11.94s/it] 90%|████████▉ | 2601/2906 [8:34:36<59:50, 11.77s/it]                                                       {'loss': 0.7599, 'grad_norm': 1.3816425800323486, 'learning_rate': 1.4528649747095863e-07, 'epoch': 0.9}
 90%|████████▉ | 2601/2906 [8:34:36<59:50, 11.77s/it] 90%|████████▉ | 2602/2906 [8:34:48<1:00:13, 11.89s/it]                                                       {'loss': 0.8204, 'grad_norm': 1.3927204608917236, 'learning_rate': 1.44347694702949e-07, 'epoch': 0.9}
 90%|████████▉ | 2602/2906 [8:34:48<1:00:13, 11.89s/it] 90%|████████▉ | 2603/2906 [8:35:00<1:00:13, 11.93s/it]                                                       {'loss': 0.7898, 'grad_norm': 1.3214237689971924, 'learning_rate': 1.4341184474529646e-07, 'epoch': 0.9}
 90%|████████▉ | 2603/2906 [8:35:00<1:00:13, 11.93s/it] 90%|████████▉ | 2604/2906 [8:35:12<59:46, 11.88s/it]                                                       {'loss': 0.8016, 'grad_norm': 1.5167561769485474, 'learning_rate': 1.424789487710898e-07, 'epoch': 0.9}
 90%|████████▉ | 2604/2906 [8:35:12<59:46, 11.88s/it] 90%|████████▉ | 2605/2906 [8:35:24<59:23, 11.84s/it]                                                     {'loss': 0.7275, 'grad_norm': 1.3280210494995117, 'learning_rate': 1.4154900794971337e-07, 'epoch': 0.9}
 90%|████████▉ | 2605/2906 [8:35:24<59:23, 11.84s/it] 90%|████████▉ | 2606/2906 [8:35:35<58:47, 11.76s/it]                                                     {'loss': 0.8052, 'grad_norm': 1.3005576133728027, 'learning_rate': 1.406220234468489e-07, 'epoch': 0.9}
 90%|████████▉ | 2606/2906 [8:35:35<58:47, 11.76s/it] 90%|████████▉ | 2607/2906 [8:35:47<58:27, 11.73s/it]                                                     {'loss': 0.7701, 'grad_norm': 1.341219425201416, 'learning_rate': 1.3969799642447047e-07, 'epoch': 0.9}
 90%|████████▉ | 2607/2906 [8:35:47<58:27, 11.73s/it] 90%|████████▉ | 2608/2906 [8:35:58<58:01, 11.68s/it]                                                     {'loss': 0.7557, 'grad_norm': 1.2591874599456787, 'learning_rate': 1.3877692804084687e-07, 'epoch': 0.9}
 90%|████████▉ | 2608/2906 [8:35:58<58:01, 11.68s/it] 90%|████████▉ | 2609/2906 [8:36:10<58:07, 11.74s/it]                                                     {'loss': 0.7652, 'grad_norm': 1.2165409326553345, 'learning_rate': 1.378588194505373e-07, 'epoch': 0.9}
 90%|████████▉ | 2609/2906 [8:36:10<58:07, 11.74s/it] 90%|████████▉ | 2610/2906 [8:36:22<57:53, 11.73s/it]                                                     {'loss': 0.764, 'grad_norm': 1.3538738489151, 'learning_rate': 1.3694367180439038e-07, 'epoch': 0.9}
 90%|████████▉ | 2610/2906 [8:36:22<57:53, 11.73s/it] 90%|████████▉ | 2611/2906 [8:36:34<57:46, 11.75s/it]                                                     {'loss': 0.7168, 'grad_norm': 1.2905495166778564, 'learning_rate': 1.3603148624954488e-07, 'epoch': 0.9}
 90%|████████▉ | 2611/2906 [8:36:34<57:46, 11.75s/it] 90%|████████▉ | 2612/2906 [8:36:45<57:01, 11.64s/it]                                                     {'loss': 0.8994, 'grad_norm': 1.427119255065918, 'learning_rate': 1.3512226392942417e-07, 'epoch': 0.9}
 90%|████████▉ | 2612/2906 [8:36:45<57:01, 11.64s/it] 90%|████████▉ | 2613/2906 [8:36:57<56:45, 11.62s/it]                                                     {'loss': 0.8369, 'grad_norm': 1.3100676536560059, 'learning_rate': 1.3421600598373886e-07, 'epoch': 0.9}
 90%|████████▉ | 2613/2906 [8:36:57<56:45, 11.62s/it] 90%|████████▉ | 2614/2906 [8:37:09<57:43, 11.86s/it]                                                     {'loss': 0.8182, 'grad_norm': 1.3139384984970093, 'learning_rate': 1.3331271354848434e-07, 'epoch': 0.9}
 90%|████████▉ | 2614/2906 [8:37:09<57:43, 11.86s/it] 90%|████████▉ | 2615/2906 [8:37:20<56:03, 11.56s/it]                                                     {'loss': 0.7623, 'grad_norm': 1.2996129989624023, 'learning_rate': 1.3241238775593634e-07, 'epoch': 0.9}
 90%|████████▉ | 2615/2906 [8:37:20<56:03, 11.56s/it] 90%|█████████ | 2616/2906 [8:37:31<55:36, 11.50s/it]                                                     {'loss': 0.775, 'grad_norm': 1.3996864557266235, 'learning_rate': 1.31515029734654e-07, 'epoch': 0.9}
 90%|█████████ | 2616/2906 [8:37:31<55:36, 11.50s/it] 90%|█████████ | 2617/2906 [8:37:44<56:27, 11.72s/it]                                                     {'loss': 0.7747, 'grad_norm': 1.3160505294799805, 'learning_rate': 1.306206406094762e-07, 'epoch': 0.9}
 90%|█████████ | 2617/2906 [8:37:44<56:27, 11.72s/it] 90%|█████████ | 2618/2906 [8:37:55<56:25, 11.75s/it]                                                     {'loss': 0.8288, 'grad_norm': 1.3191860914230347, 'learning_rate': 1.297292215015189e-07, 'epoch': 0.9}
 90%|█████████ | 2618/2906 [8:37:56<56:25, 11.75s/it] 90%|█████████ | 2619/2906 [8:38:07<56:18, 11.77s/it]                                                     {'loss': 0.8044, 'grad_norm': 1.3135181665420532, 'learning_rate': 1.2884077352817659e-07, 'epoch': 0.9}
 90%|█████████ | 2619/2906 [8:38:07<56:18, 11.77s/it] 90%|█████████ | 2620/2906 [8:38:19<55:26, 11.63s/it]                                                     {'loss': 0.7958, 'grad_norm': 1.2941393852233887, 'learning_rate': 1.2795529780311816e-07, 'epoch': 0.9}
 90%|█████████ | 2620/2906 [8:38:19<55:26, 11.63s/it] 90%|█████████ | 2621/2906 [8:38:30<55:27, 11.67s/it]                                                     {'loss': 0.8102, 'grad_norm': 1.3895289897918701, 'learning_rate': 1.2707279543628853e-07, 'epoch': 0.9}
 90%|█████████ | 2621/2906 [8:38:30<55:27, 11.67s/it] 90%|█████████ | 2622/2906 [8:38:42<54:54, 11.60s/it]                                                     {'loss': 0.7909, 'grad_norm': 1.3098688125610352, 'learning_rate': 1.2619326753390365e-07, 'epoch': 0.9}
 90%|█████████ | 2622/2906 [8:38:42<54:54, 11.60s/it] 90%|█████████ | 2623/2906 [8:38:54<55:20, 11.73s/it]                                                     {'loss': 0.8234, 'grad_norm': 1.3740012645721436, 'learning_rate': 1.2531671519845218e-07, 'epoch': 0.9}
 90%|█████████ | 2623/2906 [8:38:54<55:20, 11.73s/it] 90%|█████████ | 2624/2906 [8:39:06<55:37, 11.84s/it]                                                     {'loss': 0.7904, 'grad_norm': 1.313518762588501, 'learning_rate': 1.2444313952869242e-07, 'epoch': 0.9}
 90%|█████████ | 2624/2906 [8:39:06<55:37, 11.84s/it] 90%|█████████ | 2625/2906 [8:39:18<55:43, 11.90s/it]                                                     {'loss': 0.7608, 'grad_norm': 1.2713086605072021, 'learning_rate': 1.2357254161965176e-07, 'epoch': 0.9}
 90%|█████████ | 2625/2906 [8:39:18<55:43, 11.90s/it] 90%|█████████ | 2626/2906 [8:39:30<55:21, 11.86s/it]                                                     {'loss': 0.7835, 'grad_norm': 1.3140963315963745, 'learning_rate': 1.2270492256262424e-07, 'epoch': 0.9}
 90%|█████████ | 2626/2906 [8:39:30<55:21, 11.86s/it] 90%|█████████ | 2627/2906 [8:39:42<55:30, 11.94s/it]                                                     {'loss': 0.7681, 'grad_norm': 1.273282766342163, 'learning_rate': 1.2184028344517096e-07, 'epoch': 0.9}
 90%|█████████ | 2627/2906 [8:39:42<55:30, 11.94s/it] 90%|█████████ | 2628/2906 [8:39:54<55:41, 12.02s/it]                                                     {'loss': 0.7838, 'grad_norm': 1.2372642755508423, 'learning_rate': 1.209786253511172e-07, 'epoch': 0.9}
 90%|█████████ | 2628/2906 [8:39:54<55:41, 12.02s/it] 90%|█████████ | 2629/2906 [8:40:05<54:25, 11.79s/it]                                                     {'loss': 0.7841, 'grad_norm': 1.302681565284729, 'learning_rate': 1.2011994936055066e-07, 'epoch': 0.9}
 90%|█████████ | 2629/2906 [8:40:05<54:25, 11.79s/it] 91%|█████████ | 2630/2906 [8:40:17<54:21, 11.82s/it]                                                     {'loss': 0.7775, 'grad_norm': 1.2920187711715698, 'learning_rate': 1.1926425654982283e-07, 'epoch': 0.91}
 91%|█████████ | 2630/2906 [8:40:17<54:21, 11.82s/it] 91%|█████████ | 2631/2906 [8:40:29<54:02, 11.79s/it]                                                     {'loss': 0.7279, 'grad_norm': 1.2004656791687012, 'learning_rate': 1.1841154799154376e-07, 'epoch': 0.91}
 91%|█████████ | 2631/2906 [8:40:29<54:02, 11.79s/it] 91%|█████████ | 2632/2906 [8:40:41<53:39, 11.75s/it]                                                     {'loss': 0.7374, 'grad_norm': 1.3163625001907349, 'learning_rate': 1.17561824754584e-07, 'epoch': 0.91}
 91%|█████████ | 2632/2906 [8:40:41<53:39, 11.75s/it] 91%|█████████ | 2633/2906 [8:40:52<52:53, 11.62s/it]                                                     {'loss': 0.7929, 'grad_norm': 1.2514972686767578, 'learning_rate': 1.1671508790407238e-07, 'epoch': 0.91}
 91%|█████████ | 2633/2906 [8:40:52<52:53, 11.62s/it] 91%|█████████ | 2634/2906 [8:41:04<53:08, 11.72s/it]                                                     {'loss': 0.7725, 'grad_norm': 1.2559425830841064, 'learning_rate': 1.1587133850139264e-07, 'epoch': 0.91}
 91%|█████████ | 2634/2906 [8:41:04<53:08, 11.72s/it] 91%|█████████ | 2635/2906 [8:41:16<53:53, 11.93s/it]                                                     {'loss': 0.8069, 'grad_norm': 1.3038424253463745, 'learning_rate': 1.1503057760418518e-07, 'epoch': 0.91}
 91%|█████████ | 2635/2906 [8:41:16<53:53, 11.93s/it] 91%|█████████ | 2636/2906 [8:41:29<54:42, 12.16s/it]                                                     {'loss': 0.7866, 'grad_norm': 1.331290364265442, 'learning_rate': 1.1419280626634388e-07, 'epoch': 0.91}
 91%|█████████ | 2636/2906 [8:41:29<54:42, 12.16s/it] 91%|█████████ | 2637/2906 [8:41:41<53:52, 12.02s/it]                                                     {'loss': 0.8172, 'grad_norm': 1.367035984992981, 'learning_rate': 1.1335802553801512e-07, 'epoch': 0.91}
 91%|█████████ | 2637/2906 [8:41:41<53:52, 12.02s/it] 91%|█████████ | 2638/2906 [8:41:52<52:49, 11.83s/it]                                                     {'loss': 0.772, 'grad_norm': 1.2557017803192139, 'learning_rate': 1.1252623646559657e-07, 'epoch': 0.91}
 91%|█████████ | 2638/2906 [8:41:52<52:49, 11.83s/it] 91%|█████████ | 2639/2906 [8:42:03<51:55, 11.67s/it]                                                     {'loss': 0.8132, 'grad_norm': 1.335552453994751, 'learning_rate': 1.1169744009173588e-07, 'epoch': 0.91}
 91%|█████████ | 2639/2906 [8:42:03<51:55, 11.67s/it] 91%|█████████ | 2640/2906 [8:42:15<52:04, 11.75s/it]                                                     {'loss': 0.7727, 'grad_norm': 1.275242805480957, 'learning_rate': 1.1087163745532925e-07, 'epoch': 0.91}
 91%|█████████ | 2640/2906 [8:42:15<52:04, 11.75s/it] 91%|█████████ | 2641/2906 [8:42:27<51:31, 11.67s/it]                                                     {'loss': 0.7304, 'grad_norm': 1.2666563987731934, 'learning_rate': 1.1004882959152085e-07, 'epoch': 0.91}
 91%|█████████ | 2641/2906 [8:42:27<51:31, 11.67s/it] 91%|█████████ | 2642/2906 [8:42:38<51:20, 11.67s/it]                                                     {'loss': 0.7619, 'grad_norm': 1.3608638048171997, 'learning_rate': 1.092290175317004e-07, 'epoch': 0.91}
 91%|█████████ | 2642/2906 [8:42:38<51:20, 11.67s/it] 91%|█████████ | 2643/2906 [8:42:50<51:00, 11.64s/it]                                                     {'loss': 0.8729, 'grad_norm': 1.4263503551483154, 'learning_rate': 1.0841220230350142e-07, 'epoch': 0.91}
 91%|█████████ | 2643/2906 [8:42:50<51:00, 11.64s/it] 91%|█████████ | 2644/2906 [8:43:02<51:16, 11.74s/it]                                                     {'loss': 0.8505, 'grad_norm': 1.387105941772461, 'learning_rate': 1.0759838493080293e-07, 'epoch': 0.91}
 91%|█████████ | 2644/2906 [8:43:02<51:16, 11.74s/it] 91%|█████████ | 2645/2906 [8:43:14<51:53, 11.93s/it]                                                     {'loss': 0.7404, 'grad_norm': 1.1729495525360107, 'learning_rate': 1.0678756643372423e-07, 'epoch': 0.91}
 91%|█████████ | 2645/2906 [8:43:14<51:53, 11.93s/it] 91%|█████████ | 2646/2906 [8:43:26<51:51, 11.97s/it]                                                     {'loss': 0.759, 'grad_norm': 1.3478211164474487, 'learning_rate': 1.0597974782862674e-07, 'epoch': 0.91}
 91%|█████████ | 2646/2906 [8:43:26<51:51, 11.97s/it] 91%|█████████ | 2647/2906 [8:43:38<51:21, 11.90s/it]                                                     {'loss': 0.7849, 'grad_norm': 1.3291109800338745, 'learning_rate': 1.0517493012811159e-07, 'epoch': 0.91}
 91%|█████████ | 2647/2906 [8:43:38<51:21, 11.90s/it] 91%|█████████ | 2648/2906 [8:43:50<51:40, 12.02s/it]                                                     {'loss': 0.7273, 'grad_norm': 1.2399680614471436, 'learning_rate': 1.0437311434101705e-07, 'epoch': 0.91}
 91%|█████████ | 2648/2906 [8:43:50<51:40, 12.02s/it] 91%|█████████ | 2649/2906 [8:44:03<51:42, 12.07s/it]                                                     {'loss': 0.7885, 'grad_norm': 1.251343011856079, 'learning_rate': 1.0357430147242026e-07, 'epoch': 0.91}
 91%|█████████ | 2649/2906 [8:44:03<51:42, 12.07s/it] 91%|█████████ | 2650/2906 [8:44:15<51:54, 12.16s/it]                                                     {'loss': 0.841, 'grad_norm': 1.3159520626068115, 'learning_rate': 1.0277849252363192e-07, 'epoch': 0.91}
 91%|█████████ | 2650/2906 [8:44:15<51:54, 12.16s/it] 91%|█████████ | 2651/2906 [8:44:27<51:09, 12.04s/it]                                                     {'loss': 0.805, 'grad_norm': 1.364753246307373, 'learning_rate': 1.0198568849219964e-07, 'epoch': 0.91}
 91%|█████████ | 2651/2906 [8:44:27<51:09, 12.04s/it] 91%|█████████▏| 2652/2906 [8:44:38<50:31, 11.93s/it]                                                     {'loss': 0.843, 'grad_norm': 1.480627179145813, 'learning_rate': 1.011958903719032e-07, 'epoch': 0.91}
 91%|█████████▏| 2652/2906 [8:44:38<50:31, 11.93s/it] 91%|█████████▏| 2653/2906 [8:44:50<49:49, 11.82s/it]                                                     {'loss': 0.7823, 'grad_norm': 1.3024684190750122, 'learning_rate': 1.0040909915275399e-07, 'epoch': 0.91}
 91%|█████████▏| 2653/2906 [8:44:50<49:49, 11.82s/it] 91%|█████████▏| 2654/2906 [8:45:02<49:51, 11.87s/it]                                                     {'loss': 0.7981, 'grad_norm': 1.271493673324585, 'learning_rate': 9.96253158209956e-08, 'epoch': 0.91}
 91%|█████████▏| 2654/2906 [8:45:02<49:51, 11.87s/it] 91%|█████████▏| 2655/2906 [8:45:14<50:14, 12.01s/it]                                                     {'loss': 0.7877, 'grad_norm': 1.3138600587844849, 'learning_rate': 9.884454135910021e-08, 'epoch': 0.91}
 91%|█████████▏| 2655/2906 [8:45:14<50:14, 12.01s/it] 91%|█████████▏| 2656/2906 [8:45:26<49:53, 11.97s/it]                                                     {'loss': 0.797, 'grad_norm': 1.4206652641296387, 'learning_rate': 9.806677674576854e-08, 'epoch': 0.91}
 91%|█████████▏| 2656/2906 [8:45:26<49:53, 11.97s/it] 91%|█████████▏| 2657/2906 [8:45:38<49:44, 11.98s/it]                                                     {'loss': 0.812, 'grad_norm': 1.3901276588439941, 'learning_rate': 9.729202295592877e-08, 'epoch': 0.91}
 91%|█████████▏| 2657/2906 [8:45:38<49:44, 11.98s/it] 91%|█████████▏| 2658/2906 [8:45:50<49:36, 12.00s/it]                                                     {'loss': 0.7912, 'grad_norm': 1.318030595779419, 'learning_rate': 9.652028096073491e-08, 'epoch': 0.91}
 91%|█████████▏| 2658/2906 [8:45:50<49:36, 12.00s/it] 92%|█████████▏| 2659/2906 [8:46:02<49:32, 12.04s/it]                                                     {'loss': 0.7822, 'grad_norm': 1.2478855848312378, 'learning_rate': 9.575155172756506e-08, 'epoch': 0.92}
 92%|█████████▏| 2659/2906 [8:46:02<49:32, 12.04s/it] 92%|█████████▏| 2660/2906 [8:46:14<48:31, 11.83s/it]                                                     {'loss': 0.8488, 'grad_norm': 1.311721920967102, 'learning_rate': 9.498583622002233e-08, 'epoch': 0.92}
 92%|█████████▏| 2660/2906 [8:46:14<48:31, 11.83s/it] 92%|█████████▏| 2661/2906 [8:46:26<48:32, 11.89s/it]                                                     {'loss': 0.7957, 'grad_norm': 1.279731273651123, 'learning_rate': 9.422313539793032e-08, 'epoch': 0.92}
 92%|█████████▏| 2661/2906 [8:46:26<48:32, 11.89s/it] 92%|█████████▏| 2662/2906 [8:46:38<48:21, 11.89s/it]                                                     {'loss': 0.7853, 'grad_norm': 1.3450192213058472, 'learning_rate': 9.346345021733482e-08, 'epoch': 0.92}
 92%|█████████▏| 2662/2906 [8:46:38<48:21, 11.89s/it] 92%|█████████▏| 2663/2906 [8:46:50<48:33, 11.99s/it]                                                     {'loss': 0.7892, 'grad_norm': 1.3463250398635864, 'learning_rate': 9.270678163050218e-08, 'epoch': 0.92}
 92%|█████████▏| 2663/2906 [8:46:50<48:33, 11.99s/it] 92%|█████████▏| 2664/2906 [8:47:01<47:47, 11.85s/it]                                                     {'loss': 0.8196, 'grad_norm': 1.4561386108398438, 'learning_rate': 9.195313058591476e-08, 'epoch': 0.92}
 92%|█████████▏| 2664/2906 [8:47:01<47:47, 11.85s/it] 92%|█████████▏| 2665/2906 [8:47:14<48:12, 12.00s/it]                                                     {'loss': 0.7906, 'grad_norm': 1.3308323621749878, 'learning_rate': 9.120249802827525e-08, 'epoch': 0.92}
 92%|█████████▏| 2665/2906 [8:47:14<48:12, 12.00s/it] 92%|█████████▏| 2666/2906 [8:47:25<47:21, 11.84s/it]                                                     {'loss': 0.7966, 'grad_norm': 1.3396888971328735, 'learning_rate': 9.045488489850207e-08, 'epoch': 0.92}
 92%|█████████▏| 2666/2906 [8:47:25<47:21, 11.84s/it] 92%|█████████▏| 2667/2906 [8:47:37<46:53, 11.77s/it]                                                     {'loss': 0.8024, 'grad_norm': 1.334173560142517, 'learning_rate': 8.971029213372729e-08, 'epoch': 0.92}
 92%|█████████▏| 2667/2906 [8:47:37<46:53, 11.77s/it] 92%|█████████▏| 2668/2906 [8:47:49<46:56, 11.83s/it]                                                     {'loss': 0.8031, 'grad_norm': 1.3542250394821167, 'learning_rate': 8.896872066729872e-08, 'epoch': 0.92}
 92%|█████████▏| 2668/2906 [8:47:49<46:56, 11.83s/it] 92%|█████████▏| 2669/2906 [8:48:01<46:42, 11.83s/it]                                                     {'loss': 0.7808, 'grad_norm': 1.2870347499847412, 'learning_rate': 8.823017142877587e-08, 'epoch': 0.92}
 92%|█████████▏| 2669/2906 [8:48:01<46:42, 11.83s/it] 92%|█████████▏| 2670/2906 [8:48:12<46:19, 11.78s/it]                                                     {'loss': 0.7936, 'grad_norm': 1.2843458652496338, 'learning_rate': 8.749464534393044e-08, 'epoch': 0.92}
 92%|█████████▏| 2670/2906 [8:48:12<46:19, 11.78s/it] 92%|█████████▏| 2671/2906 [8:48:24<46:11, 11.79s/it]                                                     {'loss': 0.7827, 'grad_norm': 1.4474000930786133, 'learning_rate': 8.676214333474458e-08, 'epoch': 0.92}
 92%|█████████▏| 2671/2906 [8:48:24<46:11, 11.79s/it] 92%|█████████▏| 2672/2906 [8:48:36<46:06, 11.82s/it]                                                     {'loss': 0.8907, 'grad_norm': 1.3698378801345825, 'learning_rate': 8.603266631940943e-08, 'epoch': 0.92}
 92%|█████████▏| 2672/2906 [8:48:36<46:06, 11.82s/it] 92%|█████████▏| 2673/2906 [8:48:48<46:20, 11.93s/it]                                                     {'loss': 0.8443, 'grad_norm': 1.404606819152832, 'learning_rate': 8.530621521232435e-08, 'epoch': 0.92}
 92%|█████████▏| 2673/2906 [8:48:48<46:20, 11.93s/it] 92%|█████████▏| 2674/2906 [8:49:00<45:59, 11.89s/it]                                                     {'loss': 0.832, 'grad_norm': 1.3163598775863647, 'learning_rate': 8.45827909240965e-08, 'epoch': 0.92}
 92%|█████████▏| 2674/2906 [8:49:00<45:59, 11.89s/it] 92%|█████████▏| 2675/2906 [8:49:12<45:23, 11.79s/it]                                                     {'loss': 0.7733, 'grad_norm': 1.4190185070037842, 'learning_rate': 8.386239436153742e-08, 'epoch': 0.92}
 92%|█████████▏| 2675/2906 [8:49:12<45:23, 11.79s/it] 92%|█████████▏| 2676/2906 [8:49:23<45:10, 11.79s/it]                                                     {'loss': 0.7762, 'grad_norm': 1.3215479850769043, 'learning_rate': 8.314502642766481e-08, 'epoch': 0.92}
 92%|█████████▏| 2676/2906 [8:49:23<45:10, 11.79s/it] 92%|█████████▏| 2677/2906 [8:49:35<45:10, 11.84s/it]                                                     {'loss': 0.8293, 'grad_norm': 1.3892319202423096, 'learning_rate': 8.243068802169906e-08, 'epoch': 0.92}
 92%|█████████▏| 2677/2906 [8:49:35<45:10, 11.84s/it] 92%|█████████▏| 2678/2906 [8:49:47<44:52, 11.81s/it]                                                     {'loss': 0.8439, 'grad_norm': 1.3278058767318726, 'learning_rate': 8.171938003906394e-08, 'epoch': 0.92}
 92%|█████████▏| 2678/2906 [8:49:47<44:52, 11.81s/it] 92%|█████████▏| 2679/2906 [8:49:58<44:15, 11.70s/it]                                                     {'loss': 0.7667, 'grad_norm': 1.4434608221054077, 'learning_rate': 8.101110337138369e-08, 'epoch': 0.92}
 92%|█████████▏| 2679/2906 [8:49:58<44:15, 11.70s/it] 92%|█████████▏| 2680/2906 [8:50:10<43:58, 11.68s/it]                                                     {'loss': 0.7741, 'grad_norm': 1.3424656391143799, 'learning_rate': 8.030585890648312e-08, 'epoch': 0.92}
 92%|█████████▏| 2680/2906 [8:50:10<43:58, 11.68s/it] 92%|█████████▏| 2681/2906 [8:50:22<43:35, 11.63s/it]                                                     {'loss': 0.7861, 'grad_norm': 1.3550090789794922, 'learning_rate': 7.96036475283865e-08, 'epoch': 0.92}
 92%|█████████▏| 2681/2906 [8:50:22<43:35, 11.63s/it] 92%|█████████▏| 2682/2906 [8:50:33<43:33, 11.67s/it]                                                     {'loss': 0.7823, 'grad_norm': 1.233608603477478, 'learning_rate': 7.890447011731584e-08, 'epoch': 0.92}
 92%|█████████▏| 2682/2906 [8:50:33<43:33, 11.67s/it] 92%|█████████▏| 2683/2906 [8:50:45<43:50, 11.80s/it]                                                     {'loss': 0.8476, 'grad_norm': 1.3772261142730713, 'learning_rate': 7.820832754968976e-08, 'epoch': 0.92}
 92%|█████████▏| 2683/2906 [8:50:45<43:50, 11.80s/it] 92%|█████████▏| 2684/2906 [8:50:58<44:03, 11.91s/it]                                                     {'loss': 0.7689, 'grad_norm': 1.2877944707870483, 'learning_rate': 7.751522069812334e-08, 'epoch': 0.92}
 92%|█████████▏| 2684/2906 [8:50:58<44:03, 11.91s/it] 92%|█████████▏| 2685/2906 [8:51:09<43:40, 11.86s/it]                                                     {'loss': 0.8082, 'grad_norm': 1.3894293308258057, 'learning_rate': 7.682515043142602e-08, 'epoch': 0.92}
 92%|█████████▏| 2685/2906 [8:51:09<43:40, 11.86s/it] 92%|█████████▏| 2686/2906 [8:51:21<43:13, 11.79s/it]                                                     {'loss': 0.8084, 'grad_norm': 1.3043406009674072, 'learning_rate': 7.61381176146006e-08, 'epoch': 0.92}
 92%|█████████▏| 2686/2906 [8:51:21<43:13, 11.79s/it] 92%|█████████▏| 2687/2906 [8:51:33<43:00, 11.78s/it]                                                     {'loss': 0.7858, 'grad_norm': 1.2988002300262451, 'learning_rate': 7.545412310884347e-08, 'epoch': 0.92}
 92%|█████████▏| 2687/2906 [8:51:33<43:00, 11.78s/it] 92%|█████████▏| 2688/2906 [8:51:45<43:10, 11.88s/it]                                                     {'loss': 0.7541, 'grad_norm': 1.3189772367477417, 'learning_rate': 7.477316777154103e-08, 'epoch': 0.92}
 92%|█████████▏| 2688/2906 [8:51:45<43:10, 11.88s/it] 93%|█████████▎| 2689/2906 [8:51:57<43:15, 11.96s/it]                                                     {'loss': 0.738, 'grad_norm': 1.2673579454421997, 'learning_rate': 7.409525245627103e-08, 'epoch': 0.93}
 93%|█████████▎| 2689/2906 [8:51:57<43:15, 11.96s/it] 93%|█████████▎| 2690/2906 [8:52:09<42:52, 11.91s/it]                                                     {'loss': 0.7619, 'grad_norm': 1.3086351156234741, 'learning_rate': 7.342037801280094e-08, 'epoch': 0.93}
 93%|█████████▎| 2690/2906 [8:52:09<42:52, 11.91s/it] 93%|█████████▎| 2691/2906 [8:52:21<42:54, 11.98s/it]                                                     {'loss': 0.8032, 'grad_norm': 1.251025915145874, 'learning_rate': 7.27485452870852e-08, 'epoch': 0.93}
 93%|█████████▎| 2691/2906 [8:52:21<42:54, 11.98s/it] 93%|█████████▎| 2692/2906 [8:52:33<42:44, 11.98s/it]                                                     {'loss': 0.8157, 'grad_norm': 1.4109748601913452, 'learning_rate': 7.207975512126652e-08, 'epoch': 0.93}
 93%|█████████▎| 2692/2906 [8:52:33<42:44, 11.98s/it] 93%|█████████▎| 2693/2906 [8:52:44<41:51, 11.79s/it]                                                     {'loss': 0.8039, 'grad_norm': 1.327218770980835, 'learning_rate': 7.141400835367379e-08, 'epoch': 0.93}
 93%|█████████▎| 2693/2906 [8:52:44<41:51, 11.79s/it] 93%|█████████▎| 2694/2906 [8:52:57<42:14, 11.95s/it]                                                     {'loss': 0.7702, 'grad_norm': 1.3441333770751953, 'learning_rate': 7.075130581882e-08, 'epoch': 0.93}
 93%|█████████▎| 2694/2906 [8:52:57<42:14, 11.95s/it] 93%|█████████▎| 2695/2906 [8:53:09<41:59, 11.94s/it]                                                     {'loss': 0.7943, 'grad_norm': 1.2522746324539185, 'learning_rate': 7.009164834740318e-08, 'epoch': 0.93}
 93%|█████████▎| 2695/2906 [8:53:09<41:59, 11.94s/it] 93%|█████████▎| 2696/2906 [8:53:21<41:59, 12.00s/it]                                                     {'loss': 0.8157, 'grad_norm': 1.4354599714279175, 'learning_rate': 6.943503676630381e-08, 'epoch': 0.93}
 93%|█████████▎| 2696/2906 [8:53:21<41:59, 12.00s/it] 93%|█████████▎| 2697/2906 [8:53:32<41:33, 11.93s/it]                                                     {'loss': 0.7617, 'grad_norm': 1.3176360130310059, 'learning_rate': 6.878147189858464e-08, 'epoch': 0.93}
 93%|█████████▎| 2697/2906 [8:53:32<41:33, 11.93s/it] 93%|█████████▎| 2698/2906 [8:53:44<41:09, 11.87s/it]                                                     {'loss': 0.84, 'grad_norm': 1.3635740280151367, 'learning_rate': 6.813095456348951e-08, 'epoch': 0.93}
 93%|█████████▎| 2698/2906 [8:53:44<41:09, 11.87s/it] 93%|█████████▎| 2699/2906 [8:53:56<40:47, 11.82s/it]                                                     {'loss': 0.7518, 'grad_norm': 1.3509422540664673, 'learning_rate': 6.748348557644169e-08, 'epoch': 0.93}
 93%|█████████▎| 2699/2906 [8:53:56<40:47, 11.82s/it] 93%|█████████▎| 2700/2906 [8:54:08<40:43, 11.86s/it]                                                     {'loss': 0.7937, 'grad_norm': 1.2717399597167969, 'learning_rate': 6.683906574904364e-08, 'epoch': 0.93}
 93%|█████████▎| 2700/2906 [8:54:08<40:43, 11.86s/it] 93%|█████████▎| 2701/2906 [8:54:19<40:04, 11.73s/it]                                                     {'loss': 0.8407, 'grad_norm': 1.4656742811203003, 'learning_rate': 6.619769588907588e-08, 'epoch': 0.93}
 93%|█████████▎| 2701/2906 [8:54:19<40:04, 11.73s/it] 93%|█████████▎| 2702/2906 [8:54:31<39:26, 11.60s/it]                                                     {'loss': 0.8285, 'grad_norm': 1.3952281475067139, 'learning_rate': 6.555937680049529e-08, 'epoch': 0.93}
 93%|█████████▎| 2702/2906 [8:54:31<39:26, 11.60s/it] 93%|█████████▎| 2703/2906 [8:54:43<39:49, 11.77s/it]                                                     {'loss': 0.8112, 'grad_norm': 1.2686933279037476, 'learning_rate': 6.492410928343545e-08, 'epoch': 0.93}
 93%|█████████▎| 2703/2906 [8:54:43<39:49, 11.77s/it] 93%|█████████▎| 2704/2906 [8:54:55<40:11, 11.94s/it]                                                     {'loss': 0.7247, 'grad_norm': 1.397552490234375, 'learning_rate': 6.429189413420328e-08, 'epoch': 0.93}
 93%|█████████▎| 2704/2906 [8:54:55<40:11, 11.94s/it] 93%|█████████▎| 2705/2906 [8:55:07<40:24, 12.06s/it]                                                     {'loss': 0.7902, 'grad_norm': 1.2784473896026611, 'learning_rate': 6.366273214528124e-08, 'epoch': 0.93}
 93%|█████████▎| 2705/2906 [8:55:07<40:24, 12.06s/it] 93%|█████████▎| 2706/2906 [8:55:19<39:53, 11.97s/it]                                                     {'loss': 0.7505, 'grad_norm': 1.2269623279571533, 'learning_rate': 6.30366241053243e-08, 'epoch': 0.93}
 93%|█████████▎| 2706/2906 [8:55:19<39:53, 11.97s/it] 93%|█████████▎| 2707/2906 [8:55:31<39:35, 11.94s/it]                                                     {'loss': 0.7008, 'grad_norm': 1.3146437406539917, 'learning_rate': 6.241357079915771e-08, 'epoch': 0.93}
 93%|█████████▎| 2707/2906 [8:55:31<39:35, 11.94s/it] 93%|█████████▎| 2708/2906 [8:55:43<39:47, 12.06s/it]                                                     {'loss': 0.7896, 'grad_norm': 1.3525477647781372, 'learning_rate': 6.179357300777983e-08, 'epoch': 0.93}
 93%|█████████▎| 2708/2906 [8:55:43<39:47, 12.06s/it] 93%|█████████▎| 2709/2906 [8:55:55<39:26, 12.01s/it]                                                     {'loss': 0.7807, 'grad_norm': 1.2869138717651367, 'learning_rate': 6.117663150835756e-08, 'epoch': 0.93}
 93%|█████████▎| 2709/2906 [8:55:55<39:26, 12.01s/it] 93%|█████████▎| 2710/2906 [8:56:07<39:09, 11.99s/it]                                                     {'loss': 0.8203, 'grad_norm': 1.2709208726882935, 'learning_rate': 6.056274707422733e-08, 'epoch': 0.93}
 93%|█████████▎| 2710/2906 [8:56:07<39:09, 11.99s/it] 93%|█████████▎| 2711/2906 [8:56:19<38:27, 11.83s/it]                                                     {'loss': 0.8059, 'grad_norm': 1.2548002004623413, 'learning_rate': 5.995192047489301e-08, 'epoch': 0.93}
 93%|█████████▎| 2711/2906 [8:56:19<38:27, 11.83s/it] 93%|█████████▎| 2712/2906 [8:56:31<38:37, 11.94s/it]                                                     {'loss': 0.7552, 'grad_norm': 1.3785510063171387, 'learning_rate': 5.934415247602604e-08, 'epoch': 0.93}
 93%|█████████▎| 2712/2906 [8:56:31<38:37, 11.94s/it] 93%|█████████▎| 2713/2906 [8:56:43<38:16, 11.90s/it]                                                     {'loss': 0.7812, 'grad_norm': 1.337661623954773, 'learning_rate': 5.8739443839463675e-08, 'epoch': 0.93}
 93%|█████████▎| 2713/2906 [8:56:43<38:16, 11.90s/it] 93%|█████████▎| 2714/2906 [8:56:55<38:06, 11.91s/it]                                                     {'loss': 0.7528, 'grad_norm': 1.3496025800704956, 'learning_rate': 5.813779532320818e-08, 'epoch': 0.93}
 93%|█████████▎| 2714/2906 [8:56:55<38:06, 11.91s/it] 93%|█████████▎| 2715/2906 [8:57:06<37:45, 11.86s/it]                                                     {'loss': 0.8095, 'grad_norm': 1.3198702335357666, 'learning_rate': 5.7539207681426015e-08, 'epoch': 0.93}
 93%|█████████▎| 2715/2906 [8:57:06<37:45, 11.86s/it] 93%|█████████▎| 2716/2906 [8:57:17<36:46, 11.61s/it]                                                     {'loss': 0.7932, 'grad_norm': 1.2846359014511108, 'learning_rate': 5.6943681664446695e-08, 'epoch': 0.93}
 93%|█████████▎| 2716/2906 [8:57:17<36:46, 11.61s/it] 93%|█████████▎| 2717/2906 [8:57:29<36:35, 11.62s/it]                                                     {'loss': 0.7806, 'grad_norm': 1.352502703666687, 'learning_rate': 5.635121801876253e-08, 'epoch': 0.93}
 93%|█████████▎| 2717/2906 [8:57:29<36:35, 11.62s/it] 94%|█████████▎| 2718/2906 [8:57:41<36:46, 11.74s/it]                                                     {'loss': 0.7373, 'grad_norm': 1.2771395444869995, 'learning_rate': 5.5761817487026135e-08, 'epoch': 0.94}
 94%|█████████▎| 2718/2906 [8:57:41<36:46, 11.74s/it] 94%|█████████▎| 2719/2906 [8:57:53<36:23, 11.68s/it]                                                     {'loss': 0.7839, 'grad_norm': 1.2844654321670532, 'learning_rate': 5.5175480808051515e-08, 'epoch': 0.94}
 94%|█████████▎| 2719/2906 [8:57:53<36:23, 11.68s/it] 94%|█████████▎| 2720/2906 [8:58:05<36:44, 11.85s/it]                                                     {'loss': 0.7692, 'grad_norm': 1.208460807800293, 'learning_rate': 5.4592208716812144e-08, 'epoch': 0.94}
 94%|█████████▎| 2720/2906 [8:58:05<36:44, 11.85s/it] 94%|█████████▎| 2721/2906 [8:58:17<36:52, 11.96s/it]                                                     {'loss': 0.8041, 'grad_norm': 1.363862156867981, 'learning_rate': 5.401200194443873e-08, 'epoch': 0.94}
 94%|█████████▎| 2721/2906 [8:58:17<36:52, 11.96s/it] 94%|█████████▎| 2722/2906 [8:58:29<37:06, 12.10s/it]                                                     {'loss': 0.8575, 'grad_norm': 1.320556402206421, 'learning_rate': 5.343486121822144e-08, 'epoch': 0.94}
 94%|█████████▎| 2722/2906 [8:58:29<37:06, 12.10s/it] 94%|█████████▎| 2723/2906 [8:58:41<36:32, 11.98s/it]                                                     {'loss': 0.807, 'grad_norm': 1.2835983037948608, 'learning_rate': 5.2860787261605485e-08, 'epoch': 0.94}
 94%|█████████▎| 2723/2906 [8:58:41<36:32, 11.98s/it] 94%|█████████▎| 2724/2906 [8:58:53<36:23, 12.00s/it]                                                     {'loss': 0.8145, 'grad_norm': 1.288673996925354, 'learning_rate': 5.2289780794192726e-08, 'epoch': 0.94}
 94%|█████████▎| 2724/2906 [8:58:53<36:23, 12.00s/it] 94%|█████████▍| 2725/2906 [8:59:05<36:20, 12.05s/it]                                                     {'loss': 0.7657, 'grad_norm': 1.2727917432785034, 'learning_rate': 5.172184253174034e-08, 'epoch': 0.94}
 94%|█████████▍| 2725/2906 [8:59:05<36:20, 12.05s/it] 94%|█████████▍| 2726/2906 [8:59:17<35:40, 11.89s/it]                                                     {'loss': 0.7526, 'grad_norm': 1.2728264331817627, 'learning_rate': 5.115697318615831e-08, 'epoch': 0.94}
 94%|█████████▍| 2726/2906 [8:59:17<35:40, 11.89s/it] 94%|█████████▍| 2727/2906 [8:59:29<35:14, 11.81s/it]                                                     {'loss': 0.8067, 'grad_norm': 1.2994811534881592, 'learning_rate': 5.059517346551107e-08, 'epoch': 0.94}
 94%|█████████▍| 2727/2906 [8:59:29<35:14, 11.81s/it] 94%|█████████▍| 2728/2906 [8:59:40<35:10, 11.86s/it]                                                     {'loss': 0.7424, 'grad_norm': 1.29140305519104, 'learning_rate': 5.0036444074014204e-08, 'epoch': 0.94}
 94%|█████████▍| 2728/2906 [8:59:40<35:10, 11.86s/it] 94%|█████████▍| 2729/2906 [8:59:52<34:44, 11.78s/it]                                                     {'loss': 0.7543, 'grad_norm': 1.2506436109542847, 'learning_rate': 4.948078571203496e-08, 'epoch': 0.94}
 94%|█████████▍| 2729/2906 [8:59:52<34:44, 11.78s/it] 94%|█████████▍| 2730/2906 [9:00:04<34:23, 11.72s/it]                                                     {'loss': 0.8033, 'grad_norm': 1.2638804912567139, 'learning_rate': 4.89281990760912e-08, 'epoch': 0.94}
 94%|█████████▍| 2730/2906 [9:00:04<34:23, 11.72s/it] 94%|█████████▍| 2731/2906 [9:00:15<34:14, 11.74s/it]                                                     {'loss': 0.8347, 'grad_norm': 1.3446133136749268, 'learning_rate': 4.83786848588505e-08, 'epoch': 0.94}
 94%|█████████▍| 2731/2906 [9:00:15<34:14, 11.74s/it] 94%|█████████▍| 2732/2906 [9:00:27<34:17, 11.82s/it]                                                     {'loss': 0.8027, 'grad_norm': 1.2323936223983765, 'learning_rate': 4.783224374912909e-08, 'epoch': 0.94}
 94%|█████████▍| 2732/2906 [9:00:27<34:17, 11.82s/it] 94%|█████████▍| 2733/2906 [9:00:39<34:04, 11.82s/it]                                                     {'loss': 0.7293, 'grad_norm': 1.2709611654281616, 'learning_rate': 4.728887643189073e-08, 'epoch': 0.94}
 94%|█████████▍| 2733/2906 [9:00:39<34:04, 11.82s/it] 94%|█████████▍| 2734/2906 [9:00:51<33:42, 11.76s/it]                                                     {'loss': 0.8566, 'grad_norm': 1.4667770862579346, 'learning_rate': 4.674858358824613e-08, 'epoch': 0.94}
 94%|█████████▍| 2734/2906 [9:00:51<33:42, 11.76s/it] 94%|█████████▍| 2735/2906 [9:01:03<33:28, 11.75s/it]                                                     {'loss': 0.7415, 'grad_norm': 1.5842432975769043, 'learning_rate': 4.621136589545272e-08, 'epoch': 0.94}
 94%|█████████▍| 2735/2906 [9:01:03<33:28, 11.75s/it] 94%|█████████▍| 2736/2906 [9:01:14<33:22, 11.78s/it]                                                     {'loss': 0.8686, 'grad_norm': 1.3384555578231812, 'learning_rate': 4.567722402691321e-08, 'epoch': 0.94}
 94%|█████████▍| 2736/2906 [9:01:14<33:22, 11.78s/it] 94%|█████████▍| 2737/2906 [9:01:27<33:29, 11.89s/it]                                                     {'loss': 0.7651, 'grad_norm': 1.3813327550888062, 'learning_rate': 4.5146158652173696e-08, 'epoch': 0.94}
 94%|█████████▍| 2737/2906 [9:01:27<33:29, 11.89s/it] 94%|█████████▍| 2738/2906 [9:01:39<33:36, 12.00s/it]                                                     {'loss': 0.7209, 'grad_norm': 1.3335413932800293, 'learning_rate': 4.4618170436925565e-08, 'epoch': 0.94}
 94%|█████████▍| 2738/2906 [9:01:39<33:36, 12.00s/it] 94%|█████████▍| 2739/2906 [9:01:50<32:44, 11.76s/it]                                                     {'loss': 0.7362, 'grad_norm': 1.3951336145401, 'learning_rate': 4.4093260043001626e-08, 'epoch': 0.94}
 94%|█████████▍| 2739/2906 [9:01:50<32:44, 11.76s/it] 94%|█████████▍| 2740/2906 [9:02:01<32:14, 11.65s/it]                                                     {'loss': 0.7992, 'grad_norm': 1.3004541397094727, 'learning_rate': 4.3571428128376946e-08, 'epoch': 0.94}
 94%|█████████▍| 2740/2906 [9:02:01<32:14, 11.65s/it] 94%|█████████▍| 2741/2906 [9:02:13<31:55, 11.61s/it]                                                     {'loss': 0.7795, 'grad_norm': 1.3405935764312744, 'learning_rate': 4.305267534716828e-08, 'epoch': 0.94}
 94%|█████████▍| 2741/2906 [9:02:13<31:55, 11.61s/it] 94%|█████████▍| 2742/2906 [9:02:26<32:37, 11.94s/it]                                                     {'loss': 0.8156, 'grad_norm': 1.3493989706039429, 'learning_rate': 4.2537002349631874e-08, 'epoch': 0.94}
 94%|█████████▍| 2742/2906 [9:02:26<32:37, 11.94s/it] 94%|█████████▍| 2743/2906 [9:02:37<32:06, 11.82s/it]                                                     {'loss': 0.8477, 'grad_norm': 1.3661831617355347, 'learning_rate': 4.202440978216399e-08, 'epoch': 0.94}
 94%|█████████▍| 2743/2906 [9:02:37<32:06, 11.82s/it] 94%|█████████▍| 2744/2906 [9:02:49<32:14, 11.94s/it]                                                     {'loss': 0.7679, 'grad_norm': 1.3737757205963135, 'learning_rate': 4.1514898287299823e-08, 'epoch': 0.94}
 94%|█████████▍| 2744/2906 [9:02:49<32:14, 11.94s/it] 94%|█████████▍| 2745/2906 [9:03:01<32:03, 11.94s/it]                                                     {'loss': 0.8133, 'grad_norm': 1.3725452423095703, 'learning_rate': 4.1008468503711266e-08, 'epoch': 0.94}
 94%|█████████▍| 2745/2906 [9:03:01<32:03, 11.94s/it] 94%|█████████▍| 2746/2906 [9:03:13<31:25, 11.78s/it]                                                     {'loss': 0.7687, 'grad_norm': 1.3088113069534302, 'learning_rate': 4.050512106620913e-08, 'epoch': 0.94}
 94%|█████████▍| 2746/2906 [9:03:13<31:25, 11.78s/it] 95%|█████████▍| 2747/2906 [9:03:24<31:04, 11.73s/it]                                                     {'loss': 0.7608, 'grad_norm': 1.226536750793457, 'learning_rate': 4.000485660573872e-08, 'epoch': 0.95}
 95%|█████████▍| 2747/2906 [9:03:24<31:04, 11.73s/it] 95%|█████████▍| 2748/2906 [9:03:37<31:17, 11.88s/it]                                                     {'loss': 0.7929, 'grad_norm': 1.4207676649093628, 'learning_rate': 3.9507675749382024e-08, 'epoch': 0.95}
 95%|█████████▍| 2748/2906 [9:03:37<31:17, 11.88s/it] 95%|█████████▍| 2749/2906 [9:03:49<31:19, 11.97s/it]                                                     {'loss': 0.7371, 'grad_norm': 1.2734664678573608, 'learning_rate': 3.9013579120354696e-08, 'epoch': 0.95}
 95%|█████████▍| 2749/2906 [9:03:49<31:19, 11.97s/it] 95%|█████████▍| 2750/2906 [9:04:00<30:47, 11.85s/it]                                                     {'loss': 0.8065, 'grad_norm': 1.322462558746338, 'learning_rate': 3.852256733800769e-08, 'epoch': 0.95}
 95%|█████████▍| 2750/2906 [9:04:00<30:47, 11.85s/it] 95%|█████████▍| 2751/2906 [9:04:13<31:02, 12.01s/it]                                                     {'loss': 0.8061, 'grad_norm': 1.337783694267273, 'learning_rate': 3.803464101782367e-08, 'epoch': 0.95}
 95%|█████████▍| 2751/2906 [9:04:13<31:02, 12.01s/it] 95%|█████████▍| 2752/2906 [9:04:25<30:52, 12.03s/it]                                                     {'loss': 0.7677, 'grad_norm': 1.2825887203216553, 'learning_rate': 3.75498007714184e-08, 'epoch': 0.95}
 95%|█████████▍| 2752/2906 [9:04:25<30:52, 12.03s/it] 95%|█████████▍| 2753/2906 [9:04:37<30:36, 12.00s/it]                                                     {'loss': 0.7612, 'grad_norm': 1.3196630477905273, 'learning_rate': 3.706804720653962e-08, 'epoch': 0.95}
 95%|█████████▍| 2753/2906 [9:04:37<30:36, 12.00s/it] 95%|█████████▍| 2754/2906 [9:04:49<30:11, 11.92s/it]                                                     {'loss': 0.8211, 'grad_norm': 1.382103443145752, 'learning_rate': 3.658938092706482e-08, 'epoch': 0.95}
 95%|█████████▍| 2754/2906 [9:04:49<30:11, 11.92s/it] 95%|█████████▍| 2755/2906 [9:05:00<29:42, 11.81s/it]                                                     {'loss': 0.7224, 'grad_norm': 1.2494175434112549, 'learning_rate': 3.611380253300267e-08, 'epoch': 0.95}
 95%|█████████▍| 2755/2906 [9:05:00<29:42, 11.81s/it] 95%|█████████▍| 2756/2906 [9:05:12<29:36, 11.84s/it]                                                     {'loss': 0.7684, 'grad_norm': 1.281446933746338, 'learning_rate': 3.564131262049075e-08, 'epoch': 0.95}
 95%|█████████▍| 2756/2906 [9:05:12<29:36, 11.84s/it] 95%|█████████▍| 2757/2906 [9:05:23<28:57, 11.66s/it]                                                     {'loss': 0.7369, 'grad_norm': 1.3496100902557373, 'learning_rate': 3.517191178179474e-08, 'epoch': 0.95}
 95%|█████████▍| 2757/2906 [9:05:23<28:57, 11.66s/it] 95%|█████████▍| 2758/2906 [9:05:35<28:32, 11.57s/it]                                                     {'loss': 0.7938, 'grad_norm': 1.38158118724823, 'learning_rate': 3.470560060530953e-08, 'epoch': 0.95}
 95%|█████████▍| 2758/2906 [9:05:35<28:32, 11.57s/it] 95%|█████████▍| 2759/2906 [9:05:46<28:30, 11.64s/it]                                                     {'loss': 0.8077, 'grad_norm': 1.3379199504852295, 'learning_rate': 3.4242379675555046e-08, 'epoch': 0.95}
 95%|█████████▍| 2759/2906 [9:05:46<28:30, 11.64s/it] 95%|█████████▍| 2760/2906 [9:05:58<27:58, 11.50s/it]                                                     {'loss': 0.8062, 'grad_norm': 1.364719271659851, 'learning_rate': 3.3782249573179884e-08, 'epoch': 0.95}
 95%|█████████▍| 2760/2906 [9:05:58<27:58, 11.50s/it] 95%|█████████▌| 2761/2906 [9:06:09<27:47, 11.50s/it]                                                     {'loss': 0.8503, 'grad_norm': 1.3650456666946411, 'learning_rate': 3.332521087495627e-08, 'epoch': 0.95}
 95%|█████████▌| 2761/2906 [9:06:09<27:47, 11.50s/it] 95%|█████████▌| 2762/2906 [9:06:21<27:49, 11.59s/it]                                                     {'loss': 0.7939, 'grad_norm': 1.30885648727417, 'learning_rate': 3.287126415378261e-08, 'epoch': 0.95}
 95%|█████████▌| 2762/2906 [9:06:21<27:49, 11.59s/it] 95%|█████████▌| 2763/2906 [9:06:33<27:42, 11.63s/it]                                                     {'loss': 0.7854, 'grad_norm': 1.3460662364959717, 'learning_rate': 3.242040997868123e-08, 'epoch': 0.95}
 95%|█████████▌| 2763/2906 [9:06:33<27:42, 11.63s/it] 95%|█████████▌| 2764/2906 [9:06:45<27:46, 11.73s/it]                                                     {'loss': 0.755, 'grad_norm': 1.240177035331726, 'learning_rate': 3.1972648914797844e-08, 'epoch': 0.95}
 95%|█████████▌| 2764/2906 [9:06:45<27:46, 11.73s/it] 95%|█████████▌| 2765/2906 [9:06:56<27:24, 11.66s/it]                                                     {'loss': 0.7458, 'grad_norm': 1.3417956829071045, 'learning_rate': 3.1527981523400974e-08, 'epoch': 0.95}
 95%|█████████▌| 2765/2906 [9:06:56<27:24, 11.66s/it] 95%|█████████▌| 2766/2906 [9:07:08<27:08, 11.63s/it]                                                     {'loss': 0.7549, 'grad_norm': 1.2995433807373047, 'learning_rate': 3.108640836188115e-08, 'epoch': 0.95}
 95%|█████████▌| 2766/2906 [9:07:08<27:08, 11.63s/it] 95%|█████████▌| 2767/2906 [9:07:20<27:18, 11.78s/it]                                                     {'loss': 0.7301, 'grad_norm': 1.1671644449234009, 'learning_rate': 3.064792998375032e-08, 'epoch': 0.95}
 95%|█████████▌| 2767/2906 [9:07:20<27:18, 11.78s/it] 95%|█████████▌| 2768/2906 [9:07:32<27:12, 11.83s/it]                                                     {'loss': 0.8044, 'grad_norm': 1.2991381883621216, 'learning_rate': 3.021254693864162e-08, 'epoch': 0.95}
 95%|█████████▌| 2768/2906 [9:07:32<27:12, 11.83s/it] 95%|█████████▌| 2769/2906 [9:07:44<27:07, 11.88s/it]                                                     {'loss': 0.7834, 'grad_norm': 1.2537720203399658, 'learning_rate': 2.9780259772307362e-08, 'epoch': 0.95}
 95%|█████████▌| 2769/2906 [9:07:44<27:07, 11.88s/it] 95%|█████████▌| 2770/2906 [9:07:55<26:26, 11.67s/it]                                                     {'loss': 0.765, 'grad_norm': 1.3266226053237915, 'learning_rate': 2.9351069026619107e-08, 'epoch': 0.95}
 95%|█████████▌| 2770/2906 [9:07:55<26:26, 11.67s/it] 95%|█████████▌| 2771/2906 [9:08:07<26:29, 11.77s/it]                                                     {'loss': 0.8373, 'grad_norm': 1.2439987659454346, 'learning_rate': 2.8924975239568444e-08, 'epoch': 0.95}
 95%|█████████▌| 2771/2906 [9:08:07<26:29, 11.77s/it] 95%|█████████▌| 2772/2906 [9:08:19<26:28, 11.85s/it]                                                     {'loss': 0.7624, 'grad_norm': 1.324546217918396, 'learning_rate': 2.8501978945263132e-08, 'epoch': 0.95}
 95%|█████████▌| 2772/2906 [9:08:19<26:28, 11.85s/it] 95%|█████████▌| 2773/2906 [9:08:31<26:29, 11.95s/it]                                                     {'loss': 0.8033, 'grad_norm': 1.3576613664627075, 'learning_rate': 2.8082080673929312e-08, 'epoch': 0.95}
 95%|█████████▌| 2773/2906 [9:08:31<26:29, 11.95s/it] 95%|█████████▌| 2774/2906 [9:08:42<25:45, 11.71s/it]                                                     {'loss': 0.7077, 'grad_norm': 1.3221721649169922, 'learning_rate': 2.7665280951909847e-08, 'epoch': 0.95}
 95%|█████████▌| 2774/2906 [9:08:42<25:45, 11.71s/it] 95%|█████████▌| 2775/2906 [9:08:54<25:45, 11.80s/it]                                                     {'loss': 0.8198, 'grad_norm': 1.3863496780395508, 'learning_rate': 2.7251580301662916e-08, 'epoch': 0.95}
 95%|█████████▌| 2775/2906 [9:08:54<25:45, 11.80s/it] 96%|█████████▌| 2776/2906 [9:09:06<25:48, 11.91s/it]                                                     {'loss': 0.7813, 'grad_norm': 1.2471859455108643, 'learning_rate': 2.68409792417626e-08, 'epoch': 0.96}
 96%|█████████▌| 2776/2906 [9:09:06<25:48, 11.91s/it] 96%|█████████▌| 2777/2906 [9:09:18<25:12, 11.72s/it]                                                     {'loss': 0.7608, 'grad_norm': 1.2598916292190552, 'learning_rate': 2.643347828689663e-08, 'epoch': 0.96}
 96%|█████████▌| 2777/2906 [9:09:18<25:12, 11.72s/it] 96%|█████████▌| 2778/2906 [9:09:29<24:56, 11.69s/it]                                                     {'loss': 0.7191, 'grad_norm': 1.3248683214187622, 'learning_rate': 2.6029077947868354e-08, 'epoch': 0.96}
 96%|█████████▌| 2778/2906 [9:09:29<24:56, 11.69s/it] 96%|█████████▌| 2779/2906 [9:09:41<24:46, 11.70s/it]                                                     {'loss': 0.7963, 'grad_norm': 1.3110122680664062, 'learning_rate': 2.562777873159311e-08, 'epoch': 0.96}
 96%|█████████▌| 2779/2906 [9:09:41<24:46, 11.70s/it] 96%|█████████▌| 2780/2906 [9:09:53<24:35, 11.71s/it]                                                     {'loss': 0.8244, 'grad_norm': 1.2950363159179688, 'learning_rate': 2.5229581141099635e-08, 'epoch': 0.96}
 96%|█████████▌| 2780/2906 [9:09:53<24:35, 11.71s/it] 96%|█████████▌| 2781/2906 [9:10:04<24:10, 11.61s/it]                                                     {'loss': 0.7873, 'grad_norm': 1.3579405546188354, 'learning_rate': 2.4834485675528653e-08, 'epoch': 0.96}
 96%|█████████▌| 2781/2906 [9:10:04<24:10, 11.61s/it] 96%|█████████▌| 2782/2906 [9:10:17<24:28, 11.84s/it]                                                     {'loss': 0.7816, 'grad_norm': 1.2885818481445312, 'learning_rate': 2.4442492830132337e-08, 'epoch': 0.96}
 96%|█████████▌| 2782/2906 [9:10:17<24:28, 11.84s/it] 96%|█████████▌| 2783/2906 [9:10:28<24:01, 11.72s/it]                                                     {'loss': 0.7516, 'grad_norm': 1.2862496376037598, 'learning_rate': 2.4053603096274027e-08, 'epoch': 0.96}
 96%|█████████▌| 2783/2906 [9:10:28<24:01, 11.72s/it] 96%|█████████▌| 2784/2906 [9:10:40<24:03, 11.83s/it]                                                     {'loss': 0.7852, 'grad_norm': 1.3282561302185059, 'learning_rate': 2.3667816961426558e-08, 'epoch': 0.96}
 96%|█████████▌| 2784/2906 [9:10:40<24:03, 11.83s/it] 96%|█████████▌| 2785/2906 [9:10:52<24:04, 11.94s/it]                                                     {'loss': 0.8241, 'grad_norm': 1.3062224388122559, 'learning_rate': 2.3285134909173113e-08, 'epoch': 0.96}
 96%|█████████▌| 2785/2906 [9:10:52<24:04, 11.94s/it] 96%|█████████▌| 2786/2906 [9:11:05<24:05, 12.04s/it]                                                     {'loss': 0.8309, 'grad_norm': 1.4089434146881104, 'learning_rate': 2.2905557419205805e-08, 'epoch': 0.96}
 96%|█████████▌| 2786/2906 [9:11:05<24:05, 12.04s/it] 96%|█████████▌| 2787/2906 [9:11:16<23:46, 11.99s/it]                                                     {'loss': 0.7418, 'grad_norm': 1.3820204734802246, 'learning_rate': 2.2529084967324867e-08, 'epoch': 0.96}
 96%|█████████▌| 2787/2906 [9:11:16<23:46, 11.99s/it] 96%|█████████▌| 2788/2906 [9:11:28<23:26, 11.92s/it]                                                     {'loss': 0.831, 'grad_norm': 1.308413028717041, 'learning_rate': 2.2155718025438368e-08, 'epoch': 0.96}
 96%|█████████▌| 2788/2906 [9:11:28<23:26, 11.92s/it] 96%|█████████▌| 2789/2906 [9:11:40<22:58, 11.78s/it]                                                     {'loss': 0.8217, 'grad_norm': 1.368886947631836, 'learning_rate': 2.178545706156221e-08, 'epoch': 0.96}
 96%|█████████▌| 2789/2906 [9:11:40<22:58, 11.78s/it] 96%|█████████▌| 2790/2906 [9:11:51<22:42, 11.75s/it]                                                     {'loss': 0.7476, 'grad_norm': 1.3527077436447144, 'learning_rate': 2.141830253981847e-08, 'epoch': 0.96}
 96%|█████████▌| 2790/2906 [9:11:51<22:42, 11.75s/it] 96%|█████████▌| 2791/2906 [9:12:03<22:21, 11.66s/it]                                                     {'loss': 0.8298, 'grad_norm': 1.3097221851348877, 'learning_rate': 2.105425492043539e-08, 'epoch': 0.96}
 96%|█████████▌| 2791/2906 [9:12:03<22:21, 11.66s/it] 96%|█████████▌| 2792/2906 [9:12:14<22:00, 11.58s/it]                                                     {'loss': 0.7909, 'grad_norm': 1.2722525596618652, 'learning_rate': 2.0693314659746276e-08, 'epoch': 0.96}
 96%|█████████▌| 2792/2906 [9:12:14<22:00, 11.58s/it] 96%|█████████▌| 2793/2906 [9:12:26<21:46, 11.56s/it]                                                     {'loss': 0.7845, 'grad_norm': 1.3734513521194458, 'learning_rate': 2.0335482210190327e-08, 'epoch': 0.96}
 96%|█████████▌| 2793/2906 [9:12:26<21:46, 11.56s/it] 96%|█████████▌| 2794/2906 [9:12:38<21:46, 11.66s/it]                                                     {'loss': 0.7973, 'grad_norm': 1.3183176517486572, 'learning_rate': 1.9980758020309853e-08, 'epoch': 0.96}
 96%|█████████▌| 2794/2906 [9:12:38<21:46, 11.66s/it] 96%|█████████▌| 2795/2906 [9:12:50<21:57, 11.87s/it]                                                     {'loss': 0.7369, 'grad_norm': 1.2347452640533447, 'learning_rate': 1.962914253475251e-08, 'epoch': 0.96}
 96%|█████████▌| 2795/2906 [9:12:50<21:57, 11.87s/it] 96%|█████████▌| 2796/2906 [9:13:01<21:24, 11.68s/it]                                                     {'loss': 0.8152, 'grad_norm': 1.33145272731781, 'learning_rate': 1.9280636194267677e-08, 'epoch': 0.96}
 96%|█████████▌| 2796/2906 [9:13:01<21:24, 11.68s/it] 96%|█████████▌| 2797/2906 [9:13:13<21:23, 11.77s/it]                                                     {'loss': 0.7801, 'grad_norm': 1.3097249269485474, 'learning_rate': 1.893523943570841e-08, 'epoch': 0.96}
 96%|█████████▌| 2797/2906 [9:13:13<21:23, 11.77s/it] 96%|█████████▋| 2798/2906 [9:13:25<21:04, 11.71s/it]                                                     {'loss': 0.7564, 'grad_norm': 1.2883154153823853, 'learning_rate': 1.8592952692029486e-08, 'epoch': 0.96}
 96%|█████████▋| 2798/2906 [9:13:25<21:04, 11.71s/it] 96%|█████████▋| 2799/2906 [9:13:37<21:06, 11.84s/it]                                                     {'loss': 0.7835, 'grad_norm': 1.2836694717407227, 'learning_rate': 1.8253776392287147e-08, 'epoch': 0.96}
 96%|█████████▋| 2799/2906 [9:13:37<21:06, 11.84s/it] 96%|█████████▋| 2800/2906 [9:13:49<21:02, 11.91s/it]                                                     {'loss': 0.8506, 'grad_norm': 1.3681464195251465, 'learning_rate': 1.7917710961639356e-08, 'epoch': 0.96}
 96%|█████████▋| 2800/2906 [9:13:49<21:02, 11.91s/it] 96%|█████████▋| 2801/2906 [9:14:00<20:27, 11.69s/it]                                                     {'loss': 0.7574, 'grad_norm': 1.2883150577545166, 'learning_rate': 1.7584756821343864e-08, 'epoch': 0.96}
 96%|█████████▋| 2801/2906 [9:14:00<20:27, 11.69s/it] 96%|█████████▋| 2802/2906 [9:14:12<20:10, 11.64s/it]                                                     {'loss': 0.8066, 'grad_norm': 1.3360000848770142, 'learning_rate': 1.7254914388758758e-08, 'epoch': 0.96}
 96%|█████████▋| 2802/2906 [9:14:12<20:10, 11.64s/it] 96%|█████████▋| 2803/2906 [9:14:23<19:51, 11.57s/it]                                                     {'loss': 0.7219, 'grad_norm': 1.2673380374908447, 'learning_rate': 1.692818407734165e-08, 'epoch': 0.96}
 96%|█████████▋| 2803/2906 [9:14:23<19:51, 11.57s/it] 96%|█████████▋| 2804/2906 [9:14:35<19:51, 11.68s/it]                                                     {'loss': 0.8138, 'grad_norm': 1.2969073057174683, 'learning_rate': 1.6604566296649083e-08, 'epoch': 0.96}
 96%|█████████▋| 2804/2906 [9:14:35<19:51, 11.68s/it] 97%|█████████▋| 2805/2906 [9:14:47<19:35, 11.64s/it]                                                     {'loss': 0.7409, 'grad_norm': 1.237508773803711, 'learning_rate': 1.6284061452335464e-08, 'epoch': 0.97}
 97%|█████████▋| 2805/2906 [9:14:47<19:35, 11.64s/it] 97%|█████████▋| 2806/2906 [9:14:58<19:18, 11.59s/it]                                                     {'loss': 0.6801, 'grad_norm': 1.2159717082977295, 'learning_rate': 1.5966669946154146e-08, 'epoch': 0.97}
 97%|█████████▋| 2806/2906 [9:14:58<19:18, 11.59s/it] 97%|█████████▋| 2807/2906 [9:15:10<19:18, 11.70s/it]                                                     {'loss': 0.8411, 'grad_norm': 1.3572134971618652, 'learning_rate': 1.565239217595549e-08, 'epoch': 0.97}
 97%|█████████▋| 2807/2906 [9:15:10<19:18, 11.70s/it] 97%|█████████▋| 2808/2906 [9:15:22<19:03, 11.67s/it]                                                     {'loss': 0.7795, 'grad_norm': 1.2344613075256348, 'learning_rate': 1.5341228535686037e-08, 'epoch': 0.97}
 97%|█████████▋| 2808/2906 [9:15:22<19:03, 11.67s/it] 97%|█████████▋| 2809/2906 [9:15:33<19:00, 11.75s/it]                                                     {'loss': 0.8276, 'grad_norm': 1.2600702047348022, 'learning_rate': 1.5033179415390176e-08, 'epoch': 0.97}
 97%|█████████▋| 2809/2906 [9:15:34<19:00, 11.75s/it] 97%|█████████▋| 2810/2906 [9:15:45<18:40, 11.68s/it]                                                     {'loss': 0.7826, 'grad_norm': 1.2943321466445923, 'learning_rate': 1.4728245201207358e-08, 'epoch': 0.97}
 97%|█████████▋| 2810/2906 [9:15:45<18:40, 11.68s/it] 97%|█████████▋| 2811/2906 [9:15:57<18:36, 11.76s/it]                                                     {'loss': 0.7955, 'grad_norm': 1.3083124160766602, 'learning_rate': 1.4426426275372385e-08, 'epoch': 0.97}
 97%|█████████▋| 2811/2906 [9:15:57<18:36, 11.76s/it] 97%|█████████▋| 2812/2906 [9:16:08<18:07, 11.57s/it]                                                     {'loss': 0.8208, 'grad_norm': 1.357918620109558, 'learning_rate': 1.41277230162154e-08, 'epoch': 0.97}
 97%|█████████▋| 2812/2906 [9:16:08<18:07, 11.57s/it] 97%|█████████▋| 2813/2906 [9:16:20<18:05, 11.67s/it]                                                     {'loss': 0.7899, 'grad_norm': 1.3252607583999634, 'learning_rate': 1.3832135798160783e-08, 'epoch': 0.97}
 97%|█████████▋| 2813/2906 [9:16:20<18:05, 11.67s/it] 97%|█████████▋| 2814/2906 [9:16:31<17:29, 11.41s/it]                                                     {'loss': 0.808, 'grad_norm': 1.3049815893173218, 'learning_rate': 1.3539664991727431e-08, 'epoch': 0.97}
 97%|█████████▋| 2814/2906 [9:16:31<17:29, 11.41s/it] 97%|█████████▋| 2815/2906 [9:16:42<17:23, 11.46s/it]                                                     {'loss': 0.8397, 'grad_norm': 1.3872748613357544, 'learning_rate': 1.3250310963527358e-08, 'epoch': 0.97}
 97%|█████████▋| 2815/2906 [9:16:42<17:23, 11.46s/it] 97%|█████████▋| 2816/2906 [9:16:54<17:10, 11.45s/it]                                                     {'loss': 0.841, 'grad_norm': 1.3336957693099976, 'learning_rate': 1.2964074076265986e-08, 'epoch': 0.97}
 97%|█████████▋| 2816/2906 [9:16:54<17:10, 11.45s/it] 97%|█████████▋| 2817/2906 [9:17:06<17:08, 11.56s/it]                                                     {'loss': 0.8126, 'grad_norm': 1.345725655555725, 'learning_rate': 1.268095468874131e-08, 'epoch': 0.97}
 97%|█████████▋| 2817/2906 [9:17:06<17:08, 11.56s/it] 97%|█████████▋| 2818/2906 [9:17:17<16:43, 11.41s/it]                                                     {'loss': 0.7935, 'grad_norm': 1.4477308988571167, 'learning_rate': 1.2400953155843332e-08, 'epoch': 0.97}
 97%|█████████▋| 2818/2906 [9:17:17<16:43, 11.41s/it] 97%|█████████▋| 2819/2906 [9:17:29<16:46, 11.57s/it]                                                     {'loss': 0.808, 'grad_norm': 1.4155490398406982, 'learning_rate': 1.2124069828554075e-08, 'epoch': 0.97}
 97%|█████████▋| 2819/2906 [9:17:29<16:46, 11.57s/it] 97%|█████████▋| 2820/2906 [9:17:40<16:32, 11.54s/it]                                                     {'loss': 0.8113, 'grad_norm': 1.274346947669983, 'learning_rate': 1.185030505394702e-08, 'epoch': 0.97}
 97%|█████████▋| 2820/2906 [9:17:40<16:32, 11.54s/it] 97%|█████████▋| 2821/2906 [9:17:52<16:24, 11.58s/it]                                                     {'loss': 0.7653, 'grad_norm': 1.273787021636963, 'learning_rate': 1.1579659175185998e-08, 'epoch': 0.97}
 97%|█████████▋| 2821/2906 [9:17:52<16:24, 11.58s/it] 97%|█████████▋| 2822/2906 [9:18:03<16:10, 11.56s/it]                                                     {'loss': 0.7652, 'grad_norm': 1.2749714851379395, 'learning_rate': 1.1312132531525744e-08, 'epoch': 0.97}
 97%|█████████▋| 2822/2906 [9:18:03<16:10, 11.56s/it] 97%|█████████▋| 2823/2906 [9:18:15<15:53, 11.49s/it]                                                     {'loss': 0.8522, 'grad_norm': 1.3531739711761475, 'learning_rate': 1.1047725458310788e-08, 'epoch': 0.97}
 97%|█████████▋| 2823/2906 [9:18:15<15:53, 11.49s/it] 97%|█████████▋| 2824/2906 [9:18:26<15:43, 11.50s/it]                                                     {'loss': 0.7669, 'grad_norm': 1.226982831954956, 'learning_rate': 1.078643828697573e-08, 'epoch': 0.97}
 97%|█████████▋| 2824/2906 [9:18:26<15:43, 11.50s/it] 97%|█████████▋| 2825/2906 [9:18:38<15:49, 11.72s/it]                                                     {'loss': 0.8797, 'grad_norm': 1.4383091926574707, 'learning_rate': 1.0528271345044139e-08, 'epoch': 0.97}
 97%|█████████▋| 2825/2906 [9:18:38<15:49, 11.72s/it] 97%|█████████▋| 2826/2906 [9:18:50<15:31, 11.64s/it]                                                     {'loss': 0.7386, 'grad_norm': 1.3211568593978882, 'learning_rate': 1.0273224956127703e-08, 'epoch': 0.97}
 97%|█████████▋| 2826/2906 [9:18:50<15:31, 11.64s/it] 97%|█████████▋| 2827/2906 [9:19:02<15:29, 11.76s/it]                                                     {'loss': 0.7925, 'grad_norm': 1.2997804880142212, 'learning_rate': 1.0021299439927635e-08, 'epoch': 0.97}
 97%|█████████▋| 2827/2906 [9:19:02<15:29, 11.76s/it] 97%|█████████▋| 2828/2906 [9:19:13<15:14, 11.72s/it]                                                     {'loss': 0.8001, 'grad_norm': 1.3333642482757568, 'learning_rate': 9.772495112232438e-09, 'epoch': 0.97}
 97%|█████████▋| 2828/2906 [9:19:13<15:14, 11.72s/it] 97%|█████████▋| 2829/2906 [9:19:25<15:03, 11.73s/it]                                                     {'loss': 0.7735, 'grad_norm': 2.695584774017334, 'learning_rate': 9.526812284918196e-09, 'epoch': 0.97}
 97%|█████████▋| 2829/2906 [9:19:25<15:03, 11.73s/it] 97%|█████████▋| 2830/2906 [9:19:37<14:49, 11.70s/it]                                                     {'loss': 0.7777, 'grad_norm': 1.3211781978607178, 'learning_rate': 9.28425126594884e-09, 'epoch': 0.97}
 97%|█████████▋| 2830/2906 [9:19:37<14:49, 11.70s/it] 97%|█████████▋| 2831/2906 [9:19:49<14:46, 11.83s/it]                                                     {'loss': 0.8625, 'grad_norm': 1.293043851852417, 'learning_rate': 9.044812359373933e-09, 'epoch': 0.97}
 97%|█████████▋| 2831/2906 [9:19:49<14:46, 11.83s/it] 97%|█████████▋| 2832/2906 [9:20:01<14:39, 11.88s/it]                                                     {'loss': 0.7372, 'grad_norm': 1.1741701364517212, 'learning_rate': 8.808495865330613e-09, 'epoch': 0.97}
 97%|█████████▋| 2832/2906 [9:20:01<14:39, 11.88s/it] 97%|█████████▋| 2833/2906 [9:20:12<14:14, 11.70s/it]                                                     {'loss': 0.7799, 'grad_norm': 1.281296968460083, 'learning_rate': 8.575302080041648e-09, 'epoch': 0.97}
 97%|█████████▋| 2833/2906 [9:20:12<14:14, 11.70s/it] 98%|█████████▊| 2834/2906 [9:20:24<13:56, 11.62s/it]                                                     {'loss': 0.791, 'grad_norm': 1.3691279888153076, 'learning_rate': 8.34523129581516e-09, 'epoch': 0.98}
 98%|█████████▊| 2834/2906 [9:20:24<13:56, 11.62s/it] 98%|█████████▊| 2835/2906 [9:20:35<13:30, 11.41s/it]                                                     {'loss': 0.8223, 'grad_norm': 1.3701691627502441, 'learning_rate': 8.118283801045179e-09, 'epoch': 0.98}
 98%|█████████▊| 2835/2906 [9:20:35<13:30, 11.41s/it] 98%|█████████▊| 2836/2906 [9:20:46<13:27, 11.54s/it]                                                     {'loss': 0.8227, 'grad_norm': 1.359089970588684, 'learning_rate': 7.894459880210258e-09, 'epoch': 0.98}
 98%|█████████▊| 2836/2906 [9:20:46<13:27, 11.54s/it] 98%|█████████▊| 2837/2906 [9:20:58<13:13, 11.50s/it]                                                     {'loss': 0.8216, 'grad_norm': 1.3077201843261719, 'learning_rate': 7.673759813873749e-09, 'epoch': 0.98}
 98%|█████████▊| 2837/2906 [9:20:58<13:13, 11.50s/it] 98%|█████████▊| 2838/2906 [9:21:09<12:59, 11.47s/it]                                                     {'loss': 0.8111, 'grad_norm': 1.2759158611297607, 'learning_rate': 7.456183878683243e-09, 'epoch': 0.98}
 98%|█████████▊| 2838/2906 [9:21:09<12:59, 11.47s/it] 98%|█████████▊| 2839/2906 [9:21:21<13:02, 11.67s/it]                                                     {'loss': 0.7592, 'grad_norm': 1.278886079788208, 'learning_rate': 7.2417323473703005e-09, 'epoch': 0.98}
 98%|█████████▊| 2839/2906 [9:21:21<13:02, 11.67s/it] 98%|█████████▊| 2840/2906 [9:21:33<12:45, 11.60s/it]                                                     {'loss': 0.7661, 'grad_norm': 1.3057279586791992, 'learning_rate': 7.030405488749614e-09, 'epoch': 0.98}
 98%|█████████▊| 2840/2906 [9:21:33<12:45, 11.60s/it] 98%|█████████▊| 2841/2906 [9:21:44<12:31, 11.56s/it]                                                     {'loss': 0.7668, 'grad_norm': 1.293190836906433, 'learning_rate': 6.8222035677195655e-09, 'epoch': 0.98}
 98%|█████████▊| 2841/2906 [9:21:44<12:31, 11.56s/it] 98%|█████████▊| 2842/2906 [9:21:57<12:34, 11.79s/it]                                                     {'loss': 0.7713, 'grad_norm': 1.3007532358169556, 'learning_rate': 6.6171268452613905e-09, 'epoch': 0.98}
 98%|█████████▊| 2842/2906 [9:21:57<12:34, 11.79s/it] 98%|█████████▊| 2843/2906 [9:22:08<12:10, 11.59s/it]                                                     {'loss': 0.7497, 'grad_norm': 1.3428245782852173, 'learning_rate': 6.415175578438626e-09, 'epoch': 0.98}
 98%|█████████▊| 2843/2906 [9:22:08<12:10, 11.59s/it] 98%|█████████▊| 2844/2906 [9:22:19<12:00, 11.62s/it]                                                     {'loss': 0.8165, 'grad_norm': 1.3456618785858154, 'learning_rate': 6.216350020397388e-09, 'epoch': 0.98}
 98%|█████████▊| 2844/2906 [9:22:19<12:00, 11.62s/it] 98%|█████████▊| 2845/2906 [9:22:31<11:48, 11.61s/it]                                                     {'loss': 0.8317, 'grad_norm': 1.4084447622299194, 'learning_rate': 6.0206504203652595e-09, 'epoch': 0.98}
 98%|█████████▊| 2845/2906 [9:22:31<11:48, 11.61s/it] 98%|█████████▊| 2846/2906 [9:22:42<11:30, 11.51s/it]                                                     {'loss': 0.7828, 'grad_norm': 1.3357385396957397, 'learning_rate': 5.828077023651846e-09, 'epoch': 0.98}
 98%|█████████▊| 2846/2906 [9:22:42<11:30, 11.51s/it] 98%|█████████▊| 2847/2906 [9:22:54<11:17, 11.49s/it]                                                     {'loss': 0.7793, 'grad_norm': 1.4169102907180786, 'learning_rate': 5.638630071648221e-09, 'epoch': 0.98}
 98%|█████████▊| 2847/2906 [9:22:54<11:17, 11.49s/it] 98%|█████████▊| 2848/2906 [9:23:06<11:13, 11.60s/it]                                                     {'loss': 0.8089, 'grad_norm': 1.3900033235549927, 'learning_rate': 5.45230980182554e-09, 'epoch': 0.98}
 98%|█████████▊| 2848/2906 [9:23:06<11:13, 11.60s/it] 98%|█████████▊| 2849/2906 [9:23:17<10:57, 11.54s/it]                                                     {'loss': 0.8163, 'grad_norm': 1.411001205444336, 'learning_rate': 5.2691164477367e-09, 'epoch': 0.98}
 98%|█████████▊| 2849/2906 [9:23:17<10:57, 11.54s/it] 98%|█████████▊| 2850/2906 [9:23:28<10:44, 11.51s/it]                                                     {'loss': 0.7887, 'grad_norm': 1.2771434783935547, 'learning_rate': 5.089050239014681e-09, 'epoch': 0.98}
 98%|█████████▊| 2850/2906 [9:23:28<10:44, 11.51s/it] 98%|█████████▊| 2851/2906 [9:23:40<10:36, 11.58s/it]                                                     {'loss': 0.7776, 'grad_norm': 1.3376363515853882, 'learning_rate': 4.9121114013719886e-09, 'epoch': 0.98}
 98%|█████████▊| 2851/2906 [9:23:40<10:36, 11.58s/it] 98%|█████████▊| 2852/2906 [9:23:51<10:18, 11.46s/it]                                                     {'loss': 0.7968, 'grad_norm': 1.3146742582321167, 'learning_rate': 4.738300156602038e-09, 'epoch': 0.98}
 98%|█████████▊| 2852/2906 [9:23:51<10:18, 11.46s/it] 98%|█████████▊| 2853/2906 [9:24:03<10:02, 11.38s/it]                                                     {'loss': 0.7371, 'grad_norm': 1.3603233098983765, 'learning_rate': 4.5676167225766625e-09, 'epoch': 0.98}
 98%|█████████▊| 2853/2906 [9:24:03<10:02, 11.38s/it] 98%|█████████▊| 2854/2906 [9:24:15<10:00, 11.55s/it]                                                     {'loss': 0.7923, 'grad_norm': 1.2224767208099365, 'learning_rate': 4.40006131324805e-09, 'epoch': 0.98}
 98%|█████████▊| 2854/2906 [9:24:15<10:00, 11.55s/it] 98%|█████████▊| 2855/2906 [9:24:26<09:50, 11.57s/it]                                                     {'loss': 0.7522, 'grad_norm': 1.339548110961914, 'learning_rate': 4.2356341386468045e-09, 'epoch': 0.98}
 98%|█████████▊| 2855/2906 [9:24:26<09:50, 11.57s/it] 98%|█████████▊| 2856/2906 [9:24:38<09:39, 11.58s/it]                                                     {'loss': 0.7996, 'grad_norm': 1.3220655918121338, 'learning_rate': 4.0743354048822235e-09, 'epoch': 0.98}
 98%|█████████▊| 2856/2906 [9:24:38<09:39, 11.58s/it] 98%|█████████▊| 2857/2906 [9:24:50<09:35, 11.74s/it]                                                     {'loss': 0.7162, 'grad_norm': 1.2677327394485474, 'learning_rate': 3.916165314142295e-09, 'epoch': 0.98}
 98%|█████████▊| 2857/2906 [9:24:50<09:35, 11.74s/it] 98%|█████████▊| 2858/2906 [9:25:02<09:28, 11.84s/it]                                                     {'loss': 0.7569, 'grad_norm': 1.3252135515213013, 'learning_rate': 3.7611240646937e-09, 'epoch': 0.98}
 98%|█████████▊| 2858/2906 [9:25:02<09:28, 11.84s/it] 98%|█████████▊| 2859/2906 [9:25:14<09:13, 11.78s/it]                                                     {'loss': 0.8288, 'grad_norm': 1.3299275636672974, 'learning_rate': 3.609211850879868e-09, 'epoch': 0.98}
 98%|█████████▊| 2859/2906 [9:25:14<09:13, 11.78s/it] 98%|█████████▊| 2860/2906 [9:25:25<09:02, 11.79s/it]                                                     {'loss': 0.8419, 'grad_norm': 1.3396472930908203, 'learning_rate': 3.460428863123477e-09, 'epoch': 0.98}
 98%|█████████▊| 2860/2906 [9:25:25<09:02, 11.79s/it] 98%|█████████▊| 2861/2906 [9:25:37<08:50, 11.79s/it]                                                     {'loss': 0.8538, 'grad_norm': 1.3394750356674194, 'learning_rate': 3.3147752879236773e-09, 'epoch': 0.98}
 98%|█████████▊| 2861/2906 [9:25:37<08:50, 11.79s/it] 98%|█████████▊| 2862/2906 [9:25:49<08:40, 11.83s/it]                                                     {'loss': 0.7514, 'grad_norm': 1.2579673528671265, 'learning_rate': 3.172251307857477e-09, 'epoch': 0.98}
 98%|█████████▊| 2862/2906 [9:25:49<08:40, 11.83s/it] 99%|█████████▊| 2863/2906 [9:26:00<08:22, 11.69s/it]                                                     {'loss': 0.8393, 'grad_norm': 1.3185571432113647, 'learning_rate': 3.032857101578357e-09, 'epoch': 0.99}
 99%|█████████▊| 2863/2906 [9:26:00<08:22, 11.69s/it] 99%|█████████▊| 2864/2906 [9:26:12<08:07, 11.60s/it]                                                     {'loss': 0.9048, 'grad_norm': 1.4133191108703613, 'learning_rate': 2.896592843817103e-09, 'epoch': 0.99}
 99%|█████████▊| 2864/2906 [9:26:12<08:07, 11.60s/it] 99%|█████████▊| 2865/2906 [9:26:23<07:48, 11.42s/it]                                                     {'loss': 0.8558, 'grad_norm': 1.398635745048523, 'learning_rate': 2.7634587053809723e-09, 'epoch': 0.99}
 99%|█████████▊| 2865/2906 [9:26:23<07:48, 11.42s/it] 99%|█████████▊| 2866/2906 [9:26:34<07:36, 11.42s/it]                                                     {'loss': 0.7673, 'grad_norm': 1.2299402952194214, 'learning_rate': 2.633454853153694e-09, 'epoch': 0.99}
 99%|█████████▊| 2866/2906 [9:26:34<07:36, 11.42s/it] 99%|█████████▊| 2867/2906 [9:26:46<07:30, 11.55s/it]                                                     {'loss': 0.7886, 'grad_norm': 1.2486008405685425, 'learning_rate': 2.5065814500951914e-09, 'epoch': 0.99}
 99%|█████████▊| 2867/2906 [9:26:46<07:30, 11.55s/it] 99%|█████████▊| 2868/2906 [9:26:57<07:16, 11.50s/it]                                                     {'loss': 0.7982, 'grad_norm': 1.401445746421814, 'learning_rate': 2.3828386552410267e-09, 'epoch': 0.99}
 99%|█████████▊| 2868/2906 [9:26:57<07:16, 11.50s/it] 99%|█████████▊| 2869/2906 [9:27:09<07:05, 11.50s/it]                                                     {'loss': 0.7778, 'grad_norm': 1.2993097305297852, 'learning_rate': 2.2622266237029565e-09, 'epoch': 0.99}
 99%|█████████▊| 2869/2906 [9:27:09<07:05, 11.50s/it] 99%|█████████▉| 2870/2906 [9:27:20<06:50, 11.39s/it]                                                     {'loss': 0.8213, 'grad_norm': 1.3368326425552368, 'learning_rate': 2.1447455066681e-09, 'epoch': 0.99}
 99%|█████████▉| 2870/2906 [9:27:20<06:50, 11.39s/it] 99%|█████████▉| 2871/2906 [9:27:31<06:37, 11.37s/it]                                                     {'loss': 0.7727, 'grad_norm': 1.31710684299469, 'learning_rate': 2.030395451399214e-09, 'epoch': 0.99}
 99%|█████████▉| 2871/2906 [9:27:31<06:37, 11.37s/it] 99%|█████████▉| 2872/2906 [9:27:43<06:30, 11.49s/it]                                                     {'loss': 0.74, 'grad_norm': 1.2066534757614136, 'learning_rate': 1.9191766012338633e-09, 'epoch': 0.99}
 99%|█████████▉| 2872/2906 [9:27:43<06:30, 11.49s/it] 99%|█████████▉| 2873/2906 [9:27:55<06:21, 11.56s/it]                                                     {'loss': 0.8495, 'grad_norm': 1.2946317195892334, 'learning_rate': 1.8110890955849724e-09, 'epoch': 0.99}
 99%|█████████▉| 2873/2906 [9:27:55<06:21, 11.56s/it] 99%|█████████▉| 2874/2906 [9:28:07<06:10, 11.58s/it]                                                     {'loss': 0.725, 'grad_norm': 1.2496193647384644, 'learning_rate': 1.7061330699402745e-09, 'epoch': 0.99}
 99%|█████████▉| 2874/2906 [9:28:07<06:10, 11.58s/it] 99%|█████████▉| 2875/2906 [9:28:18<05:57, 11.54s/it]                                                     {'loss': 0.8063, 'grad_norm': 1.2858778238296509, 'learning_rate': 1.6043086558623078e-09, 'epoch': 0.99}
 99%|█████████▉| 2875/2906 [9:28:18<05:57, 11.54s/it] 99%|█████████▉| 2876/2906 [9:28:30<05:46, 11.54s/it]                                                     {'loss': 0.7788, 'grad_norm': 1.3374532461166382, 'learning_rate': 1.5056159809878624e-09, 'epoch': 0.99}
 99%|█████████▉| 2876/2906 [9:28:30<05:46, 11.54s/it] 99%|█████████▉| 2877/2906 [9:28:41<05:37, 11.64s/it]                                                     {'loss': 0.7631, 'grad_norm': 1.3161602020263672, 'learning_rate': 1.4100551690279796e-09, 'epoch': 0.99}
 99%|█████████▉| 2877/2906 [9:28:41<05:37, 11.64s/it] 99%|█████████▉| 2878/2906 [9:28:53<05:22, 11.52s/it]                                                     {'loss': 0.8158, 'grad_norm': 1.3823074102401733, 'learning_rate': 1.3176263397685075e-09, 'epoch': 0.99}
 99%|█████████▉| 2878/2906 [9:28:53<05:22, 11.52s/it] 99%|█████████▉| 2879/2906 [9:29:04<05:12, 11.59s/it]                                                     {'loss': 0.8383, 'grad_norm': 1.3057425022125244, 'learning_rate': 1.2283296090687125e-09, 'epoch': 0.99}
 99%|█████████▉| 2879/2906 [9:29:04<05:12, 11.59s/it] 99%|█████████▉| 2880/2906 [9:29:16<05:02, 11.63s/it]                                                     {'loss': 0.807, 'grad_norm': 1.37086820602417, 'learning_rate': 1.1421650888621128e-09, 'epoch': 0.99}
 99%|█████████▉| 2880/2906 [9:29:16<05:02, 11.63s/it] 99%|█████████▉| 2881/2906 [9:29:28<04:52, 11.69s/it]                                                     {'loss': 0.8312, 'grad_norm': 1.3049579858779907, 'learning_rate': 1.0591328871562e-09, 'epoch': 0.99}
 99%|█████████▉| 2881/2906 [9:29:28<04:52, 11.69s/it] 99%|█████████▉| 2882/2906 [9:29:40<04:40, 11.69s/it]                                                     {'loss': 0.7364, 'grad_norm': 1.2642364501953125, 'learning_rate': 9.792331080316074e-10, 'epoch': 0.99}
 99%|█████████▉| 2882/2906 [9:29:40<04:40, 11.69s/it] 99%|█████████▉| 2883/2906 [9:29:51<04:28, 11.70s/it]                                                     {'loss': 0.8631, 'grad_norm': 1.304897665977478, 'learning_rate': 9.024658516426643e-10, 'epoch': 0.99}
 99%|█████████▉| 2883/2906 [9:29:51<04:28, 11.70s/it] 99%|█████████▉| 2884/2906 [9:30:03<04:16, 11.64s/it]                                                     {'loss': 0.7329, 'grad_norm': 1.2706419229507446, 'learning_rate': 8.28831214217396e-10, 'epoch': 0.99}
 99%|█████████▉| 2884/2906 [9:30:03<04:16, 11.64s/it] 99%|█████████▉| 2885/2906 [9:30:15<04:06, 11.73s/it]                                                     {'loss': 0.7467, 'grad_norm': 1.2964118719100952, 'learning_rate': 7.583292880564142e-10, 'epoch': 0.99}
 99%|█████████▉| 2885/2906 [9:30:15<04:06, 11.73s/it] 99%|█████████▉| 2886/2906 [9:30:27<03:55, 11.76s/it]                                                     {'loss': 0.838, 'grad_norm': 1.4171831607818604, 'learning_rate': 6.909601615343042e-10, 'epoch': 0.99}
 99%|█████████▉| 2886/2906 [9:30:27<03:55, 11.76s/it] 99%|█████████▉| 2887/2906 [9:30:38<03:41, 11.64s/it]                                                     {'loss': 0.8626, 'grad_norm': 1.3778862953186035, 'learning_rate': 6.267239190979601e-10, 'epoch': 0.99}
 99%|█████████▉| 2887/2906 [9:30:38<03:41, 11.64s/it] 99%|█████████▉| 2888/2906 [9:30:50<03:30, 11.69s/it]                                                     {'loss': 0.7824, 'grad_norm': 1.2308915853500366, 'learning_rate': 5.656206412676945e-10, 'epoch': 0.99}
 99%|█████████▉| 2888/2906 [9:30:50<03:30, 11.69s/it] 99%|█████████▉| 2889/2906 [9:31:02<03:19, 11.74s/it]                                                     {'loss': 0.836, 'grad_norm': 1.344781517982483, 'learning_rate': 5.076504046364061e-10, 'epoch': 0.99}
 99%|█████████▉| 2889/2906 [9:31:02<03:19, 11.74s/it] 99%|█████████▉| 2890/2906 [9:31:13<03:07, 11.71s/it]                                                     {'loss': 0.8299, 'grad_norm': 1.4435378313064575, 'learning_rate': 4.5281328186985717e-10, 'epoch': 0.99}
 99%|█████████▉| 2890/2906 [9:31:13<03:07, 11.71s/it] 99%|█████████▉| 2891/2906 [9:31:25<02:54, 11.60s/it]                                                     {'loss': 0.8211, 'grad_norm': 1.2944523096084595, 'learning_rate': 4.0110934170639603e-10, 'epoch': 0.99}
 99%|█████████▉| 2891/2906 [9:31:25<02:54, 11.60s/it]100%|█████████▉| 2892/2906 [9:31:37<02:44, 11.74s/it]                                                     {'loss': 0.7325, 'grad_norm': 1.2596020698547363, 'learning_rate': 3.5253864895667956e-10, 'epoch': 1.0}
100%|█████████▉| 2892/2906 [9:31:37<02:44, 11.74s/it]100%|█████████▉| 2893/2906 [9:31:49<02:32, 11.75s/it]                                                     {'loss': 0.7884, 'grad_norm': 1.424458622932434, 'learning_rate': 3.0710126450450574e-10, 'epoch': 1.0}
100%|█████████▉| 2893/2906 [9:31:49<02:32, 11.75s/it]100%|█████████▉| 2894/2906 [9:32:00<02:19, 11.62s/it]                                                     {'loss': 0.7527, 'grad_norm': 1.3110214471817017, 'learning_rate': 2.6479724530514836e-10, 'epoch': 1.0}
100%|█████████▉| 2894/2906 [9:32:00<02:19, 11.62s/it]100%|█████████▉| 2895/2906 [9:32:11<02:07, 11.59s/it]                                                     {'loss': 0.8057, 'grad_norm': 1.3487884998321533, 'learning_rate': 2.2562664438730008e-10, 'epoch': 1.0}
100%|█████████▉| 2895/2906 [9:32:11<02:07, 11.59s/it]100%|█████████▉| 2896/2906 [9:32:23<01:56, 11.64s/it]                                                     {'loss': 0.8128, 'grad_norm': 1.2287017107009888, 'learning_rate': 1.8958951085057408e-10, 'epoch': 1.0}
100%|█████████▉| 2896/2906 [9:32:23<01:56, 11.64s/it]100%|█████████▉| 2897/2906 [9:32:35<01:45, 11.75s/it]                                                     {'loss': 0.7743, 'grad_norm': 1.3048092126846313, 'learning_rate': 1.5668588986800237e-10, 'epoch': 1.0}
100%|█████████▉| 2897/2906 [9:32:35<01:45, 11.75s/it]100%|█████████▉| 2898/2906 [9:32:47<01:33, 11.70s/it]                                                     {'loss': 0.7916, 'grad_norm': 1.3283426761627197, 'learning_rate': 1.269158226843703e-10, 'epoch': 1.0}
100%|█████████▉| 2898/2906 [9:32:47<01:33, 11.70s/it]100%|█████████▉| 2899/2906 [9:32:58<01:20, 11.56s/it]                                                     {'loss': 0.8203, 'grad_norm': 1.3505560159683228, 'learning_rate': 1.0027934661593908e-10, 'epoch': 1.0}
100%|█████████▉| 2899/2906 [9:32:58<01:20, 11.56s/it]100%|█████████▉| 2900/2906 [9:33:09<01:08, 11.38s/it]                                                     {'loss': 0.78, 'grad_norm': 1.3923689126968384, 'learning_rate': 7.677649505211104e-11, 'epoch': 1.0}
100%|█████████▉| 2900/2906 [9:33:09<01:08, 11.38s/it]100%|█████████▉| 2901/2906 [9:33:21<00:57, 11.57s/it]                                                     {'loss': 0.733, 'grad_norm': 1.224732518196106, 'learning_rate': 5.640729745348683e-11, 'epoch': 1.0}
100%|█████████▉| 2901/2906 [9:33:21<00:57, 11.57s/it]100%|█████████▉| 2902/2906 [9:33:33<00:46, 11.68s/it]                                                     {'loss': 0.8909, 'grad_norm': 1.461137294769287, 'learning_rate': 3.9171779352698005e-11, 'epoch': 1.0}
100%|█████████▉| 2902/2906 [9:33:33<00:46, 11.68s/it]100%|█████████▉| 2903/2906 [9:33:45<00:35, 11.83s/it]                                                     {'loss': 0.7755, 'grad_norm': 1.3092379570007324, 'learning_rate': 2.5069962354684618e-11, 'epoch': 1.0}
100%|█████████▉| 2903/2906 [9:33:45<00:35, 11.83s/it]100%|█████████▉| 2904/2906 [9:33:57<00:24, 12.01s/it]                                                     {'loss': 0.7482, 'grad_norm': 1.288245677947998, 'learning_rate': 1.4101864135862564e-11, 'epoch': 1.0}
100%|█████████▉| 2904/2906 [9:33:57<00:24, 12.01s/it]100%|█████████▉| 2905/2906 [9:34:09<00:11, 11.77s/it]                                                     {'loss': 0.7412, 'grad_norm': 1.2981606721878052, 'learning_rate': 6.267498444956222e-12, 'epoch': 1.0}
100%|█████████▉| 2905/2906 [9:34:09<00:11, 11.77s/it]100%|██████████| 2906/2906 [9:34:20<00:00, 11.75s/it]                                                     {'loss': 0.7229, 'grad_norm': 1.3603668212890625, 'learning_rate': 1.566875102165799e-12, 'epoch': 1.0}
100%|██████████| 2906/2906 [9:34:20<00:00, 11.75s/it][INFO|trainer.py:3984] 2025-08-21 21:56:48,894 >> Saving model checkpoint to /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906
[INFO|configuration_utils.py:419] 2025-08-21 21:56:48,899 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/config.json
[INFO|configuration_utils.py:911] 2025-08-21 21:56:48,900 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/generation_config.json
[INFO|modeling_utils.py:3580] 2025-08-21 21:57:16,075 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-08-21 21:57:16,076 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 21:57:16,076 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/special_tokens_map.json
[2025-08-21 21:57:16,660] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step2906 is about to be saved!
[2025-08-21 21:57:16,773] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/global_step2906/mp_rank_00_model_states.pt
[2025-08-21 21:57:16,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/global_step2906/mp_rank_00_model_states.pt...
[2025-08-21 21:57:48,227] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/global_step2906/mp_rank_00_model_states.pt.
[2025-08-21 21:57:48,312] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/global_step2906/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-21 21:58:44,545] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/global_step2906/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-21 21:58:44,546] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/global_step2906/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-21 21:58:44,546] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2906 is ready now!
[INFO|image_processing_base.py:260] 2025-08-21 21:58:45,568 >> Image processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/preprocessor_config.json
[INFO|tokenization_utils_base.py:2510] 2025-08-21 21:58:45,568 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 21:58:45,568 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/special_tokens_map.json
[INFO|processing_utils.py:648] 2025-08-21 21:58:45,691 >> chat template saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/chat_template.json
[INFO|processing_utils.py:654] 2025-08-21 21:58:45,783 >> processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/checkpoint-2906/processor_config.json
[INFO|trainer.py:2681] 2025-08-21 21:58:45,784 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 34585.2393, 'train_samples_per_second': 5.378, 'train_steps_per_second': 0.084, 'train_loss': 0.8056183757243777, 'epoch': 1.0}
100%|██████████| 2906/2906 [9:36:25<00:00, 11.75s/it]100%|██████████| 2906/2906 [9:36:25<00:00, 11.90s/it]
[INFO|image_processing_base.py:260] 2025-08-21 21:58:45,787 >> Image processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/preprocessor_config.json
[INFO|tokenization_utils_base.py:2510] 2025-08-21 21:58:45,787 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 21:58:45,788 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/special_tokens_map.json
[INFO|processing_utils.py:648] 2025-08-21 21:58:45,921 >> chat template saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/chat_template.json
[INFO|processing_utils.py:654] 2025-08-21 21:58:46,025 >> processor saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/processor_config.json
[INFO|trainer.py:3984] 2025-08-21 21:58:54,450 >> Saving model checkpoint to /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct
[INFO|configuration_utils.py:419] 2025-08-21 21:58:54,456 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/config.json
[INFO|configuration_utils.py:911] 2025-08-21 21:58:54,457 >> Configuration saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/generation_config.json
[INFO|modeling_utils.py:3580] 2025-08-21 21:59:25,648 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-08-21 21:59:25,649 >> tokenizer config file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-08-21 21:59:25,649 >> Special tokens file saved in /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/special_tokens_map.json
***** train metrics *****
  epoch                    =           1.0
  total_flos               = 17650626611GF
  train_loss               =        0.8056
  train_runtime            =    9:36:25.23
  train_samples_per_second =         5.378
  train_steps_per_second   =         0.084
Figure saved at: /opt/models/llava-hf/llava-hf/llava-v1.6-vicuna-7b-hf-instruct/training_loss.png
[WARNING|2025-08-21 21:59:26] llamafactory.extras.ploting:148 >> No metric eval_loss to plot.
[WARNING|2025-08-21 21:59:26] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.
[INFO|modelcard.py:450] 2025-08-21 21:59:26,595 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
